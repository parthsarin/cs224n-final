{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d554cc2-8bb3-4fd6-8f7f-932301f8673a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca55cebc-aaeb-4ec1-8dbf-7345bfbd2d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Novelty</th>\n",
       "      <th>Simplicity</th>\n",
       "      <th>Generalization</th>\n",
       "      <th>Flexibility/Extensibility</th>\n",
       "      <th>Robustness</th>\n",
       "      <th>Realistic output</th>\n",
       "      <th>Formal description/analysis</th>\n",
       "      <th>Theoretical guarantees</th>\n",
       "      <th>Approximation</th>\n",
       "      <th>...</th>\n",
       "      <th>Respect for Persons</th>\n",
       "      <th>Autonomy (power to decide)</th>\n",
       "      <th>Explicability</th>\n",
       "      <th>Respect for Law and public interest</th>\n",
       "      <th>Security</th>\n",
       "      <th>Easy to work with</th>\n",
       "      <th>Realistic world model</th>\n",
       "      <th>Fast</th>\n",
       "      <th>URL</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3D Object Recognition with Deep Belief Nets</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>http://papers.nips.cc/paper/3872-3d-object-rec...</td>\n",
       "      <td>3D Object Recognition with Deep Belief Nets\\n\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A Convergence Theory for Deep Learning via Ove...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://arxiv.org/pdf/1811.03962v3.pdf</td>\n",
       "      <td>A Convergence Theory for Deep Learning\\nvia Ov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A dual coordinate descent method for large-sca...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>http://icml2008.cs.helsinki.fi/papers/166.pdf</td>\n",
       "      <td>A Dual Coordinate Descent Method for Large-sca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A unified architecture for natural language pr...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>http://icml2008.cs.helsinki.fi/papers/391.pdf</td>\n",
       "      <td>A Unified Architecture for Natural Language Pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Addressing Function Approximation Error in Act...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://arxiv.org/pdf/1802.09477</td>\n",
       "      <td>Addressing Function Approximation Error in Act...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>ViLBERT: Pretraining Task-Agnostic Visiolingui...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>http://papers.nips.cc/paper/8297-vilbert-pretr...</td>\n",
       "      <td>ViLBERT: Pretraining Task-Agnostic Visiolingui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Video-to-Video Synthesis</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>http://papers.nips.cc/paper/7391-video-to-vide...</td>\n",
       "      <td>Video-to-Video Synthesis\\n\\nTing-Chun Wang1 , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Which Training Methods for GANs do actually Co...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>http://www.nowozin.net/sebastian/papers/mesche...</td>\n",
       "      <td>Which Training Methods for GANs do actually Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Wide Neural Networks of Any Depth Evolve as Li...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>http://papers.nips.cc/paper/9063-wide-neural-n...</td>\n",
       "      <td>Wide Neural Networks of Any Depth Evolve as\\nL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>XLNet: Generalized Autoregressive Pretraining ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>http://papers.nips.cc/paper/8812-xlnet-general...</td>\n",
       "      <td>XLNet: Generalized Autoregressive Pretraining\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title  Novelty  Simplicity  \\\n",
       "0         3D Object Recognition with Deep Belief Nets        1           0   \n",
       "1   A Convergence Theory for Deep Learning via Ove...        0           1   \n",
       "2   A dual coordinate descent method for large-sca...        0           1   \n",
       "3   A unified architecture for natural language pr...        1           0   \n",
       "4   Addressing Function Approximation Error in Act...        1           0   \n",
       "..                                                ...      ...         ...   \n",
       "92  ViLBERT: Pretraining Task-Agnostic Visiolingui...        1           0   \n",
       "93                           Video-to-Video Synthesis        1           0   \n",
       "94  Which Training Methods for GANs do actually Co...        1           1   \n",
       "95  Wide Neural Networks of Any Depth Evolve as Li...        0           1   \n",
       "96  XLNet: Generalized Autoregressive Pretraining ...        1           0   \n",
       "\n",
       "    Generalization  Flexibility/Extensibility  Robustness  Realistic output  \\\n",
       "0                1                          0           0                 0   \n",
       "1                1                          1           0                 0   \n",
       "2                0                          0           0                 0   \n",
       "3                1                          0           0                 0   \n",
       "4                1                          0           0                 0   \n",
       "..             ...                        ...         ...               ...   \n",
       "92               1                          1           0                 0   \n",
       "93               1                          1           0                 1   \n",
       "94               0                          0           0                 0   \n",
       "95               1                          0           0                 0   \n",
       "96               1                          1           0                 0   \n",
       "\n",
       "    Formal description/analysis  Theoretical guarantees  Approximation  ...  \\\n",
       "0                             0                       0              0  ...   \n",
       "1                             1                       1              0  ...   \n",
       "2                             1                       1              0  ...   \n",
       "3                             0                       0              0  ...   \n",
       "4                             0                       0              0  ...   \n",
       "..                          ...                     ...            ...  ...   \n",
       "92                            0                       0              0  ...   \n",
       "93                            0                       0              0  ...   \n",
       "94                            1                       1              0  ...   \n",
       "95                            1                       1              1  ...   \n",
       "96                            0                       0              0  ...   \n",
       "\n",
       "    Respect for Persons  Autonomy (power to decide)  Explicability  \\\n",
       "0                     0                           0              0   \n",
       "1                     0                           0              0   \n",
       "2                     0                           0              0   \n",
       "3                     0                           0              0   \n",
       "4                     0                           0              0   \n",
       "..                  ...                         ...            ...   \n",
       "92                    0                           0              0   \n",
       "93                    0                           0              0   \n",
       "94                    0                           0              0   \n",
       "95                    0                           0              0   \n",
       "96                    0                           0              0   \n",
       "\n",
       "    Respect for Law and public interest  Security  Easy to work with  \\\n",
       "0                                     0         0                  0   \n",
       "1                                     0         0                  0   \n",
       "2                                     0         0                  0   \n",
       "3                                     0         0                  0   \n",
       "4                                     0         0                  0   \n",
       "..                                  ...       ...                ...   \n",
       "92                                    0         0                  0   \n",
       "93                                    0         0                  0   \n",
       "94                                    0         0                  0   \n",
       "95                                    0         0                  0   \n",
       "96                                    0         0                  0   \n",
       "\n",
       "    Realistic world model  Fast  \\\n",
       "0                       0     0   \n",
       "1                       0     0   \n",
       "2                       0     0   \n",
       "3                       0     0   \n",
       "4                       0     0   \n",
       "..                    ...   ...   \n",
       "92                      0     0   \n",
       "93                      0     0   \n",
       "94                      0     0   \n",
       "95                      0     0   \n",
       "96                      0     0   \n",
       "\n",
       "                                                  URL  \\\n",
       "0   http://papers.nips.cc/paper/3872-3d-object-rec...   \n",
       "1              https://arxiv.org/pdf/1811.03962v3.pdf   \n",
       "2       http://icml2008.cs.helsinki.fi/papers/166.pdf   \n",
       "3       http://icml2008.cs.helsinki.fi/papers/391.pdf   \n",
       "4                    https://arxiv.org/pdf/1802.09477   \n",
       "..                                                ...   \n",
       "92  http://papers.nips.cc/paper/8297-vilbert-pretr...   \n",
       "93  http://papers.nips.cc/paper/7391-video-to-vide...   \n",
       "94  http://www.nowozin.net/sebastian/papers/mesche...   \n",
       "95  http://papers.nips.cc/paper/9063-wide-neural-n...   \n",
       "96  http://papers.nips.cc/paper/8812-xlnet-general...   \n",
       "\n",
       "                                                 Text  \n",
       "0   3D Object Recognition with Deep Belief Nets\\n\\...  \n",
       "1   A Convergence Theory for Deep Learning\\nvia Ov...  \n",
       "2   A Dual Coordinate Descent Method for Large-sca...  \n",
       "3   A Unified Architecture for Natural Language Pr...  \n",
       "4   Addressing Function Approximation Error in Act...  \n",
       "..                                                ...  \n",
       "92  ViLBERT: Pretraining Task-Agnostic Visiolingui...  \n",
       "93  Video-to-Video Synthesis\\n\\nTing-Chun Wang1 , ...  \n",
       "94  Which Training Methods for GANs do actually Co...  \n",
       "95  Wide Neural Networks of Any Depth Evolve as\\nL...  \n",
       "96  XLNet: Generalized Autoregressive Pretraining\\...  \n",
       "\n",
       "[97 rows x 77 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('values_ml_papers.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9aa225fe-a7b7-4681-91ef-151e2d86dc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = [f'Does this paper convey the value of {val.lower()}? Answer \"yes\" or \"no.\"' for val in df.loc[:, 'Novelty': 'Fast'].columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f34c4ffb-3124-4792-ad0b-e75ca1a8ebdc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prompts = []\n",
    "for t in df.Text:\n",
    "    for v in values:\n",
    "        prompts.append(f'I have the following research paper:\\n{t}\\n\\n{v}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02de5e03-5d2e-4163-8b26-bb6d8aafe96b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3D Object Recognition with Deep Belief Nets</td>\n",
       "      <td>I have the following research paper:\\n3D Objec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3D Object Recognition with Deep Belief Nets</td>\n",
       "      <td>I have the following research paper:\\n3D Objec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3D Object Recognition with Deep Belief Nets</td>\n",
       "      <td>I have the following research paper:\\n3D Objec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3D Object Recognition with Deep Belief Nets</td>\n",
       "      <td>I have the following research paper:\\n3D Objec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3D Object Recognition with Deep Belief Nets</td>\n",
       "      <td>I have the following research paper:\\n3D Objec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>XLNet: Generalized Autoregressive Pretraining ...</td>\n",
       "      <td>I have the following research paper:\\nXLNet: G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>XLNet: Generalized Autoregressive Pretraining ...</td>\n",
       "      <td>I have the following research paper:\\nXLNet: G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>XLNet: Generalized Autoregressive Pretraining ...</td>\n",
       "      <td>I have the following research paper:\\nXLNet: G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>XLNet: Generalized Autoregressive Pretraining ...</td>\n",
       "      <td>I have the following research paper:\\nXLNet: G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>XLNet: Generalized Autoregressive Pretraining ...</td>\n",
       "      <td>I have the following research paper:\\nXLNet: G...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7178 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title  \\\n",
       "0         3D Object Recognition with Deep Belief Nets   \n",
       "0         3D Object Recognition with Deep Belief Nets   \n",
       "0         3D Object Recognition with Deep Belief Nets   \n",
       "0         3D Object Recognition with Deep Belief Nets   \n",
       "0         3D Object Recognition with Deep Belief Nets   \n",
       "..                                                ...   \n",
       "96  XLNet: Generalized Autoregressive Pretraining ...   \n",
       "96  XLNet: Generalized Autoregressive Pretraining ...   \n",
       "96  XLNet: Generalized Autoregressive Pretraining ...   \n",
       "96  XLNet: Generalized Autoregressive Pretraining ...   \n",
       "96  XLNet: Generalized Autoregressive Pretraining ...   \n",
       "\n",
       "                                               Prompt  \n",
       "0   I have the following research paper:\\n3D Objec...  \n",
       "0   I have the following research paper:\\n3D Objec...  \n",
       "0   I have the following research paper:\\n3D Objec...  \n",
       "0   I have the following research paper:\\n3D Objec...  \n",
       "0   I have the following research paper:\\n3D Objec...  \n",
       "..                                                ...  \n",
       "96  I have the following research paper:\\nXLNet: G...  \n",
       "96  I have the following research paper:\\nXLNet: G...  \n",
       "96  I have the following research paper:\\nXLNet: G...  \n",
       "96  I have the following research paper:\\nXLNet: G...  \n",
       "96  I have the following research paper:\\nXLNet: G...  \n",
       "\n",
       "[7178 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = pd.DataFrame({'Title': df.Title.apply(lambda x: [x] * len(values)).explode(), 'Prompt': prompts})\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0228464-3d07-4a45-955a-bd484b35b8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv('values_ml_classification_prompts.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
