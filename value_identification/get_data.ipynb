{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "366d0fe5-147f-4805-8ad1-85115a148a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from subprocess import Popen, PIPE\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e4cd237-58b8-47f9-abf9-b4effc4cfab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('annotations.tsv', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38a485a4-a2ff-4c86-be72-3dad6c304119",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_start = df.columns.tolist().index('Value Totals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3649fee5-1cdf-4767-b0fa-73a4c5034c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [c.strip() for c in df.columns[:val_start]] + df.iloc[1, val_start:].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8d35a3e-42b5-4021-81d0-a2348bbc8cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['Title'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbc8f920-dec7-4029-a25d-098c7fb38c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_rows = df[['Title']].merge(df.iloc[:, list(range(val_start, df.shape[1]))].dropna().astype(int), right_index=True, left_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98847f59-69a9-4ee6-ac2e-f9aa095d3df7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Novelty</th>\n",
       "      <th>Simplicity</th>\n",
       "      <th>Generalization</th>\n",
       "      <th>Flexibility/Extensibility</th>\n",
       "      <th>Robustness</th>\n",
       "      <th>Realistic output</th>\n",
       "      <th>Formal description/analysis</th>\n",
       "      <th>Theoretical guarantees</th>\n",
       "      <th>Approximation</th>\n",
       "      <th>Quantitative evidence (e.g. experiments)</th>\n",
       "      <th>...</th>\n",
       "      <th>Non-maleficence</th>\n",
       "      <th>Justice</th>\n",
       "      <th>Respect for Persons</th>\n",
       "      <th>Autonomy (power to decide)</th>\n",
       "      <th>Explicability</th>\n",
       "      <th>Respect for Law and public interest</th>\n",
       "      <th>Security</th>\n",
       "      <th>Easy to work with</th>\n",
       "      <th>Realistic world model</th>\n",
       "      <th>Fast</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3D Object Recognition with Deep Belief Nets</th>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A Convergence Theory for Deep Learning via Over-Parameterization</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A dual coordinate descent method for large-scale linear SVM</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A unified architecture for natural language processing:deep neural networks with multitask learning</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Addressing Function Approximation Error in Actor-Critic Methods</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Video-to-Video Synthesis</th>\n",
       "      <td>3.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Which Training Methods for GANs do actually Converge?</th>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wide Neural Networks of Any Depth Evolve as Linear Models Under Gradient Descent</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XLNet: Generalized Autoregressive Pretraining for Language Understanding</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97 rows × 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Novelty  Simplicity  \\\n",
       "Title                                                                     \n",
       "3D Object Recognition with Deep Belief Nets             1.5         0.0   \n",
       "A Convergence Theory for Deep Learning via Over...      0.0         4.0   \n",
       "A dual coordinate descent method for large-scal...      1.0         4.0   \n",
       "A unified architecture for natural language pro...      2.0         0.0   \n",
       "Addressing Function Approximation Error in Acto...      5.0         0.0   \n",
       "...                                                     ...         ...   \n",
       "ViLBERT: Pretraining Task-Agnostic Visiolinguis...      2.0         0.0   \n",
       "Video-to-Video Synthesis                                3.5         0.0   \n",
       "Which Training Methods for GANs do actually Con...      2.0         6.0   \n",
       "Wide Neural Networks of Any Depth Evolve as Lin...      1.0         4.5   \n",
       "XLNet: Generalized Autoregressive Pretraining f...      2.0         0.0   \n",
       "\n",
       "                                                    Generalization  \\\n",
       "Title                                                                \n",
       "3D Object Recognition with Deep Belief Nets                    1.5   \n",
       "A Convergence Theory for Deep Learning via Over...            10.0   \n",
       "A dual coordinate descent method for large-scal...             0.0   \n",
       "A unified architecture for natural language pro...             6.0   \n",
       "Addressing Function Approximation Error in Acto...             3.0   \n",
       "...                                                            ...   \n",
       "ViLBERT: Pretraining Task-Agnostic Visiolinguis...             5.0   \n",
       "Video-to-Video Synthesis                                       2.5   \n",
       "Which Training Methods for GANs do actually Con...             0.5   \n",
       "Wide Neural Networks of Any Depth Evolve as Lin...             7.5   \n",
       "XLNet: Generalized Autoregressive Pretraining f...             4.5   \n",
       "\n",
       "                                                    Flexibility/Extensibility  \\\n",
       "Title                                                                           \n",
       "3D Object Recognition with Deep Belief Nets                               0.5   \n",
       "A Convergence Theory for Deep Learning via Over...                        6.0   \n",
       "A dual coordinate descent method for large-scal...                        1.0   \n",
       "A unified architecture for natural language pro...                        0.0   \n",
       "Addressing Function Approximation Error in Acto...                        1.0   \n",
       "...                                                                       ...   \n",
       "ViLBERT: Pretraining Task-Agnostic Visiolinguis...                        4.0   \n",
       "Video-to-Video Synthesis                                                  2.5   \n",
       "Which Training Methods for GANs do actually Con...                        0.0   \n",
       "Wide Neural Networks of Any Depth Evolve as Lin...                        1.0   \n",
       "XLNet: Generalized Autoregressive Pretraining f...                        2.5   \n",
       "\n",
       "                                                    Robustness  \\\n",
       "Title                                                            \n",
       "3D Object Recognition with Deep Belief Nets                0.0   \n",
       "A Convergence Theory for Deep Learning via Over...         0.0   \n",
       "A dual coordinate descent method for large-scal...         0.0   \n",
       "A unified architecture for natural language pro...         0.0   \n",
       "Addressing Function Approximation Error in Acto...         0.0   \n",
       "...                                                        ...   \n",
       "ViLBERT: Pretraining Task-Agnostic Visiolinguis...         0.0   \n",
       "Video-to-Video Synthesis                                   0.5   \n",
       "Which Training Methods for GANs do actually Con...         0.5   \n",
       "Wide Neural Networks of Any Depth Evolve as Lin...         1.0   \n",
       "XLNet: Generalized Autoregressive Pretraining f...         0.0   \n",
       "\n",
       "                                                    Realistic output  \\\n",
       "Title                                                                  \n",
       "3D Object Recognition with Deep Belief Nets                      0.0   \n",
       "A Convergence Theory for Deep Learning via Over...               0.0   \n",
       "A dual coordinate descent method for large-scal...               0.0   \n",
       "A unified architecture for natural language pro...               0.0   \n",
       "Addressing Function Approximation Error in Acto...               0.0   \n",
       "...                                                              ...   \n",
       "ViLBERT: Pretraining Task-Agnostic Visiolinguis...               0.0   \n",
       "Video-to-Video Synthesis                                        10.0   \n",
       "Which Training Methods for GANs do actually Con...               1.0   \n",
       "Wide Neural Networks of Any Depth Evolve as Lin...               0.0   \n",
       "XLNet: Generalized Autoregressive Pretraining f...               0.0   \n",
       "\n",
       "                                                    Formal description/analysis  \\\n",
       "Title                                                                             \n",
       "3D Object Recognition with Deep Belief Nets                                 0.0   \n",
       "A Convergence Theory for Deep Learning via Over...                          8.0   \n",
       "A dual coordinate descent method for large-scal...                          2.0   \n",
       "A unified architecture for natural language pro...                          0.0   \n",
       "Addressing Function Approximation Error in Acto...                          0.0   \n",
       "...                                                                         ...   \n",
       "ViLBERT: Pretraining Task-Agnostic Visiolinguis...                          0.0   \n",
       "Video-to-Video Synthesis                                                    0.5   \n",
       "Which Training Methods for GANs do actually Con...                          4.0   \n",
       "Wide Neural Networks of Any Depth Evolve as Lin...                         17.5   \n",
       "XLNet: Generalized Autoregressive Pretraining f...                          0.5   \n",
       "\n",
       "                                                    Theoretical guarantees  \\\n",
       "Title                                                                        \n",
       "3D Object Recognition with Deep Belief Nets                            0.0   \n",
       "A Convergence Theory for Deep Learning via Over...                    11.0   \n",
       "A dual coordinate descent method for large-scal...                     2.0   \n",
       "A unified architecture for natural language pro...                     0.0   \n",
       "Addressing Function Approximation Error in Acto...                     0.0   \n",
       "...                                                                    ...   \n",
       "ViLBERT: Pretraining Task-Agnostic Visiolinguis...                     0.0   \n",
       "Video-to-Video Synthesis                                               0.0   \n",
       "Which Training Methods for GANs do actually Con...                     8.0   \n",
       "Wide Neural Networks of Any Depth Evolve as Lin...                     3.0   \n",
       "XLNet: Generalized Autoregressive Pretraining f...                     0.0   \n",
       "\n",
       "                                                    Approximation  \\\n",
       "Title                                                               \n",
       "3D Object Recognition with Deep Belief Nets                   0.0   \n",
       "A Convergence Theory for Deep Learning via Over...            0.0   \n",
       "A dual coordinate descent method for large-scal...            0.0   \n",
       "A unified architecture for natural language pro...            0.0   \n",
       "Addressing Function Approximation Error in Acto...            1.0   \n",
       "...                                                           ...   \n",
       "ViLBERT: Pretraining Task-Agnostic Visiolinguis...            0.0   \n",
       "Video-to-Video Synthesis                                      0.5   \n",
       "Which Training Methods for GANs do actually Con...            0.0   \n",
       "Wide Neural Networks of Any Depth Evolve as Lin...            1.5   \n",
       "XLNet: Generalized Autoregressive Pretraining f...            0.5   \n",
       "\n",
       "                                                    Quantitative evidence (e.g. experiments)  \\\n",
       "Title                                                                                          \n",
       "3D Object Recognition with Deep Belief Nets                                              1.0   \n",
       "A Convergence Theory for Deep Learning via Over...                                       2.0   \n",
       "A dual coordinate descent method for large-scal...                                       4.0   \n",
       "A unified architecture for natural language pro...                                       1.0   \n",
       "Addressing Function Approximation Error in Acto...                                       2.0   \n",
       "...                                                                                      ...   \n",
       "ViLBERT: Pretraining Task-Agnostic Visiolinguis...                                       6.0   \n",
       "Video-to-Video Synthesis                                                                 3.0   \n",
       "Which Training Methods for GANs do actually Con...                                       1.0   \n",
       "Wide Neural Networks of Any Depth Evolve as Lin...                                       6.0   \n",
       "XLNet: Generalized Autoregressive Pretraining f...                                       0.5   \n",
       "\n",
       "                                                    ...  Non-maleficence  \\\n",
       "Title                                               ...                    \n",
       "3D Object Recognition with Deep Belief Nets         ...              0.0   \n",
       "A Convergence Theory for Deep Learning via Over...  ...              0.0   \n",
       "A dual coordinate descent method for large-scal...  ...              0.0   \n",
       "A unified architecture for natural language pro...  ...              0.0   \n",
       "Addressing Function Approximation Error in Acto...  ...              0.0   \n",
       "...                                                 ...              ...   \n",
       "ViLBERT: Pretraining Task-Agnostic Visiolinguis...  ...              0.0   \n",
       "Video-to-Video Synthesis                            ...              0.0   \n",
       "Which Training Methods for GANs do actually Con...  ...              0.0   \n",
       "Wide Neural Networks of Any Depth Evolve as Lin...  ...              0.0   \n",
       "XLNet: Generalized Autoregressive Pretraining f...  ...              0.0   \n",
       "\n",
       "                                                    Justice  \\\n",
       "Title                                                         \n",
       "3D Object Recognition with Deep Belief Nets             0.0   \n",
       "A Convergence Theory for Deep Learning via Over...      0.0   \n",
       "A dual coordinate descent method for large-scal...      0.0   \n",
       "A unified architecture for natural language pro...      0.0   \n",
       "Addressing Function Approximation Error in Acto...      0.0   \n",
       "...                                                     ...   \n",
       "ViLBERT: Pretraining Task-Agnostic Visiolinguis...      0.0   \n",
       "Video-to-Video Synthesis                                0.0   \n",
       "Which Training Methods for GANs do actually Con...      0.0   \n",
       "Wide Neural Networks of Any Depth Evolve as Lin...      0.0   \n",
       "XLNet: Generalized Autoregressive Pretraining f...      0.0   \n",
       "\n",
       "                                                    Respect for Persons  \\\n",
       "Title                                                                     \n",
       "3D Object Recognition with Deep Belief Nets                         0.0   \n",
       "A Convergence Theory for Deep Learning via Over...                  0.0   \n",
       "A dual coordinate descent method for large-scal...                  0.0   \n",
       "A unified architecture for natural language pro...                  0.0   \n",
       "Addressing Function Approximation Error in Acto...                  0.0   \n",
       "...                                                                 ...   \n",
       "ViLBERT: Pretraining Task-Agnostic Visiolinguis...                  0.0   \n",
       "Video-to-Video Synthesis                                            0.0   \n",
       "Which Training Methods for GANs do actually Con...                  0.0   \n",
       "Wide Neural Networks of Any Depth Evolve as Lin...                  0.0   \n",
       "XLNet: Generalized Autoregressive Pretraining f...                  0.0   \n",
       "\n",
       "                                                    Autonomy (power to decide)  \\\n",
       "Title                                                                            \n",
       "3D Object Recognition with Deep Belief Nets                                0.0   \n",
       "A Convergence Theory for Deep Learning via Over...                         0.0   \n",
       "A dual coordinate descent method for large-scal...                         0.0   \n",
       "A unified architecture for natural language pro...                         0.0   \n",
       "Addressing Function Approximation Error in Acto...                         0.0   \n",
       "...                                                                        ...   \n",
       "ViLBERT: Pretraining Task-Agnostic Visiolinguis...                         0.0   \n",
       "Video-to-Video Synthesis                                                   0.0   \n",
       "Which Training Methods for GANs do actually Con...                         0.0   \n",
       "Wide Neural Networks of Any Depth Evolve as Lin...                         0.0   \n",
       "XLNet: Generalized Autoregressive Pretraining f...                         0.0   \n",
       "\n",
       "                                                    Explicability  \\\n",
       "Title                                                               \n",
       "3D Object Recognition with Deep Belief Nets                   0.0   \n",
       "A Convergence Theory for Deep Learning via Over...            0.0   \n",
       "A dual coordinate descent method for large-scal...            0.0   \n",
       "A unified architecture for natural language pro...            0.0   \n",
       "Addressing Function Approximation Error in Acto...            0.0   \n",
       "...                                                           ...   \n",
       "ViLBERT: Pretraining Task-Agnostic Visiolinguis...            0.0   \n",
       "Video-to-Video Synthesis                                      0.0   \n",
       "Which Training Methods for GANs do actually Con...            0.0   \n",
       "Wide Neural Networks of Any Depth Evolve as Lin...            0.0   \n",
       "XLNet: Generalized Autoregressive Pretraining f...            0.0   \n",
       "\n",
       "                                                    Respect for Law and public interest  \\\n",
       "Title                                                                                     \n",
       "3D Object Recognition with Deep Belief Nets                                         0.0   \n",
       "A Convergence Theory for Deep Learning via Over...                                  0.0   \n",
       "A dual coordinate descent method for large-scal...                                  0.0   \n",
       "A unified architecture for natural language pro...                                  0.0   \n",
       "Addressing Function Approximation Error in Acto...                                  0.0   \n",
       "...                                                                                 ...   \n",
       "ViLBERT: Pretraining Task-Agnostic Visiolinguis...                                  0.0   \n",
       "Video-to-Video Synthesis                                                            0.0   \n",
       "Which Training Methods for GANs do actually Con...                                  0.0   \n",
       "Wide Neural Networks of Any Depth Evolve as Lin...                                  0.0   \n",
       "XLNet: Generalized Autoregressive Pretraining f...                                  0.0   \n",
       "\n",
       "                                                    Security  \\\n",
       "Title                                                          \n",
       "3D Object Recognition with Deep Belief Nets              0.0   \n",
       "A Convergence Theory for Deep Learning via Over...       0.0   \n",
       "A dual coordinate descent method for large-scal...       0.0   \n",
       "A unified architecture for natural language pro...       0.0   \n",
       "Addressing Function Approximation Error in Acto...       0.0   \n",
       "...                                                      ...   \n",
       "ViLBERT: Pretraining Task-Agnostic Visiolinguis...       0.0   \n",
       "Video-to-Video Synthesis                                 0.0   \n",
       "Which Training Methods for GANs do actually Con...       0.0   \n",
       "Wide Neural Networks of Any Depth Evolve as Lin...       0.0   \n",
       "XLNet: Generalized Autoregressive Pretraining f...       0.0   \n",
       "\n",
       "                                                    Easy to work with  \\\n",
       "Title                                                                   \n",
       "3D Object Recognition with Deep Belief Nets                       0.0   \n",
       "A Convergence Theory for Deep Learning via Over...                0.0   \n",
       "A dual coordinate descent method for large-scal...                0.0   \n",
       "A unified architecture for natural language pro...                0.0   \n",
       "Addressing Function Approximation Error in Acto...                0.0   \n",
       "...                                                               ...   \n",
       "ViLBERT: Pretraining Task-Agnostic Visiolinguis...                1.0   \n",
       "Video-to-Video Synthesis                                          1.0   \n",
       "Which Training Methods for GANs do actually Con...                0.0   \n",
       "Wide Neural Networks of Any Depth Evolve as Lin...                0.5   \n",
       "XLNet: Generalized Autoregressive Pretraining f...                0.5   \n",
       "\n",
       "                                                    Realistic world model  \\\n",
       "Title                                                                       \n",
       "3D Object Recognition with Deep Belief Nets                           0.0   \n",
       "A Convergence Theory for Deep Learning via Over...                    0.0   \n",
       "A dual coordinate descent method for large-scal...                    0.0   \n",
       "A unified architecture for natural language pro...                    0.0   \n",
       "Addressing Function Approximation Error in Acto...                    0.0   \n",
       "...                                                                   ...   \n",
       "ViLBERT: Pretraining Task-Agnostic Visiolinguis...                    0.0   \n",
       "Video-to-Video Synthesis                                              1.0   \n",
       "Which Training Methods for GANs do actually Con...                    1.0   \n",
       "Wide Neural Networks of Any Depth Evolve as Lin...                    0.0   \n",
       "XLNet: Generalized Autoregressive Pretraining f...                    0.0   \n",
       "\n",
       "                                                    Fast  \n",
       "Title                                                     \n",
       "3D Object Recognition with Deep Belief Nets          0.0  \n",
       "A Convergence Theory for Deep Learning via Over...   0.0  \n",
       "A dual coordinate descent method for large-scal...   0.0  \n",
       "A unified architecture for natural language pro...   1.0  \n",
       "Addressing Function Approximation Error in Acto...   0.0  \n",
       "...                                                  ...  \n",
       "ViLBERT: Pretraining Task-Agnostic Visiolinguis...   0.0  \n",
       "Video-to-Video Synthesis                             0.0  \n",
       "Which Training Methods for GANs do actually Con...   0.0  \n",
       "Wide Neural Networks of Any Depth Evolve as Lin...   0.0  \n",
       "XLNet: Generalized Autoregressive Pretraining f...   0.0  \n",
       "\n",
       "[97 rows x 74 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_rows.groupby('Title').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5f42fe3-2e8c-4211-adb0-8e830036cf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled = filter_rows.groupby('Title').apply(lambda s: (s > 0).all()).astype(int).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6147c5a5-205b-45a2-b971-732100ee0208",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = labeled.merge(df[['Title', 'URL']].drop_duplicates(), on='Title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3752f555-1857-462c-baa2-432d70a5a158",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_link(d):\n",
    "    if 'icml2009' in d:\n",
    "        last = d.split('/')[-1]\n",
    "        return 'https://icml.cc/Conferences/2009/papers/' + last\n",
    "    if 'pdf' not in d:\n",
    "        if 'arxiv' in d:\n",
    "            parts = d.split('/')\n",
    "            parts[-2] = 'pdf'\n",
    "            return '/'.join(parts)\n",
    "        elif 'html' in d:\n",
    "            return 'http://proceedings.mlr.press/v80/kim18b/kim18b.pdf'\n",
    "        else:\n",
    "            return d + '.pdf'\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "26883c59-41eb-4529-8a3a-5cb7bebd8a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.URL = data.URL.apply(pdf_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d2b2b7c-679a-4d49-afbc-f52839f2aa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_pdf(row):\n",
    "    url = row.URL\n",
    "    filename = 'papers/' + row.Title + '.pdf'\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "    except requests.exceptions.HTTPError as err:\n",
    "        print(f\"HTTP Error occurred: {err}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "79f7ced9-b5ec-4a60-8c13-85b94e656077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     None\n",
       "1     None\n",
       "2     None\n",
       "3     None\n",
       "4     None\n",
       "      ... \n",
       "92    None\n",
       "93    None\n",
       "94    None\n",
       "95    None\n",
       "96    None\n",
       "Length: 97, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.apply(download_pdf, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2af2c60e-c730-4844-a57e-89828c133d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Novelty</th>\n",
       "      <th>Simplicity</th>\n",
       "      <th>Generalization</th>\n",
       "      <th>Flexibility/Extensibility</th>\n",
       "      <th>Robustness</th>\n",
       "      <th>Realistic output</th>\n",
       "      <th>Formal description/analysis</th>\n",
       "      <th>Theoretical guarantees</th>\n",
       "      <th>Approximation</th>\n",
       "      <th>...</th>\n",
       "      <th>Justice</th>\n",
       "      <th>Respect for Persons</th>\n",
       "      <th>Autonomy (power to decide)</th>\n",
       "      <th>Explicability</th>\n",
       "      <th>Respect for Law and public interest</th>\n",
       "      <th>Security</th>\n",
       "      <th>Easy to work with</th>\n",
       "      <th>Realistic world model</th>\n",
       "      <th>Fast</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3D Object Recognition with Deep Belief Nets</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>http://papers.nips.cc/paper/3872-3d-object-rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A Convergence Theory for Deep Learning via Ove...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://arxiv.org/pdf/1811.03962v3.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A dual coordinate descent method for large-sca...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>http://icml2008.cs.helsinki.fi/papers/166.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A unified architecture for natural language pr...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>http://icml2008.cs.helsinki.fi/papers/391.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Addressing Function Approximation Error in Act...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://arxiv.org/pdf/1802.09477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>ViLBERT: Pretraining Task-Agnostic Visiolingui...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>http://papers.nips.cc/paper/8297-vilbert-pretr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Video-to-Video Synthesis</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>http://papers.nips.cc/paper/7391-video-to-vide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Which Training Methods for GANs do actually Co...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>http://www.nowozin.net/sebastian/papers/mesche...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Wide Neural Networks of Any Depth Evolve as Li...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>http://papers.nips.cc/paper/9063-wide-neural-n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>XLNet: Generalized Autoregressive Pretraining ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>http://papers.nips.cc/paper/8812-xlnet-general...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title  Novelty  Simplicity  \\\n",
       "0         3D Object Recognition with Deep Belief Nets        1           0   \n",
       "1   A Convergence Theory for Deep Learning via Ove...        0           1   \n",
       "2   A dual coordinate descent method for large-sca...        1           1   \n",
       "3   A unified architecture for natural language pr...        1           0   \n",
       "4   Addressing Function Approximation Error in Act...        1           0   \n",
       "..                                                ...      ...         ...   \n",
       "92  ViLBERT: Pretraining Task-Agnostic Visiolingui...        1           0   \n",
       "93                           Video-to-Video Synthesis        1           0   \n",
       "94  Which Training Methods for GANs do actually Co...        1           1   \n",
       "95  Wide Neural Networks of Any Depth Evolve as Li...        1           1   \n",
       "96  XLNet: Generalized Autoregressive Pretraining ...        1           0   \n",
       "\n",
       "    Generalization  Flexibility/Extensibility  Robustness  Realistic output  \\\n",
       "0                1                          0           0                 0   \n",
       "1                1                          1           0                 0   \n",
       "2                0                          1           0                 0   \n",
       "3                1                          0           0                 0   \n",
       "4                1                          1           0                 0   \n",
       "..             ...                        ...         ...               ...   \n",
       "92               1                          1           0                 0   \n",
       "93               0                          1           0                 1   \n",
       "94               0                          0           0                 0   \n",
       "95               1                          0           1                 0   \n",
       "96               1                          1           0                 0   \n",
       "\n",
       "    Formal description/analysis  Theoretical guarantees  Approximation  ...  \\\n",
       "0                             0                       0              0  ...   \n",
       "1                             1                       1              0  ...   \n",
       "2                             1                       1              0  ...   \n",
       "3                             0                       0              0  ...   \n",
       "4                             0                       0              1  ...   \n",
       "..                          ...                     ...            ...  ...   \n",
       "92                            0                       0              0  ...   \n",
       "93                            0                       0              0  ...   \n",
       "94                            0                       1              0  ...   \n",
       "95                            1                       0              0  ...   \n",
       "96                            0                       0              0  ...   \n",
       "\n",
       "    Justice  Respect for Persons  Autonomy (power to decide)  Explicability  \\\n",
       "0         0                    0                           0              0   \n",
       "1         0                    0                           0              0   \n",
       "2         0                    0                           0              0   \n",
       "3         0                    0                           0              0   \n",
       "4         0                    0                           0              0   \n",
       "..      ...                  ...                         ...            ...   \n",
       "92        0                    0                           0              0   \n",
       "93        0                    0                           0              0   \n",
       "94        0                    0                           0              0   \n",
       "95        0                    0                           0              0   \n",
       "96        0                    0                           0              0   \n",
       "\n",
       "    Respect for Law and public interest  Security  Easy to work with  \\\n",
       "0                                     0         0                  0   \n",
       "1                                     0         0                  0   \n",
       "2                                     0         0                  0   \n",
       "3                                     0         0                  0   \n",
       "4                                     0         0                  0   \n",
       "..                                  ...       ...                ...   \n",
       "92                                    0         0                  1   \n",
       "93                                    0         0                  0   \n",
       "94                                    0         0                  0   \n",
       "95                                    0         0                  0   \n",
       "96                                    0         0                  0   \n",
       "\n",
       "    Realistic world model  Fast  \\\n",
       "0                       0     0   \n",
       "1                       0     0   \n",
       "2                       0     0   \n",
       "3                       0     1   \n",
       "4                       0     0   \n",
       "..                    ...   ...   \n",
       "92                      0     0   \n",
       "93                      0     0   \n",
       "94                      0     0   \n",
       "95                      0     0   \n",
       "96                      0     0   \n",
       "\n",
       "                                                  URL  \n",
       "0   http://papers.nips.cc/paper/3872-3d-object-rec...  \n",
       "1              https://arxiv.org/pdf/1811.03962v3.pdf  \n",
       "2       http://icml2008.cs.helsinki.fi/papers/166.pdf  \n",
       "3       http://icml2008.cs.helsinki.fi/papers/391.pdf  \n",
       "4                    https://arxiv.org/pdf/1802.09477  \n",
       "..                                                ...  \n",
       "92  http://papers.nips.cc/paper/8297-vilbert-pretr...  \n",
       "93  http://papers.nips.cc/paper/7391-video-to-vide...  \n",
       "94  http://www.nowozin.net/sebastian/papers/mesche...  \n",
       "95  http://papers.nips.cc/paper/9063-wide-neural-n...  \n",
       "96  http://papers.nips.cc/paper/8812-xlnet-general...  \n",
       "\n",
       "[97 rows x 76 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ac212a3c-51ae-462c-ba81-87824c70c39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_to_text(pdf_path):\n",
    "    process = Popen(['pdftotext', pdf_path, '-'], stdout=PIPE, stderr=PIPE)\n",
    "    stdout, stderr = process.communicate()\n",
    "    if process.returncode == 0:\n",
    "        return stdout.decode('utf-8')\n",
    "    else:\n",
    "        print(f\"Error processing {pdf_path}: {stderr}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "85f0ea13-d71d-46bf-9c35-09b20831c9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_dir = 'papers'\n",
    "data['Text'] = ''\n",
    "for index, row in data.iterrows():\n",
    "    pdf_file_name = row['Title'] + '.pdf'\n",
    "    pdf_path = os.path.join(papers_dir, pdf_file_name)\n",
    "    if os.path.exists(pdf_path):\n",
    "        data.at[index, 'Text'] = pdf_to_text(pdf_path)\n",
    "    else:\n",
    "        print(f\"File not found: {pdf_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4fd8d3d5-841a-4e68-afad-1efee3391439",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('values_ml_papers.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
