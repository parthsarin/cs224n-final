{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "898d1a22-3628-49cc-a279-cc3d1fb59e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea36a168-b89b-484c-9950-81716bdf62a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_path = 'topic_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a140f69-0c36-46c5-94e3-2390bcf8736a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "novelty.csv\n",
      "     ['model', 'data', 'word', 'language', 'based', 'models', 'work', 'information', 'corpus', 'task']\n",
      "     ['model', 'al', 'et', 'text', 'based', 'approach', 'using', 'propose', 'sentence', 'new']\n",
      "performance.csv\n",
      "     ['results', 'using', 'performance', 'data', 'accuracy', 'word', 'sentences', 'precision', 'based', 'words']\n",
      "     ['model', 'performance', 'models', 'results', 'data', 'best', 'training', 'set', 'score', 'task']\n",
      "building on past work.csv\n",
      "     ['word', 'work', 'model', 'data', 'based', 'al', 'et', 'using', 'corpus', 'semantic']\n",
      "     ['al', 'et', 'based', 'model', 'work', 'use', 'using', 'models', 'language', 'features']\n",
      "     ['data', 'model', 'work', 'al', 'et', 'training', 'task', 'models', 'corpus', 'based']\n",
      "fairness.csv\n",
      "     ['dataset', 'task', 'number', 'present', 'information', 'biases', 'training', 'names', 'specific', 'likely']\n",
      "     ['names', 'specific', 'information', 'black', 'data', 'likely', 'training', 'work', 'change', 'number']\n",
      "     ['specific', 'training', 'bias', 'biases', 'data', 'task', 'change', 'work', 'dataset', 'names']\n",
      "reproducibility.csv\n",
      "     ['data', 'training', 'set', 'model', 'available', 'used', 'using', 'dataset', 'al', 'et']\n",
      "     ['corpus', 'data', 'used', 'based', 'al', 'et', 'sentences', 'using', 'use', 'training']\n",
      "ease of implementation.csv\n",
      "     nan\n",
      "     ['easier', 'implement', 'approach', 'simple', 'advantage', 'multiple', 'pipeline', 'require', 'models', 'language']\n",
      "     ['easy', 'application', 'task', 'word', 'language', 'set', 'use', 'way', 'database', 'new']\n",
      "     ['language', 'nlp', 'code', 'software', 'learning', 'approach', 'solution', 'use', 'able', 'design']\n",
      "     ['translation', 'interface', 'user', 'development', 'research', 'evaluation', 'machine', 'supported', 'language', 'current']\n",
      "     ['training', 'examples', 'learning', 'requires', 'end', 'grammars', 'et', 'al', 'user', 'benefits']\n",
      "     ['design', 'creation', 'information', 'mturk', 'naive', 'interface', 'effort', 'simple', 'allow', 'bayes']\n",
      "     ['easy', 'simplicity', 'use', 'tool', 'easily', 'annotation', 'based', 'end', 'textual', 'open']\n",
      "     ['approach', 'implementation', 'time', 'experiments', 'related', 'applications', 'sentences', 'efficient', 'language', 'nlp']\n"
     ]
    }
   ],
   "source": [
    "for f in os.listdir(lda_path):\n",
    "    if '.csv' in f:\n",
    "        print(f)\n",
    "        df = pd.read_csv(lda_path + f)\n",
    "        topics = df.topic_words.unique()\n",
    "        for ls in topics:\n",
    "            print('    ', ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da1770d8-22ed-46ef-ae96-01e4b0da78a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bertopic_path = 'parth code/cs224n-final/topics/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7a18051-34e2-475b-86ec-56ea3466ff80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "novelty.csv\n",
      "     ['', '', '', '', '', '', '', '', '', '']\n",
      "     ['model', 'data', 'al', 'et', 'approach', 'using', 'text', 'corpus', 'word', 'work']\n",
      "performance.csv\n",
      "     ['results', 'model', 'performance', 'models', 'data', 'best', 'system', 'better', 'baseline', 'accuracy']\n",
      "     ['results', 'performance', 'system', 'model', 'table', 'features', 'svm', 'set', 'baseline', 'precision']\n",
      "     ['parser', 'parsing', 'performance', 'sentences', 'data', 'results', 'also', 'set', 'using', 'feature']\n",
      "     ['translation', 'bleu', 'translations', 'system', 'results', 'language', 'baseline', 'quality', 'method', 'alignment']\n",
      "     ['speech', 'model', 'asr', 'utterances', 'results', 'dialogue', 'utterance', 'understanding', 'corpus', 'accuracy']\n",
      "     ['bert', 'models', 'position', 'performance', 'gpt2', 'tasks', 'pretrained', 'f1', 'results', 'embeddings']\n",
      "     ['model', 'data', 'models', 'training', 'performance', 'span', 'test', 'al', 'et', 'adaptation']\n",
      "     ['embeddings', 'sentiment', 'results', 'word', 'model', 'words', 'performance', 'using', 'lexicons', 'data']\n",
      "     ['transformer', 'bleu', 'models', 'model', 'xlm', 'newstest2019', 'results', 'newstest2018', 'fquad', 'acc']\n",
      "     ['fake', 'believable', 'toplevel', 'topic', 'text', 'topics', 'results', 'system', 'topiccorank', 'texts']\n",
      "building on past work.csv\n",
      "     ['sentiment', 'al', 'et', 'aspect', 'tweets', 'comments', 'work', 'hashtags', 'classification', 'method']\n",
      "     ['blc', 'entities', 'et', 'extraction', 'al', 'based', 'protein', 'entity', 'named', 'patterns']\n",
      "     ['et', 'al', 'data', 'model', 'work', 'language', 'using', 'features', 'corpus', 'models']\n",
      "     ['parsing', 'parser', 'dependency', 'model', 'syntactic', 'et', 'al', 'trees', 'semantic', 'sentence']\n",
      "     ['dialogue', 'summarization', 'models', 'discourse', 'corpus', 'dialog', 'et', 'al', 'work', 'information']\n",
      "     ['word', 'words', 'representations', 'similarity', 'vector', 'sense', 'senses', 'lexical', 'method', 'et']\n",
      "     ['translation', 'mt', 'data', 'al', 'et', 'quality', 'language', 'work', 'source', 'evaluation']\n",
      "     ['al', 'et', 'data', 'training', 'dataset', 'use', 'models', 'neural', '2019', '2018']\n",
      "     ['event', 'extraction', 'events', 'task', 'field', 'global', 'work', 'bionlp', 'potentials', 'types']\n",
      "     ['feature', 'features', 'arguments', 'learning', 'classifier', 'particular', 'examples', 'classes', '2007', 'algorithm']\n",
      "     ['speech', 'segmentation', 'asr', 'recordings', 'recognition', 'describe', 'however', 'used', 'boundaries', 'set']\n",
      "fairness.csv\n",
      "     ['al', 'et', 'names', 'sources', 'dataset', 'task', 'data', 'issuespecific', 'information', 'models']\n",
      "reproducibility.csv\n",
      "     ['data', 'available', 'set', 'code', 'agreement', 'section', 'also', 'et', 'al', 'using']\n",
      "     ['corpus', 'used', 'et', 'al', 'data', 'two', 'sentences', 'word', 'using', 'system']\n",
      "     ['available', 'publicly', 'code', 'dataset', 'research', 'plan', 'https', 'european', 'data', 'project']\n",
      "     ['training', 'model', 'set', 'use', 'data', 'models', 'using', 'used', 'test', 'gesture']\n",
      "ease of implementation.csv\n",
      "     ['language', 'learning', 'nlp', 'translation', 'use', 'approach', 'data', 'software', 'code', 'easy']\n"
     ]
    }
   ],
   "source": [
    "for f in os.listdir(bertopic_path):\n",
    "    if '.csv' in f:\n",
    "        print(f)\n",
    "        df = pd.read_csv(bertopic_path + f)\n",
    "        topics = df.Representation.unique()\n",
    "        for ls in topics:\n",
    "            print('    ', ls)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
