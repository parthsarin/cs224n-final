{
    "article": "This research aims to automatically extract Know-Why from documents on the website to contribute knowledge sources to support the question-answering system, especially What-Question, for disease treatment. This paper is concerned about extracting Know-Why based on multiple EDUs (Elementary Discourse Units). There are two problems in extracting Know-Why: an identification problem and an effect boundary determination problem. We propose using Na\u00efve Bayes with three verb features, a causative-verb-phrase concept set, a supporting causative verb set, and the effect-verbphrase concept set. The Know-Why extraction results show the success rate of 85.5% precision and 79.8% recall. Introduction Automatically Know -Why extraction is essential for providing the rational knowledge source, to the society through question answering system, especially in herbal medicines when assisting the locals to understand more about herbs. According to Jana Trnkova and Wolfgang Theilmann (2004) Know-Why is the knowing of the reason of why something is the way it is. Therefore, Know-Why has to involve the causal relation which is \"an irreflexive, transitive and asymmetrical\" relation that contains the properties of \"productivity (effect is 'produced' by the cause) and locality (it obeys the markov \u00a9 2008. Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-ncsa/3.0/). Some rights reserved. condition, for model A B C, if there is no B, then A does not cause C)\" ( Lemeire J. et al. (2004) ). Wolff P. (2007) stated that the causal relation can be decomposed into 2 major approaches, the dependency model and the physicalist models. The dependency model can be represented by using statistical dependency model whereas in recent physicalist models are based on the concepts of force dynamic models consisting of 2 force entities in certain events; the agonist and the antagonist (Talmy, 2000) . Later, the agonist form (Wolff P., 2007) can be viewed as the 'effect' and the antagonist as the 'cause'. According to Talmy (2000) , if there is a situation where the antagonist is stronger, which can be expressed as 'event X happens because of event Y'(Y contains the antagonist.), it is a form of causation. Moreover, the causal relation can pivot on the distinction between causality and causation (Lehmann J. et al, 2004) whereas causality is 'a law-like relation between cause events and effect events' and causation is 'the actual causal relation that holds between individual events'. For example: \"Because a bird sings a song at a window, The rock is thrown at the window.\" Causality: \"An object vibrates. An object moves.\" Causation: \"A bird sings. The rock is thrown\" This research focuses only on 'causal relation' to provide both 'causality' for extracting Know-Why from the herbal medicine domain and 'causation' for answering What-question, since what questions contain ambiguities (Girju R. and Moldovan D., 2002) /What herb is used for stopping nausea?\" From this example, 'A basil leaf is used as a medicine releasing gas' is the causation and the concept is the causality. There are various forms of causalrelation expression such as in the form of intra-NP, inter-NP, and inter-sentence (Chang and Choi,2004) . According to our research, we separated this relation into 2 main forms based on the elementary discourse unit (EDU) as defined by (Carlson et al., 2003) as a simple sentence or clause. We defined the intra-causal EDU as an expression within one simple EDU being equivalent to either the intra-NP form or the inter-NP form (Chang and Choi,2004) . The inter-causal EDU is defined as an expression within more than one simple EDU which is equivalent to the inter-sentences of Chang and Choi (2004) . However, this paper works on only the inter-causal EDU extraction because some cause-effect relation from the herbal web sites are expressed in the form of the EDU containing an EDU-like name entity with the causative action followed by some effect EDUs. Several techniques (Marcu and Echihabi,2002; Torisawa 2003; Inui and et al.,2004; Pechsiri and Kawtrakul, 2007) have been used to extract cause-effect knowledge varying from two adjacent sentences to multiple sentences. Our work aimed at mining and extracting Know-Why from Thai documents of herbal medicines. Thai has several specific characteristics, such as the existence of sentence-like name entity, zero anaphora or the implicit noun phrase. All of these characteristics are involved in the two main problems of Know-Why extraction: the first problem is how to identify the interesting causality events expressed by an EDU-like name entity from documents, and the second one is how to identify the effect boundary, where The problem of implicit delimiter of the boundary is involved. From all of these problems, we needed to develop a framework which combineed Language Processing and the machine learning technique as Na\u00efve Bayes to learn features of three verb sets, a causative concept verb set, a supporting causative verb set, and an effect concept verb set, for solving those problems. In conclusion, unlike other methods (Marcu and Echihabi ,2002; Torisawa 2003; Inui and et al.,2004) where the emphasis is based on two adjacent sentences, this paper is based on multiple EDU extraction. Our research was separated into 5 sections. In section 2, related work was summarized. Problems in causality mining from Thai documents will be described in section 3 and in section 4 our framework for causality extraction was explained. In section 5, we evaluated and concluded our proposed model. Related Work Several strategies such as those done by Marcu and Echihabi ,2002, Torisawa( 2003) , Inui and et al.(2004) , and Pechsiri and Kawtrakul (2007) have been proposed to extract and discover knowledge from the textual data. Marcu and Echihabi (2002) presented the unsupervised approach to recognize the discourse relations by using word pair probabilities between two adjacent sentences for classifying the rhetorical relations, such as Contrast, Cause-Explanation, Condition, and Elaboration, between two adjacent sentences by using Na\u00efve Bayes classifier to the BLIPP corpus (Charniak, 2000) . They determined the word pairs in the cartesian product from the sentence pairs connected with or without discourse marker or connective marker , i.e. 'because' 'but' 'then', to classify the causal relation from other rhetorical relations. The result showed an accuracy of 75% of inter-sentence causality extraction from the corpus size of more than a million sentences for learning whereas our corpus size is 3000 sentences for learning. Therefore, our approach is the supervised approach with the statistical method because our corpus size is small. Inui's work (Inui and et al.,2004) proposed a method of extraction and classification of causal knowledge. The method of extraction was accomplished under two adjacent sentences by using explicit connective markers; e.g. \"because\" \"since\" \"if..then\" \"as the result\" etc.. SVM was used for the classification process in (Inui and et al.,2004) . Four types of causal relations are studied, including the following: cause, precondition, mean, effect relations. Inui's work's precision is high: 90% but the recall is low: 30%, because of unresolved anaphora. However, in our work, we extract multiple EDUs with some implicit discourse markers. Torisawa( 2003) ' s work in extracting the verb phrase pair from the news corpus worked on the assumption that if two events share a common participant (is specified by a noun) then the two events are likely to have a logical relation as causal relation. For example \"A man drank liquor and was intoxicated by the liquor.\"(a common participant is 'liquor'). However, this assumption can not be applied in our research because most of our causality expression does not share a common participant; e. g. \" !\" /Ginger is used as being laxative medicine. [The ginger] stops constipation. Pechsiri and Kawtrakul (2007) , proposed verb-pair rules learned by two different machine learning techniques (NB and SVM) to extract causality with multiple EDUs of a causative unit and multiple EDUs of an effect unit with the problems of the discourse marker ambiguity and the implicit discourse marker. This verb-pair rule has been represented by the following equation (1) (Pechsiri and Kawtrakul, 2007) where V c is the causative verb concept set, V e is the effect verb concept set , C is the Boolean variables of causality and non-causality, and a causative verb concept (v c , where v c V c ) and an effect verb concept (v e , where v e V e ) are referred to Word-Net (http://wordnet.princeton.edu/) and the predefined plant disease information from Department of Agriculture (http://www.doa.go.th/). CausalityFunction: V c V e C (1) They also proposed using V c and V e to solve the boundary of the causative unit and using the Centering theory along with V e to solve the boundary of the effect unit. The outcomes of their research were the verb-pair rule, V c , V e , and the multiple EDUs of causality (extracted from textual data) was at their highest precision of 89% and their highest recall of 76%. The correctness of the causality-boundary determination is 88% on average. However, our causative unit consisted of only one EDU containing an EDUlike name entity as a cause, and this EDU was followed by several effect EDUs. In our current work, we aimed at extracting the Know-Why in Natural Language description instead of visualizing only associations of concepts, by applying both language processing and learning technique by Na\u00efve Bayes to identify the causality expression. Problem of Know-Why Extraction To extract the cause-effect expressions, there are two main problems that must be solved. The first problem is how to identify interesting causeeffect relations from the documents. The second problem is how to determine the effect boundary. There is also the problem of implicit noun phrase. Causality Identification The problem involves the word level and the sentence level. For the word level, the medicinal name entity may express in the form of a sentence like name entity or an EDU-like name entity which explains the medicinal action as the causative action of medicine, and medical characteristic. The problem of this level is how to identify the causative name entity. For example: a) \" /A basil leaf #is used as # medicine #releases #gas\" where 'a medicine releases gas' is an EDUlike name entity with the causative action, 'release'. b) \" $ % # Nicolson stem & #is used for making #medicine #soaks in ' # liquor\" where 'a medicine soaks in liquor' is an EDU-like name entity with the characteristic of medicine being preserved in the alcohol. The above examples, a) and b), contain an EDU-like name entity which is a cause in a) and a non cause in b). For the sentence level, the EDU containing an EDU-like name entity with the causative action may be followed by an effect EDU(s) to form the cause-effect or causality relation between the EDU like name entity and that following EDU(s). For example: Causality EDU1 \"( ' /Lemon grass is used as #medicine ) contracts , \" #a uterus\" (where 'a medicine contracts a uterus.' is the EDU-like name entity with concept of 'the medicine causes uterus to contract'.) EDU2 \"[The plant ] /discharges %& # period.\" (=The plant discharges period.) Non causality EDU1 \" /A basil leaf #is used as #medicine #releases #gas.\" (where 'a medicine releases gas' is the causative EDUlike name entity.) EDU2 \"[the basil leaf] * #relieves ! #ulcer #in ' #stomach.\"(= [The basil leaf relives ulcer in a stomach. ) Where in this example, EDU 1 is the cause and EDU2 is the effect Effect Boundary Determination There are two problems of an implicit effect boundary cue and the effect EDU containing interrupts. Implicit Effect Boundary Cue Some cause-effect relations from the herbal web sites are expressed in the form of the EDU containing an EDU like name entity with the causative action followed by some effect EDUs without any cue of ending effect boundary, e.g. \" and\". For example: EDU1 \" A basil leaf is used as # medicine #releases #gas\" (=A basil leaf is used as a medicine releasing gas.) EDU2 \"[The basil leaf ] #stops # nauseate.\" (=The basil leaf stop being nausea.) EDU3 \"[And the leaf ] #stops /pain # abdomen.\" (= [And the leaf] stops paining abdomen.) Where in this example, EDU 1 is the cause and EDU 2 & EDU3 are the effects. EDU 2 and EDU3 help us to determine the boundary. Effect EDU Containing Interrupts There are some effect EDUs containing interrupts as shown in the following example: EDU1 \"' #A red onion is used as # medicine +$ /be laxztive\" (=A red onion is used as a laxative medicine.) Where the EDU-like name entity in EDU1 is a cause with EDU2 and EDU4 as its effects. The EDU3 is an interrupt. Although EDU3 is the effect of red onions, but EDU 3 is not the effect of laxatives. A Framework for Know-Why Extraction Figure 1. System Overview There are three steps in our framework. First is the corpus preparation step followed by causality learning, and causality recognition steps (as shown in figure 1 ). Corpus Preparation There are two steps of pre-annotation and Causality annotation. Pre-annotation This step is the preparation of the corpus in the form of EDU from the text. The step involves using Thai word segmentation tools to solve a boundary of a Thai word and tagging its part of speech (Sudprasert and Kawtrakul, 2003) . This process includes Name entity (Chanlekha and Kawtrakul, 2004) , and word-formation recognition (Pengphom, et al 2002) to solve the boundary of Thai Name entity and Noun phrase. After the word segmentation is achieved, EDU segmentation is dealt with. According to Charoensuk et al. (2005) , this process segments plain text into units of EDUs by using the rule based and the machine learning technique of C4.5 (Mitchell T.M., 1997) . These generated EDUs will be kept as an EDU corpus. This corpus will contain 4500 EDUs and will be separated into 2 parts, one part is 3500 EDUs for causality learning and the other part of 1000 EDUs for causality recognition and extraction. Causality Annotation Due to the problems in the causality identification, verbs from three EDUs (with one EDU as an EDU-like name entity) in the EDU corpus are used in this process to learn for extracting causality. Word ambiguity will be solved through the finding of word concepts from Wordnet. Since Thai Wordnet does not exist, we need to translate from Thai to English, using Lexitron (the Thai-English dictionary)( http://lexitron.nectec.or.th/), before using Wordnet(http://wordnet.princeton. edu/obtain). In this process, we manually annotate the causality EDUs by annotating the EDU containing the causative EDU-like name entity as the causative EDU. We annotate a verb phrase in the causative EDU-like name entity to be a causative-verb-phrase concept (referred to Wordnet). The verb from EDU which contains the causative EDU-like name entity is annotated with a concept and we call this verb as 'supporting causative verb'. We also annotate the effectverb-phrase concept(referred to Wordnet and http://www.ars-grin.gov/duke/ethnobot.html) from effect EDUs following the EDU containing the causative EDU-like name, as shown in Figure 2 ) Causality Learning The aim of this step was to learn cause-effect relation between causative events and effect events from annotating an EDU corpus. Feature Extraction All annotated verb features from the previous step are extracted into database table (in Table 1 ) including surface forms of verb features along with their concepts used for probability determination in the next step. Probability Determination After we had obtained the extracted verb features, we then determined the probability of causal and non causal from the occurrences of the cartesian products of three verb feature concepts , shown in Table2, by using Weka which is a software tool for machine learning (http://www.cs. waikato.ac.nz/ml/weka/ ). Causality Recognition and Extraction The objective of this step was to recognize and extract the cause-effect relation from the testing EDU corpus. In order to start the causality recognition process, Na\u00efve Bayes Classifer shown in equation ( 2 ) is applied with the feature probabilities in Table 2 , where EDUs class is determined by class1 (causality EDUs) and class0 (non causality EDUs). Therefore, Causality Recognition can be separated into 2 steps: causality identification and effect boundary determination. Causality Identification This step was to determine the interesting locations that are cause-effect relations by searching any EDU which consists of a verb matching to a verb in the supporting causative concept set, V s , and an EDU-like name entity containing a causative-verb-phrase concept as vp c (where vp c VP c ). Effect Boundary Determination The effect EDU and the effect boundary were determined at the same time by checking all sequence EDUs right after the EDU containing vp c in the EDU-like name entity. If a verb phrase from the sequence of checked EDUs is not in VP e , the possible effect boundary is end. After the possible boundary is determined, v s_inEDU1 , vp c_inEDU1 and vp e_inEDU2 ..vp e_inEDUn (where n>2) will be used to determine the causality class from the Na\u00efve Bayes Classifier equation (2) as shown in Figure 3 . The actual effect boundary is determined from the last class1 in the sequence of EDU 2 .. EDU n . Furthermore, where the implicit noun phrase occurs as the subject of the current EDU, this has to be solved in this step by using the heuristic rule which is that the noun phrase as a subject of the previous EDU will be the subject of the current EDU. Evaluation and Conclusion The Thai corpora used to evaluate the proposed causality extraction algorithm consist of about 1,000 EDUs collected from several herbal web sites. The evaluation of the causality extraction performance of this research methodology is expressed in terms of the precision and the recall as shown below, where R is the causality relation: The results of precision and recall are evaluated by three expert judgments with max win voting. The precision of the extracted causality 85.5% with 79.8% recall. The correctness of our effect boundary determination by these expert judgments is 86%. These research results can be increased if we use a larger corpus. However, our methodology will be very beneficial for con-tribute the causality knowledge for supporting What-question with the concept of causal relation from a web page by inference method of backward chaining, for example: Extracted causality: \" .' /A basil leaf is used for a gas released medicine. [The leaf] stops nausea. [The leaf] stop stomachache.\" \u2026\u2026\u2026\u2026\u2026. The above extracted causality can be represented by the following predication.  Figure3. Show Causality Extraction algorithm for the EDU containing the causative EDU-like name entity, and followed by multiple effect EDUs . ",
    "abstract": "This research aims to automatically extract Know-Why from documents on the website to contribute knowledge sources to support the question-answering system, especially What-Question, for disease treatment. This paper is concerned about extracting Know-Why based on multiple EDUs (Elementary Discourse Units). There are two problems in extracting Know-Why: an identification problem and an effect boundary determination problem. We propose using Na\u00efve Bayes with three verb features, a causative-verb-phrase concept set, a supporting causative verb set, and the effect-verbphrase concept set. The Know-Why extraction results show the success rate of 85.5% precision and 79.8% recall.",
    "countries": [
        "Thailand"
    ],
    "languages": [
        "Thai"
    ],
    "numcitedby": "4",
    "year": "2008",
    "month": "August",
    "title": "Know-Why Extraction from Textual Data for Supporting What Questions"
}