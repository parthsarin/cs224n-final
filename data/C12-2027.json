{
    "article": "Microblogging services continue to grow in popularity, users publish massive instant messages every day through them. Many tweets are marked with hashtags, which usually represent groups or topics of tweets. Hashtags may provide valuable information for lots of applications, such as retrieval, opinion mining, classification, and so on. However, since hashtags should be manually annotated, only 14.6% tweets contain them (Wang et al., 2011) . In this paper, we adopt topic-specific translation model(TSTM) to suggest hashtags for microblogs. It combines the advantages of both topic model and translation model. Experimental result on dataset crawled from real world microblogging service demonstrates that the proposed method can outperform some state-of-the-art methods. Introduction Hashtags, which are usually prefixed with the symbol # in microblogging services, represent the relevance of a tweet to a particular group, or a particular topic (Kwak et al., 2010) . Popularity of hashtags grows concurrently with the rise and popularity of microblogging services. Many microblog posts contain a wide variety of user-defined hashtags. It has been proven to be useful for many applications, including microblog retrieval (Efron, 2010) , query expansion (A. Bandyopadhyay et al., 2011) , sentiment analysis (Davidov et al., 2010; Wang et al., 2011) , and many other applications. However, not all posts are marked with hashtags. How to automatically generate or recommend hashtags has become an important research topic. The task of hashtag recommendation is to automatically generate hashtags for a given tweet. It is similar to the task of keyphrase extraction, but it has several different aspects. Keyphrases are defined as a short list of phrases to capture the main topics of a given document (Turney, 2000) . Keyphrases are usually extracted from the given document. However, hashtags indicate where a tweet is about a particular topic or belong to a particular group. So words and hashtags of a tweet are usually diverse vocabularies, or even hashtags may not occur in the tweet. Take the tweet in Table 1 for instance, the word \"Lion\" is used in the tweet, while users annotate with the hashtag \"Mac OS Lion\". That is usually refered to as a vocabulary gap problem. Tweet At the WWDC conference 2012, Apple introduces its new operating system release-Lion. Annotated tags Apple Inc, WWDC, MAC OS Lion Table 1 : An example of a tweet with annotated hashtags. Tweet Tags At the WWDC conference 2012, Apple introduces its new opera\u019fng system release-Lion. Apple Inc, WWDC, MAC OS Lion Word alignment Figure 1 : The basic idea of word alignment method for suggesting hashtags. To solve the vocabulary gap problem, most researchers applied a statistic machine translation model to learn the word alignment probabilities (Zhou et al., 2011; Bernhard and Gurevych, 2009) . Liu et al. (2011) proposed a simple word alignment method to suggest tags for book reviews and online bibliographies. In this work, tags are trigged by the important words of the resource. Figure 1 shows the basic idea of using word alignment method for tag suggestion. Due to the open access in microblogs, topics tend to be more diverse in microblogs than in formal documents. However, all the existing models did not take into account any contextual information in modeling word translation probabilities. Beyond word-level, contextual-level topical information can help word-alignment choice because sometimes translation model is vague due to their reliance solely on word-pair co-occurrence statistics. For example, the word \"apple\" should be translated into \"Apple Inc\" in the topic of technology, or \"juice\" in the topic of drink. Thus the idea is using topic information to facilitate word alignment choice. Based on this perspective, in this paper, we propose a topic-specific translation model(TSTM) to recommend hashtags for microblogs. This method regards hashtags and tweets as parallel description of a resource. We first investigate to combine topic model and word alignment model to estimate the topic-specific word alignment probabilities between the words and hashtags. After that, when given an unlabeled dataset, we first identify topics for each tweet and then compute importance scores for candidate tags based on the learned topic-specific word-  tag alignment probabilities and topic distribution. Figure 2 illustrates the basic idea of our model. In Figure 2 , for simplicity, we suppose there are totally two topics, topic 1(information technology) and topic 2(food). We use the font size of tags to indicate the word-tag alignment probability for each specific topic. With the topic distribution and word-tag alignment probabilities for each topic, we can compute the importance score for each candidate tag. The remainder of this paper is organized as follows: related work and state-of-the-art approaches are reviewed in Section 2. The proposed approach is detailed in Section 3. Experimental results and analysis are described and discussed in Section 4. The last section concludes the paper. Related work Our approach relates to two research areas: tag suggestion and keyphrase extraction. In this section, we discuss them in detail. Tag suggestion Previous work on tag suggestion can be roughly divided into three directions, including collaborative filtering(CF) (Rendle et al., 2009; Herlocker et al., 2004) , discriminative models (Ohkura et al., 2006; Heymann et al., 2008) , and generative models (Krestel et al., 2009; Iwata et al., 2009) . Our proposal is complementary to these efforts, because microblogs differ from other media in some ways: (1) microblog posts are much shorter than traditional documents. (2) topics tend to be more diverse than in formal documents. So these methods cannot be directly applied to hashtag recommendation in microblogs. Keyphrase extraction Keyphrase extraction from documents is the most similar task to this research. Existing methods can be categorized into supervised and unsupervised approaches. Unsupervised approaches usually selected general sets of candidates and used a ranking step to select the  most important candidates (Mihalcea and Tarau, 2004; Wan and Xiao, 2008) . Supervised approaches used a corpus of training data to learn a keyphrase extraction model that is able to classify candidates as keyphrases (Turney, 2003; Hulth., 2003) . 3 Proposed method Preliminaries We assume an annotated corpus consisting of D tweets with a word vocabulary of size W and a hashtag vocabulary of size T . Suppose there are K topics embedded in the corpus. The dth tweet consists of a pair of words and assigned hashtags (w d , t d ), where w d = {w dn } N d n=1 are N d words in the tweet that represent the content, and t d = {t dm } M d m=1 are M d assigned hashtags. Our notation is summarized in Table 2 . Given an unlabeled data set, the task of hashtag recommendation is to discover a list of hashtags for each tweet. The proposed topic-specific translation model is based on the following assumptions. When a user wants to write a tweet, he first generates the content, and then generates the hashtags. When starting the content, he first chooses some topics based on the topic distribution. Then he chooses a bag of words one by one based on the word distribution for each chosen topic. During the generative process for hashtags, a topic is first chosen from topics that have previously generated the content. And hashtags are chosen according to the chosen topic and important words in the content. Formally, let \u03b8 denotes the topic distribution and \u03d5 k denotes the word distribution for topic k. Let \u03b7 d denote the distribution of topic choice when assigning hashtags for the dth tweet and the choice probability of topic k is sampled randomly from topics of content, as follows, ) and B presents the topic-specific word alignment table between a word and a hashtag, where B i, j,k = P(t = t j |w = w i , z = k) is the word alignment probability between the word w i and the hashtag t j for topic k, P(w dn |w d ) indicates the importance of the word in the dth tweet, which will be described in detail in section 3.4.2 . \u03b7 d k = N d k +\u03b3 N d (.) +K\u03b3 , In summary, the generation process of annotated tweets is described as follows: where \u03b1, \u03b2 and \u03b3 are Dirichlet distribution parameters. Figure 3 shows a graphical model representation of the proposed model. Learning and inference We use collapsed Gibbs sampling (Griffiths and Steyvers, 2004) to find latent variables. The sampling probability of a latent topic for each word and hashtag in the tweet is sampled respectively. Due to the space limit, we leave out the derivation details and the sampling formulas. After the topics of each word and hashtag become stable, we can estimate topic-specific word alignment table B by: B t,w,c = N t c,w N (.) c,w . where N t c,w is a count of the hashtag t that co-occurs with the word w for topic c in tweet-hashtag pairs. The possibility table B t,w,c have a potential size of W T K, assuming the vocabulary sizes for words, hashtags and topics are W , T and K. The data sparsity poses a more serious problem in estimating B t,w,c than the topic-free word alignment case. To reduce the data sparsity problem, we introduce the remedy in our model. We can employ a linear interpolation with topic-free word alignment probability to avoid data sparseness: B * t,w,c = \u03bbB t,w,c + (1 \u2212 \u03bb)P(t|w), where P(t|w) is topic-free word alignment probability from the word w and the hashtag t, \u03bb is tradeoff of two probabilities. Here we explore IBM model-1 (Brown et al., 1993) , which is a widely used word alignment model, to obtain P(t|w). . we first identify topics for each tweet using the standard LDA model. The collapsed Gibbs sampling is also applied for inference. After the topics of each word become stable, we can estimate the distribution of topic choice for hashtags of the dth tweet in unlabeled data by: \u03b7 Tag recommendation using * dk = N d k +\u03b3 N d (.) +\u03b3K , where N d k is a count of words that are assigned topic k in the dth tweet of unlabeled dataset. Tag recommendation With topic distribution \u03b7 * and topic-specific word alignment table B * , we can rank hashtags for the dth tweet in unlabeled data by computing the scores: P(t * dm |w * d , \u03b7 * d , B * ) = K \u2211 c * d m =1 L d \u2211 n=1 P(t * Experiments Data collection and analysis In our experiments, we use a Microblog dataset collected from Sina-Weibo 1 for evaluation. Sina-Weibo is a Twitter-like microblogging system in China provided by Sina, one of the largest Chinese Internet content providers. It was launched in August, 2009 and quickly become the most popular microblogging service in China. We collected a dataset with totally 10,320,768 tweets. Among them, there are 551,479 tweets including hashtags annotated by users. We extracted these annotated tweets for training and evaluation. Some detailed statistical information is shown in Table 3 . We divided them into a training set of 446,909 tweets and a test set of 104,570 tweets. The training set is applied for building topic-specific translation model, while the test set is for evaluation. We use hashtags annotated by users as the golden set. #tweet W T Nw Nt 551,479 244,027 116,958 19.97 1.24 Table 3 : Statistical information of dataset. W , T , Nw and Nt are the vocabulary of words, the vocabulary of hashtags, the average number of words in each tweet and the average number of hashtags in each tweet respectively. Evaluation metrics and settings We use Precision(P), Recall(R), and F-value(F ) to evaluate the performance of hashtag recommendation methods. We ran topic-specific translation model with 1000 iterations of Gibbs sampling. After trying a few different numbers of topics, we empirically set the number of topics to 100. We use \u03b1 = 50.0/K and \u03b2 = 0.1 as (Griffiths and Steyvers, 2004) suggested. Parameter \u03b3 is also set to 0.1. We use IDF to indicate the importance of a word and set smoothing parameter \u03bb to 0.8 which gives the best performance. The influence of smoothing to our model can be found in Section 4.5. Comparison with other methods In this subsection, we implement several methods for comparison, where Naive Bayes(NB) is a representative classification method, while LDA (Krestel et al., 2009) is selected to represent generative model for tag suggestion, IBM model-1 (Liu et al., 2011 ) is a novel translationbased model.  In Figure 4 , we show the Precision-Recall curves of NB, LDA, IBM1 and TSTM on the data set. Each point of a Precision-Recall curve represents different numbers of suggested hashtags from M = 1(bottom right, with higher Precision and lower Recall) to M = 5(upper left, with higher Recall but lower Precision) respectively. The closer the curve to the upper right, the better the overall performance of the method. From the Figure, we have the following observations: (1)TSTM outperforms all the baselines. This indicates the robustness and effectiveness of our approach for hashtag recommendation. (2)IBM1 underperforms TSTM, because IBM1 relies solely on word-tag co-occurrence statistics. And contextual topical information can help to disambiguate word-alignment choices in TSTM. (3)LDA performs so poor, because it ranks the candidate hashtags by the hashtag distribution for each topic. So it can only suggest general hashtags. To further demonstrate the performance of TSTM and other baseline methods, in Table 4 , we show the Precision, Recall and F-measure of NB, LDA, IBM1 and TSTM suggesting top-1 hashtag, because the number is near the average number of hashtags in dataset. We find that the F-measure of TSTM comes to 0.334, outperforming all the baselines more than 8%. Example In Table 5 , we show top-8 hashtags suggested by NB, LDA, IBM1 and TSTM for the tweet in Table 1 2 . The number in brackets after the name of each method is the count of correctly suggested hashtags. The correctly suggested hashtags are marked in bold face. From Table 5 , we observe that classification model NB suggests some unrelated hashtags. While LDA, as generative models, tends to suggest general hashtags, such as \"Information News\", \"mobile phone\" and \"Technology leaders\", and fail to generate the specific hashtags \"WWDC\", \"MAC OS Lion\". IBM1 method will suggest some topic-unrelated hashtags. For instance, \"2012 Jinshan Inc cloud computing\" and \"2012 spring and summer men's week\" are triggered by the word \"2012\". On the contrary, TSTM succeeds to suggest specific hashtags, and most of them are topic-related to the tweet. Influences of smoothing To validate the power of smoothing in TSTM on different sizes of datasets, the experiments were conducted on two datasets, including a small dataset(a training set of 100,000 tweets  Figure 5 and Figure 6 show the performance on both of the datasets when \u03bb ranges from 0.0 to 1.0. We find that TSTM achieves the best performance when \u03bb = 0.8 in both of the two Figures. Furthermore, the model cannot perform well without smoothing (when \u03bb = 1) on the small data set. That indicates smoothing is more powerful on the small data set. While the model can still perform well without smoothing on the large data set. This is reasonable because large data set can help to solve the problem of data sparsity to some extent. Conclusions In this paper, we address the issue of suggesting hashtags for microblogs. The existing methods cannot be directly applied to this task due to the following challenges. (1) tweets are much shorter than traditional documents. (2) topics are more diverse in microblogs than other media. To solve these problems, we proposed a topic-specific translation model, which combines the advantages of both topic model and translation model. Experimental result on tweets crawled from real world service demonstrates that the proposed method can outperforms some state-of-the-art methods. Acknowledgments The author wishes to thank the anonymous reviewers for their helpful comments. This work was partially funded by 973 Program (2010CB327900), National Natural Science Foundation of China (61003092, 61073069), and \"Chen Guang\" project supported by Shanghai Municipal Education Commission and Shanghai Education Development Foundation (11CG05).",
    "abstract": "Microblogging services continue to grow in popularity, users publish massive instant messages every day through them. Many tweets are marked with hashtags, which usually represent groups or topics of tweets. Hashtags may provide valuable information for lots of applications, such as retrieval, opinion mining, classification, and so on. However, since hashtags should be manually annotated, only 14.6% tweets contain them (Wang et al., 2011) . In this paper, we adopt topic-specific translation model(TSTM) to suggest hashtags for microblogs. It combines the advantages of both topic model and translation model. Experimental result on dataset crawled from real world microblogging service demonstrates that the proposed method can outperform some state-of-the-art methods.",
    "countries": [
        "China"
    ],
    "languages": [
        "Chinese"
    ],
    "numcitedby": "49",
    "year": "2012",
    "month": "December",
    "title": "Automatic Hashtag Recommendation for Microblogs using Topic-Specific Translation Model"
}