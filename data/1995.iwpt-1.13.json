{
    "article": "Introduction I explore in this paper a variety of approaches to Prolog term encoding typed feature structure grammars. As in Carpenter [3] , the signature for such grammars consists of a bounded complete partial order of types under subsumption (;J) along with a partial function Approp : Type x Feat _._ Ty pe. The appropriateness specification is subject to the constraint that feature-value specifications for subtypes are at least as specific as those for supertypes: if Approp(t, F) = s and t subsumes t', then Approp( t', F) = s' for-<some s' subsumed by s . 1   Previous approaches to term encoding of typed feature structures ( [1] , [2] , [7] ), have assumed a similar signature plus additional restrictio\ufffds such as: limitations on multiple inheritance, or exclusion of more specific feature-value declarations on subtypes. The encoding presented here is subject to no such restrictions. The encoding will ensure that every feature structure is well typed (Carpenter [3] ), i.e., for every feature F on a node with type t, the value of this feature must be subsumed by Approp(t, F). And furthermore, the encoding will ensure, as required by HPSG, that every feature structure is extendible to a maximally specific well-type feature structure. 2  Previous approaches, discussed in \u00a72, have adopted a technique from Mellish [18] [19] in which each type is encoded as an open-ended data structure representing the path taken through the type hierarchy to reach that type. Or, in other words, a type t is represented as a sequence of types, starting at the most general type bele>w T and ending at t, in which each consecutive pair consists of supertype followed by immediate subtype. By bundling features together with the types that introduce them, it is then possible to allow the number of features on a type to increase as the type is further instantiated. The disadvantage of this representation, though, is that there is no unique path leading to a multiply-inherited type or any of its subtypes. While a grammar with multiple-inheritance cannot generally be represented in this approach, it is still possible, as explained in \u00a72.1, to compile the multiple inheritance out of the type hierarchy and then term-encode a semantically equivalent g:,ammar. In this approach, multiple inheritance exists as a convenience to the grammar writer, but is not actually used at run time. 1 Other more complex constraints can be compiled out [13) . So a system that only uses appropriateness conditions is more general than it might first appear. The encoding presented here will in some instances require the introduction of disjunctions in order to ensure satisfiability of feature structures, i.e., to ensure that feature structures are ex tendible to maximally specific well-typed feature structures. 3 This introduction of disjunctions may, in the worst case, exponentially increase the size of the grammar. Practical experience with HPSG grammars on the Troll system ((9] , ( 15 )) has shown, however, that feature structure compaction techniques can be used to keep this increase reasonably small. In \u00a73, I discuss how these techniques can be incorporated into a term unification approach. In \u00a73.1, I discuss the technique of unextension, which involves replacing disjunctions of feature structures with maximally specific types on their nodes by smaller disjunctions of feature structures in which the nodes are labelled by more general types . In \u00a73.2, I discuss the use of unfilling to remove uninformative feature-value pairs. I show how this technique can be used not only to make feature structures smaller, but also to eliminate disjunctions. Then, in \u00a73. Types-as-Paths Encoding The types-as-paths encoding, introduced by Mel_ lish (18] , uses an open-ended data structure representing the path taken through the type hierarchy to reach that type. For simplicity, let us first consider how to represent types that do not take any features, such as the types subsumed by a in fig. 1 It is clear that the encodings for a, a2 and a4 will all unify, whereas the encodings for a2 and al will not unify. 4 While, in general, the encoding employs open data structures, the example 3 1 am simplifying here for the sake of exposition. The notion of \"satisfiable feature structure\" is treated in full in King [16) . 4 The encoding used in ALE [4) is similar except that the paths may be gappy. Thus, a4 could be encoded as any of the f\ufffdllowirig: _-a4-a2-a, _-a4-a, _-a4-a2 or _-a4. _ In this example, the path reflects the derivational history of how the a4 got to be an a4. This same principle is used in the implementation of updateable arrays in the Quintus Prolog library. Since the encoding is not unique, a special purpose unifier must be used, which dereferences each type before unifying. Thus this gappy representation is not applicable for the goal of this paper, which is to use ordinary (Prolog-style) term unification. shows that a3, since it is maximally specific, can be encoded as a ground term. If, however, we wish to be able to distinguish in a feature structure between reentrant and non-reentrant instances of a3, then we would need encode a3 also as an open term: a(a2(a3(_))) . 5 This encoding allows a particularly convenient encoding of feature information . If a type introduces n features, then we simply add n additional argument slots to that type in each path. For example, consider the encodings of b and e: . As can be seen from this example, there is essentially no difference between the encoding of a simple type t and the encoding of a feature structure of type t. The encoding of each type has slots in it where all of the feature value information can be included. The encoding for e is particularly instructive. As can be seen, e takes two features, which are introduced <;1,t two different points along the path. Furthermore, e is a subtype of b, which has only a single argument position for the feature F. It is clear then that the number of slots for features can increase as a type is further instantiated. The idea of bundling feature information along with the type that introduces that feature is certainly elegant. However, there is a drawback when not all of the information about a feature is located on a single type. For example, the type d inherits a feature F from the supertype b, but then adds a more specific value specification for this feature. Consider what happens when the feature structure b[F : a] (encoded: b(_, a(_)))) unifies with the feature structure d (encoded: b(d, ...F) )). The unification of these two encodings is b(d,a(_))), i.e., d[F : a] , which is not well-typed. This, however, is not really a problem specific to the types-as-paths encoding. Any typed feature structure approach with appropriateness specifications needs to incorporate type inferencing. As discussed in \u00a72.2 (see also [11]), one way to maintain appropriateness is to multiply out disjunctive possibilities. For example, b[F : a] should be multiplied out to: { d[F : al], e[F : a]}. As seen in the next section, handling multiple inheritance will also involve introducing disjunctions. So the problem of efficiently representing such disjunction ( discussed in \u00a73 ) will be of crucial importance. Compiling Out Multiple Inheritance Multiple inheritance is a genuine problem for the types-as-paths representation. The problem is that if a type can be reached by multiple paths through the type hierarchy, then there is no longer a unique representation for that type. A partial solution to this to use multi-dimensional inheritance as in Erbach [7] and Mellish [18] . This idea involves encoding types as a set of paths rather than as a single path. The intuition is supposed to be that each path in this set represents a different dimension in the inheritance quant ). So the restriction on this encoding is the following: if types t and t' have a subtype in common, then every subtype of t must be subsumed by t'. In the list example, ne-1ist and list....sign have a subtype in common (ne.Jist....sign). However, list....sign also subsumes e-1ist , which is not subsumed by ne.Jist. So while this approach may work for some special cases of multiple inheritance, it is not a general solution to the problem. 6 '[F : +, a: -] , a\"[F : -, G: + Given the problems with representing multiple inheritance, it is reasonable to ask how important multiple inheritance is. In fact, given some reasonable closed world assumptions as discussed in the next section, it is possible to compile out all multiple inheritance. To see this, consider what happens when we remove from the list hierarchy the types list....sign and lisLquant . As seen in fig. 3, removing these two types is sufficient to eliminate all .sign and one with e-1ist. So some lexical entries or rules may have to be compiled out into multiple instances. The question of how to deal with this introduced disjunction is treated in \u00a73. Closed Wo rld Assumptions So far, we have seen that a closed world interpretation of the type hierarchy will allow us to compile out multiple inheritance at the cost of introducing some disjunctions into the grammar . But the closed world assumption is not a condition that is imposed solely for the purpose of term encoding. As shown in Gerdemann & King [10] [11], the closed world assumption is needed if types are to be used to encode any kind of feature cooccurrence restrictions. As noted by Copestake et al . [5] this deficiency of open-world type systems leads to serious problems for expressing any kind of linguistic constraints. While the closed world assumption is clearly needed, it is also the case that there is a price to be paid for maintaining this condition. In particular, Gerdemann & King [10] [11] showed that maintaining this condition will sometimes involve multiplying out disjunctive possibilities. For example, consider the type hierarchy in fig. 4. Every feature structure of type a must ultimately be resolved to either a feature structure of type a' or of type a\" . So the feature structure a[F: bool, G: boo/] really represents the set of resolvants {a ] } and the fe ature structure a[F: [D, G: [D] really represents the empty set of feature structures. 8 To make our terminology precise, let us call feature structures such as a'[F: +] , a'[F : -] , a\"[F : +] 6 A second problem with the approach is that it provides no way to attach features to multiply inherited types. So if ne-1ist_quant has some features which are not inherited from either ne-1ist or lisLquant, then there is no position in either path of types to which these features can be attached . 7 Such disjunctive appropriateness specifications are allowed, at least internally, in the Troll system [9] . 8 Note that this last feature structure would be considered \"well-typed\" in ALE. For ALE, one must assume If we use a specialized feature structure unifier, then there exists the possibility of building in type inferencing as part of unification. If all unification is simply term unification, however, then we don't have this option. We need all type inferencing to be static, i.e., applied at compile time. 1 0 So when two feature structures which satisfy appropriateness conditions unify, the result of this unification must also satisfy appropriateness conditions. As shown in Gerdemann & King [1 1] and King [16] , this is indeed the case for resolved feature structures. Intuitively, the reason for this is quite simple. Type inferencing in a system like ALE has the effect of increasing the specificity of types on certain nodes in a feature structure. If all of these types are already maximally specific, then ALE-style type inferencing could only apply vacuously. Minimizing Disj unctions We have now seen two instances in which feature structures may need to be multiplied out into disjunctive possibilities. First, this may arise as a result of eliminating multiple inheritance from the type hierarchy. And second, as a result of the type resolution which is needed in order to ensure static typing. Now in this section, I discuss how the need for this disjunction can be reduced by the technique of unextension \u00a73.l and by unfilling \u00a73.2. And then in \u00a73. 3, I show how the remaining disjunctions can at least sometimes be efficiently represented by using distributed disjunctions. 10 Note, for the sake of comparison, that type inferencing is not static in ALE. The unification of well-typed feature structures is not guaranteed to be well-typed. It is, in fact, not even guaranteed to be well-typable. Thus, the ALE unifier must do type inferencing at run time. U nextension extension of a feature structure a to be a feature structure in which the type on each node of a has been replaced by a species subsumed by that type. Now, let us define the extensions of a set of feature structures S as the set of all extensions of the members of S. And then define the unextension of a set of feature structures S as the minimal cardinality set of feature structures S' such that extensions(S' ) = S. 1 1 So whenever a feature structure is resolved to a large disjunction of feature structures S, we can normally compact this disjunction back down to a much smaller unextended set S'. Since the extensions of S and S' are the same, it is clear that these two sets of feature structures represent the same information. As a simple-but extremely commonly occurring-example, consider a feature structure F, all of whose extensions are well-typed . In this case, the set of resolvants of F is exactly the set of extensions of F. So the unextended set of resolvants of F is simply { F} . 1 2 So resolving and then unextending F appears at first to accomplish nothing. But, in fact, there is a gain. Initially, with the feature structure F we had no guarantee that static typing would be safe. But with the resolved-unextended set {F}, we now know that there are no non-well typed extensions, so there will never be a need for run-time type inferencing. As another example, consider the set of resolvants that HPSG allows for: head-st ruc[HEAD-DTR: sign, COMP-DTRS : elist] Since the only subtype of head-struc for which elist is an appropriate value on comp-dtrs is head-comp-_ struc, we get the following set of resolvants: { head-comp-struc[HEAD-DTR: word, COMP-DTRS : elist], head-comp-struc[HEAD-DTR : phrase, COMP-DTRS : elist]}. This two element set corresponds exactly to the set of extensions for the following one element unextended set: { head-comp-struc[HEAD-DTR: sign, COMP-DTRS : elist]} So the combination of resolving and unextending simply has the effect of bumping the top level _ type from head-struc to head-comp-struc. This then rules out the malformed feature structure that might have been obtained, for example, by unification with a feature structure of type head-filler-struc. Consider now the disjunctions that are introduced by compiling out multiple inheritance. -Recall that this technique involves eliminating intermediate types from the hierarchy. It does not remove any species from the hierarchy. Thus, regardless of whether or not multiple inheritance has been compiled out, the resolvants of a feature structure F will be exactly the same. Since, unextension involves replacing species on nodes with intermediate types, the possibilities for unextending a set of feature structures will be reduced when some intermediate types have been removed, So it turns out that compiling out multiple inheritance actually introduces disjunction in a rather indirect manner. Unfilling Another operation that can be used to reduce the need for disjunction is unfilling, which is the reverse of Carpenter's [3] fill operation. In general, the purpose of unfilling is to keep feature structures small. If a feature in a feature structure has a value which is no more specific than the appropriateness specification would require, then-assuming no reentrancies would be eliminated and no dangling parts of the feature structure would be created-that feature and its value may be removed. So, in HPSG for example, if the AUX feature in a feature structure of type verb has the value boolean, then this AUX feature can be removed. Unfilling is most important, however, when it turns out that eliminating features allows us to further apply unextension to eliminate disjunctions. For example, given the type hierarchy and appropriateness specification in fig. 4 So these two features can be unfilled to give us the new set of resolvants {a', a\" } . This new set of resolvants can now be unextended to the set {a } . There is clearly a great deal more that can be said about unfilling and about the class of unfilled feature structures. The issues, however, are not specific to the problem of term encoding. So I will simply refer the reader to the discussion in Gerdemann & King [11] and Gotz [12] . The idea is that if the nth alternative is chosen for a disjunction of a particular name, then then nth alternative has to be chosen uniformly for all other instances of disjunction with the same name. [14] ). This version of distributed disjunction, however, is particularly simple since only the type labels are involved. It is not at all difficult to modify a graph unification algorithm in order to handle such disjunctions. Such a modified unification algorithm is used, for example, in the Troll system [9] . Distributed Disjunctions Unextension and unfilling can be used to eliminate quite a lot of disjunctions. Unfortunately, not all disjunctions can be eliminated with these techniques. But still, as noted in Gerdemann & King [10] [11], the remaining disjunctions, have a rather special property. All of the resolvants of a feature structure have the same shape. They differ only in the types labelling the nodes. In a graph-unification based approach, this property can be used to allow the use of a relatively simple version of distributed ( or named) disjunction. This device can be used to push top level disjunctions down to local, interacting disjunctions as in this example: Distributed disjunctions have been discussed in a fair amount of recent literature ([17], [6] , [8] , For term-represented feature structures, however, it will not be possible to directly encode such distributed disjunctions. 14 So rather than encoding distributed disjunctions in a feature 13 The example is a little unrealistic since the features HEAD and TAIL could be unfilled. To make the example more realistic, imagine the feature structures embedded in a larger feature structure and imagine that the values of HEAD and TAIL are reentrant with other parts of this feature structure, so that these features could not be unfilled without breaking these reentrancies. 14 Actually there is an alternative representation for types that would allow a limited amount of direct encoding of distributed disjunctions. Fo llowing the basic idea of Mellish [18] , one could represent each type as a set of species encoded as a vset, where a vset is a term vset(Xo , X1 , ... , XN ), with the conditions that:  Suppose now, that we want to use this feature structure as the \u2022 lexical entry for the word w. For this simple example, we can encode this with just one definite clause attachment: 16 . \u2022 Xo = 0 \u2022 XN = 1 \u2022 Xi = Xi- lex(w, b(X, a(Y) )) :p(X, Y ) . p(d, a1 (_) ). p(e(_) ' _ ) . One should note here the similarity to distributed disjunctions. The term b(X , a(Y) ) rep resents the underlying shape of the feature structure and the defining clauses for p encode dependencies between types. It is, in fact, rather surprising that this division is even possible. One of the features of the types-as-paths encoding is that the features are bundled\u2022 together with the types that introduce them. So one might not have expected to see these two types of information unbundled in this manner. Conclusions Some previous approaches to term encoding of typed feature structures have enforced restric tions against multiple inheritance and against having having more specific feature-value dec larations on subtypes. But such restrictions make typing virtually useless for encoding any meaningful constraints. The only restriction imposed in the present approach is the feature introduction condition, which is also imposed in ALE ([4]). In fact, even this minor restriction could be eliminated if we were to allow somewhat less efficient definite clause attachments. We have seen that in order to enforce constraints encoded in the appropriateness specifica tions, it will sometimes be necessary to use definite clause attachments to encode disjunctive possibilities. Practical experience with the Troll system suggests that not many such attach ments will be needed. Nevertheless, they will arise and will therefore need to be processed efficiently. Certainly options such as delaying these goals or otherwise treating them as con straints can be explored. In fact, one of the main advantages of having a term encoding is that so many options are available from all of the literature on efficient processing of logic programs. So the approach to term encoding presented here should really be viewed as just the first step in the direction of efficient processing of typed feature structure grammars.",
    "abstract": "",
    "countries": [
        "Germany"
    ],
    "languages": [
        ""
    ],
    "numcitedby": "16",
    "year": "1995",
    "month": "September 20-24",
    "title": "Term Encoding of Typed Feature Structures"
}