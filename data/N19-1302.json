{
    "article": "Question Answering (QA) naturally reduces to an entailment problem, namely, verifying whether some text entails the answer to a question. However, for multi-hop QA tasks, which require reasoning with multiple sentences, it remains unclear how best to utilize entailment models pre-trained on large scale datasets such as SNLI, which are based on sentence pairs. We introduce Multee, a general architecture that can effectively use entailment models for multi-hop QA tasks. Multee uses (i) a local module that helps locate important sentences, thereby avoiding distracting information, and (ii) a global module that aggregates information by effectively incorporating importance weights. Importantly, we show that both modules can use entailment functions pre-trained on a large scale NLI datasets. We evaluate performance on MultiRC and OpenBookQA, two multihop QA datasets. When using an entailment function pre-trained on NLI datasets, Multee outperforms QA models trained only on the target QA datasets and the OpenAI transformer models. Introduction How can we effectively use textual entailment models for question answering? Previous attempts at this have resulted in limited success (Harabagiu and Hickl, 2006; Sacaleanu et al., 2008; Clark et al., 2012) . With recent large scale entailment datasets (Bowman et al., 2015; Williams et al., 2018; Khot et al., 2018) pushing entailment models to high accuracies (Chen et al., 2017; Parikh et al., 2016; Wang et al., 2017) , we re-visit this challenge and propose a novel method for repurposing neural entailment models for QA. A key difficulty in using entailment models for QA turns out to be the mismatch between the inputs to the two tasks: large-scale entailment datasets are typically framed at a sentence level, whereas question answering requires verifying whether multiple sentences, taken together as a premise, entail a hypothesis. There are two straightforward ways to address this mismatch: (1) aggregate independent entailment decisions over each premise sentence, or (2) make a single entailment decision after concatenating all premise sentences. Neither approach is fully satisfactory. To understand why, consider the set of premises in Figure 1 , which entail the hypothesis H c . Specifically, the combined information in P 1 and P 3 entails H c , which corresponds to the correct answer Cambridge. On one hand, aggregating independent decisions will fail because no individual premise entails H C . On the other hand, simply concatenating premises to form a single paragraph will fail because distracting information in P 2 and P 4 can muddle useful information in P 1 and P 3. An effective approach, therefore, must recognize relevant sentences (i.e., avoid distracting ones) and compose their sentence-level information. Our solution to this challenge is based on the observation that a sentence-level entailment function can be re-purposed for both recognizing relevant sentences, and for computing sentence-level representations. Both tasks require comparing in-formation in a pair of texts, but the objectives of the comparison are different. This means we can take an entailment function that is trained for basic entailment (i.e., comparing information in texts), and adapt it to work for both recognizing relevance and computing representations. Thus, this architecture allows us to incorporate advances in entailment architectures and to leverage pretrained models obtained using large scale entailment datasets. To this end, we propose a general architecture that uses a (pre-trained) entailment function f e for multi-sentence QA. Given a hypothesis statement H qa representing a candidate answer, and the set of premise sentences {P i }, our proposed architecture uses the same function f e for two components: (a) a sentence relevance module that scores each P i based on its potential relevance to H qa , with the goal of weeding out distractors; and (b) a relevance-weighted aggregator that combines entailment information from multiple P i . Thus, we build effective entailment aware representations of larger contexts (i.e., multiple sentences) from those of small contexts (i.e., individual sentences). The main strength of our approach is that, unlike standard attention mechanisms, the aggregator module uses the attention scores from the relevance module at multiple levels of abstractions (e.g., multiple layers of a neural network) within f e , using join operations that compose representations at each level. We refer to this multilevel aggregation of textual entailment representations as Multee (pronounced multi). Our implementation of Multee uses ESIM (Chen et al., 2017) , a recent sentence-level entailment model, pre-trained on SNLI and MultiNLI datasets. We demonstrate its effectiveness on two challenging multi-sentence reasoning datasets: MultiRC (Khashabi et al., 2018) and OpenBookQA (Mihaylov et al., 2018) . Multee using ELMo contextual embeddings (Peters et al., 2018) matches state-of-the-art results achieved with large transfomer-based models (Radford et al., 2018) that were trained on a sequence of large scale tasks (Sun et al., 2019) . Ablation studies demonstrate that both relevance scoring and multi-level aggregation are valuable, and that pre-training on large entailment corpora is particularly helpful for OpenBookQA. This work makes three main contributions: (i) A novel approach to use pre-trained entailment models for question answering. (ii) A model that incorporates local (sentence level) entailment decisions with global (document level) entailment decisions to effectively aggregate information for multi-hop QA task. (iii) An empirical evaluation that shows entailment based QA can achieve stateof-the-art performance on two challenging multihop QA datasets, OpenBookQA and MultiRC. Question Answering using Entailment Non-extractive question answering can be seen as a textual entailment problem, where we verify whether a hypothesis constructed out of a question and a candidate answer is entailed by the knowledge-a collection of sentences 1 in the source text. The probability of an answer A, given a question Q, can be modeled as the probability of a set of premises {P i } entailing a hypothesis statement H qa constructed from Q and A: Pr[A | Q, {P i }] \u2206 = Pr[{P i } H qa ] (1) Here we use to denote textual entailment. Given QA training data, we can then learn a model that approximates the entailment probability Pr[{P i } H qa ]. Can one build an effective QA model g e using an existing entailment model f e that has been pretrained on a large-scale entailment dataset? Figure 2 illustrates two straightforward ways of doing so, using f e as a black-box function: Use f e to check how much each sentence P i entails H qa on its own, and aggregate these local entailment decisions, for instance, using a max operation. g e ({P i }, H qa ) = max i f e (P i , H qa ) (2) (ii) Concatenate Premises (Concat): Combine the premise sentences in a sequence to form a single large passage P , and use f e to check whether this passage as a whole entails the hypothesis H qa , making a single entailment decision: g e ({P i }, H qa ) = f e (P, H qa ) (3) Our experiments reveal, however, that neither approach is an effective means of using pre-trained entailment models for QA (see Table 1 ). For the example in Figure 1 , Max model would not be able to consider information from P1 and P3 together. Instead, it will pickup Silicon Valley as the answer since P2 is close to H s , \"Facebook was launched in Silicon Valley\". Similarly, Concat would also be muddled by distracting information in P2, which will weaken its confidence in answer Cambridge. Therefore, without careful guidance, simple aggregation can easily add distracting information into the premise representation, causing entailment to fail. This motivates the need for new, effective mechanisms for global reasoning over a collection of premises. Our Approach: Multee We propose a new entailment based QA model, Multee, with two components: (i) a sentence relevance model, which learns to focus on the relevant sentences, and (ii) a multi-layer aggregator, which uses an entailment model to obtain multiple layers of question-relevant representations for the premises and then composes them using the sentence-level scores from the relevance model. Finding relevant sentences is a form of local entailment between each premise and the answer hypothesis, whereas aggregating questionrelevant representations is a form of global entailment between all premises and the answer hypothesis. This means, we can effectively re-purpose the same pre-trained entailment function f e for both components. Figure 3 shows an architecture that uses multiple copies of f e to achieve this. Sentence Relevance Model The goal of this module is to identify sentences in the paragraph that are important for the given hypothesis. As shown in Figure 1 , this helps the global module aggregate relevant content while reducing the chances of picking up distracting information. A sentence is considered important if it contains information that is relevant to answering the question. In other words, the importance of a sentence can be modeled as its entailment probability, i.e., how well the sentence by itself supports the answer hypothesis. We can use a pre-trained entailment model to obtain this. The importance \u03b1 i of a sentence P i can be modeled as: \u03b1 i = f e (P i , H qa ) (4) This can be further improved by modeling the sentence with its surrounding context. This is especially useful for passage-level QA, where the neighboring sentences provide useful context. Given a premise sentence P i , the entailment function f e computes a single hypothesis-aware representation x i containing information in the premise that is relevant to entailing the answer hypothesis H qa . This is essentially the output of last layer of neural function f e before projecting it to logits. We denote this part of f e that outputs last vector representation as f ev and full f e that gives entailment probability as f ep . We use these hypothesis-aware x i vectors for each sentence as inputs to a BiLSTM producing a contextual representation c i for each premise sentence P i , which is then fed to a feedforward layer that predicts the sentence-level importance as: \u03b1 i = softmax(W T c i + b) (5) The components for generating x i are part of the original entailment function f e and can be pretrained on the entailment dataset. The BiLSTM to compute c i and the parameters W and b for computing \u03b1 i are not part of the original entailment function and thus can only be trained on the target QA task. We perform this additional contextualization only when sentences form contiguous text. Additionally, for datasets such as MultiRC, where the relevant sentences have been marked, we introduce a loss term based on the true relevance label and predicted weights, \u03b1 i . Multi-level Aggregation The goal of this module is to aggregate representations from important sentences in order to make a global entailment decision. There are two key questions to answer: (1) how to combine the sentence-level information into a paragraph-level representation and (2) how to use the sentence relevance weights {\u03b1 i }. Most entailment models include many layers that transform the input premise and the hypothesis. A typical neural entailment stack includes en- coding layers that independently generate contextual representations of the premise and the hypothesis, followed by some cross-attention layer that yields relationships between the premise and hypothesis words, and additional layers that use this cross-attention to generate premise attended representations of the hypothesis and vice versa. The final layers are classification layers which determine entailment based on the representations from the previous layer. Each layer thus generates intermediate representation that captures different type of entailment related information. This presents us with a choice of multiple points for aggregation. Figure 3 illustrates our approach for aggregating sentence-level representations into a single paragraph level representation. For each premise P i in the passage, we first process the pair (P i , H qa ) through the entailment stack (f ev ) resulting in a set of intermediate representations { Xi } for each layer . We can choose a particular layer to be the aggregation layer. We then compute a weighted combination of the sentence-level outputs at this layer { Xi } to produce a passage-level representation \u1ef8 . The weights for the sentences are obtained from the Sentence Relevance model. We refer to this as a join operation as shown in the Figure 3 . Layers of the entailment function f ev that are below the join operate at a sentencelevel, while layers above the join now operate over paragraph-wise representations. The final layer (i.e. the top most layer) of f ev thus gives us a vector representation of the entire passage. This type of join can be applied at multiple layers resulting in paragraph vectors that correspond to multiple levels of aggregation. We concatenate these paragraph vectors and pass them through a feedforward network projecting them down to logits, that can be used to compute the final passage wide entailment probabilities. Join Operations Given a set of sentence-wise outputs from the lower layer { Xi } and the corresponding sentencerelevance weights {\u03b1 i }, the join operation combines them into a single passage-level representation \u1ef8 , which can be directly consumed by the layer above it in the stack. The specifics of the join operation depends on the shape of the outputs from the lower layer, and the shape of the inputs expected by the layer after the join. Here we show four possible join operations, one for each layer. The ones defined for Score Layer and Embedding Layer can be reduced to black-box baselines, while we use the other two in Multee. Score Layer: The score layer outputs the entailment probabilities {s i } for each premise to hypothesis independently, which need to be joined to one entailment score. One way to do this is to simply take a weighted maximum of the individual entailment probabilities. So we have Xi = s i \u2200i and \u1ef8 = max i \u03b1 i s i . This reduces to black-box Max model (Equation 2 ) when using {\u03b1 i } = 1. Embedding Layer: The embedding layer outputs a sequence of embedded vectors of [ Pi ] 2 one sequence for each premise P i and another sequence of embedded vectors [ Hqa ] for the answer hypothesis H qa . A join operation in this case scales each embedded vector in a premise by its relevance weight and concatenates them together to For non-contextual word embeddings, this reduces to Concat Premises (Eq. 3) when {\u03b1 i } = 1. Final Layer (FL): The final layer in the entailment stack usually outputs a single vector h which is then used in a linear layer and softmax to produce label probabilities. The join operation here is a weighted sum of the premise-level vectors. So we have Xi = hi \u2200i and \u1ef8 = i \u03b1 i hi . This is similar to a standard attention mechanism, where attended representation is computed by summing the scaled representations. However, such scaled addition is not possible when the outputs from lower layers are not of the same shapes, as in the following case. Cross Attention Layer (CA): Cross-attention is a standard component of many entailment and reading comprehension models. This layer produces three outputs: (i) For each premise P i , we get a hypothesis to premise cross attention matrix M hp i with shape (h \u00d7 p i ), where h is the number of hypothesis tokens, and p i is the number of tokens in premise P i ; (ii) for each premise P i , we get a sequence of vectors [ Pi ] that corresponds to the token sequence of the premise P i ; and (iii) for the hypothesis, we get a single sequence of vectors [ Hqa ] that corresponds to its token sequence. M hp i attention matrix was generated by cross attention from [ Hqa ] to [ Pi ] . The join operation in this layer produces a cross attention matrix that spans the entire passage, i.e., has shape (h \u00d7 p), where p is the total number of tokens across all premises. The operation first scales the cross-attention matrices by the sentence-relevance weights {\u03b1 i } in order to \"tone down\" the influence of distracting/irrelevant sentences, and then re-normalizes the final matrix: Xi = (M hp i , [ Pi ], [ Hqa ]) \u2200i M hp = \u03b1 i M hp 1 ; . . . ; \u03b1 i M hpn M hp ij = M hp ij k M hp ik [ P ] = [ P1 ]; [ P2 ]; ...; [ Pn ] \u1ef8 = (M hp , P , Hqa ) where M hp ij is i th row and j th column of M hp . Multee's multi-layer aggregator module uses join operations at two levels: Cross Attention Layer (CA) and Final Layer (FL). The two corresponding aggregators share parameters up till the lower of the two join layers (CA in this case), where they both operate at the sentence level. Above this layer, one aggregator switches to operating at the paragraph level, where it has its own, unshared parameters. In general, if Multee were to aggregate at layers i1 , i2 , . . . , ik , then the aggregators with joins at layers and respectively could share parameters at layers 1, . . . , min{ , }. Implementation Details Multee uses the ESIM stack as the entailment function pre-trained on SNLI and MultiNLI for both the relevance module and for the multi-layer aggregator module. It uses aggregation at twolevels, one at the cross-attention level (CA) and one at the final layer (FL). All uses of the entailment function in Multee are initialized with the same pre-trained entailment model weights. The embedding layer and the BiLSTM layer process paragraph-level contexts but processing at higher layers are done either at premise level or paragraph-level depending on where the join operation is performed. Experiments Datasets: We evaluate Multee on two datasets, OpenBookQA (Mihaylov et al., 2018) and Mul-tiRC (Khashabi et al., 2018) , both of which are specifically designed to test reasoning over multiple sentences. MultiRC is paragraph-based multiple-choice QA dataset derived from varying topics where the questions are answerable based on information from the paragraph. In MultiRC, each question can have more than one correct answer choice, and so it can be viewed as a binary classification task (one prediction per answer choice), with 4,848 / 4,583 examples in Dev/Test sets. OpenBookQA, on the other hand, has multiple-choice science questions with exactly one correct answer choice and no associated paragraph. As a result, this dataset requires the relevant facts to be retrieved from auxiliary resources including the open book of facts released with the paper and other sources such as WordNet (Miller, 1995) and ConceptNet (Speer and Havasi, 2012) . It contains 500 questions in the Dev and Test sets. (Mihaylov et al., 2018) 53.9 48.9 --KER (Mihaylov et al., 2018) 55 Preprocessing: For each question and answer choice, we create an answer hypothesis statement using a modified version of the script used in Sc-iTail (Khot et al., 2018) construction. We wrote a handful of rules to better convert the question and answer to a hypothesis. We also mark the span of answer in the hypothesis with special begin and end tokens, @@@answer and answer@@@ respectively 3 . For MultiRC, we also apply an offthe-shelf coreference resolution model 4 and replace the mentions when they resolve to pronouns occurring in a different sentence 5 . For Open-BookQA, we use the exact same retrieval as released by the authors of OpenBookQA 6 and use the OpenBook and WordNet as the knowledge source with top 5 sentences retrieved per query. Training Multee: For OpenBookQA we use cross entropy loss for labels corresponding to 4 answer choices. For MultiRC, we use binary cross entropy loss for each answer-choice separately since in MultiRC each question can have more than one correct answer choice. The entailment components are pre-trained on sentence-level entailment tasks and then fine-tuned as part of endto-end QA training. The MultiRC dataset includes sentence-level relevance labels. We supervise the Sentence Relevance module with a binary cross entropy loss for predicting these relevance labels when available. We used PyTorch (Paszke et al., 2017) and AllenNLP to implement our models and ran them on Beaker 7 . For pre-training we use the same hyper-parameters of ESIM (Chen et al., 2017) as available in implementation of AllenNLP (Gardner et al., 2017) and fine-tune the model parameters. We do not perform any hyper-parameter tuning for any of our models. We fine-tune all layers in ESIM except for the embedding layer. Models Compared: We experiment with Glove (Pennington et al., 2014) and ELMo (Peters et al., 2018) embeddings for Multee and compare with following three types of systems: (A) Baselines using entailment as a black-box We use the pre-trained entailment model as a black-box in two ways: concatenate premises (Concat) and aggregate sentence level decisions with a max operation (Max). Both models were also pre-trained on SNLI and MultiNLI datasets and fine-tuned on the target QA datasets with same pre-processing. (B) Previously published results: For MultiRC, there are two published baselines: IR (Information Retrieval) and LR (Logistic Regression). These simple models turn out to be strong baselines on this relatively smaller sized dataset. For Open-BookQA, we report published baselines from (Mihaylov et al., 2018) : Question Match with ELMo (QM + ELMo), Question to Answer ESIM with ELMo (ESIM + ELMo) and their best result with the Knowledge Enhanced Reader (KER). (C) Large Transformer based models: We compare with OpenAI-Transformer (OFT), pre-trained on large-scale language modeling task and finetuned on respective datasets. A contemporaneous work, 8 which published these transformer results, also fine-tuned this transformer further on a large scale reading comprehension dataset, RACE (Lai et al., 2017) , before fine-tuning on the target QA datasets with their method, Reading Strategies. Results Table 1 summarizes the performance of all models. Multee outperforms the black-box entailment baselines (Concat and Max) that were pretrained on the same data, previously published baselines, OpenAI transformer models. We note that the 95% confidence intervals around baseline accuracy for OpenBookQA and MultiRC are 4.3% and 1.3%, respectively. On OpenBookQA test set, Multee with GloVe outperforms ensemble version of OpenAI transformer by 3.0 points in accuracy. It also outperforms single model version of Reading Strategies system and is comparable to their ensemble version. On MultiRC dev set, Multee with ELMo outperforms ensemble version of OpenAI transformer by 1.9 points in F1a, 2.7 in F1m and 6.3 in EM. It also outperforms single model version of Reading Strategies system and is comparable to their ensemble version. Recall that the Reading Strategies results are reported with an additional fine-tuning on another larger QA dataset, RACE (Lai et al., 2017) aside from the target QA datasets we use here. While ELMo contextual embeddings helped in MultiRC, it did not help OpenBookQA. We believe this is in part due to the mismatch between our ELMo training setup where all sentences are treated as a single sequence, which, while true in  MultiRC, is not the case in OpenBookQA. In general, gains from Multee are more prominent in OpenBookQA than in MultiRC. We hypothesize that a key contributor to this difference is distraction being a lesser challenge in Mul-tiRC, where premise sentences come from a single paragraph whose other sentences are often irrelevant and rarely distract towards incorrect answers. OpenBookQA has a noisier set of sentences, since an equal number of sentences is retrieved for the correct and each incorrect answer choice. Ablations Relevance Model Ablation. Table 2 shows the utility of the relevance module. We use the same setting as the full model (aggregation at Cross Attention (CA) and the Final Layer (FL)). As shown in the table, using the relevance module weights (\u03b1 i ) leads to improved accuracy on both datasets (substantially so in OpenBookQA) as compared to ignoring the module, i.e., setting all weights to 1 (\u03b1 i ). In MultiRC, we show that the additional supervision for the relevance module leads to even further improvements in score. Multi-Level Aggregator Ablation. Multee performs aggregation at two levels: Cross Attention Layer (CA) and Final Layer (FL). We denote this by CA+FL. To show that multi-level aggregation is better than individual aggregations, we train models with aggregation at only FL and at only CA. Table 3 shows that multi-layer aggregation is better than CA or FL alone on both the datasets. Effect of Pre-training One of the benefits of using entailment based components in a QA model is that we can pre-train them on large scale entailment datasets and finetune them as part of the QA model. Table 4 shows that such pre-training is valuable. The model trained from scratch is substantially worse in the case of OpenBookQA, highlighting the benefits of our entailment-based QA model. Multee benefits come from two sources: (i) Re-purposing of entailment function for multisentence question answering, and (ii) transferring from a large-scale entailment task. In the case of OpenBookQA, both are helpful. For MultiRC, only the first is a significant contributor. Table 5 shows that re-purposing was a bigger factor for MultiRC, since Max and Concat models do not work well when trained from scratch.  scores for a question in MultiRC. Overall, we find that two types of behaviors emerge from different loss functions. For instance, trying to minimize the sum of attention probability mass on irrelevant sentences i.e. i \u03b1 i (1 \u2212 y i ), called IR Sum Loss, causes the attention scores to become \"peaky\" i.e, high for one or two sentences, and close to zero for others. This leads to higher precision but at significantly lower recall for the QA system, as it now uses information from fewer but highly relevant sentences. Binary cross entropy loss (BCE) allows the model to attend to more relevant sentences thereby increasing recall without too much drop in precision. Failure Cases. As Figure 5 shows, our model with BCE loss tends to distribute the attention, especially to sentences close to the relevant ones. We hypothesize that the model is learning to use the contextualized BiLSTM representations to incorporate information from neighboring sentences, which is useful for this task and for passage understanding in general. For example, more than 60% of Dev questions in MultiRC have at least one adjacent relevant sentence pair. Figure 4a illustrates this behavior. On the other hand, if the relevant sentences are far apart, the model finds it difficult to handle such long-range cross sentence dependencies in its contextualized representations. As a result, it ends up focusing attention on the most relevant sentence, missing out on other relevant sentences (Figure 4b ). When these unattended but relevant sentences contain the answer, the model fails. Related Work Entailment systems have been applied to questionanswering before but have only had limited success (Harabagiu and Hickl, 2006; Sacaleanu et al., 2008; Clark et al., 2012) in part because of the small size of the early entailment datasets (Dagan et al., 2006 (Dagan et al., , 2013)) . Recent large scale entailment datasets such as SNLI (Bowman et al.,   2015) and MultiNLI (Williams et al., 2018) have led to many new powerful neural entailment models that are not only more effective, but also produce better representations of sentences (Conneau et al., 2017) . Models such as Decomposable Attention (Parikh et al., 2016) and ESIM (Chen et al., 2017) , on the other hand, find alignments between the hypothesis and premise words through crossattention. However, these improvements in entailment models have not yet translated to improvements in end tasks such as question answering. SciTail (Khot et al., 2018) was created from a science QA task to push for models with a direct impact on QA. Entailment models trained on this dataset show minor improvements on the Aristo Reasoning Challenge (Clark et al., 2018; Musa et al., 2018) . However, these QA systems make independent predictions and can not combine in-formation from multiple supporting sentences. Combining information from multiple sentences is a key problem in language understanding. Recent Reading comprehension datasets (Welbl et al., 2018; Khashabi et al., 2018; Yang et al., 2018; Mihaylov et al., 2018) explicitly evaluate a system's ability to perform such reasoning through questions that need information from multiple sentences in a passage. Most approaches on these tasks perform simple attention-based aggregation (Mihaylov et al., 2018; Song et al., 2018; Cao et al., 2018) and do not exploit the entailment models trained on large scale datasets. Conclusions Using entailment for question answering has seen limited success. Neural entailment models are designed and trained on tasks defined over sentence pairs, whereas QA often requires reasoning over longer texts spanning multiple sentences. We propose Multee, a novel QA model that addresses this mismatch. It uses an existing entailment model to both focus on relevant sentences and aggregate information from these sentences. Results on two challenging QA datasets, as well as our ablation study, indicate that entailment based QA can achieve state-of-the-art performance and is a promising direction for further research. Acknowledgements This work is supported in part by the National Science Foundation under Grant IIS-1815358. The computations on beaker.org were supported in part by credits from Google Cloud. ",
    "abstract": "Question Answering (QA) naturally reduces to an entailment problem, namely, verifying whether some text entails the answer to a question. However, for multi-hop QA tasks, which require reasoning with multiple sentences, it remains unclear how best to utilize entailment models pre-trained on large scale datasets such as SNLI, which are based on sentence pairs. We introduce Multee, a general architecture that can effectively use entailment models for multi-hop QA tasks. Multee uses (i) a local module that helps locate important sentences, thereby avoiding distracting information, and (ii) a global module that aggregates information by effectively incorporating importance weights. Importantly, we show that both modules can use entailment functions pre-trained on a large scale NLI datasets. We evaluate performance on MultiRC and OpenBookQA, two multihop QA datasets. When using an entailment function pre-trained on NLI datasets, Multee outperforms QA models trained only on the target QA datasets and the OpenAI transformer models.",
    "countries": [
        "United States"
    ],
    "languages": [],
    "numcitedby": "26",
    "year": "2019",
    "month": "June",
    "title": "Repurposing Entailment for Multi-Hop Question Answering Tasks"
}