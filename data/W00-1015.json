{
    "article": "We present an application independent dialogue engine that reasons on application dependent knowledge sources to calculate predictions about how a dialogue might continue. Predictions are language independent and are translated into language dependent structures for recognition and synthesis. Further, we discuss how the predictions account for different kinds of dialogue, e.g., question-answer or mixed initiative. Introduction The computerized spoken information systems (or Spoken Dialogue System--SDS) that we will consider in this paper are systems where a computer acts as the operator of some service and interacts with a user in natural language, e.g., switch board, directory assistance, or ticket service. Before an SDS can provide its information, it needs to acquire data from the user, e.g., customer name and number, birth date, service location, or service date. We call these parameter values. In an SDS they are acquired orally and speech recognition is used to decode the speech signal into words. A dialogue manager facilitates the negotiation of parameter values between a user and an SDS. We emphasize keeping our dialogue manager application and language independent, thus we factored out the independent information into two components. A dialogue engine calculates predictions for how to continue a dialogue from dependent knowledge sources (e.g., dialogue grammar and history, application description). A pragmatic interpreter maps syntactic/semantic interpretation results onto predictions. Our predictions are called dialogue primitives; GEN-primitives predict system utterances and REC-primitives predict user utterances. They are language independent and on both the recognition and the generation side, other modules translate them into language dependent structures. In this paper, we will discuss the kinds of primitives our dialogue manager calculates and how they account for different kinds of dialogue, e.g., question-answer or mixed initiative. 2 Background First, we discuss our system architecture and data flow between modules. Second, we present the application description of a movie service, which we will use for the examples in later sections. Third, we present some of our current primitives, and fi-naUy, we describe the dialogue engine and how it uses the application description and other sources to calculate dialogue primitives. 2.1 System Architecture Our system architecture is presented in Figure 1 . The dialogue manager takes an application description (Section 2.2) and a set of dialogue strategies (Sections 3 and 4) as input--both provided by the service designer. The application description describes the parameters needed by the service and is necessarily application dependent. The dialogue strategies contain directions for how the dialogue shall proceed in certain situations. For example, whether to ask for confirmation or spelling of a badly recognized parameter value or whether to generate system or user directed dialogue. The output of our dialogue manager is a bag of abstract, language independent primitives. On the generation side they encode the next system utterance and a response generator translates the GEN-primitives into text, which is then synthesized. On the recognition side, the RECprimitives represent the dialogue manager's predictions about the next user utterance. RECprimitives are translated into (recognition) contexts and grammars for speech recognition and they may activate sub-components of a synsem grammar. After speech recognition has taken place, the dialogue engine must be told which predictions came true, thus the pragmatic interpreter maps the output of synsem interpreter onto a subbag of REC-primitives, which is then returned to the dialogue engine for further processing (Section 2.4). Application Description The application description (AD) specifies the tasks that a service can solve and the parameter values needed to solve them. The AD for a movie service is presented in Figure 2 . Our representation is an extended version of and-or trees 1 and in Figure 2 , the U-shaped symbols represent and-relations, while the V-shaped symbols represent or-relations. Thus, this movie service can perform three tasks: selling tickets or providing movie or theatre information. If the user wants to buy tickets, the system needs to acquire six pararneter values, e.g., the show time, the date, and the name of the film. Date and show time can be acquired in several ways. For example, a date can be a simple date (e.g., \"November 17th ~) or a combination of day of the week and week (e.g., \"Wednesday this week.\"). The nodes keep state information. Open nodes have not yet been negotiated, topic nodes are being negotiated, and closed nodes have been negotiated. The currently active task has status active. Parameters can be retrieved through the functions activeTask(AD), openParams(AD), closed-Params(AD), and topicParams(AD). Status(p) returns the status of parameter p. tasks(AD) and params(AD) return the task and parameter nodes. Similar hierarchical domain descriptions have been suggested in (Young et al., 1990) for a naval domain and in (Caminero-Gil et al., 1996) for an e-mall assistance domain. A tree-like organization of the domain is sufficent for the information retrieval domains, which we are currently considering. We expect, however, that in future work we 1Extensions include has-a relations. will need to switch to a semantic network structure or since our future research includes automatic generation of system utterances from our dialogue primitives, we hope to be able to utilize the ontology and domain organization work, which has proven so useful for text generation (Bateman et al., 1994; Bateman et al., 1995) , for both dialogue management and text generation. Dialogue Primitives Following the procedure outlined in Section 2.4, the dialogue manager calculates a bag of primitives for each turn and speaker. Our current collection is motivated through our experience with several domains, e.g., movie service, horoscope service, and directory assistance. The collection is not exhaustive and we will add primitives as wider dialogue coverage is required. Notation: A primitive is written prim-Name(p=v,n), where primName is its name; p E params(AD) U {aTask}; aTask is a special parameter whose values E tasks(AD); v is the value of p; and n is an integer denoting the number of times a primitive has been uttered. If v is uninstantiated, it is left out for readability. Unless otherwise stated, p E params(AD). GEN-Primitives Our current GEN-primitives: salutation(p=v): system opens or closes the interaction, p E {hello, goodbye}, v E {morning, day, evening}. requestValue(p): system requests a value for the paramter p. p E params(AD) U {aTask}. requestValue(p=v): system asks whether the value v of parameter p is correct. If this form is used, the system has a list of alternative values for p, and v is not a recognition result (e.g., Frankfurt am Main or Frankfurt an der Oder where Frankfurt is the recognition result.) requestValue(aTask=v), v E tasks(AD) U {repeat-PreServiceTask, useService, repeatService}: system requests a value for aTask. If v E {repeatPre-ServiceTask, useService, repeatService}, the system requests whether the user wants the pre-service task repeated, the service started (first task after pre-service task), or a new task started. requestConfirm(p=v): system asks whether the value v of parameter p is correct, v is a recog- withdrawPrornise(aTask=v): system withdraws a promise for reason v E {error}. In Section 3, we present several sample instantiations of the primitives. REC-Primitives Our current REC-primitives: requestParam(p): user requests which parameter the system requested, p E params(AD) U {null}. requestAIternatives(p): user requests possible values for parameter p. requestConffirm(aTask=n): user asks system to confirm an answer that it has given, e.g., \"Was the first answer $30?\" 0 < n < no of query results. null(): returned to the dialogue manager if the ,user does not say anything and is not ezpected to say anything, e.g., after a greeting or promise. In Section 3, we present several sample instantiations of the primitives. Dialogue Engine The dialogue engine (Hagen, 1999) consists of a reasoning engine and several knowledge sources: An AD defines an application's data-needs, a dialogue grammar defines how a dialogue may proceed at the level of speech acts, and a dialogue history is a dynamically growing parse tree of an on-going dialogue with respect to the dialogue grammar. Other knowledge sources may be required, for instance, recognition confidence or disambiguation of city names. The dialogue engine calculates the next turn by consulting and combining information from the knowledge sources. It consults with the dialogue history and the dialogue grammar in order to calculate which speech acts may continue a dialogue. Speech acts have no propositional content, thus in the context of the current dialogue history and the state of the application description, they are translated into dialogue primitives, which have content, for example, the name of a parameter and a potential value for this parameter. Here we will walk through an example of how some primitives are calculated in a simple question-answer dialogue. Example: For our example we will use the AD in Figure 2 . Assume that the task has already been negotiated and set to theatre information (i.e., activeTask(AD) = theatrelnfo), i.e., the system needs to acquire the name of the theatre and the name of the city. All other nodes in the AD are closed since they are not relevant to this task. The speech act grammar used in our system is presented in Appendix A but we will use a trivial grammar for the example. It can account for simple question-answer dialogues where a request from the system (sys) is followed by an inform from the user (usr). The system can respond to the inform with a sub-dialogue: s Dialogue(sys)--~(request(sys) + Inform(usr))* Inform(usr)--+inform(usr) + [Dialogue(sys)] The dialogue history reflects all previous negotiations (here: task theatreinfo). Dialogue(sys) request(sys) .. Inform(usr) requestValue(task) intprm.(usr) . . , informValue(task=theatrelnto) The next turn can be rooted in either the Inform(usr) after the inform(usr) or in the Dia-Iogue(sys) after Inform(usr). With all the above knowledge sources in place, the calculation of the next dialogue turn can start: 1. The last speech act in the dialogue history gives us a starting point in the grammar, thus moving forward from inform(usr), the next atomic speech act is request(sys)--either as a flat structure (i.e., request(sys) off Dialogue(sys)) or in a sub-dialogue (i.e., Dialogue(sys)-I-request(sys) off Inform(usr)). 2. Knowing that the system can request something, the dialogue engine consults with the AD for what the system can ask about. The flat strucutre (request(us)) represents negotiation of the task but since we assume that negotiation of the task is complete (i.e., Status(theatrelnfo) = active), this speech act is not interpreted into a prim-SThe star (') means that a dialogue may contain several request(sys) -I-Inform(usr) sequences. Lowercase speech acts are atomic, while others are complex. The dialogue in square brackets ([]) is optional. itive. Next we consider the sub-diaJogue structure. Both children of theatrelnfo are open (i.e., they have not been negotiatied yet) thus the system randomly chooses to pursue city whose state is changed to topic. The speech act and the parameter are combined into the primitive request-Value(city)--request a value for the parameter city (e.g., \"In which city is the theatre?\"). We chose to use the sub-dialogue structure instead of the flat strucutre to represent negotiation of parameter values since they are subordinate to the task in the sense that the task dictates which parameter values are needed. This is also the case for the real gammar (Appendix A). 3. Reasoning that a user-inform in response to a system requestValue should involve the same parameter as the system's requestValue, the information is combined to form the primitive informValue(city), i.e., the user should respond to the system request with a value for the parameter city. Let's assume that the user replied \"Hong Kong\", thus the dialogue history is expanded: Dialogue(sys) request (sys) ., Inform(usr) req uestVa lue (task),...-. intorm(u.sr). . o .Dialogue(sys) informValue(task=theatrelnto) / request(sys) . Inform(usr) requestValue(city) intorm(usr~ informValue(city& Hohg Kong) 5. Starting ~om inform(usr), the grammar returns reques't(sys) and Dialogue(sys)-t-request(sys). Since a recogniton result is available from the previous turn, the engine checks its recogution confidence. If it is high, it would consider the negotiation of city finished, change its state to closed, and discard Dialogue(sys)+request(sys) since there is nothing to be requested about a closed parameter. It would translate request(sys) into request-Value(theatre) since theatre is the only remaining open parameter. If confidence is low, the dialogue engine may decide to ask the user to confirm the recognized value. In which case, Dia-Iogue(sys)+request(sys) would be interpreted into requestConfirm(city=Hong Kong). Whether request(sys) would be interpreted or not depends on the dialogue strategies chosen by the service designer (see Sections 3 and 4). If confidence is extremely low, the dialogue engine may decide to repeat the question. In which case, request(sys) would be interpreted into re-questValue(city, 2), while the sub-dialogue structure would be discarded. 6. Any interpretation of the flat strucutre would result in the following addition to the last Dia-Iogue(sys) in the dialogue history. Our example shows how a speech act can result in several primitives depending on the context and thus how the dialogue manager dynamically reacts to external events. Although this brief description may not show it, our dialogue manager can handle mixed initiative dialogue (Hagen, 1999) . In (Hagen, 1999) , we also present our theory of taking, keeping, and relinquishing the initiative. Heisterkamp and McGlashan (1996) presented an approach that uses a similar division of functionality as we do: task (=application), contextual (=synsem + pragmatic), and pragmatic interpretation (=dialogue engine). They also use abstract parameterized units similar to ours, but they do not use a speech act grammar to calculate the units. Rather, they map contextual functions onto dialogue goals, e.g., the function new_for_system(gaalcity:munich) introduces the dialogue goal confirm(goalcity:munich). In terms of our primitievs this could be expressed as requestConfirm 0 follows informValue 0. We choose not to start our modelling at this level since we want to be able to vary what follows informValue0, e.g., requestConfirmO, requestValueABCO, or evaluate(). Primitives in Use Conceptually, GEN-primitives are calculated first and then a bag of possible responses (RECprimitives). One dialogue primitive corresponds to one information unit or communicative goal, e.g., in an information retrieval setting: providing or requesting one piece of infi)rmation. Primitives can be used individually or combined to account for more complex dialogue. Whether and how they are combined depends on the dialogue strategies specified by the service designer. In this and the following section, we will examine several such strategies and show how the primitives are combined to achieve them. Question-Answer Dialogue In the simplest case, the service designer wants a strickt question-answer dialogue: 4 Dialogue 1: Question-Answer Sys: \"Which film do you want to see?\" Int: inform Positive(theatre= Ridge.) For this type of dialogue, only the RECprimitives representing direct answers, rejects, and withdraws are calculated. In Table 1 , we present those calculated in response to the first and the third system turn. We see that, after requestValue(film), only iinformValue(film) is calculated and the pragmatic', interpreter has no chance to detect \"At the Ridge\" (even if synsem parsed it correctly) since there is no in-formExtraValue(theatre) available to map it onto. Similarly, after requescConfirm(theatre=Ridge) only informPositive (theatre=Ridge) and in-formNegative(theatre=Ridge) are available and \"R I D G E\" cannot be detected since there is no informValueABC(city) primitive present. 41n the sample dialogues, 'Sys' means system turn, 'Usr' means user turn, and 'Int' means primitives recognized and sent back to the dialogue engine from the pragmatic interpreter. GEN- Over-Answering In our experience, users frequently provide more information than explicitly asked for, thus a more flexible dialogue strategy would be to allow overanswering and Dialogue 1 could have developed as follows: Dialogue 2: Over-Answering Sys: \"Which film do you want to see?\" In Table 2 , we present the REC-primitives calculated in response to the same system turns as in Dialogue 1. In Dialogue 2, only over-answering of requestValue 0 primitives were allowed, thus \"R I D G E\" could still not be accounted for. Complex Mixed Initiative Here we consider the most complex dialogue strategy that we can currently offer: The system is able to account for complex mixed initiative dialogue (at least from a dialogue point of view In Table 3 , we present the REC-primitives calculated in response to two system utterances. Multi-Functional Turns It has been argued that speech act grammars cannot be used to describe dialogue since utterances can be multi-functional or encode more than one speech act; Speech act grammars can typically be in only one state at a time, thus they cannot capture this phenomenon (Levinson, 1981) . In an information retrieval setting such situations occur, for example, when users disregard the system utterance and provide unrelated information or when a recogniton mistake occured and the sytem asks for confirmation. Instead of answering yes or no, users frequently answer with the correct value, which implicitly disconfirms the previous value: Dialogue 4: Multi-Functional Utterances Sys: \"How many tickets?\" req uestVal ue(noOfTickets) Usr: \"I want tickets for July 4.\" I.ut: reject Request (noOf'l'ickets) + informExtraValue(date-~July 3) Sys: \"Did you say July 3?\" requestConfirm (date=July 3) Usr: \"Tomorrow!\" Int: informNegative(date=July 3) -t-correctValue(date=July 4) In the first utterance, the user both ignores the system utterance and provides some information. In the second one, she negated and correctd the system suggestion with a single word. Since we are not using the speech act grammar directly and instead interpret the speech acts into a bag of primitives, we can assign as many primitives to an utterance as necessary and are not bound by the states dictated by a grammar. This aspect of our approach becomes even more interesting when the system combines several primitives in its utterance (Section 4). Dialogue Strategies Although, the procedure outlined in Section 2.4, only shows how to calculate one primitive per system turn, the approach is, of course, not limited to this. The service designer can decide to employ mixed initiative dialogue strategies for the system utterances as well, for example, requesting or confirming several values at once or implicitly confirming values. The dialogue strategies for system utterances include choosing nodes in the application description, dealing with speech recognition results, or dealing with ambiguous data from other knowledge sources. Here we present a few examples of how the dialogue manager would combine hypotheses (for more information see (Hagen, 2001) ). Confirmation Strategies We illustrate implicit and multiple confirmation, For the first two utterances, the system has a recognition result for the parameter film with a low recognition score. Consequently, it calculates requestConfirm(film=Matrix/Buena Vista). Additionally, there are still open parameter nodes in the AD, thus the dialogue engine picks one (either at random or if the service designer has ordered them, the next one) and calculates a requestValue primitive, here requestValue(time). If the service designer allows implicit confirmation, the two primitives are combined and uttered together in one turn. If the service de. signer does not allow implicit confirmation, the dialogue engine continues the dialogue with the topic that has alread been introduced, i.e., re. questConfirm (film= Matrix/Buena Vista). 5 For its last utterance, the system has two recognition results with a low recognition score, thus for each one of them it calculates a requestConfirm primitive. If the service designer, allows multiple confirmations, they are combined and realized as one utterance. If not, the dialogue engine chooses requestConfirm(time=21:00), since this topic was introduces first. If topics are introduced in the same utterance, it pickes one at random. AD Based Strategies When requesting parameter values from the user, the system consults the application description for SThis is a conceptual account. In the implementation, the requestValue primitive would not be calcualted at all, if the service designer does not allow implicit confirmation. open nodes. If there are several open nodes, the dialogue manager can decide to keep the initiative and produce several primitives, which can be combined into one turn. If the nodes are joined with an or-relation, the text generator would translate the primitives into an utterance offering alternative ways of entering the same information. For example, \"Please tell me the show time or early or late show.\" (requestValue(time) + re-questValue(namedTime)). If the nodes are joined with an and-or a has-a relation, the text generator would translate the primitives into an utterances requesting several different pieces of information. For example, \"What is the name of the city and the theatre?\" (requestValue(city) + requestValue(theatre)). As seen in the application descriptions there may be several ways of acquiring a particular value e.g., date and time in Figure 2 . If a parameter value is recognized with a low score, the service designer can decide whether the system shall continue processing the original parameter or whether it shall switch to one of the alternative ones. Thus after a bad recognition of date, the system can switch strategy and request weekDay and week instead. Which strategies to follow is decided by the service designer through a set of switches in the dialogue strategies specification file (Figure 1 ). Pragmatic Interpreter After synsem interpretation, the user utterance must be mapped onto dialogue primitives. A bag of REC-primitives is calculated for each user utterance and the pragmatic interpreter must assure that the utterance is mapped onto primitives in this bag. There is always a mapping. The reject and withdraw primitives are always part of the bag thus in the worst case, the user utterance would be mapped onto one of these. Since primitives in their uninstantiated form are application independent, we can develop generic rules for this mapping. In other words, the rules define how the dialogue strategies presented in Section 3 are mapped onto primitives and how we account for several primitives per utterance. A rule has the form: GEN-Primitives A user utterance =~-REC-primitives. In Table 4 , we present two rules for implicit confirmation. (Hagen, 2001) ). One reviewer asked whether we can modify the approach such that expectations can be overridden if there is sufficently good information from the synsem module. The short answer is that we could (re-)calcnlate the primitives pretending that the service designer allowed mixed initiative regardless of the dialogue strategies actually chosen. W~, however, think it is important to give her the right to decide. For example, if she has decided that over-answering is allowed, informExtraValue0 primitives for all parameters whose status is still open would be calculated and thus there is nothing to override. If, however, the service designer has decided that over-answering is not allowed, we assume that she had good reasons for doing that and the dialogue manager will not try to overrule this decision. Conclusion We have presented some results from our research on spoken dialogue management. We concentrated on how to dynamically calculate a collection of predictions for how to continue a dialogue (dialogue primitives), how to account for different dialogue strategies and utterances with several communicative goals through combinations of primitives, and how to map the user utterances onto primitives. The approach has been implemented and tested in several prototype systems, e.g., horoscope, movie, and telephone rate service (Feldes et al., 1998) . Dialogue grammars have previously been used to manage dialogue (Bunt, 1989; Bilange, 1991; Traum and Hinkelman, 1992; JSnsson, 1993; Mast et al., 1994; Novick and Sutton, 1994; Chino and Tsuboi, 1996 ), but we are not aware of an approach where speech acts are translated into a collection of primitives with propositional content. Previous grammar approaches use the speech acts directly or assume a one-to-one correspondence between utterance and speech act. Through the natural division of the knowledge into type and content, we have achieved a flexible dialogue manager that adapts to users' behaviour. We can take advantage of the predictive capabilites of speech act grammars and still be able to account for multi-functional utterances. We have also demonstrated that our approach is flexible: 1. the dialogue engine, the pragmatic interpreter, the primitives and the algorithm for mapping user utterances onto predictions are application and language independent, which makes it easy to reuse our dialogue manager in new applications, and 2. the dialogue manager can easily account for several types of dialogue, e.g., strict question-answer or mixed initiative. We give the service designer the freedom to decide which kind of dialogue she wants---on a high level--and the dialogue manager combines the basic primitives accordingly. Future work includes empirical testing to verify whether we are calculating appropriate predictions. Also, several aspects of our dialogue grammar have not yet been translated into primitives, for example, the frequent use of assert in natural dialogue. As a wider dialogue coverage is required, we will add primitives accordingly. We are also working on using the primities as input to a multi-lingual automatic text generation system. Acknowledgements The author thanks the three anonymous reviewers for their helpful comments on the first draft of this paper. Financial support from the Norwegian Research Council, project number 116578/410 is greatly appreciated.",
    "abstract": "We present an application independent dialogue engine that reasons on application dependent knowledge sources to calculate predictions about how a dialogue might continue. Predictions are language independent and are translated into language dependent structures for recognition and synthesis. Further, we discuss how the predictions account for different kinds of dialogue, e.g., question-answer or mixed initiative.",
    "countries": [
        "Canada"
    ],
    "languages": [
        ""
    ],
    "numcitedby": "6",
    "year": "2000",
    "month": "October",
    "title": "Flexible Speech Act Based Dialogue Management"
}