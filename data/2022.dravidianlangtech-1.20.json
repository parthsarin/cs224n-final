{
    "article": "Emotion analysis is the process of identifying and analyzing the underlying emotions expressed in textual data. Identifying emotions from a textual conversation is a challenging task due to the absence of gestures, vocal intonation, and facial expressions. Once the chatbots and messengers detect and report the emotions of the user, a comfortable conversation can be carried out with no misunderstandings. Our task is to categorize text into a predefined notion of emotion. In this thesis, it is required to classify text into several emotional labels depending on the task. We have adopted the transformer model approach to identify the emotions present in the text sequence. Our task is to identify whether a given comment contains emotion, and the emotion it stands for. The datasets were provided to us by the LT-EDI organizers Sampath et al. (2022)  for two tasks, in the Tamil language. We have evaluated the datasets using the pretrained transformer models and we have obtained the micro-averaged F1 scores as 0.19 and 0.12 for Task1 and Task 2 respectively. Introduction In today's world, the user has complete liberty to express their opinion on any topic in the form of comments, videos, reels, and reviews. Identifying emotions from a video or a graphic image is simple. By analyzing the body language, facial expressions, and speech modulation we can determine the emotion. However, the identification of emotion from a text is quite challenging due to the absence of discrete evidence. Emotions in the text are not only identified by their cue words such as happy, good, bore, hurt, hate, and fun, but also by the presence of interjections (e.g., \"oopsie\"), emoticons (e.g., \":)\"), idiomatic expressions (e.g., \"am on cloud nine\"), metaphors (e.g., \"sending clouds\") and other descriptors mark the existence of emotions in the conversational text (Thenmozhi et al., 2019; Chakravarthi, 2020) . With the growth and advancement of text messaging applications, it is possible to detect the emotion during conversation and proceed with the conversation with no miscommunications. In the last years, the recognition of emotions has become a multi-disciplinary research area (Ghanghor et al., 2021a,b; Yasaswini et al., 2021) . This plays an important role in HumanMachine interaction (Ram and Ponnusamy, 2014) . There are three main classification levels in Emotion Analysis: document-level, sentence-level, and aspect-level Emotion Analysis. Document-level Emotion analysis aims at classifying an opinion as a positive or a negative opinion or sentiment. Sentence-level emotion analysis strives to classify the emotion expressed in each sentence. The first step is to identify whether the sentence is subjective or objective. If the sentence is subjective, Sentencelevel EA will determine whether the sentence expresses positive or negative opinions. The authors Wilson et al. (2005) points out that emotional expressions are not necessarily subjective in nature. The authors Liu (2012) states that there is no fundamental difference between document and sentence level classifications because sentences are just short documents. Tamil is one of the world's longest-surviving classical languages (Anita and Subalalitha, 2019b,a; Subalalitha and Poovammal, 2018; Subalalitha, 2019) . According to A. K. Ramanujan, it is \"the only language of modern India that is recognizably continuous with a classical history.\" Because of the range and quality of ancient Tamil literature, it has been referred to as \"one of the world's major classical traditions and literatures.\" For about 2600 years, there has been a recorded Tamil literature. The earliest period of Tamil literature, known as Sangam literature, is said to have lasted from from 600 BC to AD 300. Among Dravidian languages, it possesses the oldest existing literature. The earliest epigraphic documents discovered on rock edicts and \"hero stones\" date from the 6th century BC (Sakuntharaj and Mahesan, 2021 , 2017 ,?, 2016; Thavareesan and Mahesan, 2019 , 2020a ,b, 2021a) . Recently there are many research shared tasks on Tamil and other Dravidian languages conducted by researchers (Priyadharshini et al., 2021; Kumaresan et al., 2021; Chakravarthi and Muralidaran, 2021; Chakravarthi et al., 2020b; Sampath et al., 2022; Ravikiran et al., 2022; Chakravarthi et al., 2022; Bharathi et al., 2022; Priyadharshini et al., 2022) . The goal of this task is to determine the emotional state of the user who writes comments. In this paper, we will look into the classification, and analyze the different emotions of the YouTube comments. Our focus lies in the study of emotion analysis in Tamil. The datasets were provided by the LT-EDI organizers in the Tamil language in two forms, namely, Task A and Task B, each consisting of a different number of comments or posts. The language constriction poses several challenges due to the limited resources available for the Tamil language. We have used multilingual models such as BERT, XLNet, and m-BERT transformer models to tackle this issue. In this paper, we investigate the efficacy of different learning models in identifying emotions. We then compare the F1-Score of the different transformer models for both datasets and conclude which is the better model. The remainder of the paper is organized into 5 sections. Section 2 discusses the related works in the field of Artificial Intelligence, on emotion or sentiment analysis for both Tamil, and other languages. The methodology proposed for the model along with the models implemented are elaborately explained in the 3rd section of this paper. In section 4 the results and the observations are discussed. Section 5 concludes the paper. Related Works In this section, we will be reviewing the research work reported for emotion analysis from the text. The authors Abdelrahman et al. ( 2016 ) had proposed an architectural framework to identify the sentiments of both English and Tamil tweets. Tweets were gathered with the help of Twitter API. They had used the word sense disambiguation technique to determine the correct usage of the word sense and went about classifying the sentiments of tweets using a linear classifier like the Support Vector Machine. K-means clustering and k-nearest neighbor clas-sifier to predict the sentiments expressed in Tamil texts is used in Thavareesan and Mahesan (2021b) . The data points are considered in two different ways for the clustering of the corpus; clustering by considering class-wise information and clustering without considering class-wise information. They extracted features using Tf, BoW, fastText, and word embeddings. The fastText and class-wise clustering method has yielded the best results of accuracy of 89.87 The authors of Jenarthanan et al. (2019) this paper had worked on ACTSEA: Annotated Corpus for Tamil & Sinhala Emotion Analysis, to develop emotion annotated twitter corpus in Sinhala and Tamil Languages. They had adopted the scalable semi-automatic approach and found it an effective process for creating a large-scale emotion corpus with acceptable quality. They've also concluded that it is useful for under-resourced languages. A research work done by Vas aimed at creating a monolingual corpus for the Tamil language. They advanced the corpus solution and created the TamilEmo, a large dataset for fine-grained emotion detection that has been extensively annotated manually. They've further presented a detailed data analysis that illustrates that the accuracy of the annotations over the whole taxonomy with a high inter-annotator agreement in terms of Krippendorff's alpha There are many research works on classifying the emotion of document sources into a single type of emotion. In Sharma et al. (2017) , provides an insight on how to characterize a person's multiple emotions. The LEXicon Based Emotion AnalyzeR abbreviated as LEXER is employed to analyze the emotion underlying the text. The proposed method contains a dictionary that has different emotional values for words. Emotion values from the vocabulary are allotted to every expression that's being used in the text. A fuzzy set function is used to complement the emotional value of a negated word. This in comparison to polarity reversal is more realistic and reliable. The lexicon assigns an emotional value that is derived from a fuzzy set function. This is an efficient multi-emotion analyzer model which has still not been applied to the best of our understanding. Seq2Seq deep neural network for detecting the emotions from textual conversations which include a sequence of phrases are adopted in Thenmozhi et al. (2019) . The Seq2Seq model is adopted and the sequence of n words is mapped with a target label(n:1 mapping). The sequence was vectorized and sent to the bidirectional LSTM for encoding and decoding. A study on how sentiment communicates in Dravidian social media language in a code-mixed setting was taken up as a shared task by Chakravarthi et al. (2021) . The results of the sentiment analysis shared task on Tamil, Malayalam, and Kannada are presented. The top-performing systems involved the application of attention layers on the contextualized word embeddings. Methodology and Data Pre-processing In this section, we have illustrated our implementation of the pre-trained machine learning transformer models in detail. Further, we investigate the performance of the various transformer models in the coming sections. The architecture of the proposed model and the steps are given in the Fig. 1 . The dataset provided by the LT-EDI organizers Sampath et al. (2022) for the Tamil Tasks A and B, consisted of 22,200 and 38,717 posts/comments respectively. The details are given in Table 1 . In task A we were provided with data annotated for 8-10 emotions for social media comments in Tamil. In task B we were provided with data annotated for fine-grained 30 emotions for social media comments in Tamil Sampath et al. (2022) . Data-set Analysis The goal of this task is to identify whether a given comment contains emotions, and which emotion it represents. A comment or post within the corpus may contain more than one sentence but the average sentence length of the corpora is 1. The annotations in the corpus are made at a comment or post level Sampath et al. (2022) . The dataset provided by LT-EDI 2021 organizers, consisted of the training set, development set, and test set of 14208, 3552, and 4440 instances respectively for Task A text, and 30179, 4269, and 4269 instances for the Task B text. The dataset contained text sequences that include user utterances along with the context, followed by the offensive class label. The task is to identify the emotion underlying the text and label them accordingly. Data Pre-processing Data pre-processing is essential for any machine learning problem. The given dataset of YouTube comments shows signs of irregularities in spelling and words. Firstly, the dataset is cleaned and processed before classifying. We've implemented data processing with the use of the nltk package, abbreviated as the Natural Language Toolkit, built to work with the NLP (Natural Language Processing). It provides various text processing libraries for classification, tokenization, parsing, semantic reasoning, etc. For our model, we've only used the regular expression (re) module. The re. sub() function was used to clean and scrape the text, remove URLs, remove numbers, and remove tags. Regexp() module we were able to extract the tokens from the string by using the regular expression with the RegexpTokenizer() method. Tokenizing is a crucial step when it comes to cleaning the text. It is used to split the text into words or sentences, splitting it into smaller pieces that still hold its meaning outside the context of the rest of the text. When it comes to analyzing the text, we need to tokenize by word and tokenize by sentence. This is how unstructured data is turned into structured data, which is easier to analyze. Model Description The dataset text was classified using 3 transformer models, namely BERT, XLNet, and m-BERT \u2022 BERT: BERT stands for Bidirectional Encoder Representations from Transformers. BERT is a pre-trained model for the top 104 languages of the world on Wikipedia (2.5B words) with 110 thousand shared word piece vocabulary, using masked language modeling (MLM) objective, which was first introduced in Devlin et al. (2018) . BERT uses bi-directional learning to gain context of words from left to right context simultaneously. This is optimized by the Masked Language Modelling. The MLM is different from the traditional recurrent neural networks (RNNs), which generally see the word one after the other. This model randomly masks 15% of the words in the input and predicts the masked words when the entire masked sentence is run through the model. \u2022 XLNet: The XLNet transformer model was proposed in 'XLNet: Generalized Autoregressive Pretraining for Language Understanding ' Yang et al. (2019) . It is pre-trained using an autoregressive model (a model that predicts future behavior based on past behavior) which enables learning bidirectional contexts by maximizing the expected likelihood over all permutations of the factorization order and overcomes the limitations of BERT thanks to its autoregressive formulation Yang et al. (2019) . It integrates the Transformer-XL mechanism with a slight improvement in the language modeling approach. \u2022 m-BERT: m-BERT is a pre-trained model on a large corpus of multilingual data It is trained on the top 104 languages with the largest Wikipedia using a masked language modeling (MLM) objective. It was first introduced in Devlin et al. ( 2018 ) Results and Analysis The BERT (Bidirectional Encoder Representations from Transformers) models and XLNET were used for the Task A dataset. The BERT model operates on the principle of an attention mechanism to learn contextual relations between words. The transformer encoder used is bidirectional, unlike the other directional methods which read input sequentially. BERT reads the entire sequence of text at once. This bidirectional property of the encoder has made it very useful for classification tasks. The BERT models BERT and m-BERT were trained for 5 epochs. XLNet does not suffer from pre-train fine-tune discrepancy since it does not depend on data corruption. We have trained the XLNet model for 5 epochs. The bert-base-uncased model showed the best F1-Score of 0.19, 0.08 for Task A and Task B respectively. Task A The accuracy obtained by the BERT model was found to be 0. Task B For Task B, the training data was run for the 3 transformer models. The training data with the best F1 score is run with the test data. The bertbase-multilingual-uncased model yielded the best results, with an F1 score of 0.12. The weighted precision, weighted recall, weighted F1 score, and accuracy is given in the Table 3 . Performance Metrics In this task we have evaluated the models based on the macro average of Precision, Recall, and F1 Score. They provide us with an evaluation of the performance of the ML algorithm. We've used classification metrics for our research. Classification Metrics evaluate a model's performance and tell you how good or bad the classification is, but each of them evaluates it in a different way. Precision: Precision is the ratio of true positives and total positives predicted. As the name goes, Precision refers to the accuracy of the classification algorithm. Recall: Recall may be defined as the number of positives returned by our ML model. Recall is the measure of the model correctly identifying the True Positives (TP). F1 Score: The F1-score metric uses a combination of precision and recall. The F1 score is the harmonic mean of the two. Since it takes both, Precision, and Recall into account, it is more useful than accuracy. Conclusions In this paper, we have investigated the baseline accuracy of different models as well as their variants on the datasets, and also proposed an approach for identifying emotions from the text. We have achieved F1 scores of 0.19 and 0.12 for Task A and Task B respectively. Due to the time constraint and not promising results, we had not submitted our results to the organizers. Identifying emotions based on text is quite a challenge and the performance of this model can further be enhanced by adopting favorable features.",
    "abstract": "Emotion analysis is the process of identifying and analyzing the underlying emotions expressed in textual data. Identifying emotions from a textual conversation is a challenging task due to the absence of gestures, vocal intonation, and facial expressions. Once the chatbots and messengers detect and report the emotions of the user, a comfortable conversation can be carried out with no misunderstandings. Our task is to categorize text into a predefined notion of emotion. In this thesis, it is required to classify text into several emotional labels depending on the task. We have adopted the transformer model approach to identify the emotions present in the text sequence. Our task is to identify whether a given comment contains emotion, and the emotion it stands for. The datasets were provided to us by the LT-EDI organizers Sampath et al. (2022)  for two tasks, in the Tamil language. We have evaluated the datasets using the pretrained transformer models and we have obtained the micro-averaged F1 scores as 0.19 and 0.12 for Task1 and Task 2 respectively.",
    "countries": [
        "India"
    ],
    "languages": [
        "Tamil",
        "English"
    ],
    "numcitedby": "0",
    "year": "2022",
    "month": "May",
    "title": "{SSNCSE}{\\_}{NLP}@{T}amil{NLP}-{ACL}2022: Transformer based approach for Emotion analysis in {T}amil language"
}