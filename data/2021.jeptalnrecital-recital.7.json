{
    "article": "Cet article pr\u00e9sente les exp\u00e9riences effectu\u00e9es sur un syst\u00e8me de liage d'entit\u00e9s nomm\u00e9es. Cette t\u00e2che se d\u00e9coupe en deux principales parties que sont la d\u00e9tection de mentions m\u00e9ritant d'\u00eatre li\u00e9es \u00e0 la base de connaissance et la d\u00e9sambigu\u00efsation qui permet de s\u00e9lectionner l'entit\u00e9 finale \u00e0 lier \u00e0 chaque mention. Deux approches existent pour r\u00e9soudre cette t\u00e2che. Il y a celle de d\u00e9sambigu\u00efsation seule et celle end-to-end qui effectue les deux sous-t\u00e2ches simultan\u00e9ment. Nous nous sommes int\u00e9ress\u00e9s au mod\u00e8le end-to-end atteignant l'\u00e9tat de l'art. Le coeur de ces exp\u00e9riences \u00e9tait d'exploiter des embeddings contextuels afin d'am\u00e9liorer les performances. Trois approches ont \u00e9t\u00e9 test\u00e9es afin d'int\u00e9grer ces embeddings et de remplacer les embeddings de mots. Les diff\u00e9rentes versions atteignent au mieux l'\u00e9tat de l'art. L'article pr\u00e9sente quelques pistes d\u00e9j\u00e0 \u00e9tudi\u00e9es expliquant les raisons pour lesquelles les exp\u00e9riences test\u00e9es ne d\u00e9passent pas le mod\u00e8le initial et ouvrent des possibilit\u00e9s d'am\u00e9lioration. Introduction La t\u00e2che de liage d'entit\u00e9s nomm\u00e9es permet d'identifier les \u00e9l\u00e9ments d'int\u00e9r\u00eats dans un texte et de les relier \u00e0 une entr\u00e9e d'une base de connaissances. Cette t\u00e2che est primordiale pour d'autres applications telles que le r\u00e9sum\u00e9 de texte, les syst\u00e8mes de question-r\u00e9ponses ou l'augmentation de bases de connaissances (Shen et al., 2014) . C'est cependant une t\u00e2che difficile car elle doit \u00e0 la fois se charger de rep\u00e9rer les mentions d'int\u00e9r\u00eats dans un texte et en m\u00eame temps d\u00e9terminer \u00e0 quelle entr\u00e9e de la base de connaissance chaque mention correspond. Or il est fr\u00e9quent que relier une mention \u00e0 une entit\u00e9 soit ambigu. Plusieurs entr\u00e9es peuvent correspondre et se tromper entra\u00eene alors la g\u00e9n\u00e9ration d'un contre-sens sur le texte analys\u00e9. Les deux t\u00e2ches que sont (a) trouver les mentions puis (b) les relier \u00e0 une entit\u00e9 peuvent \u00eatre disjointes, beaucoup de travaux ne concernent que l'un des deux aspects. N\u00e9anmoins, effectuer la t\u00e2che d'un seul trait, par une approche dite end-to-end, peut avoir l'avantage de renforcer les performances globales du mod\u00e8le. \u00c0 partir d'un syst\u00e8me end-to-end, l'objectif de ce travail est d'en modifier l'architecture afin de tenter de l'am\u00e9liorer. L'axe privil\u00e9gi\u00e9 a \u00e9t\u00e9 l'am\u00e9lioration des embeddings de mots, initialement du Word2Vec (Mikolov et al., 2013) , pour les remplacer par des embeddings contextuels de type BERT (Devlin et al., 2018) . Le mod\u00e8le BERT a \u00e9t\u00e9 choisi car il correspond \u00e0 l'\u00e9tat de l'art en terme de mod\u00e8le d'embeddings contextuels. Le travail pr\u00e9sent\u00e9 se base sur un corpus de liage d'entit\u00e9s en anglais. Cette article pr\u00e9sentera dans un premier temps la t\u00e2che de liage d'entit\u00e9s nomm\u00e9es ainsi que les travaux r\u00e9cents, puis pr\u00e9sentera les diff\u00e9rentes exp\u00e9riences r\u00e9alis\u00e9es avec BERT avant de pr\u00e9senter les r\u00e9sultats obtenus et de les discuter. Travaux r\u00e9cents La t\u00e2che de Liage d'Entit\u00e9s Nomm\u00e9es (LEN) consiste \u00e0 rep\u00e9rer les mentions d'int\u00e9r\u00eats dans un document permettant sa compr\u00e9hension et sa mise en contexte en les reliant \u00e0 une base de connaissances. Elle est traditionnellement compos\u00e9e de deux sous-t\u00e2che (Shen et al., 2014) . La premi\u00e8re est La Reconnaissance d'Entit\u00e9s Nomm\u00e9es (REN) qui consiste \u00e0 trouver dans un texte les mots ou groupes de mots significatifs qui doivent \u00eatre mis en relation avec la base de connaissances, dont les \u00e9l\u00e9ments sont appel\u00e9s entit\u00e9s. Ces mots ou groupes de mots sont appel\u00e9s des mentions car ils mentionnent des \u00e9l\u00e9ments de la base de connaissances. La seconde t\u00e2che est La D\u00e9sambigu\u00efsation d'Entit\u00e9s Nomm\u00e9es (DEN) qui consiste \u00e0 relier \u00e0 chaque mention la bonne entit\u00e9 dans la base de connaissances. C'est une t\u00e2che de d\u00e9sambigu\u00efsation car plusieurs entit\u00e9s peuvent initialement correspondre \u00e0 une m\u00eame mention. Par exemple, si dans un texte on rel\u00e8ve la mention \"le pr\u00e9sident fran\u00e7ais\", plusieurs entit\u00e9s issues d'une base de connaissances peuvent correspondre en premier lieu car il y a eu plusieurs pr\u00e9sidents fran\u00e7ais (m\u00eame si on se limite aux pr\u00e9sidents de la R\u00e9publique). De m\u00eame, un texte comportant un nom comme \"Obama\" pourra correspondre \u00e0 plusieurs entit\u00e9s car plusieurs personnes peuvent porter ce patronyme. Il faut donc d\u00e9terminer duquel on parle. Cette t\u00e2che est souvent d\u00e9coup\u00e9e en 2 temps (Shen et al., 2014) . On commence par g\u00e9n\u00e9rer l'ensemble des entit\u00e9s qui pourraient correspondre \u00e0 la mention donn\u00e9e (Candidate Entity Generation), puis on les classe de la plus pertinente \u00e0 la moins pertinente pour prendre la d\u00e9cision d'association finale (Candidate Entity Ranking), la pertinence pouvant correspondre \u00e0 la fr\u00e9quence (moyen le plus na\u00eff). Ainsi, un syst\u00e8me LEN a besoin d'une base de connaissances qui servira de r\u00e9f\u00e9rence pour associer les mentions de tous les textes. Wikipedia 1 est souvent retenu pour ce r\u00f4le. Chaque page correspond \u00e0 une entit\u00e9 unique, et il n'existe pas deux pages r\u00e9f\u00e9ren\u00e7ant la m\u00eame personne, institution, concept ou autre (on exclut les cas des pages traduites). Une bonne base de connaissances n'est pas qu'un simple dictionnaire et poss\u00e8de des liens entre les entit\u00e9s qui permettent de les situer les unes par rapport aux autres. Dans Wikipedia de tels liens peuvent s'exprimer par les liens hypertextes pr\u00e9sents dans une page et permettant d'atteindre d'autres pages. Ces liens hypertextes \u00e9tant associ\u00e9s \u00e0 des mots ou groupes de mot, ils permettent aussi d'avoir des exemples de mentions devant \u00eatre reli\u00e9s \u00e0 ces entit\u00e9s. Ces liens peuvent permettre aussi de d\u00e9finir des relations qui peuvent s'av\u00e9rer utiles lors du classement des entit\u00e9s comme leur fr\u00e9quence. Les autres bases de connaissances fr\u00e9quemment utilis\u00e9es sont YAGO (Fabian et al., 2007) , DBPedia (Auer et al., 2007 ) et Freebase (Bollacker et al., 2008) . Le travail sur la base de connaissances est fait en amont, le mod\u00e8le l'utilise seulement. Un syst\u00e8me LEN a ensuite besoin d'un corpus de textes sur lequel le mod\u00e8le devra extraire et lier les mentions vers les entit\u00e9s de la base de connaissances. Chaque texte du corpus (ou document) est compos\u00e9 de plusieurs phrases et potentiellement de plusieurs mentions afin de les mettre en relation, de les contextualiser et de faciliter ainsi le travail de d\u00e9sambigu\u00efsation. Un corpus de textes peut \u00eatre un recueil d'articles de presse. Les deux principaux corpus pour le liage d'entit\u00e9s nomm\u00e9es sont CoLNN (Hoffart et al., 2011) et TAC 2 (Getman et al., 2018; McNamee & Dang, 2009) . Certains mod\u00e8les d\u00e9couplent les parties REN et DEN. La partie DEN est la plus complexe et il existe des syst\u00e8mes permettant de r\u00e9aliser la t\u00e2ches REN en amont (tels que StandfordNER 3 ou OpenNLP 4 ). Cependant, depuis quelques ann\u00e9es, les mod\u00e8les tentent davantage une approche end-to-end (Shen et al., 2014) . L'id\u00e9e est de rendre la t\u00e2che REN plus robuste en utilisant les r\u00e9sultats de la d\u00e9sambigu\u00efsation pour aider \u00e0 mieux capturer les mentions. Par exemple, un syst\u00e8me d\u00e9coupl\u00e9 aura tendance \u00e0 mal \u00e9tiqueter The New York Times pour le tronquer en New York Times ou simplement New York (l'article the \u00e9tant le plus souvent oubli\u00e9). Or, un bon \u00e9tiquetage de mention peut permettre de faciliter sa correspondance avec une r\u00e9f\u00e9rence de la base de connaissance. DeepType (Raiman & Raiman, 2018) est un exemple de syst\u00e8me de d\u00e9sambigu\u00efsation seule. Il est la r\u00e9f\u00e9rence de l'\u00e9tat de l'art en DEN. End-to-End Neural Entity Linking (Kolitsas et al., 2018) est un exemple de syst\u00e8me end-to-end. Il est la r\u00e9f\u00e9rence de l'\u00e9tat de l'art pour cette approche. Certains syst\u00e8mes utilisent BERT (Devlin et al., 2018) pour obtenir des embeddings contextuels car il peut \u00eatre sp\u00e9cialis\u00e9 pour r\u00e9aliser une t\u00e2che de liage d'entit\u00e9s nomm\u00e9es (Broscheit, 2019) . D'autres approches se concentrent sur une adaptation de BERT dans le cadre de datasets plus sp\u00e9cifiques auxquels BERT n'a pas \u00e9t\u00e9 confront\u00e9, comme le fait PEL-BERT (Li et al., 2020) . BERT n'est pas le seul mod\u00e8le d'embeddings contextuels (comme ELMo (Peters et al., 2018) ou GPT (Radford et al., 2019) ), mais il constitue la r\u00e9f\u00e9rence. Nous avons choisi de nous appuyer sur un mod\u00e8le NEL pr\u00e9-existant : le End-to-End Neural Entity Linking de Kolitsas (Kolitsas et al., 2018) . Il effectue la t\u00e2che d'Entity Linking (EL) de la d\u00e9tection de mention (REN) jusqu'\u00e0 la d\u00e9sambigu\u00efsation (DEN). Ce choix a \u00e9t\u00e9 motiv\u00e9 car le mod\u00e8le de Kolitsas est \u00e0 l'\u00e9tat de l'art actuel en tant que syst\u00e8me end-to-end. Des travaux comme ceux de Broscheit (Broscheit, 2019) l'utilise comme point de comparaison. Son architecture est, de plus, ais\u00e9e \u00e0 modifier, contrairement \u00e0 des mod\u00e8les comme DeepType qui repose principalement sur son syst\u00e8me de types. Ainsi, il \u00e9tait plus envisageable d'explorer l'impact de nouveaux modules en les utilisant sur le mod\u00e8le de Kolitsas. Enfin, les modules utilis\u00e9s par ce syst\u00e8me sont des outils \u00e9prouv\u00e9s tels que Word2Vec (Mikolov et al., 2013) et des Bidirectional Long Short-Term Memory (Bi-LSTM). Il \u00e9tait donc int\u00e9ressant de tester des am\u00e9liorations en int\u00e9grant des approches plus r\u00e9centes ayant prouv\u00e9 leur robustesse (notamment BERT). Mod\u00e8le Initial Cette section a pour but d'expliquer le fonctionnement du mod\u00e8le End-to-End Neural Entity Linking de Kolitsas (Kolitsas et al., 2018) , illustr\u00e9 dans la Figure 1 afin de comprendre par la suite les modifications qui y ont \u00e9t\u00e9 apport\u00e9es. Le mod\u00e8le part d'un document, soit un texte coh\u00e9rent, de quelques phrases. Le mod\u00e8le y d\u00e9tecte les mentions, les relie aux entit\u00e9s correspondantes dans la base de connaissances et renvoie une liste des couples Mention-Entit\u00e9s ainsi pr\u00e9dits dans le document. Le principe g\u00e9n\u00e9ral est de construire un embedding de mention \u00e0 partir des embeddings de mots. Cet embedding de mention pourra \u00eatre compar\u00e9 \u00e0 des embeddings d'entit\u00e9s pr\u00e9-calcul\u00e9s, permettant d'assigner un score de similarit\u00e9 \u00e0 chacun. Enfin, on choisit la meilleure entit\u00e9 candidate gr\u00e2ce au score de similarit\u00e9 des embeddings et de la coh\u00e9rence globale en utilisant les autres entit\u00e9s pr\u00e9sentes dans le document. L'entr\u00e9e est constitu\u00e9e des embeddings de mots Word2Vec pr\u00e9-entra\u00een\u00e9s. Les embeddings de mots finaux {\u03bd k } k\u2208 1 ,n sont obtenus par concat\u00e9nation des embeddings de mots Word2Vec et des embeddings de caract\u00e8res de chaque mot. Ces embeddings de caract\u00e8res sont appris gr\u00e2ce \u00e0 un bi-LSTM appliqu\u00e9 sur les caract\u00e8res du mot (\u00e9tape absente sur la figure 1 ). Ces embeddings de mots sont ensuite transform\u00e9s en embeddings de contexte {x k } k\u2208 1 ,n (appel\u00e9 context-aware word embedding dans la figure 1 ) gr\u00e2ce \u00e0 un bi-LSTM. Une fois les embeddings de contexte fix\u00e9s, ceux pertinents dans la construction d'une mention (c'est-\u00e0-dire les embeddings de contexte correspondant \u00e0 la mention m = w q , ..., w r ) sont combin\u00e9s gr\u00e2ce \u00e0 un r\u00e9seau Feed Foward (appel\u00e9 FFNN de Mention ou F F N N 1 dans la figure 1 ) pour transformer l'ensemble en Embedding de Mention. Le mod\u00e8le ne pr\u00e9d\u00e9finit pas les mentions qui seront construites. Il construit et teste toutes les mentions possibles. Compte tenu des notations pr\u00e9c\u00e9dentes, l'Embedding de Mention est obtenu ainsi : x m = F F N N 1 (g m )o\u00f9 g m = [x q ; x r ; xm ] et xm = r k=q \u03b1 m k \u03bd k . Les coefficients \u03b1 m k sont obtenus ainsi : \u03b1 m k = exp(\u03b1) r t=q exp(\u03b1 k ) et \u03b1 k = w \u03b1 , x k Chaque Embedding de Mention est ensuite compar\u00e9 \u00e0 une liste de candidats ((e j ) \u22651 ) issus des Embeddings d'Entit\u00e9s pr\u00e9-entra\u00een\u00e9s (Ganea & Hofmann, 2017) (y e ) \u2208wikipedia et s\u00e9lectionn\u00e9s par des probabilit\u00e9s pr\u00e9-calcul\u00e9es (ou prior (p(e j , m)) \u00e0 partir des liens hypertextes de Wikipedia. Ces probabilit\u00e9s ont \u00e9t\u00e9 \u00e9tablies lors de l'apprentissage des embeddings d'entit\u00e9s et sont consid\u00e9r\u00e9es comme acquises par le mod\u00e8le. Chaque couple Entit\u00e9-Mention re\u00e7oit ensuite un score de similarit\u00e9 \u03a8 obtenu par le r\u00e9seau Feed Foward (appel\u00e9 FFNN de Score ou F F N N 2 dans la figure 1 ) : \u03a8(e j , m) = F F N N 2 ([logp(e j , m); x m ; y i ]) Seules les entit\u00e9s avec un score final suffisamment haut sont test\u00e9es (sup\u00e9rieur \u00e0 un param\u00e8tre \u03b3 ). Ceci permet de filtrer les mentions construites par le mod\u00e8le qui ne correspondent \u00e0 aucune r\u00e9elle entit\u00e9. On obtient donc l'ensemble des couples (mention, candidat) s\u00e9rieux : V G = {(m, e) \u2208 M, e \u2208 (e j ) \u22651 , \u03a8(e, m) \u2265 \u03b3 } Enfin, le mod\u00e8le proc\u00e8de \u00e0 une d\u00e9sambigu\u00efsation globale qui permet d'unifier les entit\u00e9s retenues en prenant en compte la coh\u00e9rence globale entre toutes les entit\u00e9s s\u00e9lectionn\u00e9es. On compare donc chaque candidat retenu avec l'ensemble des candidats retenus pour les autres mentions G(e j , m) = cos(y e j , y m G ) o\u00f9 y m G = e\u2208V m G y e et V m G = {e|(m , e) \u2208 V G \u2227 m = \u03a6(e j , m) = F F N N 3 ([\u03a8(e j , m), G(e j , m)]) On obtient ainsi en sortie, pour chaque mention initiale du texte, l'entit\u00e9 \u00e0 laquelle elle fait r\u00e9f\u00e9rence. C'est \u00e0 partir de cette architecture que nous allons chercher \u00e0 am\u00e9liorer le mod\u00e8le. Exp\u00e9riences et r\u00e9sultats Cette section pr\u00e9sente les travaux r\u00e9alis\u00e9s pour remplacer les embeddings de mots Word2Vec (Mikolov et al., 2013) par des embeddings plus robustes. Il a \u00e9t\u00e9 choisi d'utiliser BERT (Devlin et al., 2018) car il s'agit des embeddings contextuels les plus performants de l'\u00e9tat de l'art. De plus, la premi\u00e8re \u00e9tape du mod\u00e8le consiste \u00e0 transformer les embeddings de mots en embeddings de contexte par l'interm\u00e9diaire d'un bi-LSTM. Protocole exp\u00e9rimental Trois mani\u00e8res d'utiliser les embeddings contextuels BERT (Devlin et al., 2018) sont explor\u00e9es. -La premi\u00e8re (Hypoth\u00e8se 1) consiste \u00e0 remplacer la couche d'embeddings de mots et le bi-LSTM de contextualisation par les embeddings BERT. L'id\u00e9e est de consid\u00e9rer que les embeddings contextuels de BERT ont d\u00e9j\u00e0 l'information initialement produite par le bi-LSTM et peuvent donc le remplacer. Le but est de v\u00e9rifier s'ils sont plus performants que ceux g\u00e9n\u00e9r\u00e9s par le mod\u00e8le. -La seconde (Hypoth\u00e8se 2) consiste \u00e0 remplacer les embeddings de mots par les embeddings contextuels BERT. L'id\u00e9e ici est de consid\u00e9rer que les embeddings contextuels BERT peuvent \u00eatre assimil\u00e9s \u00e0 des embeddings de mots (et non plus contextels) plus puissants que ceux de Word2Vec. Ils passent donc par le bi-LSTM afin de cr\u00e9er du contexte. -La derni\u00e8re (Hypoth\u00e8se 3) est de consid\u00e9rer que les embeddings BERT peuvent apporter de l'information suppl\u00e9mentaire et venir en soutien du bi-LSTM. L'id\u00e9e est de combiner les embeddings BERT aux embeddings de contexte issus du bi-LSTM en supposant que la connaissance issue de BERT va ainsi am\u00e9liorer la qualit\u00e9 de l'embedding contextuel global. Les trois m\u00e9thodes ont donc \u00e9t\u00e9 test\u00e9es selon les protocoles d\u00e9crits ci-dessous. Les exp\u00e9riences ont toutes \u00e9t\u00e9 men\u00e9es sur 50 it\u00e9rations. Les autres param\u00e8tres d'apprentissage ont \u00e9t\u00e9 conserv\u00e9s identiques \u00e0 ceux originellement utilis\u00e9s par Kolitsas (Kolitsas et al., 2018) \u00e0 l'exception des modifications pr\u00e9cis\u00e9es. Utilisation des embeddings en tant qu'embeddings de mots Comme illustr\u00e9 dans la figure 2 , le mod\u00e8le subit peu de modifications pour l'Hypoth\u00e8se 1. On remplace uniquement les embeddings de mots initiaux (Word2Vec) par ceux extraits depuis BERT. (Devlin et al., 2018) . Apr\u00e8s exp\u00e9rience, nous avons choisi de sommer les quatre derni\u00e8res couches ce qui donne de meilleures performances par rapport aux autres m\u00e9thodes de combinaison des couches BERT (Devlin et al., 2018) . R\u00e9sultats et Analyses",
    "abstract": "Cet article pr\u00e9sente les exp\u00e9riences effectu\u00e9es sur un syst\u00e8me de liage d'entit\u00e9s nomm\u00e9es. Cette t\u00e2che se d\u00e9coupe en deux principales parties que sont la d\u00e9tection de mentions m\u00e9ritant d'\u00eatre li\u00e9es \u00e0 la base de connaissance et la d\u00e9sambigu\u00efsation qui permet de s\u00e9lectionner l'entit\u00e9 finale \u00e0 lier \u00e0 chaque mention. Deux approches existent pour r\u00e9soudre cette t\u00e2che. Il y a celle de d\u00e9sambigu\u00efsation seule et celle end-to-end qui effectue les deux sous-t\u00e2ches simultan\u00e9ment. Nous nous sommes int\u00e9ress\u00e9s au mod\u00e8le end-to-end atteignant l'\u00e9tat de l'art. Le coeur de ces exp\u00e9riences \u00e9tait d'exploiter des embeddings contextuels afin d'am\u00e9liorer les performances. Trois approches ont \u00e9t\u00e9 test\u00e9es afin d'int\u00e9grer ces embeddings et de remplacer les embeddings de mots. Les diff\u00e9rentes versions atteignent au mieux l'\u00e9tat de l'art. L'article pr\u00e9sente quelques pistes d\u00e9j\u00e0 \u00e9tudi\u00e9es expliquant les raisons pour lesquelles les exp\u00e9riences test\u00e9es ne d\u00e9passent pas le mod\u00e8le initial et ouvrent des possibilit\u00e9s d'am\u00e9lioration.",
    "countries": [
        "France"
    ],
    "languages": [],
    "numcitedby": "0",
    "year": "2021",
    "month": "6",
    "title": "Modification d{'}une mod{\\`e}le de liage d{'}entit{\\'e}s nomm{\\'e}es end-to-end par l{'}ajout d{'}embeddings contextuels (Modifying an end-to-end named entity linking model by adding contextual embeddings )"
}