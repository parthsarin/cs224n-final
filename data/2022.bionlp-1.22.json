{
    "article": "Text summarization (TS) is an important NLP task. Pre-trained Language Models (PLMs) have been used to improve the performance of TS. However, PLMs are limited by their need of labelled training data and by their attention mechanism, which often makes them unsuitable for use on long documents. To this end, we propose a hybrid, unsupervised, abstractive-extractive approach, in which we walk through a document, generating salient textual fragments representing its key points. We then select the most important sentences of the document by choosing the most similar sentences to the generated texts, calculated using BERTScore. We evaluate the efficacy of generating and using salient textual fragments to guide extractive summarization on documents from the biomedical and general scientific domains. We compare the performance between long and short documents using different generative text models, which are finetuned to generate relevant queries or document titles. We show that our hybrid approach out-performs existing unsupervised methods, as well as state-of-the-art supervised methods, despite not needing a vast amount of labelled training data. Introduction Recent advancements in transformer-based architectures have enabled improvements in natural language processing (NLP) tasks. The use of encoder-decoder models, such as the T5 language model (Raffel and al., 2020) in generative linguistic tasks, such as abstractive summarization (Cachola et al., 2020) and query generation (Nogueira and Lin., 2019; Klein and Nabi, 2019) , have been shown to significantly improve performance over existing methods. Bidirectional-encoder transformer architectures, namely BERT-based PLMs (Devlin et al., 2018) have also proven to be powerful for a broad range of NLP tasks, including text summarization (Liu and Lapata, 2019) . Whilst transformers have made great advancements in their ability at capturing semantic knowledge, they have also introduced new limitations. Firstly, they are restricted by the number of tokens that they can process at any one time. Another issue is the computational cost of finetuning the attention mechanisms embedded in transformers. These constraints are challenging for recent text summarization methods, often resulting in analysis being done on a truncated version of a document (Cachola et al., 2020; Liu and Lapata, 2019; Xu et al., 2020; Zhong et al., 2020; Dou et al. 2021; Zhang and Zhao, 2020) . Since summarization should be able to succinctly capture the meaning of very long documents in a few sentences, the requirement to truncate a document before summarization is a major disadvantage. As a result, recent works have shifted their attention towards addressing the issue of long document summarization (Xiao and Carenini, 2020; Grail et al., 2021; Rohde et al., 2021; Xiao and Carenini, 2019) . However, these are mostly supervised methods, requiring large amounts of labelled training data, which are often unavailable or time-consuming and costly to produce. We address the challenges of supervised methods by adopting a hybrid unsupervised approach, where the PLMs are required only to act on short sections of the document at any time, meaning that our method can be extended to any document length. Furthermore, by nature of it being an unsupervised approach, it does not require manually labelled training data for the extractive summarization task. To-date, unsupervised methods for text summarization have generally used graph-based methods (Erkan and Radev, 2004; Mihalcea and Tarau, 2004; Liang et al 2021; Zheng and Lapata, 2019; Done et al., 2021) , the more recent of these using transformer-based embeddings to calculate weights between the nodes in the graph (Zheng and Lapata, 2019; Done et al., 2021) . We differ from these previous approaches as we do not use a graph-based model and instead evaluate the effectiveness of a novel approach -generating and using salient textual fragments to guide the extractive summarization. Moreover, earlier unsupervised, graph-based methods have been criticised in their ability to effectively represent documents which present multiple facts (Liang et al., 2021) . Our method addresses this by generating multiple salient texts per document, thus enabling it to represent multiple facts per document. Text summarization methods are divided into extractive and abstractive groupings. Extractive methods select the most relevant sentences from a document and abstractive methods consider the most relevant pieces of information to produce new textual fragments which convey the core message. Although abstractive summarization has the potential to be more succinct and readable, in its current state it cannot be trusted to be factually consistent (Wallace et al., 2021) , making it unsuitable in many practical applications, such as summarization of biomedical articles for use by clinicians. Furthermore, Huang (2020) showed extractive techniques to outperform their abstractive counterparts in human evaluation. See (2017) recognises the advantage of hybrid extractiveabstractive summarization methods and uses a pointer-generator approach, where the model is mostly abstractive, but identifies and copies key facts directly from the source document to try to reduce factual inconsistency. We consider these factors and choose also to opt for a hybrid approach; however, we differ from See (2017) in our use of abstractive models. Specifically, we use transformer-based models for the generation of salient points, but ultimately, we generate an extractive summarization to ensure factual consistency. Our method, GenCompareSum is a two-step hybrid summarization approach. GenCompareSum first splits a document into sections of several sentences and walks through them, generating salient textual fragments which represent each section. We experiment with different generative models, which are finetuned 1 https://github.com/jbshp/GenCompareSum to predict either queries or document titles, that best represent a section of the document. Our method then uses these generated textual fragments to guide an unsupervised extractive summarization by calculating the BERTScore similarity between each of the generated texts and each of the sentences in the source document. We then select the sentences with the highest scores to form the extractive summarization. We evaluate our approach on short and long versions of data sets from the biomedical and scientific domains. Furthermore, we compare the use of different PLMs for generating salient textual fragments. Our main contributions are as follows: 1. A novel two-step unsupervised hybrid abstractive-extractive summarization method, which generates salient textual fragments -queries and document titles -which represent sections of a document, and then uses them to guide the extractive summarization step. 2. The fusion of state-of-the-art PLMs with unsupervised approaches, to achieve a summary which harnesses the semantic knowledge of transformer-based models, whilst being extendable to any length document, without requiring a large corpus of training data. Methods We propose GenCompareSum, a hybrid abstractive-extractive model, which makes use of transformer-based architectures but is extendable to any document length, can represent multiple facts, and does not require vast amounts of training data. The method is comprised of two steps: first, using a generative model to produce salient textual fragments, i.e., queries or document titles, which represent key points from across a document, then a comparison between these salient fragments and each sentence, to select the most important sentences from across the document. A representation of our method can be seen in Figure 1 . We make our code publicly available 1 . Where aggregation occurs, we apply a count to represent the number of textual fragments which were combined and use this as a weighting going forwards. The highest weighted textual fragments are then selected to guide the summary. (e) The similarity between each sentence from the source document and each selected textual fragment is calculated using BERTScore. (f) We create a similarity matrix from the scores calculated in the previous step. These are then summed over the textual fragments, weighted by the values calculated in step (d), to give a score per sentence. (g) The highest scoring sentences are selected to form the summary. Text splitting Given a document \ud835\udc37, we first split it into sentences \ud835\udc60, such that \ud835\udc37 = {\ud835\udc60 ! , \u2026 , \ud835\udc60 \" }, using the Stanford CoreNLP software package (Manning et al., 2014) . We then combine sentences into document sections of \ud835\udc65 sentences, i.e., \ud835\udc37 = {\ud835\udc5d ! , \u2026 , \ud835\udc5d # } ; \ud835\udc5a = \ud835\udc50\ud835\udc52\ud835\udc56\ud835\udc59 0 \" $ 1 . We chose not to use any pre-defined sections already existing within the documents as we found that the documents were not consistently extracted into their sections well across the different datasets. Splitting the document into a consistent number of sentences per section removes the requirement for high quality text extraction into document sections. The number of sentences \ud835\udc65 used to form the short text sections was decided via experimentation on the validation data sets. 2 https://commoncrawl.org Salient text generation T5 (Raffel and al., 2020) is a sequence-tosequence model, pre-trained on a cleaned and pre-processed version of the Common Crawl 2 data set -a data set consisting of textual content scraped from the internet. T5-based models have been shown to be high performing sequence-tosequence models across a range of generative tasks, from question generation (Nogueira and Lin, 2019) , to graph-to-text generation (Ribeiro et al., 2021) , to generative common-sense reasoning (Yuchen Lin, et al., 2020) , to abstractive text summarization (Zhang and Zhao, 2020; Goodwin, 2020) . The T5 model uses an encoder-decoder architecture and is pretrained via an unsupervised task in which 15% of tokens are masked; the masked words can be individual words or a span of words; the target of the training objective is to predict these masked words, given the un-masked tokens and their respective positions. For downstream tasks, the pre-trained T5 model is finetuned using pairs of input and output sequences. A diagram of the T5 architecture and its pre-training and finetuning settings can be seen in Appendix A. We experiment with several T5-based models for the salient text generation task. We use each section, \ud835\udc5d, as an input to a generative model to give \ud835\udc58 salient texts \ud835\udc61, which aim to encapsulate the key facts of that section: {\ud835\udc61 ! , \u2026 , \ud835\udc61 % } = \ud835\udc61\ud835\udc52\ud835\udc65\ud835\udc61_\ud835\udc54\ud835\udc52\ud835\udc5b(\ud835\udc5d). (1) In the case where \ud835\udc5d is longer than 512 tokens, it is truncated. We then aggregate the generated textual fragments from across the document sections to give \ud835\udc47 = {\ud835\udc61 ! , \u2026 , \ud835\udc61 #% }. For the generation of the textual fragments, we first experiment with a T5-based model finetuned with a query generation task in the general domain. This model, provided textual input, aims to generate queries which ask the most relevant questions of it. We use docTTTTTquery (Nogueira and Lin, 2019) , a question generation model trained on the MS-MARCO data set (Bajaj et al., 2018) , which is a question-answer data set generated from Bing's 3 search query logs. Surita et al. (2020) , showed this pre-trained model to be effective at generating questions for long, biomedical texts. Second, we follow the approach taken by Nogueira and Lin (2019) and finetune our own model on long-answer -query pairs from the biomedical domain, details of which can be found in Appendix B. We refer to this model as 't5-med-query'. Last, we experiment using an open-source T5based model, finetuned on abstract-title pairs from the scientific domain 4 . This approach has shown to be effective at proxying highly abstractive summaries (Cachola et al., 2020) . We apply this model to our problem space, generating potential 'titles' for each document section. We refer to this model as 't5-s2orc-title'. N-gram blocking N-gram blocking is a technique which is applied to reduce redundancy and improve coverage in summarization models (Liu and Lapata, 2019) . We apply n-gram blocking to the generated textual fragments, resulting in \ud835\udc47 * \u2286 \ud835\udc47, where \ud835\udc47 * = <\ud835\udc61 ! , \u2026 \ud835\udc61 ',')#% =. Where we have removed generated texts by applying this technique, we keep a count of how many times a similar textual fragment was seen before n-gram blocking. We associate this count with the remaining generated text after n-gram blocking. We refer to these counts as weights, which can be described by \ud835\udc64 = {\ud835\udc64 ! , \u2026 , \ud835\udc64 ' }, such we have one weight associated with each generated textual fragment remaining after n-gram blocking. A visualization of this can be seen in steps c and d of Figure 1 . We then take the top \ud835\udc5e; \ud835\udc5e < \ud835\udc59 generated texts after ordering by the weight. Text vector comparison BERT-based comparisons have been shown to outperform traditional sentence comparative metrics like TF-IDF when used in unsupervised summarization tasks (Done et al., 2021) . Furthermore, they have been demonstrated to align better with human judgement of text similarity than n-gram matching approaches during evaluation, likely due to their ability to match based on semantic meaning and their penalization of word re-ordering which changes a text's meaning (Zhang et al,. 2020 ). BERTScore (Zhang,et al., 2020) uses BERTbased token embeddings, calculates the cosine similarity between them and uses greedy matching to match each token in the first text to its most similar token in the second; these scores are averaged across the sentences to give precision, recall and F1 scores which quantify the similarity between two texts. Table 1 : Description of the four data sets used in the extractive summarization experiments. For each data set, we give the number of articles in each of the train, validation and test splits, the mean number of tokens and sentences in the input research article, as well as the mean number of tokens and sentences in the gold summary (abstract) of the articles. We weight the score by \ud835\udc64, the count representing the number of textual fragments which were aggregated during n-gram blocking to give: \ud835\udc60\ud835\udc50\ud835\udc5c\ud835\udc5f\ud835\udc52 * = \u2211 \ud835\udc64 + * \ud835\udc35\ud835\udc38\ud835\udc45\ud835\udc47\ud835\udc46\ud835\udc50\ud835\udc5c\ud835\udc5f\ud835\udc52(\ud835\udc60 * , ,-. ! \ud835\udc61 + ) (2) We then select the sentences with the highest score to form our summary and reorder them back into the sequence that they appear within the original document. Experiments Data sets We evaluate the efficacy of our hybrid summarization model with four publicly available data sets from the biomedical and scientific domains. All four data sets consist of full-article research papers and their corresponding abstracts. In line with previous literature, we use their abstracts as the target summaries. Since most previous literature using transformerbased models in their methods either evaluates them on short or truncated texts (Cachola et al., 2020; Liu and Lapata, 2019; Xu et al., 2020; Zhong et al., 2020; Dou et al., 2021; Zhang and Zhao, 2020) , we also create short data sets for evaluating our models. We create these data sets by truncating documents to the end of the sentence which contains their 512 th token. We evaluate our models both on the short and fulltext versions of the four data sets described above. Table 1 gives, for each data set, the mean number of tokens and sentences for the documents and their target summaries. As training is not required for unsupervised models, for these methods only the test data sets are used. To train the supervised method, BERTExtSum (Liu and Lapata, 2019) , which we implement for comparison, we use the training data set to train the model and the validation data set to select the best performing epoch for evaluation on the test set. Parameter selection To select the optimal parameters for our models, we take a constant but random sample of 1000 articles from the PubMed validation data set and experiment with different combinations of the parameters, details of which can be found in Appendix C. Different methods for calculating text similarity were also compared, namely, BERTScore, SimCSE (Gao et al., 2021) and Sentence Transformers (Reimers and Gurevych, 2019) , with BERTScore shown to be the highest performing against a ROUGE metric for the extractive summarization task, details of this analysis can be found in Appendix D. Implementation details We run all experiments requiring GPUs on NVIDIA Quadro RTX 6000 hardware. We report all our results in terms of ROUGE-1, ROUGE-2 and ROUGE-L scores (Lin, 2004) , calculated using pyrouge 5 python package. Several extractive text summarization methods are compared across the short and full-text versions of the four scientific data sets. For the short-text data sets, we take 6 sentences to generate our predictive summary. We choose to give results on a short-text summary for a fair comparison against supervised methods, which are restricted by the length of document that they can easily summarize. For the full-text articles, the number of sentences that we select for the predictive summary is the same as the average number of sentences in the target summaries for a given data set, shown in Table 1 . E.g., for the PubMed data set, we select 9 sentences to summarize the full text article. Related work ORACLE summaries indicate the upper bound for extractive text summarization. We calculate ORACLE summaries by adapting code from Liu and Lapata (2019), which applies greedy sentence selection to maximise ROUGE scores. As baseline methods for comparison, we implement the LEAD method, taking the first \ud835\udc5b sentences to form the summary, and the RANDOM method, taking a random sample of \ud835\udc5b sentences to form the summary. We also compare our method to unsupervised extractive methods, LexRank (Erkan and Radev, 2004) , TextRank (Mihalcea and Tarau, 2004) 5 https://github.com/bheinzerling/pyrouge and SumBasic (Nenkova and Vanderwende, 2005) , all of which were implemented using the sumy 6 package. LexRank (Erkan and Radev, 2004) and TextRank (Mihalcea and Tarau, 2004 ) are both graph-based models, based on Google's PageRank algorithm (Brin and Page, 1998) , which assume that the sentences with the highest centrality are the most important and use these to form a summary. SumBasic simply assumes that sentences containing the words which are used with the highest frequency across the whole document will be the most important. Additionally, we compare our method to BERTExtSum (Liu and Lapata, 2019) , a stateof-the-art supervised method using BERT-based transformer models. For evaluation on the short data sets, where the documents are truncated at the end of the sentence containing the 512 th token, we use their implementation without modification to train and evaluate the models. For the full-text article, we adapt their code, denoted BERTExtSum*, to cycle through the article in 512 token-length blocks and predict the best sentences to select from across this cycle. However, due to hardware limitations and the computational intensity of the attention calculation, we were still required to truncate the document at 1024 tokens to evaluate this method. Lastly, we implement GenCompareSum and compare the performance between using different generative text models: docTTTTTquery, t5-med-query, and t5-s2orctitle. Experimental Results Automatic evaluation We report the results of our unsupervised hybrid abstractive-extractive method on the extractive summarization task in Table 2 . For the short documents, our method GenCompareSum (t5-s2orc-title) performs best across three out of four of the data sets, and second-best for the fourth data set. There is no clear 'second-best' model out of the methods compared for the short data sets. Table 2 : Results of the extractive summarization task on the PubMed, ArXiv, s2orc and CORD-19 data sets. The short text version of the data set consists of the articles truncated at the end of the sentence containing the 512 th token. We select 6 sentences for the short text summary. For the full-text document prediction, we use select the average number of sentences in the gold summaries of the respective data sets, which are given in Table 1 , PubMed: 9, S2ORC: 9, CORD-19: 8, ArXiv: 11. Bold font indicates the top result within a data set, underlined font indicates the second-best result. Interestingly, for the S2ORC data set, the method outperforming all others is LEAD, i.e., taking the first sentences from the document as the predictive summary. However, in evaluation of the full-text version of the S2ORC data set, it does not hold that LEAD is the best method, and it is seen to be outperformed by several other methods. For the long document data sets, GenCompareSum (t5-s2orc-title) outperforms all other unsupervised models. A strong unsupervised baseline, LexRank has been shown in prior literature to give competitive performance when compared to supervised approaches (Cohan et al., 2018; Subramanian, Li and Pilault, 2020) . In-line with these works, we show LexRank to be the best-performing unsupervised method after our own. Our method, GenCompareSum (t5-s2orc-title), outperforms LexRank by a large margin -an average \u2206R1, \u2206R2, \u2206R1 of 2.35, 1.47, 2.27 across the four data sets. We also demonstrate a slight performance increase over our implementation of the supervised method BERTExtSum*, which we adapted to run over longer documents. The same calculation across the data sets with BERTExtSum* shows us outperforming \u2206\ud835\udc451, \u2206\ud835\udc452, \u2206\ud835\udc451 by 0.36, 0.56, 0.06 across the four data sets. Given that our method is unsupervised, and therefore does not require labelled training data and can be extended to any document length, we believe this is a significant improvement. Considering the different implementations of GenCompareSum, we can see that, as expected, our results show that finetuning on in-domain data gives notable performance increases. Table 2 shows that the \u2206\ud835\udc451 between an out-of-domain query generation model (docTTTTTquery) and a query generation model trained on biomedical data (t5-med-query) were as high as 3 and 2.49 for the short and long articles respectively, for the CORD-19 biomedical data set. However, for the ArXiv data set, which consists of predominantly physical and computer science related research articles, the performance decreased when using the t5-med-query generative model instead of the general domain docTTTTTquery model. Our best-performing GenCompareSum model, t5-s2orc-title, uses a generative PLM finetuned on document-title pairs from the S2ORC data set to guide the extractive summarization. In many ways, a title can be considered as a highly abstractive summarization (Cachola et al., 2020) . A major advantage of this finding is that, although it does require training data to finetune this generative model, document-title pairs are readily available across many domains, thus a model can easily be trained for a specific task without needing extensive manual labelling effort. Furthermore, this model, although finetuned on biomedical and scientific data, is finetuned on a very broad range of documents within these fields. We demonstrate that, despite the broad coverage of fields in its training data, it performs very well when applied to data from a more specific domain, e.g., biomedicine in the PubMed and CORD-19 data sets. Lastly, we observe that there is big difference in ORACLE scores between the short and full text data sets. Although our models out-perform all other methods evaluated for both short and full text documents, the gap between the best predictive scores in our experiments and the ORACLE upper bound is large for long documents, suggesting that much more research could be done in this space. Furthermore, based on this observation, we also hypothesise that predicting summaries from short documents is a significantly easier task than doing the same for long documents. This is supported by TextRank performing worse on the long documents than on the truncated versions. We believe this is explainable both by the fact that there are much fewer sentences to choose from within a shorter document (we select approximately 32% of all sentences across the data sets for short document predictions and 5% for the full documents), thus less room for error. Furthermore, previous work has shown that often the most important parts of the document are towards the beginning of it (Zheng et al., 2019) , implying that there is less 'noise' (i.e., unimportant sentences) to select from a truncated document. Qualitative analysis In Appendix E we provide a randomly sampled PubMed document, the associated generated salient fragments, and the predicted extractive summary given by each of the three GenCompareSum methods. We also provide the gold summary (document abstract) for comparison. In Appendix F, we give the same for a randomly sampled document from the ArXiv data set. In this section, we comment on the difference between the texts generated by the difference T5-based models and hypothesise on how this influences the extractive summary. The docTTTTTquery model produces questions which are relatively general and imply little biomedical knowledge when provided the PubMed document as input. In this setting, it produces textual fragments such \"what is nlrp3\". Interestingly, it does manage to produce more complex texts from sections of the ArXiv data set, such as: \"what is the contribution of the spiral arm to the resonant structure in the solar neighborhood?\". In comparison, the t5-med-query model, whilst also generating questions, better encapsulates biomedical concepts when given a document from the PubMed dataset, e.g., \"what is the role of nuclear and mitochondrial dna damage and repair in people with depression?\". However, in line with the ROUGE results given in Section 4.1, it seems to perform less well on out-ofdomain (i.e., scientific rather than biomedical) literature, and appears to default to a more general question generation model, generating texts for the ArXiv document such as \"what is the effect of a spiral arm?\". The t5-s2orc-title model generates texts which read much more like very short, highly abstractive summaries. E.g., for the PubMed article, it generated the textual fragment: \"the role of the nuclear and mitochondrial dna in depression\" and for the ArXiv article it generated: \"the spiral arm contribution to the resonant structure of the solar neighborhood\". Although outperformed by the title-generation model t5-s2orc-title in the automatic evaluation, on analysis of the generated textual fragments, the query generation models do seem to effectively represent the important facts from an article, especially in the biomedical domain. We hypothesise that our use of BERTScore, to calculate the similarity between salient texts and document sentences, favours the title generation model due to it calculating the similarity between words in different texts and not being designed to answer questions. In future work, we would like to experiment further with the combination of the query generation models and extractive question answering approaches for the extractive summarization task. Future work In this section we suggest future directions for our research. Firstly, we highlight that our method is generalizable and not restricted to T5based architectures for the generation of salient text fragments. Therefore, we would like to experiment with different models for this step, e.g., BART-based (Lewis, 2019) models, or models trained with different data. Another interesting direction would be the inclusion of zoning into the method. As mentioned previously, we chose not to use an article's pre-defined sections as they are often not available. However, it would be interesting to predict a classification for a sentence within the text (e.g., 'Results' for a scientific article), and to incorporate this into the model. We would also like to evaluate our models on other data sets and domains in future research, e.g., clinical notes, and would like to carry out a human evaluation to validate the results, ideally with experts from the same domain as the data being summarized. Human evaluation would allow for aspects such as fluency, factual consistency, and coherence to be assessed, which have been shown not to necessarily align well with ROUGE evaluation in previous works (Kryscinski et al., 2019; Huang et al., 2020) . Lastly, our analysis (details in Appendix D) showed that BERTScore was the best performing method for calculating text similarity for the extractive summarization task, outperforming methods using sentence embeddings. We hypothesise that this could be due to our evaluation metric being ROUGE scoring, which favours methods that produce summaries containing exactly the same words as the gold summary, rather than semantically similar sentences. Experimentation into different evaluation metrics for extractive summarization, including human evaluation, and how they correlate to the performance of our methods when using different models for calculating text similarity, is also an interesting direction for future work. Conclusion In this work we propose GenCompareSum, a novel two-step unsupervised hybrid abstractiveextractive method for text summarization. We evaluate the efficacy of using PLMs to generate salient textual fragments which represent the key points of a document -experimenting with generation of both queries and document titlesand using them to guide the second step, extractive summarization. We show that that our unsupervised method, which can be extended to any length of document and does not require a corpus of annotated training data, outperforms over both strong supervised and unsupervised baselines on long and short documents. Furthermore, we show that our best-performing model uses title-document pairs for the generative task, which are readily available across many domains without the need for manual labelling effort.  \u2022 moreover , we induced oxidative dna damage in those pbmcs by incubating t hem with hydrogen peroxide , measured the kinetics of removing of such da mage , and compared the results between the patients and the controls . Appendix C. Parameter selection. \u2022 we evaluated the level of basal endogenous dna damage by subjecting pbmcs to comet assay procedure immediately after isolation from blood . \u2022 figure 2 shows basal endogenous dna damage and the damage induced after 10 -min incubation with 20 m h2o2 in pbmcs isolated from the patients and controls without psychiatric disturbances . \u2022 figure 3 shows mean dna damage changes in pbmcs of the patients with depr ession and the controls without psychiatric disturbances during the repair inc ubation . \u2022 it is possible that increased oxidative dna damage occurs only in patients wit h more severe forms of depression , or in later stages of the disease develop ment . \u2022 these results indicate that in the patients , oxidative dna damage is less effici ently removed than in the controls . \u2022 moreover , nlrp3 inflammasome , activation of which was detected in the pat ients pbmcs , was also found to inhibit dna repair after induction of oxidative stress . \u2022 for the first time , we showed that patients with depression had elevated level s of dna breaks , alkali -labile sites , and oxidative dna damage , and that the se lesions may be accumulated by impairments of dna repair pathways . \u2022 we conclude that the contribution of the spiral arms to the solar neighborhoo d kinematics may be comparable to that of the bar . \u2022 another unexpected aspect of the bar -and spiral arm -induced phase space s tructure is the effect on the local dark matter kinematics . \u2022 our results show that these models generate dark matter currents inside the g alactic dark disk . \u2022 the spiral arm contribution to the resonant structure in the solar neighborhoo d may be comparable to that of the galactic bar . \u2022 we show that the galactic non -axisymmetric potential develops dark kinema tic groups in the dark disk predicted in cosmological simulations of galaxy f ormation . \u2022 in summary , the imprints of the non -axisymmetric galactic structure on the local stellar kinematics are strong . Author contributions JA Bishop proposed the research themes, developed the code, conducted the experiments, and drafted the manuscript. Q Xie and S Ananiadou supervised all steps of the work and revised the manuscript. All authors approved the final version of the manuscript. Appendix A. T5 model architecture. Appendix B. t5-med-query training. To finetune our GenCompareSum (t5-med-query) model, we combine four biomedical data sets to make a large corpus of text-question pairs, where the questions can be answered by the long textual input. From the BioAsq data set (Nentidis et al., 2021) , 3,433 'ideal answer'-question pairs were used, 2,720 text-question pairs from COVID-QA (M\u00f6ller et al., 2020) , where the paragraph containing the answer is used as the text input, 61,244 context-question pairs from PubMedQA (Jin et al. 2019) , where the 'context' refers to the abstract without its 'conclusion' section, and 27,722 long answer-question pairs from the MASH-QA (Zhu et al. 2020 ) data set. The t5-base model is loaded and finetuned on this data set for 5 epochs, with a batch size of 8. Appendix D. Analysis of methods for calculating text similarity In this section we compare different methods for calculating the similarity between the generated salient text fragments and the document sentences. We use our best performing model, GenCompareSum (s2orc-title), and implement different models for the text comparison step. We present results for the extractive summarization task on the PubMed 'Short Document' data set. We compare BERTScore, a method which uses word embeddings to calculate the similarity between texts, with two other methods to calculate the similarity between texts using sentence embeddings. Sentence Transformers (Reimers and Gurevych, 2019) is trained with a triplet / siamese bert-based architecture and a training objective designed to minimize distances between similar sentences. We implement this method with their python package 11 . We compare both their suggested base model for the general domain 'all-mpnet-base-v2' and a model trained to calculate document-level similarity for scientific documents 'allenai-specter' (Cohan et al., 2020) . We also implement SimCSE (Gao et al., 2021) , which generates sentence embeddings with a model trained using contrastive learning. For this method, we use the general-domain base model which is suggested to be the best performing in SimCSE's documentation 12. For the BERTScore method, we experiment with base models from the general domain, namely 'bert-base-uncased' 13 , which was used in our implementations to give the results in Table 2 of the main manuscript, and a base model pretrained on data from the scientific domain (Beltagy et al., 2019) , 'allenai/scibert_scivocab_cased'. Table 4 gives the results. We can observe that BERTScore, implemented with a base model from the general domain, outperforms all other methods compared for calculating text similarity on the extractive summarization task when evaluated using ROUGE metrics.  depressive disorder ( dd ) , including recurrent dd ( rdd ) , is a severe psychological di sease , which affects a large percentage of the world population . although pathogenes is of the disease is not known , a growing body of evidence shows that inflammation t ogether with oxidative stress may contribute to development of dd . since reactive oxy gen species produced during stress may damage dna , we wanted to evaluate the exten t of dna damage and efficiency of dna repair in patients with depression. material / we measured and compared the extent of endogenous dna damage single -and double -st rand breaks , alkali -labile sites , and oxidative damage of the pyrimidines and purine s in peripheral blood mononuclear cells isolated from rdd patients ( n = 40 ) and healt hy controls ( n = 46 ) using comet assay . we also measured dna damage evoked by h ydrogen peroxide and monitored changes in dna damage during repair incubation. we found an increased number dna breaks , alkali -labile sites , and oxidative modificatio n of dna bases in the patients compared to the controls . exposure to hydrogen peroxid e evoked the same increased damage in both groups . examination of the repair kineti cs of both groups revealed that the lesions were more efficiently repaired in the contro ls than in the patients. the first time we showed that patients with depression , compar ed with non -depresses individuals , had more dna breaks , alkali -labile sites , and o xidative dna damage , and that those lesions may be accumulated by impairments of t he dna repair systems . more studies must be conducted to elucidate the role of dna da mage and repair in depression . Salient Texts -GenCompareSum (docTTTTTquery) \u2022 what is nlrp3 \u2022 since the findings described above are inconsistent , we wanted to determine if the oxidative modification of purines , like 8 -oxog , and pyrimidines are present in a higher degree in patients with depression than in controls . \u2022 to achieve these objectives , we measured and compared the extent of endog enous dna damage single -and double -strand breaks , alkali -labile sites , a nd oxidative damage of the pyrimidines and purines in pbmcs isolated from dd patients and healthy controls . \u2022 we evaluated the level of basal endogenous dna damage by subjecting pbmcs to comet assay procedure immediately after isolation from blood . \u2022 moreover , we estimated the extent of oxidative dna damage by employing m odified comet assay with 2 glycosylases : nth removing oxidized pyrimidines and hogg1 excising oxidized purines . \u2022 figure 3 shows mean dna damage changes in pbmcs of the patients with depr ession and the controls without psychiatric disturbances during the repair inc ubation . \u2022 the goal of our research was to examine the susceptibility of rdd patients to d na damage induced by oxidative stress by measuring the level of endogenous dna damage , including oxidative dna damage , the amount of dna damage in duced by h2o2 , and efficiency of dna damage repair in the patients as compa red to the controls without psychological disturbances . \u2022 apart from measuring the extent of endogenous dna damage , we also estimat ed the amount of dna damage induced by the incubation of pbmcs with h2o2 and efficiency of its repair . \u2022 additionally , we monitored the repair efficiency of the induced dna damage . \u2022 moreover , nlrp3 inflammasome , activation of which was detected in the pat ients pbmcs , was also found to inhibit dna repair after induction of oxidative stress . \u2022 what is the association between 8 -oxog and depression in japanese office w orkers? \u2022 which is the most versatile nlr? \u2022 what enzymes are bifunctional glycosylases? Predicted Summary -GenCompareSum (t5-med-query) \u2022 moreover , we also wanted to know if the patients have elevated levels of oth er kinds of dna damage , such as strand breaks . \u2022 we evaluated the level of basal endogenous dna damage by subjecting pbmcs to comet assay procedure immediately after isolation from blood . \u2022 figure 2 shows basal endogenous dna damage and the damage induced after 10 -min incubation with 20 m h2o2 in pbmcs isolated from the patients and controls without psychiatric disturbances . \u2022 figure 3 shows mean dna damage changes in pbmcs of the patients with depr ession and the controls without psychiatric disturbances during the repair inc ubation . \u2022 figure 5 compares basal endogenous dna damage and the level of this param eter at the end of the repair incubation in pbmcs of the patients and the contr ols measured by the alkaline version of comet assay . \u2022 the goal of our research was to examine the susceptibility of rdd patients to d na damage induced by oxidative stress by measuring the level of endogenous dna damage , including oxidative dna damage , the amount of dna damage in duced by h2o2 , and efficiency of dna damage repair in the patients as compa red to the controls without psychological disturbances . \u2022 apart from measuring the extent of endogenous dna damage , we also estimat ed the amount of dna damage induced by the incubation of pbmcs with h2o2 and efficiency of its repair . \u2022 additionally , we monitored the repair efficiency of the induced dna damage . \u2022 there is a need for further studies to define the role of nuclear and mitochond rial dna damage and repair in people with depression , and their implications for clinical outcome . Salient Texts -GenCompareSum (t5-s2orc-title) \u2022 dna damage in patients with depression. \u2022 oxidative dna damage in depression \u2022 the oxidative dna damage in patients with renal failure \u2022 activation of nlrp3 by oxygen species in pbmc patients. \u2022 activation of mitochondrial nlrp3 in patients with pbmcs. \u2022 urinary 8-oxog in japanese office workers \u2022 the use of the alkaline version of comet assay for assessing dna damage in pb mcs \u2022 the role of the nuclear and mitochondrial dna in depression. \u2022 the role of the dna repair rate in the repair of pbmcs in patients with squamou s cell carcinoma. Predicted Summary -GenCompareSum (t5 -s2orc-title) \u2022 in agreement with this , activation of nlrp3 in pbmcs of the patients was acco mpanied by increased lipid peroxidation , which can be attributed to increase d oxidative stress and elevated mitochondrial ros ( mtros ) production . Appendix F. Example output of our method on an ArXiv article. ArXiv Sample Document and Predictions ArXiv Sample Document https://arxiv.org/abs/0906.4682 ArXiv Sample Abstract (Target Summary) we study the phase space available to the local stellar distribution using a galactic pot ential consistent with several recent observational constraints . we find that the induced phase space structure has several observable consequences . the spiral arm contribution to the kinematic structure in the solar neighborhood may be as important as the one produced by the galactic bar . we suggest that some of the stellar kinematic groups in the solar neighborhood , like t he hercules structure and the kinematic branches , can be created by the dynamical res onances of self -gravitating spiral arms and not exclusively by the galactic bar . a structure coincident with the arcturus kinematic group is developed when a hot stell ar disk population is considered , which introduces a new perspective on the interpret ation of its extragalactic origin . a bar -related resonant mechanism can modify this kinematic structure . we show that particles in the dark matter disk -like structure predicted by recent lcd m galaxy formation experiments , with similar kinematics to the thick disk , are affect ed by the same resonances , developing phase space structures or dark kinematic grou ps that are independent of the galaxy assembly history and substructure abundance . we discuss the possibility of using the stellar phase space groups as constraints to no n -axisymmetric models of the milky way structure . \u2022 however , it is unclear whether there is any dependence of the induced local solar neighborhood kinematics on the detailed galactic structure . \u2022 in order to study the effect of the non -axisymmetric galactic structure on th e solar neighborhood kinematic distribution , we have performed numerical i ntegrations of test particle orbits on the galactic plane , adopting the initial c onditions discussed in sect . \u2022 the induced kinematic distribution at the end of the simulation is studied by c onsidering the particles inside a circle of radius @xmath7 centered at the sol ar position . \u2022 therefore we focused on the recently induced kinematic structure in the solar neighborhood . \u2022 with these initial conditions , we can study the relatively rapid induced effect s of the non -axisymmetric component on the local kinematics . \u2022 we conclude that the contribution of the spiral arms to the solar neighborhoo d kinematics may be comparable to that of the bar . \u2022 in our simulations the positions of these kinematic arches are modified when the bar is added to the model . \u2022 furthermore , these simulations show the important role of the bar in the dev elopment of the local kinematic structure . \u2022 the spiral arm contribution to the resonant structure in the solar neighborhoo d may be comparable to that of the galactic bar . \u2022 in summary , the imprints of the non -axisymmetric galactic structure on the local stellar kinematics are strong . Salient Texts -GenCompareSum (t5-med-query) \u2022 what is the effect of dark matter kinematics on the bar -and spiral arm -indu ced phase space structure? \u2022 what is the main argument of @xcite? \u2022 what is the structure of the hercules? \u2022 what is the solar neighborhood? \u2022 what is the kinematic distribution of the particles? \u2022 what is the relationship between spiral arms and stellar behavior? \u2022 what is the galactic potential? \u2022 what is the required condition for a thick disk? \u2022 what is the difference between ic3 and ic2? \u2022 why is the observed velocity field a useful parameter for predicting the beha vior of galaxies? Predicted Summary -GenCompareSum (t5-med-query) \u2022 however , it is unclear whether there is any dependence of the induced local solar neighborhood kinematics on the detailed galactic structure . \u2022 moreover , the initial conditions hardly consider the evolution of the mw . \u2022 the induced kinematic distribution at the end of the simulation is studied by c onsidering the particles inside a circle of radius @xmath7 centered at the sol ar position . \u2022 therefore we focused on the recently induced kinematic structure in the solar neighborhood . \u2022 we conclude that the contribution of the spiral arms to the solar neighborhoo d kinematics may be comparable to that of the bar . \u2022 in our simulations the positions of these kinematic arches are modified when the bar is added to the model . \u2022 another unexpected aspect of the bar -and spiral arm -induced phase space s tructure is the effect on the local dark matter kinematics . \u2022 the spiral arm contribution to the resonant structure in the solar neighborhoo d may be comparable to that of the galactic bar . \u2022 the main differences to previous studies are the arm force contrast and force field shape? \u2022 in summary , the imprints of the non -axisymmetric galactic structure on the local stellar kinematics are strong . Salient Texts -GenCompareSum (t5-s2orc-title) \u2022 dark matter kinematics in the solar neighborhood \u2022 a note on the arcturus structure in a $xmath26$ plane \u2022 dark kinematic groups in the dark disk \u2022 the spiral arm contribution to the resonant structure of the solar neighborhoo d \u2022 the birth of stars in the disk with small velocity dispersion \u2022 the solar neighborhood kinematics and the spiral arms \u2022 spiral arms in the mw-type galaxies \u2022 the hercules branch of a galactic model using only a bar \u2022 theoretical study of the bar and spiral arm perturbations in the xci model \u2022 dark matter currents in the galactic dark disk Predicted Summary -GenCompareSum (t5 -s2orc-title) \u2022 in @xcite we presented a study of the solar neighborhood kinematic groups using a sample of 24,190 stars . \u2022 lastly , we investigate effects on the local dark matter kinematics , in particul ar in the disk -like dark matter structure recently predicted by lcdm models . \u2022 the induced kinematic distribution at the end of the simulation is studied by c onsidering the particles inside a circle of radius @xmath7 centered at the sol ar position . \u2022 therefore we focused on the recently induced kinematic structure in the solar neighborhood .",
    "funding": {
        "defense": 0.0,
        "corporate": 0.0,
        "research agency": 0.0,
        "foundation": 5.51223498068687e-07,
        "none": 0.9988647134259659
    },
    "reasoning": "Reasoning: The article does not provide specific information regarding funding sources for the research. Without explicit mention of support from defense, corporate entities, research agencies, foundations, or an indication of no funding, it is not possible to accurately determine the funding sources.",
    "abstract": "Text summarization (TS) is an important NLP task. Pre-trained Language Models (PLMs) have been used to improve the performance of TS. However, PLMs are limited by their need of labelled training data and by their attention mechanism, which often makes them unsuitable for use on long documents. To this end, we propose a hybrid, unsupervised, abstractive-extractive approach, in which we walk through a document, generating salient textual fragments representing its key points. We then select the most important sentences of the document by choosing the most similar sentences to the generated texts, calculated using BERTScore. We evaluate the efficacy of generating and using salient textual fragments to guide extractive summarization on documents from the biomedical and general scientific domains. We compare the performance between long and short documents using different generative text models, which are finetuned to generate relevant queries or document titles. We show that our hybrid approach out-performs existing unsupervised methods, as well as state-of-the-art supervised methods, despite not needing a vast amount of labelled training data.",
    "countries": [
        "United Kingdom"
    ],
    "languages": [],
    "numcitedby": 1,
    "year": 2022,
    "month": "May",
    "title": "{G}en{C}ompare{S}um: a hybrid unsupervised summarization method using salience"
}