{
    "article": "In this paper we present a new empirical method for coreference resolution, implemented in the COCKTAIL system. The resuits of COCKTAIL are used for lightweight abduction of cohesion and coherence structures. We show that referential cohesion can be integrated with lexical cohesion to produce pragmatic knowledge. Upon this knowledge coherence abduction takes place. I Motivation Coreference evaluation was introduced as a new domain-independent task at the 6th Message Under-standi~ Conference (MUC-6) in 1995. The task focused on a subset of coreference, namely the ide~tiQ/ coreference, established between nouns, pronouns and noun phrases (including proper names) that refer to the same entity. In d~-;,~ the coreference task (d. (Hirschnum and Chinchor, 1997) ) special care was taken to use the coreference output not only for supporting Information Extraction(IE), the central task of the MUCs, but also to create means for re.arch on corefea~mce and discourse phenom~ independent of IE. Annotated corpora were made available, using SGML tagging with~, the text stream. The annotated texts served as tralz~g examples for a variety. of corderence resolution methods, that had to focus not only on precision and recall, but also on robustness. Two general classes of approaches were distinguished. The first class is characterized by adaptations of previously known reference algon'thms (e.g. (Lappin and Leass, 1994) , (Brennan et al., 1987) ) the scarce syntactic and semantic knowledge available m an w. system (e.g. (Kameyama, 1997) ). The second class is based on statistical and machine learning techniques that rely on the tagged corpora to extract features of the coreferential relations (e.g. (Aone and Bennett, 1994) (Kehler, 1997) ). \u2022 In the past two MUC competitions, the high scoring systems achieved a recall in the high 50's to low 60's and a precision in the low 70's (d. (Hirschman et al., 1998) ). A study z of the contribution of each form of coreference to the overall performance shows that generally, proper name anaphora resolution have the highest precision (69%), followed by pronominal reference (62%). The worse .precision is obtained by the resolution of d~_ n!te nominals anaphors (46%). However, these results need to be contrasted with the distribution of coreferential links on the tagged corpora. The majority of coreference links (38.42%) connect names Of people, organizations or locations. In addition, 19.68% of the tagged co~ce links are accounted by appositives. Only 16.35% of the tagged coreferences are pronominal. Nominal anaphors account for 25.55% of the coreference links, and their resolution is generally poorly represented in IE systems. Due to the distribution of coreference links in newswire texts, a coreference module that is merely capable of handling recognition of appositives with high precision and incorporates rules of name alias identification can achieve a baseline coreference precision up to 58.1%, without sophisticated syntactic or discourse information. Precision increase is obtained by extending lfigh-performance pronoun resolution methods (e.g. (Lappin and Leass, 1994) ) to nominal corderence as well. Such enhancements rely on semantic and discourse knowledge. In this paper we describe COCKTAIL, a highperformance coreference resolution system that operatas on a mixture of heuristics that combine semantic and discourse information. The resulting tThe study, reported in (Kameyama, 1997) , was performed on the coreference module of SRI's FASTUS (Appelt et al., I993), an IE system representative of today's IE technology. coreference chains are shown to contribute in the derivation of cohesive chains and coherence graphs. Both cohesive and coherence structures are considered, partly because of their incremental complexity and partly because the tradition (started with (Hobbs, 1979 )) of studying the interaction of coreference and coherence. Section 2 presents COCKTAIL and the coreference methods it built upon. Sections 3 and 4 describe the derivation the cohesion and coherence structures. Coreference Resolution Coreference resolution relies on a combination of linguistic and cognitive aspects of language. Linguistic constraints are provided mostly by the syntactic modeling of language, whereas computational models of discourse bring forward the cognitive aesumplions of anaphora resolution. Three different methods of combining anaphoric constraints am known to date. The Rrst one integrates anaphora resolution in computational models of discourse interpretation. Dynamic properties of discourse, especially focusing and centering are invoked as the primary b~-~|~ for identifying antecedents. Such computational methods were presented in (Grosz et al., 1995) and (Webber, 1988) . A second category of approaches combines a v~ riety of syntactic, semantic and discourse factors as a multi-dimensional metric for ranking antecedent candidates. Anaphora resolution is determined by a composite of several distinct scoring procedures, each of which scores the prominence of the candidate with respect to a specific.type of information. The systems described in (Asher and Wada, 1988) (Carbonell and Brown, 1988) and (Rich and Luperfoy, 1988) are examples of the mixed evaluation strategy. Alternatively, other discourse-based methods consider co~eference resolution a by-product of the recognition of coher~ce relations between sentences. Such methods were presented in (Hoblm et al., 1993) and ~flensky, 1978) . Although M-complete, this approach has the appeal that it resolves the most complicated cases of coreference, uncovered by syntactic or semantic cues. We have revisited these methods by setting the relation between coreference and coherence on empirical grounds. Pronominal Coreference Two tendencies characterize current pronominal coreference algorithms. The first one makes use of the advances in the parsing technology or on the availability of large parsed corpora (e.g. Trcebank (Marcus et al.1993 )) to produce algorithms inspired by Hobbs' baseline method (Hobbs, 1978) . For example, the Resolution of Anaphor~ Procedure (RAP) i~itroduced in (Lappin and Leass, 1994 ) combines syntactic information with agreement and salience constraints. Recently, a probabilistic approach to pronominal coreference resolution was also devised (Ge et al., 1998) , using the parsed data available from Treebank. The knowledge-based method of Lappin and Leass produces better results. Nevertheless, RkPSTAT, a version of RAP obtained by using statistically measured preference patterns for the antecedents, prodticed a slight enhancement of performance over RAP. Other pronominal resolution approaches promote knowledge-poor methods (Mitkov , 1998) , either by using an ordered set of general heuristics or by combining scores assigned to candidate antecedents. The CogNIAC algorithm (Baldwin, 1997) uses six heuristic rules to resolve coreference, whereas the algorithm presented in (Mitkov, 1998) is based on a limited set of preferences (e.g. definitiveness, lexical reiteration or immediate reference). Both these algorithm rely only on part-of-speech tagging of texts and on patterns for NP identification. Their performance (dose to 90% for certain types of pronouns) indicates that full syntactic knowledge is not required by certain forms of pronominal coreference. The same claim is made in (Kennedy and Boguraev, 1996) and (Kameyama, 1997) , where algo-rithm~ approximating RAP for poorer syntactic input obtain precision of 75% and 71%, respectively, a surprising small precision decay from RAP's 86%. These results prompted us to devise COCKTAIL, a corderence resolution system, as a mixture of heuristics performing on the various syntactic, semantic and dL~ourse cues. COCKTAIL is a composite of heuristics learned from the tagged corpora, which has the following novel characteristics: Antecedents of reflexive pronouns are always sought in the same sentence. Antecedents of other types of pronouns are sought in preceding sentences too, starting from the immediately preceding sentence. Inside the sentence, the search for a specific word is performed from the current position towards the beginning of the sentence, whereas in the pre-Before Pennzoii's court fight with Texaco over the Getty purchase, Mr. Liedtke -one of the ploy's foremost practitionersportrayed him.~elfas something of an oil-patch tube, a notable f~---'~\"~-~nsidering his diplomas from Amherst College and Harvard Business School. The' woman who is kuown to me as hard-working and. responsible, clearly isn't hersel/. Unlike many of her peers, m~t of whom are males in their 30s, s.he never takes herself too seriously. Table h Examples of reflexive pronouns Heuristic HIR H2R H3R H4K Precision on a test set of I00 randomly 95% 92% 98% 89% selected pronouns Table 2 : Coreference precision (reflexive pronovns) ceding sentences, the search starts at the beginning of the sentence and proceeds in a left to right fashion. The same search order was used in (Kameyama, 1997) COCKTAIL's test of semantic consistency blends togerber information available from WordNet and on statistics gathered from ~ebank. Different consistency checks are modeled for each of the heuristics. We detail here the check that applies to heuristic HIPos, that resolves the possessive from the first example listed in Table 3 . For this heuristic, we have to test whether from the possessive [Ante Nount] we can grant the pos~_~ve [Ante Noone] as well. There axe three cases that allow us to do so: \u2022 ~ase 1 Nount and Nouno corder. \u2022 Case ~Theceis ase~se ss of Nounx and asense so of Nouno such that a synonym of Noun~ i or of its immediate hypernym is found in the gloss of Noon~ or vicevers& \u2022 ~ There is a sense st of Nounx and a sense So of Nouno such that a common concept is found in their glosses. Cases 2 and 3 extend to synsets obtained through derivational morphology as well (e.g. nominalizations). For cases 2 and 3 COCKTAIL reinforces the coreference hypothesis by using a possessive. similarity metric based on Resuik's similarity measures for noun groups (B___,~m_ i_k, 1995). From a subset of Treebank, we collect all possessives, and measure whether the similarity~clam of Nouno, Noun1 and their eventual common concept is above a threshold produced off-line. Other pronominal coreference heuristics employ Search2, a search procedure that enhances Searchx, since it prefers antecedents that are immediately succeeded by relative pronouns. This search is in. corporated in COCKTAIL's heuristics that resolve 3rd person pronominal coreference: 0 O O O O 0 O @ @ O O 0 0 O O @ @ 0 0 0 e O 0 0 O O 0 0 0 @ 0 0 0 @ @ 0 0 0 O @ @ olution. FYom our initial experiments, we do not see the need for special semantic consistency checks, since all heuristics performed with precision in excess of 90% Part of this is explained by our usage of pleonastic filters and of recognizers of idiomatic usage. Table 5 illustrates some of the successful coreference resolutions. H_qe says that in many years as a banker he has grown accustomed to \"dealing with honest people 99% of the time. sen. Byrd takes pains to reassure the voter that he will see to it that the trade picture improves. A..nurse who deals with the new patient ~Jmits sh. . _~e isn't afraid of her temper. ~ect is sensitive at a time when IMB is !aying off thousands of employees Mr Iacocca led Chrysler through one of the 'largest stock sales ever for a U.S. industrial company, raising .$1.78 billion. Chrysler is using most of the proceeds to reduce its $4.4. billion unfunded pension liability. We read where the Clinton White House is seeking a deputy to chief of staff Mack McLarty to impose some disciplined coherence on the p/ace's \u2022 ambunctious young staff. Table 6 : Examples of nominal coreference the term repetition indicator, when consistency checks apply. For this heuristic, consistency checks are conservative, imposing that either the adjuncts be identical, coreferring or the adjunct of the referent be less specific than the antecedent. Specificity principles apply also to HSNom, where hyponymy is promoted, similarly to (Poesio and Vieirs, 1998) . Heuristic H3Nom allows coreference between \"the Securities and F_,z~ange Commission n and .~he commission ~ but it bans links between ~Reardon Steel Co.\" and \"tons of steal\". Many times coreferring nomln~l~ share a~o semantic relations (e.g. synonym#). Heuristic HSNom identifies such cases, by applying consistency checks. Based on experiments with the coreference module of FASTUS, where this heuristic was initially implemented, we require that most frequent senses of nouns be promoted. The same precedence of f~quent senses is implemented in the assi~ment of categories, defined as the immediate WordN~ h~ pernTpn. The category of proper names is dictated by the proper name recognizer, ~qlo~ing such categories m Person, Organization or In this way, coreference between \"IBM ~ and ~he wo,mded computer 9lent ~ can be estab!|~bed, since sense 3 of noun #/ant is Organim6on, the category of ~IBM~. Simi!m-~tegory-based semaatic cheCkS allow the recognition of the antecedent of proceeds from the second example listed in Table 6 . The h~l~ern~ of ~eceezk is ga/n, whose glou genus is amount, the category of $1.78 biUio~ Semantic checks are also required in H?Nom and HSNom, heuristic that rely on derivational morphology. The first example from The empirical \u2022 methods employed in COCKTAIL are an alternative to the inductive approaches described in (Cardie and Wagstatf, 1999) and (McCarthy and Lehnert, 1995) . Our results show that high-precision empirical techniques can be ported from pronominal coreference resolution to the more difficult problem of nominal coreference. Lexical Cohesion The heuristics encoded in COCKTAIL make light use of textual cohesion, i.e. the property of texts to Ustick together s by using related words. Both pronominal and nominal coherence resolution heuristics use cohesion cues indicated by term repetition while nominal corofexence relies on semantic relations between anaphors and their antecedents. In addition, coreference chains are a form of textual cohesion, known as referential cohesion (d. (Halliday and Haesan, 1976) ). Until now, lex/m/cohes/on, arising from semantic connections between words, was successfully used as the only form of textual cohesive structure, known as \u2022 lez/cd chdn& At present there are three methods of generating lexical chains. The first one, implemented in the TextTning algorithm (Hearst, 1997), counts the f~lUencies of term repetitions and is an ideal, lightweight tool for segmenting texts. The second method, adds knowledge from semantic dictionaries (e.g. Roget's Thesaurus in the work of (Morris and Hirst, 1991) or WordNet in the methods presented in (B~y and Elhadad, 1997), (Hirst and St-Onge, 1998) ). Besides term repetition, this approach reco~i,~s relations between text words that are connected in the dictionaries with predefined patterns. This method was applied for generation of text ~lmmm'ies, the recognition of the intentional structure of texts and in the detection of malapropism. The third method is based on a path-finding algorithm detailed in (Harabagiu and Moldovan, 1998) . This method creates a richer SDefiuition introduced in (Halliday and Ha.man, 1976) and (Morris and Hirst, 1991) 34 0 0 0 @ 0 @ 0 O O 0 @ 0 0 @ 0 0 0 0 0 0 @ 0 @ 0 @ 0 0 0 0 @ 0 0 0 0 0 0 0 0 0 0 0 0 O @ O O O O O O O O O O O @ O O O 0 O O O O O O O @ O 0 O @ O O O O @ O O O O O @ O @ O O @ structure, useful for the al~duction of coherer~e relations from the knowledge encoded in WordNet. Here we describe a new cohesion structure that (a) incorporates both lexical and referential cohesion and (b) produces a unique chain that contains not only single words, but also textual entities encompassing head-adjunct lists. We use the finite-state parses of FaSTU$ (Appelt et al., 1993) for recognizing these entities, but the method extends to any basic phrasal parser 4. We produce this novel cohesive structure to exploit the close relation between text cohesion and coherence. It is known (cf. (Harabagiih 1999) ) that cohesion, as a surface indicator of the text coherence, can indicate the lexico-semantic knowledge upon which coherence is inferred. Our aim is to use this cohesive chain for producing axiomatic knowledge for CICERO, a TACITUS-like system that abducts coherence relations. TACITU$ (Hobbs etal., 1993) is a successful abductive system when provided with extensive pra\u00a3~n~ic and linguistic knowledge. CICERO is des~ned as a Jightwe~t version of TACITUS, that performs reliable abductions, with minimal knowledge and effective searches. Translating all the lexical, morphological, synta~'c and semantic ambiguities from texts would make the search intractable. Out solution for CICERO is to use a cohesive chain to create manageable knowledge upon which the abduction can be performed. Section 4 describes this knowledge and the operation of CICERO. Our cohesive chain is a link~! structure consisting of three parts: (1) the connected text entity, (2) its incoming and outgoing pointers and (3) a fez/cosemantic. ~ph~ containing paths of WordNet con-cepts and relations. The lexico-semantic structure is later translated in the axiomatic knowledge that supports coherence inference. Textual entities are either basic phrases contained in the coreference chaln.q or lists of phrases collected from the parse, by scanning for all NGs or NAMEphrases directly connected to a verb phrase through a S~bject, Ob3ect or prepositional relations. For example, as phrase \"Toys R (.ramie the antecedent from a coreference chain, its corresponding textual entity is: |a~oys R Us\"-Subject-+ '%ame\"] [ |nm~-Objectl-\"Mid~d GoMste/n~ . 1 \" [n~-Object2-\"cA/e/e~cuffve offu~,~ The cohesion chain for our. text is illustrated in Figure 1 . The algorithm that generates cohesion chains is: Algorithm Cohesion-Chaln-Builder I. if (current N@ belongs to a core/erenc~ chain) . Create its te.z'htal entity TE and place .it on the Chain ~,. if (the an ~__dent @ already/in the chain) Place the corefer~ pointer bet~eea the two TEs if (the ooreferen~ is not an appositive) Populate the lezico-semantic s~ctu~(TE) \" The derivation of the lexico-semantic structure (LSS) follows the steps: Lfor every re/at/on r(wt,,n2) from a TE   We base our consideration of textual coherence on the definitions introduced in (Hobbs, 1985) . The formal definition of relations that capture the coherence between textual assertious is based on the relations between the states they infer, their changes and their logical connections. States, changes and logical connections can be retrieved from pragmatic knowledge, accessible in lexical knowledge bases like WordNet. The complex structure of our cohesion chains help guiding these inferences. 0 For each textual unit, defined from the parse of the O text, axiomatic knowledge produced. The acquisition of axiomatic knowledge is cued by the concepts O and relations from the LSS portion of the cohesion O chain, and is mined from WordNet. CICERO, our system, adds to this knowledge axioms that feature the O characteristics of every coherence relation. CICER0's O job is to abduct the coherence structure of a text. To do so, it follows the steps: 0 /.for every textual unit TUi @ ~. Derive pragmatic knowledge for TUi @ 3. for every pair (TUi,TUj),i ~ j 4-for every coherence relation 7~k O 5. hypothesize R~(TU. TUj) 6. Perform abduction R~ (TU. TUj) O 7. Choose cheapest abduction @ For the text illustrated in Section 3, this proce-O dure generates the coherence graph illustrated in @ Figure 2 We exemplify the operation of CICERO on this text by presenting the way it derives the Elaboration relation between the textual unit from the first sentence that announces the nomination of Michael Goldstein (TU.) and the textual unit from the same sentence that deals with the succession of Charles Lazarus (TUb). l~st, CICERO generates the knowledge upon which the abductions can be performed. This knowledge is represented in axiomatic form, using the notation proposed in (Hobbs et al., 1993) and previously implemented in TACITUS. In this formalism each text unit represents an event or a state, thus has a special variable e associated with it. Events are lexicalized by verbs, which are reaped into predicates verb (e,z,y) , where z represents the subject of the event, and y represents its object (in the case of intransitive verbs, y is not attached to a predicate, In the next step, ~!1 coherence relations are hypothesized, and the cost of their abduction is obtained. The appendix lists the LISP function created on the fly by CICERO that produces the abduction of the Elaboration function. Because of the computational expense, an intermediary Step simplifies the axiomatic knowledge. The appendix lists also the full abduciton and its cost. CICERO is a system still under development, and at present we did not evaluate the precision of its results. Conclusion We have introduced a new empirical method for coreference resolution, implemented in the COCgTtIL system. The results of this algorithm are used to \u2022 guide the abduction of coherence relations, as performed in our ClC~0 system. In an intermediary step, a rich cohesion structure is produced. This novel relation between coreference and coherence contrasts with the traditional view that coreference is a by-product of coherence resolution. Moreover, we reiterate the belief that coherence builds up from cohesion. Communication of the A CM, 38(11) :39-41. Ruslan Mitkov. 1998 . Robust pronoun resolution with limited knowledge. In ProeePdings of COLING-A 0L'98, pages 869-875. Jane Morris and Graeme Hirst. 1991 . Lexieal cohesion computed by thesaura] relations as an indicator of the  (CO~ [1 i~ El) Con: 22.0 2ro8 .e~ IIO-SPECI~'rZOIIS :1~ 0 ~:rmg u:lLeo 2.0: ((CO~lJ~ FA E2 F.).I0.00.0)((ASSOI~-FOSZTZ~ E2 l),S.00,1) (0~pl'Yoposrrza E2 A), 6.00o 1) cIm-s~q~cuu'l~lnls E2 A) 3 Cost: 24.400002 fz~8 e~ ~_ltrquLT1/H in I uJLng mrA~ 1.1:",
    "abstract": "In this paper we present a new empirical method for coreference resolution, implemented in the COCKTAIL system. The resuits of COCKTAIL are used for lightweight abduction of cohesion and coherence structures. We show that referential cohesion can be integrated with lexical cohesion to produce pragmatic knowledge. Upon this knowledge coherence abduction takes place.",
    "countries": [
        "United States"
    ],
    "languages": [],
    "numcitedby": "36",
    "year": "1999",
    "month": "",
    "title": "Knowledge-Lean Coreference Resolution and its Relation to Textual Cohesion and Coherence"
}