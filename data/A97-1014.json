{
    "article": "We describe an annotation scheme and a tool developed for creating linguistically annotated corpora for non-configurational languages. Since the requirements for such a formalism differ from those posited for configurational languages, several features have been added, influencing the architecture of the scheme. The resulting scheme reflects a stratificational notion of language, and makes only minimal assumptions about the interrelation of the particu-Jar representational strata. Introduction The work reported in this paper aims at providing syntactically annotated corpora ('treebanks') for stochastic grammar induction. In particular, we focus on several methodological issues concerning the annotation of non-configurational languages. In section 2, we examine the appropriateness of existing annotation schemes. On the basis of these considerations, we formulate several additional requirements. A formMism conrplying with these requirements is described in section 3. Section 4 deals with the treatment of selected phenomena. For a description of the annotation tool see section 5. Motivation Linguistically Interpreted Corpora Combining raw language data with linguistic intormation offers a promising basis for the development of new efficient and robust NLP methods. Realworld texts annotated with difihrent strata of linguistic information can be used for grarninar induetion. The data-drivenness of this approach presents a clear advantage over tile traditional, idealised notion of competence grammar. Existing Treebank Formats Corpora annotated with syntactic structures are commonly referred to as trt:tbauk.~. Existing tree-bank annotation schemes exhibit a fairly uniform architecture, as they all have to meet the same basic requirements, namely: Descriptivity: GrammaticM phenomena are to be described rather than explained. Theory-independence: Annotations should not be influenced by theory-specific considerations. Nevertheless, different theory-specific representations shMl be recoverable from the annotation, cf. (Marcus et al., 1994) . Multi-stratal representation: Clear separation of different description levels is desirable. Data-drivenness: The scheme must provide representational means for all phenomena occurring in texts. Disambiguation is based on human processing skills (cf. (Marcus et at., 1994) , (Sampson, 1995) , (Black et al. , 1996) ). The typical treebank architecture is as follows: Structures: A context-free backboI~e is augmented with trace-filler representations of non-local dependencies. The underlying argum~.nt structure is not represented directly, but can be recovered from the tree and trace-filler ammtations. Syntactic category is encoded in node IM:,els. Gralnmatical flinctioxls constitute a complex label system (cf. (Bies et al., 1995) , (Sampson, 1995) ). Part-of-Speech is annotated at word level. Thus the context-li'ee constituent backbone plays a pivotal role in the annotation scherne. Due to the substantial differences between existing models of constituent structure, tile question arises of how the theory indcp~ndcnc~, requirement can be satisfied. At this point the mlportance of the underlying argument struc~ur\u00a2: is emphasised (cf. (Lehmaim et al., 1996) , (Marcus et al., 1994) , (Sampson, 1995) ). Language-Specific Features Treebanks of the tbrmat described ill tile M)ove section have been designed tbr English. Tllereff)re, the solutions they offer are not always optirnal for other language types. As for free word order languages, the following features may cause problems: \u2022 local a,nd ram-local dependencies tbrm a continuum rather than clear-cut classes of phenomena; \u2022 there exists a rich inventory of discontinuous constituency types (topicalisation, scrambling, clause union, pied piping, extraposition, split NPs and PPs); \u2022 word order variation is sensitive to many factors, e.g. category, syntactic flmction, focus; \u2022 the gramrn~ticMity of different word permutations does not fit the tr~,ditional binary 'rightwrong' pattern; it, rather tbrms a gradual transition between the two poles. In light of these facts, serious difficulties can be expected arising from the structurM component of the existing formalisms. Due to the frequency of discontinuous constituents in non-eonfigurational langua.ges, the filler-trace mechanism would be used very often, yielding syntactic trees fairly different from the underlying predicate-argument structures. Consider the German sentence The fairly short sentence contains three non-local dependencies, marked by co-references between traces and the corresponding nodes. This hybrid representation makes the structure less transparent, and therefore more difficult to annotate. Apart from this rather technical problem, two further arguments speak against phrase structure as the structural pivot of the annotation scheme: \u2022 Phrase structure models stipulated tbr nonconfigura.tionM languages differ strongly from each other, presenting a challenge to the intended theory-independence of the schelne. \u2022 Constituent structure serves as an exl)la.natory device for word order variation, which is difficult to reconcile with the descriptivity requirement. Finally, the structural handling of free word order means stating well-formedness constraints on structures involving many trace-filler dependencies, which ha:s proved tedious. Since most methods of handling discontinuous constituents make the fornaalism more powerfifl, the efficiency of processing deteriorates, too. An Mternative solution is to make argurnent structure the main structural component of the formalism. This assumption underlies a growing number of recent syntactic theories which give up the context-free constituent ba.ckbone, cf. (McCawley, 1987) , (Dowty, 1989) , (Reape, 1993) , (Kathol and Pollard, 1995) . These approaches provide an adequate explanation for several issues problematic ibr phrase-structure grammars (clause union, extraposition, diverse second-position phenomena). Annotating Argument Structure Argument structure can be represented in terms of unordered trees (with crossing branches). In order to reduce their ambiguity potential, rather simple, 'flat' trees should be employed, while more information can be expressed by a rich system of function labels. Furthermore, the required theory-independence means that the form of syntactic trees should not reflect theory-specific assumptions, e.g. every syntactic structure has a unique hea.d. Thus, notions such as head should be distinguished at the level of syntactic flmctions rather than structures. This requirement speaks against the traditional sort of d~:pendency trees, in which heads are represented as non-terminal nodes, cf. (Hudson, 1984) . A tree meeting these requirements is given below: (,,)--- I Adv V NP NP V CPL NP V daran wird ihn Anna erkennen, &tss er weint Such a word order independent representation has the advantage of all structural ini'orrrlation being encoded in a single data structure. A unifbrm representation of local and non-local dependencies makes the structure more transparent 1 . The Annotation Scheme 3.1 Architecture YVe distinguish the tbllowmg levels of representation: 1A context-Kee constituent backboIm ca.it still be recovered fl'mn tile surfa,ce string a.nd a.rgmnent structure by rea, tta,ching 'extra.cted' structures to ;t higher node. Argument structure, represented in terms of unordered trees. Grammatical functions, encoded in edge labels, e.g. SB (subject), MO (modifier), HD (head). Syntactic categories, expresse(l by category labels assigned to non-terminal nodes and by part-of-speech tags assigned to terlninals. Argulnent Structure A structure for (2) is shown in fig. 2. (2) schade, dM~ kein Arzt anwesend ist, tier pity that no doctor present is who sich auskennt is competent 'Pity that no competent doctor is here' Note that the root node does not have a head descendant (HD) as the sentence is a predicative construction consisting of a subject (SB) and a predicate (PD) without a copula. The subject is itself a sentence in which the copula (is 0 does occur and is assigned the tag HD 2. The tree resembles traditional constituent structures. The difference is its word order independence: structural units (\"phrases\") need not be contiguous substrings. For instance, the extraposed relative clause (RC) is still treated as part of the subject NP. As the annotation scheme does not distinguish different bar levels or any similar intermediate categories, only a small set of node labels is needed (currently 16 tags, S, NP, AP ...). 3.3 Grammatical Functions Due to the rudimentary character of the argument structure representations, a great deal of reformation has to be expressed by gramnlatical functions. Their further classification must reflect different kinds of linguistic information: morphology (e.g., case, inflection), category, dependency type (complementation vs. modification), thematic role, etc. 3 However, there is a trade-off between the granularity of information encoded in the labels and the speed and accuracy of annotation. In order to avoid inconsistencies, the corpus is annotated in two stages: basic annotalion and r'efincment. While in the first phase each annotator has to annotate structures as well as categories and functions, the refinement can be done separately for each representation level. During the first, phase, the focus is on almotating correct structures and a coarse-grained classification of grammatical functions, which represent the following areas of information: 2CP stands for conwlementizer, OA for accusative object and RC for relative clause. NK denotes a 'kernel NP' component (v. section 4.1). aFor an extensive use of gr;tnllnaticM functions Cf. (K~trlsson et al., 1995) , (Voutilainen, 1994) . Dependency type: complemcnls are fllrther classified according to features su(:h as category and case: clausal complements (OC), accusative objects (OA), datives (DA), etc. Modifiers are assigned the label MO (further classification with respect to thematic roles is planned). Separate labels are defined for dependencies that do not fit the complement/modifier dichotomy, e.g., pre-(GL) and postnominal genitives (GR). Headedness versus non-headedness: Headed and non-headed structures are distinguished by the presence or absence of a branch labeled HD. Morphological information: Another set of labels represents morphological information. PM stands for moTThological partich, a label tbr German infinitival zu aml superlative am. Separable verb prefixes are labeled SVP. During the second annotation stage, the annotation is enriched with information about, thematic roles, quantifier scope and anaphoric ret)rence. As already mentioned, this is done separately for each of the three information areas. Structure Sharing A phrase or a lexical item can perform multiple functions in a sentence. Consider ~.qui verbs where the subject of the infinitival VP is not realised syntactically, but co-referent with the subject or object of the matrix equi verb: (3) er bat reich ZU kolnlnen he asked me to come (mich is the imderstood subject of komm~.u.). In such cases, an additional edge is drawn from tim embed-(led VP node to the controller, thus changing the syntactic tree into a graph. We call such additional edges secondary links and represent them as dotted lines, see fig. 4 , showing the structure of (3). 4 Treatment of Selected Phenomena As theory-independence is one of our objectives, the annotation scheme incorporates a number of widely accepted linguistic analyses, especially ill the area of verbal, adverbial and adjectival syntax. However, some other s~andard analyse.s turn out to be proMemarie, mainly due to the partial, idealised character of competence grammars, which often margmalise or ignore such important phenolnena as 'deficient' (e.g. headless) constructions, apl)ositions, temporal expressions, etc. In the following paragraphs, we give annotations for a number of such phenomena. 4.1 Noun Phrases Most linguistic theories treat NPs as structures hea-(led by a unique lexical item (no,m) However, this idealised model needs severa.l additional assumptions in order to account for such important phenomena as complex norninal NP components (cf. ( 4 )) or nominalised a.djectives (of. ( 5 )). (4) my uncle Peter Smith (5) tier sehr (41iickliche the very lta.ppy 'tire very ha.pl)y one' In (4), different theories make different headedness predictions. In ( 5 ), either a lexical nominalisation rule for the adjective Gliicklichc is stipulated, or the existence of an empty nominal head. Moreover, the so-called DP analysis views the article der as the head of the phrase. Further differences concern the a.ttachment of the degree modifier ,ehr. Because of the intended theory-independence of the scheme, we annotate only the cornmon rninimum. We distinguish an NP kernel consisting of determiners, a.djective phrases and nouns. All components of this kernel are assigned the label NK aml trea.ted as sibling nodes. The diff>rence between the particular NK's lies in the positional and part-of-speech information, which is also sufficient to recover theory-specific structures frorn our 'underspecified' representations. For instance, the first determiner among the NK's can be treated as the specifier of the phrase. The head of the phrase can be determined in a similar way according to theory-specific assumptions. In addition, a number of clear-cut NP components can be defined outside that juxtapositional kernel: pre-and postnorninal genitives (GL, GR), relative clauses (RC), clausal and sentential complements (OC). They are all treated as siblings of NK's regardless of their position (in situ or extraposed). Attaehlnent Ainbiguities Adjunct attachment often gives rise to structural ambiguities or structural uncertainty. However, fill or partial disambiguation takes place in context, and the annotators do not consider unrealistic readings. In addition, we have adopted a simple convention for those cases in which context information is insufficient f~)r total disaml~iguat,ion: the highest possible attachment site is chosen. A similar convention has been adopted ibr constructions in which scope ambiguities ha.ve syntactic effe, cts but a. one-to-one correspondence between scope a.nd attachment does not seem reasonable, cf. focus particles such a.s only or also. If the scope of such a word does not directly correspond to a tree node, the word is attached to the lowest node dominating all subconstituents a.pl)earing ill its scope. Coordination A problem for the rudimentary a.rgument structure representations is tile use of incomplete structures in natural language, i.e. t)henornena such as coordination and ellipsis. Since a precise structural description of non-constituent coordination would require a rich inventor.), of incomplete phrase types, we have agreed on a sort of nnderspecified representations: the coordinated units are assigned structures in which missing lexical material is not represented at the level of primary links. Fig. 3 shows the representation of the sentence: (6) sie wurde van preuliischen Truppen besetzt site was by Prussiaa, troops occupied und 1887 dem preutlischen Staat angegliedert and 1887 to-the Prussia.n state incorporated 'it was occupied by Prussian troops and incorporated into Prussia i,t 1887' The category of the coordination is labeled CVP here, where C stands for coordination, and VP tar the actual category. This extra, marking makes it easy to distinguish between 'normal' and coordinated categories. Multiple coordination as well a.s enumerations are annotated in the same way. An explicit coordinating conjunction need not be present. Structure-sharing is expressed using secondary links. 5 The Annotation Tool Requirenlents The development of linguistically interpreted corpora, presents a laborious and time-consuming task. In order to make the annotation process more efficient, extra effort has been put into the development of an annotation tool. The tool supports immediate graphical feedback and automatic error checking. Since our scheme permits crossing edges, visualisa.tion as bracketing and indentation would be insufficient. Instead, the con> plete structure should be represented. The tool should also permit a convenient handling of node and edge hd)els. In particular, variable tagsets and label collections should be allowed. Implementatioll As the need for certain flmctionalities becomes obvious with growing annota.tion experience, we have decided to iml)lement the tool in two stages. In the first phase, the ma.in flmctionality for buihling and displaying unordered trees is supplied. In the second phase, secondary links and additional structural flmctions are supported. The implementation of the first phase as described in the following paragraphs is completed. As keyboard input is rnore efficient than mouse input (cf. (Lehmalm et al., 1!)95)) rnost effort has been put in developing an efficient keyboard interlace. Menus are supported as a. usefld way of getting help on commands and labels. In addition to pure annotation, we can attach conlments to structures. Figure 1 shows a screen dump of the tool. The largest part of the window contains the graphical representation of tim structure being annot, ate(t. The tbllowing commands are available: \u2022 group words and/or phrases to a new phrase; \u2022 ungroup a phrase; \u2022 change the name of a phrase or an edge; \u2022 re-attach a node; \u2022 generate the postscript output of a sentence. The three tagsets used by the annotation tool (for words, phrases, and edges) are variable and are stored together with the corpus. This allows easy modification if needed. The tool checks the appropriateness of the input. For the implementation, we used Tcl/Tk Version 4.1. The corpus is stored in a SQL database. Automation The degree of automation increases with the amount of data available. Sentences annotated in previous steps are used as training material for further processing. We distinguish five degrees of automation: 0) Completely manual annotation. 1) The user determines phrase boundaries and syntactic categories (S, NP, etc.). The program automatically assigns grammatical fimetion labels. The annotator can alter the assigned tags. 2) The user only determines the conrponents of a new phrase, the program determines its syntactic category and the grammatical functions of its elements. Again, the annotator has the option of altering the assigned tags. 3) Additionally, the program performs simple bracketing, i.e., finds 'kernel' phrases. 4) Tile tagger suggests partial or cornplete parses. So far, about 1100 sentences of our corpus have been annotated. This amount of data suffices as training material to reliably assign the grammatical functions if the user determines the elements of a phrase and its type (step 1 of the list above). Assigning GramInatical Function Labels Grammatical functions are assigned using standard statistical part-of-speech tagging methods (cf. e.g. (Cutting et al., 1992) and (Feldweg, 1995) ). For a phrase Q with children of type T ...... T~: and grammatical fimctions G,,..., (7~:, we use the lexical probabilities PO(GiITi) and the contextual (trigram) probabilities PQ(T; [Ti-,, Ti-~ ) 92 The lexical and contextual probabilities are determined separately for each type of phrase. During annotation, the highest rated granmlatical fimction labels Gi a.re calculated using the Viterbi algorithnr and a.ssigned to the structure, i.e., we. <'Mculate k argma.x H PQ(T, IT, ~_~, ) . PQ (G, IT,) . G i=1 To keep the human annotator from missing errors made by the tagger, we additionally calculate the strongest competitor for each label Gi. If its probability is close to the winner (closeness is defined by a threshold on the quotient), the assignment is regarded as unreliable, and the annotator is asked to confirm the assignment. For evaluation, the already annota.ted sentences were divided into two disjoint sets, one tbr training (90% of the corpus), the other one tbr testing (10%). The procedure was repeated 10 times with different partitionings. The tagger rates 90% of all assignments as reliable and carries them out fully automatically. Accuracy for these cases is 97%. Most errors are due to wrong identification of the subject and different kinds of objects in sentences and VPs. Accuracy of the unreliable 10% of assignments is 75%, i.e., the annotator has to alter the choice in 1 of 4 cases when asked ibr confirmation. Overall accuracy of the tagger is 95%. Owing to the partial automation, the average annotation efficiency improves by 25% (from around 4 minutes to 3 minutes per sentence). Conclusion As the annotation scheme described ill this paper focusses on annotating argunlent structure rather than constituent trees, it differs from existing treebanks in several aspects. These differences can be illustrated by a comparison with the Penn Treeba.nk annotation scheme. The following features of our fornlMisrn a.re then of particular importance: * simpler (i.e. 'fiat') representation structures \u2022 complete absence of ernl.)ty categories \u2022 no special nlechanisnls tbr handling discontinuous constituency The current tagset conlprises only 16 node labels and 34 function tags, yet a. finely grained cla.ssification will take place in the nea.r future. We have argued that the selected approach is better suited for producing higl, quality interpreted col pora m languages exhil)iting free constituent order. In general, the resulting interpreted data also are closer to semantic annotation and more netltra.l with respect to particular synta, ctic theories. As modern linguistics is a.lso becorning rnore aware of the irnportance of larger sets of m~turally occur-  preferences for the choice of certain syntactic constructions, linea.rizations, and atta.chments that have been observed in online experiments of language production and comprehension can now be put in relation with the frequency of these alterna,tives m la.rger amounts of texts. Syntactically a.nnotated corpora of German haze been missing until now. In the second phase of the project Verbnmbi] a. treebank for 30,000 German spoken sentences a.s well a.s for the S~tllle anlounl, of English ~md .]apanese sentences will be created. We will closely coordinate the further develolmlent of our corpus with the annotation work in Verbmobil and with other German efforts in corpus annotation. Since the combinatorics of syntactic constructions crea.tes a demand tbr very large corpora, efficiency of annotation is an important criterion tbr the success of the developed methodology a.nd tools. Our annotation tool supplies efficient ma.nipulation and immediate visualization of argument structures. Partial automation included it, the current version significantly reduces the manual effort. Its extension is subject to fllrther investigations. Acknowledgements This work is part of the DFG Somlerforschungsbereich 378  Proc~:s.~e~,  Project (;3 Conc,:r'r~',.t Gramm.ar Proces.~ug.    We wish to thank Ta,nia, Avgustinova, Berthold Crysmann, La.rs Konieczny, Stephan Oepen, Karel Oliva, Christian Wei6 and two anonymous reviewers {'or their help:[ul comments on the content of this paper. We also wish to thank Robert Maclntyre and Ann Taylor for valualde discussions on the Penn Treebank annotation. Special thanks go to Oliver Plaehn, who implemented the annotation tool, and to our fearless annotators Roland Hendriks, Kerstin K15ckner, Thomas Schulz, and Bernd-Paul Simon.",
    "abstract": "We describe an annotation scheme and a tool developed for creating linguistically annotated corpora for non-configurational languages. Since the requirements for such a formalism differ from those posited for configurational languages, several features have been added, influencing the architecture of the scheme. The resulting scheme reflects a stratificational notion of language, and makes only minimal assumptions about the interrelation of the particu-Jar representational strata.",
    "countries": [
        "Germany"
    ],
    "languages": [
        "English",
        "German"
    ],
    "numcitedby": "386",
    "year": "1997",
    "month": "March",
    "title": "An Annotation Scheme for Free Word Order Languages"
}