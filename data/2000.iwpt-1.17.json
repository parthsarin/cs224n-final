{
    "article": "Existing parsing algorithms for Lexicalized Tree Grammars (LTG) formalisms (LTAG, TIG, DTG, ... ) are adaptations of algorithms initially dedicated to Context Free Grammars ( CFG). They do not really take into account the fact that we do not use context free rules but partial parsing trees that we try to combine. Moreover the lexicalization raises up the important problem of multiplication of structures, a problem which does not exist in .CFG. This paper presents parsing techniques for LTG taking into account these two fundamental features. Our approach focuses on robust and pratical purposes. Our parsing algorithm results in more extended partial parsing when the global parsing fails and in an interesting average complexity compared with others bottom-up algorithms. Introduction Lexicalized Tree Adjoining Grammars (LTAG) [Joshi and Schabes, 1992] have given rise to a lot of interests for the modeling of syntax, in particular thanks to its three \"key\" properties: the principle of Extended Domain of Locality (EDL), the lexicalization and the representation of recursive phenomena using the operation of adjunction. Since these properties alow LTAG to capture semantic dependencies in elementary trees, the parsing result (the derivation trees) is closed to semantic dependency trees which is a relevant structure for post-parsing processes [Candito and Kahane, 1998 ]. This paper focuses on robust chart parsing with Lexicalized Tree Grammars. We do not con sider here probabilistic approximation but only complete or partial structures obtained with valid rule applications. The classical parsing algorithms for LTAG, for . instance CKY-like algorithm [Vijay-Shanker, 1987] , Head-Corner [van Noord, 1994] or Earley-like algorithm [Schabes, 1994] focus on the parsing of complete grammatical utterances. We argue that an algorithm dedicated to the parsing of a Lexicalized Tree Grammar can take into account more efficiently EDL and lexicalization in order to (1) obtain beneficial extended partial results if the global parsing fails, (2) decrease the average complexity of the analysis obtained with bottum-up parsers. The constraints expressed with lexicalized elementary trees are richer than the constraints captured with a set of rewriting context free rules. The extended domain of locality is the fact that an elementary tree encodes directly a syntactical substructure view as a partial parsed tree. It allows to define constraints in more than one level of the parsing tree as compared to context free rules and permits to use atomic features. One way to exploit this property during parsing is to consider for instance co-anchors which are often neglected in existing parsing algorithm. Co-anchors encode cooccurrence information which are significant for parsing. Co-anchors are fr equently used in the French LTAG grammar for prepositional complements and idioms [Abeille et al., 1999) . They could also be massively used in elementary trees obtained with Explanation Based Learning (EBL) methods used to speed up parsing . The lexicalization imposes that each elementary tree contains at least one lexical terminal symbol called the anchor. This constraint permits to represent in each elementary tree one of the syntactical contexts of a lexical entry. This property is usually exploited during a pre-parsing process which consists in the selection of the sub-set of elementary trees that can anchor at least one of the words of the input sentence . But such a property results also in a lot of duplication of the same sub-structures in the grammar which does not exist in a CFG. Existing parsers usually ignore this drawback and result in a lot of redundant computations . Considering the syntactic level, the two main differences between parsing a sentence using a formal grammar and a grammar dedicated to natural language are the necessity to take into account the ambiguity of the language and the potential \"out of grammar\" words and structures. Addressing the problem of ambiguities, efficient results preserving all valid rule applications has been obtained using tabular parsing technics: The result stored in a chart is a shared parse forest [Lang, 1991] . From the point of view of robustness, it is important to be able to implement local analyses, i.e. to try to extract a maximum of information from the utterance ( at least all potential constituents) even if the complete parsing failed. Prediction usually speeds up a parser. Howeve r as explained for example in [Magerman and Weir, 1992] , Earley-style prediction can improve the average case performance but it has serious impacts on ro bust processing of incomplete and ungrammatical sentences which are very common in natural language systems. _The same limit can be observed for LR-style parsing results as [Nederhof, 1998] . As a consequence, we present here a new tabular parsing algorithm for LTAG called connection driven parsing. This incremental bottom-up algorithm could be applied to other kind of LT G. Classical top-down predictions could be used to improve t_ he parsing but they would decrease ro bustness. Connection driven parsing technics Lexicalized Tree Grammars A Thee Adjoining Grammar is specified as a quintuplet G = (E, NT , I , A , S), where E is a set of terminal symbols, NT the disjoint set of nonterminals including the start symbol S, and where I and A are two finite sets of trees called respectively initial trees and auxiliary trees. The set I U A gathers the elementary trees. We consider the standard definition of completely Lexicalized TAG in which each tree contains at least a leaf node, called the anchor, which corresponds to a word. Fo r the complexity results we note N the maximum number of nodes of an elementary tree, G the size of the set I U A and n the lenght of the input string to parse. We note a substitution node with its category and the mark .!,., internal nodes without mark, root nodes with D.. and anchors with the lexical mark O. Finally, we note * l (resp . *r ) the foot node of a left (resp. right) auxiliary tree and * the foot node of a wrapping auxiliary tree. In order to make explanations easier, we will not consider non-adjunction constraints on nodes. A Thee Inserted Grammar (TIG) is a LT G which does not include any wrapping auxiliary tree and supposes that this kind of tree never appears dynamically during the parsing . Using a TIG the worst case complexity of the parsing is decreased to (n 3 ) as all derivations are equivalent to Context Free deriva tions [Schabes and Waters, 1995] . Limits of CF algorithms invariant One of the most important caracteristic of a parser for natural language is its ability to deliver the richest possible partial parsing results when the complete parsing fails. Diagnostic, repairing and interpretation are much easier when we can exploit informative partial derivation trees. When we use a chart parsing algorithm, the partial results are given by the items which represent a chunk of well recognized words. The nature of a partial result is given by the invariant of the algorithm which caracterizes the properties of each produced item. In CFG algorithms, the invariants are based on subtree recognition: Each item represents one position in a elementary tree and a portion of the string to parse. The classical invariants im pose that the sub-tree dominated by the dotted node associated to an item is completely parsed [Shieber et al ., 1995] . Non predictive rules combine complete subtrees into larger ones preserving this invariant. s Not {,V , N ,\ufffd / \ufffd ' , , , , ' , \u2713 I I \"' ' / ' --- ,' \u2713 ' I ' \u2713 \u2713 ( ad ' ' ,' -. ,v\\ N 1 . -' \ufffd _ , _ ------\ufffd, , , I \\ n I \\ I \\ ,'_ \u25ca _\\ n n+l N \u2713 ' ,, ' ,,,' (a :i) ' , , -------_, ? Figure 1 : Bottom-up tree walk and subtree invariant. In figure 1 , we indicate different subtrees which have to be completely recognized to allow the processing of the parsing of the elementary tree. Now we suppose that the utterance to be parsed is agrammatical because of an unexpected component on the right ( at position marked with a ?) . The subtree a 1 on the right is not adjacent to the anchor of the elementary and so the attachment on substitution node N 1 is impossible. The subtree dominated by the node SV can not be complete and the parsing process of this elementary tree must stop, even if the subtree a0 can be combined by adjacency to the susbtitution node N0\u2022 Considering a bidirectional parsing as a CKY type or Head Driven type [Lavelli and Satta, 1991] [van Noord, 1994] when an unexpected phenomena occurs the classical invariant stops the parsing process on both sides of the current recognized subtree even when it is possible to continue the parsing on one side, resulting in poorer partial results. Our first proposition is to focus the parsing on recognized islands and not on recognized subtree and to allow real bidirectional extensions. Since tabular technics impose adjacency of items to combine, we will see that we can take into account the topology of the trees to decrease the average complexity with a new level of granularity for a linearized tree called connected route. Finite States Automata representation of an elementary tree The existing representations of the parsing process of a elementary tree are dotted tree [Vijay-Shanker, 1987 ] and dotted rules [Nederhof, 1997] . In both case this representation is con strained by their locality. We propose an alternative representation that allows to express contraints of significant parts of the tree . The linearization of a tree can be represented with a Finite State Automaton (FSA) as in figure 2 . Every tree traversal (left-to-right, bidirectional from an anchor, ... ) can be performed on this au tomaton . The dotted trees used for example in [Schabes , 1994] or [Shieber et al ., 1995] are equivalent to the states of these automata. (1/ s ft) '1 1) \u25ca S N .!, V \u25ca V S \u00a9-0-0-0-0-0-\u00a9 Figure 2 : Simple FSA representing an elementary tree for the normal form of an intransive verb. We consider the following definitions and notations \u2022 Each automaton transition is annotated with a category of node, each non-leaf node appears twice in the list of transition framing the nodes which it dominates . In order to simplify our explanation the transition is shown by the annotated category. \u2022 Transitions can be bidirectionnal in order to be able to start a bidirectionnal tree walk of a tree starting from any state. \u2022 Considering a direction of transition (left-to-right, right-to-left) the FSA becomes acyclic . Parsing invariant and island representation A set of FSA corresponds to a global representation of the grammar, for the parsing we use a classical local representation called item. An item is defined as a 7-tuple of the following form : The two first indices are the limits on the input string of the island ( an anchor or consecutive anchors) corresponding to the item . During the initialization, we build an item for each anchor ( or co-anchor) present in the input string . An item also stores two states of the same FSA corresponding to the maximal extension of the island on the left and on the right, and only if necessary two additional indices for the position of the foot node of a wrapping auxiliary tree and the state star corresponding to the node where the current wrapping adjunction have been predicted. This representation maintains the following invariant: An item of the form (p, q, (7 \u00a3, UR) specifies the fac t that the linearized tree represented by a FSA .6. is completely parsed between the states l7\u00a3 and UR of .6. and between the indices p and q. No other attachment on the tree can happen on the nodes located between the anchors p and q-1. Connected routes Considering an automaton re presenting the linearization of an elementary tree, we can define a con nected route as a part of this automaton corresponding to the list of nodes crossed successively until reaching a substitution, a foot node or a root node (included transition) or an anchor (excluded tran sition). Connected route is an intermediate level of granularity when representing a linearized tree : each elementary ( or a derived tree) can be represented as a list of connected routes . Since they can represent frontiers of the constituants, considering connected routes during the parsing permits to take into account the topology of the elementary trees and to locate significative nodes for an attachment . The main advantage of considering connected routes during the parsing is the following: The connected routes located between two c\ufffdnsecutive anchors become useless, because there is no place for any operation, and they can be directly eliminated without considering the states they contain . Such elimination will be performed during the parsing each time anchors get close to each other, so each time that an attachment is performed because, by using classical tabular techniques and linearized trees, the parsing is driven by the connection of anchors . This elimination operation is called co-anchor reduction and permits to consider less states (so nodes) during the parsing and so less hypotheses to test . We use the following additional simplified notations and primitives \u2022 The connected route passing through the state ad is noted r d. \u2022 next(r) (resp. previous(r)) gives the first state of the connected route after (resp . before) r according to a left-to-right automaton walk. \u2022 next(N) (resp . previous(N)) gives the state after (resp . before) the transition N. \u2022 head(f) (resp. tail(f)) gives the first right (resp . left) transition of the leftmost (resp . rightmost) state of the connected route r. Inference rules system The derivation process can be viewed as inference rules which use and introduce items . The inference rules (Schabes, 1994] have the following meaning : If item1 and item2 are present in the chart and if the conditions are fulfilled then add item3 in the chart if necessary: item1 add item3 ( conditions ) We present in tables 1 to 5 the different rules of the parser. We illustrate each rule with an abstract tree combination diagram and the state positions on the automata involved in the rule . The first item can be considered as the functor of the rule, for each items we examine successively the nodes on the left and right connected routes . We just have to test then if another adjacent item fulfills the requirements to be the operand of one of the rules. Fo r the bidirectional parsing we just implement the symetric rules . Each rule extends the position on the linearized elementary tree instead of climbing up the spine 1 of the elementary tree as in (Lavelli and Satta, 199 1] or [van Noord, 1994] . Even if the parsing is stopped on one side of the spine, our algorithm allows to reach the root node on the other side ( of course if no agrammaticality occurs on this second side) when the classical algorithms would completely stop the parsing on the both sides . (p, q,uL,UR) (q, r,UL 1 ,UR 1 (p, q,uL,uR) (q, r,uL',uR') (p, r, UL, next(N) Left adjunction: ( 3( N 6. V N) E r L ' head(r L ) = N 6. Right adjunction: ( 3(N 6. V N) E r R head(r L ') = N*r (uL I\\ UR) E \ufffd tail(r R ) = N*t ) (uL' I\\ UR 1 ) E \ufffd tail(r R ') = N 6. Chart parsing Items are stored in a chart type data structure, indexed by their indices and combined according to their adjacency, which allows the factorization of items of the chart (tabular techniques) . No item can be added that already exists in the chart. We use classical item history that prevents to add in the chart already existing items. The same technique is used to select possible operand items for a rule exploiting mutual exclusion between items corresponding to concurrent lexical hypothesis (same anchors or co-anchors). It allows to obtain a global coherence of an item considering its corresponding tree. We also have used a subsomption test, as described in [Satta and Stock, 1989) and suggested for LTAG in [Lavelli and Satta , 199 1) , in order to limit redundant items due to the bidirectional expansion . Parsing is complete when all possible rules have been executed. Coanchors reduction rule \u2022 \u2022 . I ()+-... -+6--0->----\ufffd . q. -----o aR cr L p q (p, q,uL,UR) (q, r,UL 1 ,UR  ementary trees for any kind of tree walk, this FSA does not impose a specific strategy during the parsing and makes it possible to exploit the granularity of connected route . V s s Figure 3 : FSA representing 28 elementary trees corresponding to some intransive and transitive contexts . Figure 3 gives an example of a minimalized FSA which allows to share 28 elementary trees . The number in a state indicates how many trees pass through that state . Ta ble 6: An example of Lexicalized Thee Grammar compaction When FS A are shared in a single one, each state contains identifiers of the elementary trees which pass through it and each item the list of elementary tree identifiers valid for the item 's positions. To test conditions of a rule we must consider every possible transitions paths according to connected routes and the shared FSA. The resulting item of a rule is valid for a subset of identifiers of the elementary trees passing throught the both position states . The \"uncompaction\" can be done when we enumerate the derivations . Implementation and results The algorithm has been implemented in Java and is integrated in a graphical environment system dedicated to grammar design and parsing tests . The parsing workbench allows to test a grammar on corpus and to compare different parsing algorithms for LTA G. The connection driven parsing algorithm and the graphical workbench will be freely avalaible with an open-source licence by the end of 1999. The connection driven parser includes derivation enumeration from the shared parse forest, features unification but not yet sharing of automata. We present in table 7 statistics for the chart parsing of a corpora of 86 1 utterances in French of transcripted spontaneous spoken language with a Sun Ultra 1. We compared two sets of rules: One for the bottum-up connected driven parsing and one for a generalized CKY algorithm for LTAG with predictions as suggested by [Vijay-Shanker and Weir, 1993] , both on the same data, with the same When no connected parse can span the whole sentence , our algorithm results not only in more extended partial derivation trees but also consists in representations of islands and both their right and left connected routes. We can then exploit these results for parsing repairs: The adjacency of two islands which can not be combined according to a given LTAG often lo calizes an agrammaticality. The corresponding chart items can trigger additional repairing ru les and flexible controls in a two-step strategy as shown in [Lopez , 1999b] . Rules for substitution --- Substitution case 1: (p, q, U L , U R) (q, r, (7'\u00a3 r, U L , next(r R)) p End of connected route rule q (p, q, (n , O'R ) (p, q, head(aL), tail(aR)) Ta ble 4: Inference rule for end of connected route. Wr apping adjunction case 1 -1111111 p q r Foot node initialization: (p, q, O'L , O'R ) (q, r, O'L Wr apping adjunction: (p, t, O'L , O'R , q, r, No) (q, r, O'L Ta ble 5: Inference rules for wrapping adjunction case 1. Capting CF factorizations: LT G sharing Lexicalization raises the problem of multiplication of the same substructures which can be serious. In CFG the same rule can be used for all possible parsing trees which contain the corresponding substructure , but in LT G this substructure is duplicated. Considering classical linguistics choices , polystructures (for example to speak to ... , speak about ... , to speak to ... about ... ) are very common. The corresponding elementary trees must share common substructures and therefore do not cost as much as an independant elementary tree for each. As chart parsing can reduce the complexity in n exploiting factorisation of chart items by their positions on the string and on the elementary trees , we can reduce the average complexity in G using compaction of common substructures because such com mon structures of elementery trees imply common actions of the parser. Fo r example [Nederhof, 1998] adresses this problem for LR parsing algorithm . [ Evans and Weir, 1998 ] shares different substructures of elementary trees using FSA and classical minimalization techniques . As presented in [Evans and Weir, 1997] , the authors use automata corre sponding to one particular traversal of the trees . We use similar techniques to share here linearized structures between different elementary trees . The main differences are that , since it represents el- 2.06 Table 7 : Global results of the complete parsing A partial result corresponds here to the maximal extension of an island, so to an item which is not the origin of any other item. Table 8 shows that the average length of partial recognized substrings is higher with our techniques than with this other bottum-up strategy, preserving a running time better than the predictive CKY. This result means that our algorithm has checked more possible attachments and has delivered more extented partial results. Table 8: Comparaison between bottum-up parsers for partial parses The difference between these two running times can be explained by the consideration of connected routes which results in less items to tabulate and by the initialization of foot node. In a predictive CKY-like algorithm for LTAG, the foot nodes are initialized each time that an internal node (with the same category label) is recognized independently to other positions in the auxiliary trees they belong to. This initialization is more determinist in our algorithm since a foot node is initialized when a left or right extension has reached this node. Conclusion We have presented a new tabular algorithm dedicated to LTG which really takes into account the fact that we manipulate partial parsing trees and not CF rules. Lexicalized partial parsing trees are richer structures than CF rules and allow to obtain more extended partial results which are relevant for natural language robust parsing. A complementary compaction of the LTG allows the factorization of sub-structures parsing. This algorithm tries to compromise a chunk parsing and the complete parsing of an utterance, it satisfies the following properties at any moment: \u2022 The maximal extension of islands according to adjacency and local constraints located on the left and right connected route of this island. \u2022 The global correction of each partial results. The theorical worst case complexity is in O(N 2 G 2 n 6 ) , but we argue that in practice, when dealing with natural language, decreasing the average complexity is more important than considering a worst case complexity which conditions almost never happen.",
    "abstract": "Existing parsing algorithms for Lexicalized Tree Grammars (LTG) formalisms (LTAG, TIG, DTG, ... ) are adaptations of algorithms initially dedicated to Context Free Grammars ( CFG). They do not really take into account the fact that we do not use context free rules but partial parsing trees that we try to combine. Moreover the lexicalization raises up the important problem of multiplication of structures, a problem which does not exist in .CFG. This paper presents parsing techniques for LTG taking into account these two fundamental features. Our approach focuses on robust and pratical purposes. Our parsing algorithm results in more extended partial parsing when the global parsing fails and in an interesting average complexity compared with others bottom-up algorithms.",
    "countries": [
        "Germany"
    ],
    "languages": [
        "French"
    ],
    "numcitedby": "9",
    "year": "2000",
    "month": "February 23-25",
    "title": "Extended Partial Parsing for Lexicalized Tree Grammars"
}