{
    "article": "Grounded\" language learning employs training data in the form of sentences paired with relevant but ambiguous perceptual contexts. B\u00f6rschinger et al. (2011) introduced an approach to grounded language learning based on unsupervised PCFG induction. Their approach works well when each sentence potentially refers to one of a small set of possible meanings, such as in the sportscasting task. However, it does not scale to problems with a large set of potential meanings for each sentence, such as the navigation instruction following task studied by Chen and Mooney (2011) . This paper presents an enhancement of the PCFG approach that scales to such problems with highly-ambiguous supervision. Experimental results on the navigation task demonstrates the effectiveness of our approach. Introduction The ultimate goal of \"grounded\" language learning is to develop computational systems that can acquire language more like a human child. Given only supervision in the form of sentences paired with relevant but ambiguous perceptual contexts, a system should learn to interpret and/or generate language describing situations and events in the world. For example, systems have learned to commentate simulated robot soccer games by learning from sample sportscasts (Chen and Mooney, 2008; Liang et al., 2009; B\u00f6rschinger et al., 2011) , or understand navigation instructions by learning from action traces produced when following the directions (Chen and Mooney, 2011; Tellex et al., 2011) . B\u00f6rschinger et al. (2011) recently introduced an approach to grounded language learning using unsupervised induction of probabilistic context free grammars (PCFGs) to learn from ambiguous contextual supervision. Their approach first constructs a large set of production rules from sentences paired with descriptions of their ambiguous context, and then trains the parameters of this grammar using EM. Parsing a novel sentence with this grammar gives a parse tree which contains the formal meaning representation (MR) for this sentence. This approach works quite well on the sportscasting task originally introduced by Chen and Mooney (2008) . In this task, each sentence in a natural-language commentary describing activity in a simulated robot soccer game is paired with the small set of actions observed within the past 5 seconds, one of which is usually described by the sentence. Even with this low level of ambiguity in a constrained domain, their method constructs a PCFG with about 33,000 productions. More fundamentally, their approach is restricted to a finite set of potential meaning representations, and the grammar size grows at least linearly with the number of possible MRs, which in turn is inevitably exponential in the number of objects and actions in the domain. The navigation task studied by Chen and Mooney (2011) provides much more ambiguous supervision. In this task, each instructional sentence is paired with a formal landmarks plan (represented as a large graph) that includes a full description of the observed actions and world-states that result when someone follows this instruction. An instruction generally refers to a subgraph of this large graph. Therefore, there are a combinatorial number of possible meanings to which a given sentence can refer. Chen and Mooney (2011) circumvent this combinatorial problem by never explicitly enumerating the exponential number of potential meanings for each sentence. Their system first induces a semantic lexicon that maps words and short phrases to formal representations of actions and objects in the world. This lexicon is learned by finding words and phrases whose occurrence highly correlates with specific observed actions and objects in the simulated environment when executing the corresponding instruction. This learned lexicon is then used to directly infer a formal MR for observed instructional sentences using a greedy covering algorithm. These inferred MRs are then used to train a supervised semantic parser capable of mapping novel sentences to their formal meanings. We present a novel enhancement of B\u00f6rschinger et al.'s PCFG approach that uses Chen and Mooney's lexicon learner to avoid a combinatorial explosion in the number of productions. The learned lexicon is first used to build a hierarchy of semantic lexemes (i.e. lexicon entries) called the Lexeme Hierarchy Graph (LHG) for each ambiguous landmarks plan in the training data. The intuition behind utilizing an LHG is that the MR for each lexeme constitutes a semantic concept that corresponds to some naturallanguage (NL) word or phrase. Therefore, the LHG represents how complex semantic concepts are composed of simpler semantic concepts and ultimately connected to NL words and phrases. B\u00f6rschinger et al.'s approach instead produces NL groundings at the level of atomic MR constituents, which causes an explosion in the number of PCFG productions for complex MR languages. We estimated that B\u00f6rschinger et al.'s approach would require more than 20! (> 10 18 ) productions for our navigation problem. 1 On the other hand, our method, which uses correspondences from the LHG at the semantic concept level, constructs a more focused PCFG of tractable size. It then extracts the MR for a novel sentence from the most-probable parse tree for the resulting PCFG. Our approach can produce a large, combinatorial number of different MRs for a wide range of novel sentences by composing relevant MR components from the resulting parse tree, whereas B\u00f6rschinger et al.'s approach is only able to output MRs that are explicitly included as a nonterminals in the original learned PCFG. The remainder of the paper is organized as follows. Section 2 reviews B\u00f6rschinger et al.'s PCFG approach as well as the navigation task and data. Section 3 describes our enhanced PCFG approach and Section 4 presents an experimental evaluation of it. Then, Section 5 discusses the unique aspects of our approach and Section 6 describes additional related work. Finally, Section 7 presents future research directions and Section 8 gives our conclusions. Background Existing PCFG Approach Our approach extends that of B\u00f6rschinger et al. (2011) , which in turn was inspired by a series of previous techniques (Lu et al., 2008; Liang et al., 2009; Kim and Mooney, 2010) following the idea of constructing correspondences between NL and MR in a single probabilistic generative framework. Particularly, their approach automatically constructs a PCFG that generates NL sentences from MRs, which indicates how atomic MR constituents are probabilistically related to NL words. The nonterminals in the grammar correspond to complete MRs, MR constituents, and NL phrases. The nonterminal for a composite MR generates each of its MR constituents, and each atomic MR, x, generates an NL phrase, P hrase x . Each P hrase x then generates a sequence of W ord x 's for describing x, and each W ord x can generate each possible word in the natural language. This allows the system to learn the words and phrases used to describe each atomic MR by properly weighting these rules. Figure 1 shows one possible derivation tree for a sample NL-MR pair and the PCFG rules that are constructed for it. Once a set of productions are assembled, their probabilities are learned using the Inside-Outside algorithm. Computing the most probable parse for a novel sentence with the trained PCFG provides its preferred MR interpretation in the topmost nonterminal. Unfortunately, as discussed earlier, this approach only works for finite MR languages, and the grammar becomes intractably large even for finite but complex MRs. It effectively assumes that MRs are fairly small and includes every possible MR constituent as a nonterminal in the PCFG. This is not tractable for more complex MRs. Therefore, our extension incorporates a learned lexicon to constrain the space of productions, thereby making the size of the PCFG tractable for complex MRs, and even giving it the ability to handle infinite MR languages. Moreover, when processing novel sentences, our approach can produce a large space of novel MRs that were not anticipated during training, which is not the case for B\u00f6rschinger et al.'s approach. Navigation Task and Dataset We employ the task and data introduced by Chen and Mooney (2011) whose goal is to interpret and follow NL navigation instructions in a virtual world. Figure 2 shows a sample execution path in a particular virtual world. The challenge is learning to perform this task by simply observing humans following instructions. Formally, given training data of the form {(e 1 , a 1 , w 1 ), . . . , (e n , a n , w n )}, where e i is an NL instruction, a i is an observed action sequence, and w i is the current world state (patterns of floors and walls, positions of any objects, etc.), we want to produce the correct actions a j for a novel (e j , w j ).  In order to learn, their system infers the intended formal plan p i (the MR for a sentence) which produced the action sequence a i from the instruction e i . However, there is a large space of possible plans for any given action sequence. Chen and Mooney first construct a formal landmarks plan, c i , for each a i , which is a graph representing the context of every action and the world-state encountered during the execution of the sequence. The correct plan MR, p i , is assumed to be a subgraph of c i , and this causes a combinatorial matching problem between e i and c i in order to learn the correct meaning of e i among all the possible subgraphs of c i . The landmarks and correct plans for a sample instruction are shown in Figure 3 , illustrating the complexity of the MRs. Instead of directly solving the combinatorial correspondence problem, they first learn a semantic lex- icon that maps words and short phrases to small subgraphs representing their inferred meanings from the (e i , c i ) pairs. The lexicon is learned by evaluating pairs of n-grams, w j , and MR graphs, m j , and scoring them based on how much more likely m j is a subgraph of the context c i when w occurs in the corresponding instruction e i . This process is similar to other \"cross-situational\" approaches to learning word meanings (Siskind, 1996; Thompson and Mooney, 2003) . Then, a plan refinement step estimates p i from c i by greedily selecting high-scoring lexemes of the form (w j , m j ) whose words and phrases (w j ) cover the instruction e i and introduce components (m j ) from the landmarks plan c i . The refined plans are used to construct supervised training data (e i , p i ) for a supervised semantic-parser learner. The trained semantic parser can parse a novel instruction into a formal plan, which is finally executed for end-to-end evaluation. Figure 4 illustrates the overall system. As this figure indicates, our new PCFG method replaces the plan refinement and semantic parser components in their system with a unified model that both disambiguates the training data and learns a semantic parser. We use the landmarks plans and the learned lexicon produced by Chen and Mooney (2011) as inputs to our system. 2 Like B\u00f6rschinger et al. (2011) , our approach learns a semantic parser directly from ambiguous supervision, specifically NL instructions paired with their complete landmarks plans as context. Our method incorporates the semantic lexemes as building blocks to find correspondences between NL words and semantic concepts represented by the lexeme MRs, instead of building connections between NL words and every possible MR constituent as in B\u00f6rschinger et al.'s approach. Particularly, we utilize the hierarchical subgraph relationships between the MRs in the learned semantic lexicon to produce a smaller, more focused set of PCFG rules. 3 The intuition behind our approach is analogous to the hierarchical relations between nonterminals in syntactic parsing, where higher-level categories such as S, VP, or NP are further divided into smaller categories such as V, N, or Det, thereby forming a hierarchical structure. Inspired by this idea, we introduce a directed acyclic graph called the Lexeme Hierarchy Graph (LHG) which represents the hierarchical relationships between lexeme MRs. Since complex lexeme MRs represent complicated semantic concepts while simple MRs represent simple concepts, it is natural to construct a hierarchy amongst them. The LHGs for all of the training examples are used to construct production rules for the PCFG, which are then parametrized using EM. Finally, a novel sentence is semantically parsed by computing its mostprobable parse using the trained PCFG, and then its MR is extracted from the resulting parse tree. Constructing a Lexeme Hierarchy Graph An LHG represents the hierarchy of lexical meanings relevant to a particular training instance by encoding the subgraph relations between the MRs of relevant lexemes. Algorithm 1 describes how an LHG is constructed for an ambiguous training pair of a sentence and its corresponding context, (e i , c i ). First, we obtain all relevant lexemes (w i j , m i j ) in the lexicon L, where the MR m i j is a subgraph of the context c i (denoted as m i j \u2282 c i ). These lexemes are The initial LHG may contain nodes with too many children. This is a problem, because when we subsequently extract PCFG rules, we need to add a production for every k-permutation of the children of each node (see Section 3.2). To reduce the branching factor in the LHG, we introduce pseudo-lexeme nodes by repeatedly combining the two most similar children of each node. Pseudocode for the process is shown in Algorithm 2. The MR for a pseudo-lexeme is the minimal graph, m , that is a supergraph of both of the lexeme MRs that it combines. The pair of Sim(m i , m j , m ) = |m i | + |m j | 2 |m | where |m| is the number of nodes in the MR m. Adding pseudo-lexemes also has another advantage. They can be considered to be higher-level semantic concepts composed of two or more subconcepts. These higher-level concepts will likely occur in other training examples as well, which allows for more flexible interpretations. For example, assuming the rule A \u2192 BCD is constructed from an LHG, we will introduce a pseudo lexeme E and build two rules A \u2192 BE and E \u2192 CD. It is likely that E also occurs in another rule constructed from other training examples such as E \u2192 F G. This increases the model's expressive power by supporting additional derivations such as A \u2192 * BF G, providing more flexibility when parsing novel NL sentences. Composing PCFG Rules The next step composes PCFG rules from the LHGs and is summarized in Figure 6 . We basically follow the scheme of B\u00f6rschinger et al. (2011) , but instead of generating NL words from each atomic MR, words are generated from each lexeme MR, and smaller lexeme MRs are generated from more complex ones as given by the LHGs. A nonterminal S m is generated for the MR, m, of each LHG node. Then, for every LHG node, T , with MR, m, we add rules of the form S m \u2192 S m i ...S m j , where the RHS is some k-permutation of the nonterminals for the MRs of the children of node T . B\u00f6rschinger et al. assume that every atomic MR generates at least one NL word. However, since we do not know which subgraph of the overall context (i.e. c i , the MR of the root node) conveys the intended plan and is therefore expressed in the NL instruction, we must allow each ordered subset of the children of a node (i.e. each k-permutation) to be a possible generation. The rest of the process more closely follows B\u00f6rschinger et al.'s. Every MR, m, of a lexeme node 4 generates a rule S m \u2192 P hrase m , and every P hrase m generates a sequence of NL words, including one or more \"content words\" (W ord m ) for expressing m and zero or more \"extraneous\" words (W ord \u2205 ). While B\u00f6rschinger et al. have W ord m generate all possible NL words (each of which are subsequently weighted by EM training), in our approach, each W ord m only produces the NL phrase associated with m in the lexicon, or individual words that appear in this phrase. The words not covered by W ord m also can be generated by W ord \u2205 which has rules for every word. P h m and P hX m ensure that P hrase m produces at least one W ord m , where P hX m indicates that one or more W ord m 's have already been generated, and P h m indicates that no W ord m has yet been generated. Parsing Novel NL Sentences To learn the parameters of the resulting PCFG, we use the Inside-Outside algorithm. 5 Then, the standard probabilistic CKY algorithm is used to produce the most probable parse for novel NL sentences (Jurafsky and Martin, 2000) . B\u00f6rschinger et al. (2011) simply read the MR, m, for a sentence off the top S m nonterminal of the most probable parse tree. However, in our approach, the correct MR is constructed by properly composing the appropriate subset of lexeme MRs from the most-probable parse tree. This allows the system to produce a wide variety of novel MRs for novel sentences, as long as the correct MR is a subgraph of the complete context (c i ) for at least one of the training sentences. First, the parse tree is pruned to remove all subtrees starting with P hrase x nodes. This leaves a tree consisting of the Root and a set of S m nodes. The pruned subtrees only concern generating NL words and phrases from the selected MRs. The remaining tree shows which MR constituents were selected from the available context, from which the sentence is then generated. Each leaf in the pruned tree represents an MR constituent that was used to generate a phrase in the sentence. These are the constituents we want to assemble and compose into a final MR for the sentence. Algorithm 3 describes the procedure for extracting the final MR from the pruned parse tree. Figure 7 graphically depicts a sample trace of this algorithm. The algorithm recursively traverses the parse tree. When a leaf-node is reached, it marks all of the nodes in its MR. After traversing all of its children, 5 We used the implementation available at http://web. science.mq.edu.au/ \u02dcmjohnson/Software.htm which was also used by B\u00f6rschinger et al. (2011) . a node in the MR for the current parse-tree node is marked iff its corresponding node in any of the children's MRs were marked. The final output is the MR constructed by removing all of the unmarked nodes from the MR for the root node. Experimental Evaluation For evaluation, we used the same data and methodology as Chen and Mooney (2011) . Please see their paper for more details. Data We used the English instructions and follower data collected by MacMahon et al. (2006). 6 This data contains 706 route instructions for three virtual worlds. The instructions were produced by six instructors for 126 unique starting and ending location pairs spread evenly across the three worlds, and there were 1 to 15 human followers for each instruction who executed an average of 10.4 actions per instruction. Each instruction is a paragraph consisting of an average of 5.0 sentences, each containing an average of 7.8 words. Chen and Mooney constructed the additional single-sentence corpus by matching each sentence with the majority of human  followers' actions. We use this single-sentence version for training, but use both the single-sentence and the original paragraph version for testing. Each sentence was manually annotated with a \"gold standard\" execution plan, which is used for evaluation but not for training. Methodology and Results Experiments were conducted using \"leave one environment out\" cross-validation, training on two environments and testing on the third, averaging over all three test environments. We perform direct comparison to the best results of Chen and Mooney (2011) (referred to as CM). A Wilcoxon signed-rank test is performed for statistical significance, and ' * ' denotes significant differences (p < .01) in the tables. Semantic Parsing Results We first evaluated how well our system learns to map novel NL sentences for new test environments into their correct MRs. Partial semantic-parsing accuracy (Chen and Mooney, 2011) comparing the system's MR output to the handannotated gold standard. Accuracy is measured in terms of precision, recall, and F1 for individual MR constituents (thereby awarding partial credit for approximately correct MRs). Table 1 demonstrates that our method outperforms CM by 6 points in F1. Our PCFG-based approach is able to probabilistically disambiguate the training data as well as simultaneously learn a statistical semantic parser within a single framework. This results in better overall performance compared to CM, since they lose potentially useful information, particularly during the refinement stage, due to the separate disjoint components of the system. Navigation Plan Execution Results Next, we test the end-to-end system by executing the parsed navigation plans for test instructions in novel environments to see if they reach the exact desired destinations in the environment. Table 2 shows the successful end-to-end navigation-task completion rate for both single-sentences and complete paragraph instructions. Again, our system outperforms CM's best results since more accurate semantic parsing produces more successful plans. However, the difference in performance is smaller than that observed for semantic parsing. This is because the redundancy in the human generated instructions allows an incorrect semantic parse to be successful, as long as the errors do not affect its ability to guide the system to the correct destination. Discussion Our approach improves on B\u00f6rschinger et al. (2011) 's method in the following ways: \u2022 The building blocks for associating NL and MR are semantic lexemes instead of atomic MR constituents. This prevents the number of constructed PCFG rules from becoming intractably large as happens with B\u00f6rschinger et al.'s approach. As previously mentioned, lexeme MRs are intuitively analogous to syntactic categories in that complex lexeme MRs represent complicated semantic concepts whereas higher-level syntactic categories such as S, VP, or NP represent complex syntactic structures. \u2022 Our approach has the ability to produce previously unseen MRs, whereas B\u00f6rschinger et al. can only generate an MR if it is explicitly included in the PCFG rules constructed from the training data. Even though our MR parse is restricted to be a subgraph of some training context, c i , our model allows for exponentially many combinations. In addition, our approach can produce a wider range of MR outputs than Chen and Mooney (2011) 's even though we use their semantic lexicon as input. Their system deterministically builds a supervised training set by greedily selecting highscoring lexemes, thus implicitly including only high-scoring lexemes during training. On the other hand, our probabilistic approach also considers relatively low-scoring but useful lexemes, thereby utilizing more semantic concepts in the lexicon. In particular, this explains why our approach obtains higher recall in the evaluation of semantic parsing. Even though we have demonstrated our approach on the specific task of following navigation instructions, it is straightforward to apply it to other language-grounding tasks where NL sentences potentially refer to some subset of states, events, or actions in the world, as long as this overall context can be represented as a semantic graph or logical form. Since the semantic lexicon is an input to our system, other approaches to lexicon learning are also easily incorporated. Related Work Most work on learning semantic parsers that map natural-language sentences to formal representations of their meaning have relied upon totally supervised training data consisting of NL/MR pairs (Zelle and Mooney, 1996; Zettlemoyer and Collins, 2005; Kate and Mooney, 2006; Wong and Mooney, 2007; Zettlemoyer and Collins, 2007; Lu et al., 2008; Zettlemoyer and Collins, 2009) . Several recent approaches have investigated grounded learning from ambiguous supervision extracted from perceptual context. A number of approaches (Kate and Mooney, 2007; Chen and Mooney, 2008; Chen et al., 2010; Kim and Mooney, 2010; B\u00f6rschinger et al., 2011) assume training data consisting of a set of sentences each associated with a small set of MRs, one of which is usually the correct meaning of the sentence. Many of these approaches (Kate and Mooney, 2007; Chen and Mooney, 2008; Chen et al., 2010) disambiguate the data and match NL sentences to their correct MR by iteratively retraining a supervised semantic parser. Kim and Mooney (2010) proposed a generative semantic parsing model that first chooses which MRs to describe and then generates a hybrid tree structure (Lu et al., 2008) containing both the MR and NL sentence. They train this model on ambiguous data using EM. As previously discussed, B\u00f6rschinger et al. (2011) use a PCFG generative model and also train it on ambiguous data using EM. Liang et al. (2009) assume each sentence maps to one or more semantic records (i.e. MRs) and trains a hierarchical semi-Markov generative model using EM, and then finds a Viterbi alignment between NL words and records and their constituents. Several recent projects (Branavan et al., 2009; Vogel and Jurafsky, 2010) use NL instructions to guide reinforcement learning from independent exploration with delayed rewards. These systems do not even need the ambiguous supervision obtained from observing humans follow instructions; however, they do not learn semantic parsers that map sentences to complex, structural representations of their meaning. Interpreting and executing NL navigation instructions is our primary task, and several other recent projects have studied related problems. Shimizu and Haas (2009) present a system that parses natural language instructions into actions. However, they limit the number of possible actions to only 15 and treat the problem as a sequence labeling problem that is solved using a CRF with supervised training. Matuszek et al. (2010) developed a system that learns to map NL instructions to executable commands for a robot navigating in an environment constructed by a laser range finder. However, their approach has limitations of ignoring any objects or other landmarks in the environment to which the instructions can refer. There are several recent projects (Vogel and Jurafsky, 2010; Kollar et al., 2010; Tellex et al., 2011) which learn to follow instructions in more linguistically complex environments. However, they assume predefined spatial words, direct matching between NL words and the names of objects and other landmarks in the MR, and/or an existing syntactic parser. By contrast, our work does not assume any prior linguistic knowledge, syntactic, lexical, or semantic, and must learn the mapping between NL words and phrases and the MR terms describing landmarks. Future Work In the future, we would like to develop a better lexicon learner since our PCFG approach critically relies on the quality of the learned lexicon. Particu-larly, we would like to investigate how syntactic information (such as part-of-speech tags induced using unsupervised learning) could be used to improve semantic-lexicon learning. For example, some of the current lexicon entries violate the general constraint that nouns usually refer to objects and verbs to actions. Ideally, the lexicon learner would be able to induce and then utilize this sort of relationship between syntax and semantics. In addition, we want to investigate the use of discriminative reranking (Collins, 2000) , which has proven effective in various other NLP tasks. We would expect the final MR output to improve if a discriminative model, which uses additional global features, is used to rerank the top-k parses produced by our generative PCFG model. Conclusions We have presented a novel method for learning a semantic parser given only highly ambiguous supervision. Our model enhances B\u00f6rschinger et al. (2011) 's approach to reducing the problem of grounded learning of semantic parsers to PCFG induction. We use a learned semantic lexicon to aid the construction of a smaller and more focused set of PCFG productions. This allows the approach to scale to complex MR languages that define a large (potentially infinite) space of representations for capturing the meaning of sentences. By contrast, the previous PCFG approach requires a finite MR language and its grammar grows intractably large for even moderately complex MR languages. In addition, our algorithm for composing MRs from the final parse tree provides the flexibility to produce a wide range of novel MRs that were not seen during training. Evaluations on a previous corpus of navigational instructions for virtual environments has demonstrated the effectiveness of our method compared to a recent competing system. Acknowledgments We thank the anonymous reviewers and David Chen for useful comments that helped improve this paper. This work was funded by NSF grants IIS-0712907 and IIS-1016312. Experiments were performed on the Mastodon Cluster, provided by NSF grant EIA-0303609.",
    "funding": {
        "defense": 0.0,
        "corporate": 0.0,
        "research agency": 1.0,
        "foundation": 0.0,
        "none": 0.0
    },
    "reasoning": "Reasoning: The acknowledgments section of the article mentions that the work was funded by NSF grants IIS-0712907 and IIS-1016312. The National Science Foundation (NSF) is a government-funded organization that provides grants for research, which classifies it as a research agency. There is no mention of funding from defense, corporate entities, foundations, or an absence of funding sources.",
    "abstract": "Grounded\" language learning employs training data in the form of sentences paired with relevant but ambiguous perceptual contexts. B\u00f6rschinger et al. (2011) introduced an approach to grounded language learning based on unsupervised PCFG induction. Their approach works well when each sentence potentially refers to one of a small set of possible meanings, such as in the sportscasting task. However, it does not scale to problems with a large set of potential meanings for each sentence, such as the navigation instruction following task studied by Chen and Mooney (2011) . This paper presents an enhancement of the PCFG approach that scales to such problems with highly-ambiguous supervision. Experimental results on the navigation task demonstrates the effectiveness of our approach.",
    "countries": [
        "United States"
    ],
    "languages": [
        "English"
    ],
    "numcitedby": 56,
    "year": 2012,
    "month": "July",
    "title": "Unsupervised {PCFG} Induction for Grounded Language Learning with Highly Ambiguous Supervision"
}