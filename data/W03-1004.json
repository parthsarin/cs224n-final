{
    "article": "We address the problem of sentence alignment for monolingual corpora, a phenomenon distinct from alignment in parallel corpora. Aligning large comparable corpora automatically would provide a valuable resource for learning of text-totext rewriting rules. We incorporate context into the search for an optimal alignment in two complementary ways: learning rules for matching paragraphs using topic structure and further refining the matching through local alignment to find good sentence pairs. Evaluation shows that our alignment method outperforms state-of-the-art systems developed for the same task. Introduction Text-to-text generation is an emerging area of research in NLP (Chandrasekar and Bangalore, 1997; Caroll et al., 1999; Knight and Marcu, 2000; Jing and McKeown, 2000) . Unlike in traditional conceptto-text generation, text-to-text generation applications take a text as input and transform it into a new text satisfying specific constraints, such as length in summarization or style in text simplification. One exciting new research direction is the automatic induction of such transformation rules. This is a particularly promising direction given that there are naturally occurring examples of comparable texts that convey the same information yet are written in different styles. Presented with two such texts, one can pair sentences that convey the same information, thereby building a training set of rewriting examples for the domain to which the texts belong. We believe that automating this process will provide researchers in text-to-text generation with valuable training and testing resources, just as techniques to align multilingual parallel corpora boosted research in Machine Translation (MT) . In this paper, we address the task of aligning sentences in text pairs. We focus on monolingual comparable corpora, that is, texts in the same language (e.g., English) that overlap in the information they convey. Stories about the same events from different press agencies and texts presenting the same information to experts and lay people are two examples. In MT, the task of sentence alignment was extensively studied for parallel corpora. 1 A typical sentence alignment algorithm can be roughly described as a two-step process: (1) for each sentence pair compute a local similarity value, independently of the other sentences; (2) find an overall sequence of mapped sentences, using both the local similarity values and additional features. In the case of monolingual corpora, step (2) might seem unnecessary. Since the texts share the same language, it would be enough to choose for local similarity a function based on lexical cues only and select sentence pairs with high lexical similarity. Even a simple lexical function (e.g., one that counts word overlap) could produce an accurate alignment. After all, two sentences which share most of their words are likely to paraphrase each other. The problem is that there are many sentences that convey the same information but have little surface resemblance. As a result, simple word counts cannot distinguish the matching pair (A) in Figure 1 from the unrelated pair (B). An accurate local similarity measure would have to account for many complex paraphrasing phenomena. A simple, weak lexical similarity function alone is not sufficient. (A) \u2022 Petersburg served as the capital of Russia for 200 years. \u2022 For two centuries Petersburg was the capital of the Russian Empire. (B) \u2022 The city is also the country's leading port and center of commerce. \u2022 And yet, as with so much of the city, the port facilities are old and inefficient. Figure 1 : Sentence pairs from our corpus sharing two content words. (A) is a matching pair, (B) is not. In MT, a weak similarity function is compensated for by searching for a globally optimal alignment, using dynamic programming or taking advantage of the geometric/positional or contextual properties of the text pair (Gale and Church, 1991; Shemtov, 1993; Melamed, 1999) . But these techniques operate on the assumptions that there are limited insertions and deletions between the texts and that the order of the information is roughly preserved from one text to another. Texts from comparable corpora, as opposed to parallel corpora, contain a great deal of \"noise.\" In Figure 2 which plots the manually identified alignment for a text pair in our corpus, only a small fraction of the sentences got aligned (35 out of 31 \u00d7 270 sentence pairs), which illustrates that there is no complete information overlap. Consider two texts written by different press agencies: while both report on the same events, one may contain additional interviews and the other, background information. Another distinguishing characteristic of comparable corpora is that the order in which the information is presented can differ greatly from one text to another. Analysis of comparable texts in different domains (Paris, 1993; Barzilay et al., 2002) showed that there is wide variability in the order in which the same information can be presented. This is also illustrated in Figure 2 . We investigate a novel approach informed by text structure for sentence alignment. Our method emphasizes the search for an overall alignment, while relying on a simple local similarity function. We incorporate context into the search process in two complementary ways: (1) we map large text fragments using hypotheses learned in a supervised fashion and (2) we further refine the match through local alignment within mapping fragments to find sentence pairs. When the documents in the collection belong to the same domain and genre, the fragment mapping takes advantage of the topical structure of the texts. This structure is derived in an unsupervised fashion by analyzing commonalities among texts on each side of the comparable corpora separately. Our experiments show that our overall approach identifies even pairs with low lexical similarity. We also found that a fully unsupervised method using a minimalist representation of contextual information, viz., paragraph-level lexical similarity, outperforms existing methods based on complex local similarity functions. In the next section, we provide an overview of existing work on monolingual sentence alignment. Section 3 describes our algorithm. In sections 4 and 5, we report on data collection and evaluation. Related Work Most of the work in monolingual corpus alignment is in the context of summarization. In single document summarization, alignment between full docu-ments and summaries written by humans is used to learn rules for text compression. Marcu (1999) computes sentence similarity using a cosine-based metric. Jing (2002) identifies phrases that were cut and pasted together using a Hidden Markov Model with features incorporating word identity and positioning within sentences, thereby providing an alignment of the document and its summary. However, both of these methods construct an alignment by looking at sentences one at a time, independently of the decisions made about other sentences. Because summaries often reuse original document text to a large extent, these methods achieve good results. In the context of multidocument summarization, SimFinder (Hatzivassiloglou et al., 1999) identifies sentences that convey similar information across input documents to select the summary content. Even though the input documents are about the same subject, they exhibit a great deal of lexical variability. To address this issue, SimFinder employs a complex similarity function, combining features that extend beyond a simple word count and include noun phrase, proper noun, and WordNet sense overlap. Since many documents are processed in parallel, clustering is used to combine pairwise alignments. In contrast to our approach, SimFinder does not take the context around sentences into account. Algorithm Given a comparable corpus consisting of two collections and a training set of manually aligned text pairs from the corpus, the algorithm follows four main steps. Steps 1 and 2 take place at training time. Steps 3 and 4 are carried out when a new text pair (T ext 1 , T ext 2 ) is to be aligned. Off-Line Processing Given two sentences with moderate lexical similarity, we may not have enough evidence to decide accurately whether they should be aligned. Looking at the broader context they appear in can provide additional insight: if the types of information expressed in the contexts are similar, then the specific information expressed in the sentences is more likely to be the same. On the other hand, if the types of information in the two contexts are unrelated, chances are that the sentences should not be aligned. In our implementation, context is represented by the paragraphs to which the sentences belong. 2 Our goal in this phase is to learn rules for determining whether two paragraphs are likely to contain sentences that should be aligned, or whether, on the contrary, two paragraphs are unrelated and, therefore, should not be considered for further processing. A potentially fruitful way to do so is to take advantage of the topical structure of texts. In a given domain and genre, while the texts relate different subjects, they all use a limited set of topics to convey information; these topics are also known as the Domain Communication Knowledge (Kittredge et al., 1991) . For instance, most texts describing diseases will have topics such as \"symptoms\" or \"treatment.\" 3 If the task is to align a disease description written for physicians and a text describing the same disease for lay people, it is most likely that sentences within the topic \"symptoms\" in the expert version will map to sentences describing the symptoms in the lay version rather than those describing treatment options. If we can automatically identify the topic each paragraph conveys, we can decide more accurately whether two paragraphs are related and should be mapped for further processing. In the field of text generation, methods for representing the semantic structure of texts have been investigated through text schemata (McKeown, 1985) or rhetorical structures (Mann and Thompson, 1987) . In our framework, we want to identify the different topics of the text, but we are not concerned with the relations holding between them or the order in which they typically appear. We propose to identify the topics typical to each collection in the comparable corpus by using clustering, such that each cluster represents a topic in the collection. The process of learning paragraph mapping rules is accomplished in two stages: first, we identify the topics of each collection, Corpus 1 and Corpus 2 , and label each paragraph with its specific topic. Second, using a training set of manually aligned text pairs, we learn rules for mapping paragraphs from Corpus 1 to Corpus 2 . Two paragraphs are considered mapped if they are likely to contain sentences that should be aligned. Vertical Paragraph Clustering We perform a clustering at the paragraph level for each collection. We call this stage Vertical Clustering because all the paragraphs of all the documents in Corpus 1 get clustered, independently of Corpus 2 ; the same goes for the paragraphs in Corpus 2 . At this stage, we are only interested in identifying the topics of the texts in each collection, each cluster representing a topic. We apply a hierarchical complete link clustering. Similarity is a simple cosine measure based on the word overlap of the paragraphs, ignoring function words. Since we want to group together paragraphs that convey the same type of information across the documents in the same collection, we replace all the text-specific attributes, such as proper names, dates and numbers, by generic tags. 4 This way, we ensure that two paragraphs are clustered not because they relate the same specific information, but rather, because they convey the same type of information (an example of two automatically clustered paragraphs is shown in Figure 3 ). The number of clusters for each collection is a parameter tuned on our training set (see Section 4). Lisbon has a mild and equable climate, with a mean annual temperature of 63 degree F (17 degree C). The proximity of the Atlantic and the frequency of sea fogs keep the atmosphere humid, and summers can be somewhat oppressive, although the city has been esteemed as a winter health resort since the 18th century. Average annual rainfall is 26.6 inches (666 millimetres). Jakarta is a tropical, humid city, with annual temperatures ranging between the extremes of 75 and 93 degree F (24 and 34 degree C) and a relative humidity between 75 and 85 percent. The average mean temperatures are 79 degree F (26 degree C) in January and 82 degree F (28 degree C) in October. The annual rainfall is more than 67 inches (1,700 mm). Temperatures are often modified by sea winds. Jakarta, like any other large city, also has its share of air and noise pollution. Horizontal Paragraph Mapping Once the different topics, or clusters, are identified inside each collection, we can use this information to learn rules for paragraph mapping (Horizontal Mapping between texts from Corpus 1 and texts from Corpus 2 ). Using a training set of text pairs, manually aligned at the sentence level, we consider two paragraphs to map each other if they contain at least one aligned sentence pair (see Figure 4 ). Our problem can be framed as a classification task: given training instances of paragraph pairs (P , Q) from a text pair, classify them as mapping or not. The features for the classification are the lexical similarity of P and Q, the cluster number of P , and the cluster number of Q. Here, similarity is again a simple cosine measure based on the word overlap of the two paragraphs. 5 These features are weak indicators by themselves. Consequently, we use the publiclyavailable classification tool BoosTexter (Singer and Schapire, 1998) to combine them accurately. 6 Macro Alignment: Find Candidate Paragraph(s) At this stage, the clustering and training are completed. Given a new unseen text pair (T ext 1 , T ext 2 ), the goal is to find a sentence alignment between them. Two sentences with very high lexical similarity are likely to be aligned. We allow such pairs in the alignment independently of their context. This step allows us to catch the \"easy\" paraphrases. We focus next on how our algorithm identifies the less obvious matching sentence pairs. For each paragraph in each text, we identify the cluster in its collection it is the closest to. Similarity between the paragraph and each cluster is computed the same way as in the Vertical Clustering step. We then apply mapping classification to find the mapping paragraphs in the text pair (see Figure 5 ). Micro Alignment: Find Sentence Pair(s) Once the paragraph pairs are identified in (T ext 1 , T ext 2 ), we want to find, for each paragraph pair, the (possibly empty) subsets of sentence pairs which constitute a good alignment. Context is used in the following way: given two sentences with moderate similarity, their proximity to sentence pairs with high similarity can help us decide whether to align them or not. To combine the lexical similarity (again using cosine measure) and the proximity feature, we com-pute local alignments on each paragraph pair, using dynamic programming. The local alignment we construct fits the characteristics of the data we are considering. In particular, we adapt it to our framework to allow many-to-many alignments and some flips of order among aligned sentences. Given sentences i and j, their local similarity sim(i, j) is: sim(i, j) = cos(i, j) \u2212 mismatch penalty The weight s(i, j) of the optimal alignment between the two sentences is computed as follows: s(i, j) = max \uf8f1 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f2 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f3 s(i, j \u22121) \u2212 skip penalty s(i\u22121, j) \u2212 skip penalty s(i\u22121, j \u22121) + sim(i, j) s(i\u22121, j \u22122) + sim(i, j) + sim(i, j \u22121) s(i\u22122, j \u22121) + sim(i, j) + sim(i\u22121, j) s(i\u22122, j \u22122) + sim(i, j \u22121) + sim(i\u22121, j) The mismatch penalty penalizes sentence pairs with very low similarity measure, while the skip penalty prevents only sentence pairs with high similarity from getting aligned. Evaluation Setup The Data. We compiled two collections from the Encyclopedia Britannica and Britannica Elementary. In contrast to the long (up to 15-page) detailed articles of the Encyclopedia Britannica, Britannica Elementary contains one-to two-page entries targeted towards children. The elementary version generally contains a subset of the information presented in the comprehensive version, but there are numerous cases when the elementary entry contains additional or more up-to-date pieces of information. 7 The two collections together exhibit many instances of complex rewriting. We collected 103 pairs of comprehensive/elementary city descriptions. We set aside a testing set of 11 text pairs. The rest (92 pairs) was used for the Vertical Clustering. Nine text pairs were used for training (see Table 1 for statistics). Human Annotation. Each text pair in the training and testing sets was annotated by two annotators. 8 In our guidelines to them, we defined two sentences as aligned if they contain at least one clause  that expresses the same information. We allowed many-to-many alignments. On average, each annotator spent 50 minutes per text pair. While the annotators agreed for most of the sentence pairs they identified, there were some cases of disagreement. Alignment is a tedious task, and sentence pairs can easily be missed even by a careful human annotator. For each text pair, a third annotator went through contested sentence pairs, deciding on a case-by-case basis whether to include it in the alignment. Overall, 320 sentence pairs were aligned in the training set and 281 in the testing set. The other sentence pairs which were not aligned served as negative examples, yielding a total of 4192 training instances and 3884 testing instances. 9 As a confirmation that there is no order preservation in comparable corpora, there were up to nine order shifts in each of the annotated text pairs. Table 2 shows that a large fraction of manually aligned sentence pairs have low lexical similarity. Similarity is measured here by the number of words in common, normalized by the number of types in the shorter sentence. Parameter Tuning. We tuned all the parameters on our training set, obtaining the following values: the skip penalty is 0.001, and the cosine threshold for selecting pairs with high lexical similarity is 0.5. BoosTexter was trained in 200 iterations. To find the optimal number of clusters for each collection, Vertical Clustering was performed with different numbers of clusters, ranging from 10 to 40; we selected Results We first present the comparison of our method with other systems developed for the same task. Next we focus on the impact of individual components on the performance of our method. Comparison with Other Systems An obvious choice for a baseline in this task is the following: any two sentences are considered aligned if their cosine similarity exceeds a certain threshold. We also compare our algorithm with two state-ofthe-art systems, SimFinder (Hatzivassiloglou et al., 1999) and Decomposition (Jing, 2002) . 10 Figure 6 shows Precision/Recall curves for the different systems. For our full system, we obtain different values of Recall keeping constant the skip penalty and the cosine threshold and varying the value of the mismatch penalty from 0 to 0.45. 11 This setup results in recall values in a 25%-65% range. The curve for SimFinder was obtained by running SimFinder with different similarity thresholds, ranging from 0.1 to 0.95. In the case of Decomposition, there are several hard-coded parameters which are not trainable. As a result, we were able to obtain results for Decomposition only at a 55.8% Recall level. Table 3 reports Precision values at this level of Recall. 10 Jing (2002) reports that Decomposition outperforms the algorithm of Marcu (1999) ; we, therefore, did not compare our method against his system. 11 Varying the mismatch penalty is a natural choice: varying the skip penalty produces a narrow range of Recall values, while the cosine threshold controls only a small portion of the sentence pairs that can be identified (the ones with high similarity).  Prague is a centuries-old city with a wealth of historic landmarks. System The physical attractions and landmarks of Prague are many. Figure 7 : Aligned pairs, (*) denotes an incorrect alignment. Our full method outperforms both the baseline (\"Cosine\") and the more complex systems (\"SimFinder\" and \"Decomposition\"). Interestingly, methods that use simple local similarity functions significantly outperform SimFinder (SimFinder was trained on newswire texts; we did not have access to SimFinder's training component for retraining on our corpus). This confirms our hypothesis that while it is an appealing idea, putting all one's eggs in the basket of a sophisticated local similarity measure to achieve good performance may be too hard a task. The simple cosine baseline is competitive with the Hidden Markov Model of Decomposition (Decomposition was specifically developed to identify sentence pairs with cut-and-paste transformations, not all possible paraphrase pairs). This suggests that when looking for an alignment, Cosine is a good, yet simple, starting local similarity measure. Adding on top of it an explicit search mechanism relying on the context surrounding the sentences, as in our method, results in a performance improvement of 19% at 55.8% Recall. Figure 7 shows examples of pairs identified by our method. Analysis Impact of Horizontal Paragraph Mapping. We hypothesize that exploiting the regularity in mapping between semantic units, such as topics, improves the alignment. We compared the performance of our full method with a variation that does not take any topical information into account. For the paragraph mapping, we replaced the learned rules by a single rule based on lexical similarity: two paragraphs are mapped if their cosine measure is above a pre-specified threshold. 12 This new mapping is a good point of comparison because it does not rely on any knowledge inferred from the other texts in the corpus. The results confirm our hypothesis: learning paragraph mapping based on topical structures improves the performance (see \"Without Topic Mapping\" vs. \"Full Method\", Table 3 ). This experiment also shows that representing context, even simply using only the paragraphs and their lexical similarity, achieves higher performance than methods based on more complex local similarity functions. It is an important finding, because this simplified method can be used when topic structure cannot be derived (e.g., in heterogeneous collections) or when no training data is available, since it is unsupervised. Impact of Cluster Quality. Our method uses clustering to identify the different topics of each collection. It is important to know how sensitive our overall algorithm is to the quality of the identified clusters. Fortunately, in our corpus, some of the texts contain section headings (e.g., \"Climate\" or \"Demography\"). Even though our method ignores this piece of information, we used it to derive manually \"ideal\" clusters. 13 We obtained eight clusters for the elementary version and 11 for the comprehensive one. When feeding these ideal clusters instead of the automatically identified ones to the learning module for paragraph mapping, we achieve 4% improvement in Precision (at 55.8% Recall). We interpret this as a sign that the algorithm handles imperfect, automatically induced clusters fairly well. Impact of Local Alignment. Our hypothesis for computing local alignments between pairs of mapped paragraphs is that our approach allows us to identify additional matching sentence pairs: if two sentences paraphrase each other but have a low cosine measure, looking at the sentence pairs around  them may increase their chances of getting selected. We compared our full method with a version of our algorithm that does not perform local alignment (\"Without Local Alignment\"). Instead, it simply selects sentence pairs inside the mapped paragraphs based on their cosine measure. This incomplete version of the algorithm achieves 73.3% Precision (at 55.8% Recall), 3% lower than the full method, validating our hypothesis. Impact of Lexical Similarity. We investigated how the performance of our method depends on the lexical similarity of the input sentences. Table 4 shows Precision and Recall for our method and others at three sentence-similarity ranges based on word overlap counts (at the overall Recall of 55.8%). Our method outperforms the Cosine baseline and Decomposition on all similarity ranges. Conclusions The central finding of our work is that context plays an important role in the task of sentence alignment for monolingual comparable corpora. A weak sentence similarity measure combined with contextual information outperforms methods based on sophisticated sentence similarity functions. Experiments show that a simple representation of context is helpful. Relying on a more elaborate representation, such as topical text structure, has an even stronger impact on performance. Acknowledgments We would like to thank Michael Elhadad, Klara Kedem, Kathy McKeown and Becky Passonneau for the useful discussions. Thanks to Mirella Lapata, Lillian Lee, Vincent Ng and Bo Pang for their helpful comments on previous drafts. We are grateful to Hongyan Jing for giving us access to her code for Decomposition. Finally we would like to thank all the annotators (they are many). This paper is based upon work supported in part by the National Science Foundation under ITR/IM grant IIS-0081334, Digital Library Initiative Phase II Grant No. IIS-98-17434, and a Sloan Research Fellowship to Lillian Lee. Any opinions, findings, and conclusions or recommendations expressed above are those of the authors and do not necessarily reflect the views of the National Science Foundation or the Sloan Foundation.",
    "abstract": "We address the problem of sentence alignment for monolingual corpora, a phenomenon distinct from alignment in parallel corpora. Aligning large comparable corpora automatically would provide a valuable resource for learning of text-totext rewriting rules. We incorporate context into the search for an optimal alignment in two complementary ways: learning rules for matching paragraphs using topic structure and further refining the matching through local alignment to find good sentence pairs. Evaluation shows that our alignment method outperforms state-of-the-art systems developed for the same task.",
    "countries": [
        "United States"
    ],
    "languages": [
        "English",
        "Russian"
    ],
    "numcitedby": "215",
    "year": "2003",
    "month": "",
    "title": "Sentence Alignment for Monolingual Comparable Corpora"
}