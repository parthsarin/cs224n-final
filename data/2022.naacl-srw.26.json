{
    "article": "This PhD project leverages advancements in multimodal large language models to build an inclusive collaboration feedback loop, in order to facilitate the automated detection, modeling, and feedback for participants developing general collaboration skills. This topic is important given the role of collaboration as an essential 21st century skill, the potential to ground large language models within learning theory and real-world practice, and the expressive potential of transformer models to support equity and inclusion. We address some concerns of integrating advances in natural language processing into downstream tasks such as the learning analytics feedback loop. Introduction Collaboration, a coordinated process involving two or more individuals participating in a task in an interdependent way, is an important topic of study given its importance as a major 21st century skill (Lai et al., 2017; Council, 2011; Rios et al., 2020) . Though collaboration as a general term is viewed as a learnable competency, notable distinctions emerge when examining how collaboration surfaces within relevant research. One semantic distinction is that the term collaboration is not explicitly defined, or is used interchangeably with concepts such as group collaboration, teamwork, collective problem solving, cooperation, and more (OECD, 2015) . These inconsistencies in meaning make it challenging to connect various research agendas that purport the advantages of collaboration. Another distinction to note is modalityrelated. Some research does not make any modality distinctions when reporting the impacts of results, though much has viewed collaboration via online/computer-mediated interactions, both synchronous and asynchronous, while other research has examined co-located collaborative acts that happen face-to-face. Despite semantic, modality, and other distinctions, various fields have advanced what we know about collaboration, specifically collaboration as a language-mediated process. Scholars within the fields of NLP, cognitive science, and educational research have focused separately on verbal and written aspects of collaborative exchanges -speech, text-based outputs, and audio such as non-linguistic pauses -to better understand aspects of collaboration. Recent NLP research, for example, has explored neural models equipped with dynamic knowledge graph embeddings, the use of large language models to model real world speech, and the development of collaboration datasets (Ekstedt and Skantze, 2020; He et al., 2017; Lee et al., 2022) , while cognitive science has explored general modeling approaches for collaborative behavior and large language models as knowledge sources for intelligent agents (Goldstone and Gureckis, 2009; Huang et al., 2022; Wray et al., 2021) . Learning analytics, a subset of educational research that extracts diverse datastreams from the learning process to improve learning, has developed automated multimodal approaches to detect, model and provide feedback about collaborative learning exchanges (Dowell et al., 2019; Pugh et al., 2022; Worsley and Ochoa, 2020) . Though these studies differ in their disciplinary perspectives, they view language as essential to individuals' application of collaborative behavior and researchers' understanding of said behavior. Purpose of Research Project Because language is grounded in experience (Bisk et al., 2020) , and collaboration is mediated through language, collaboration is an appropriate skill to be learned, practiced, and analyzed through languagemediated experiences and techniques. This dissertation project, situated at the intersection of NLP, cognitive science, and learning analytics, focuses on how we may support people in their development of complex, dynamic collaborative language skills. The project extends prior research, but also introduces unexplored areas such as multimodal language modeling and inclusive collaboration. Therefore, the aim is to contribute to several open research questions related to how we may foster collaborative language, a proxy for overall collaboration skills, in people as an explicit act of learning. This project examines these critical gaps in current research to explore the ultimate question of: How can we use multimodal large language models to detect, model, and provide feedback on inclusive collaboration behavior? Sub-questions include: \u2022 How may a multimodal framework offer improved collaborative language detection over and above unimodal language modeling?; \u2022 What are possibilities for detecting and modeling inclusive collaboration language among a group of diverse participants?, and \u2022 How may we leverage multimodal large language modeling in the service of learning to collaborate through automated and feedback mechanisms? This study explores the potentials of adopting multimodal NLP techniques within a learning analytics lens. Multimodal NLP is an emerging area within NLP that stems from the development of the large language model, a massive-parameter pretrained model. Large language models are an active area of development within NLP, and one set of researchers have demonstrated impressive semantic and generative capabilities (Kaplan et al., 2020; Tay et al., 2021) , while others pose ethical, environmental, and interpretability concerns about unbounded scaling of model size (Bender et al., 2021; Strubell et al., 2020; Weidinger et al., 2021) . We focus on the potential of multimodal NLP, large language models that integrate multimodal (acoustic, image, tactile, and/or video) data beyond text-based language, and explore potentials of multimodal NLP for automated, fine-grained detection of collaborative processes that will support learners within and across experiences, an important downstream application of the technology (Bommasani et al., 2021; Brown et al., 2020; Islam and Iqbal, 2021; Rahman et al., 2020) . We also contribute to current critiques of performance-first modeling that may overlook important opportunities to create real world NLP models that reduce bias. This project operationalizes an inclusive collaboration index with the goal of general equity and inclusion over identityspecific bias mitigation. Integrating Inclusion into Downstream NLP Collaboration Tasks Within learning analytics (Holstein and Doroudi, 2021) , NLP (Blodgett et al., 2020; Tsvetkov et al., 2018) , and general machine learning/AI applications (Doshi-Velez and Kim, 2017; Dwork et al., 2012) , researchers have made arguments for more equitable, fair, and inclusive practices. This includes verifying that the research approach is informed by ethical and human-centered principles, developing research methods that detect/mitigate unethical outcomes, and/or our aim of proposing that research methods should translate ethically when used in real-world contexts. With the recent focus on equity and inclusion across our fields of interest, formal inclusion theories are stated as important to integrate as a future idealized goal, though we lack blueprints for what forms these integrations may take. Within research across learning analytics, NLP, and machine learning, formal experiments provide empirical support for those methods with the most promise for identifying and reducing unwanted societal bias, ambiguity, and exclusion in datasets and models (Caliskan et al., 2017; Dinan et al., 2020; Hutchinson et al., 2020; Sap et al., 2020) , though there is less support for what works as an embedded practice within downstream tasks that utilize these algorithms, datasets, and platforms. This study considers ethical research approaches and outcomes, but primarily focuses on the stated areas of potential development -the ethical deployment of our NLP and learning analytics research methods in downstream tasks situated within actual learning settings by detecting lack of inclusion and intervening. Our focus is not yet to identify any causal relationship between one or more social identities and collaboration quality, but rather to detect inclusive collaboration of individuals and groups, and in the process identify any disparities in collaboration quality among individuals and within the group as a whole. In this sense, our work advances the concept of inclusion (Mor-Barak and Cherin, 1998; Young, 1995) , defined as the degree to which diverse individuals demonstrate that they are part of the collaborative process. We recognize that this study falls short of addressing equity since equity examines outcomes at the societal rather than individual or group level, though we highlight that inclusion is an integral step on the way to equity and ethical treatment within collaborative experiences (Bernstein et al., 2020) . Methodology We have sub-divided the planned methodology into multiple tasks as: Due to the multidisciplinary nature of collaboration, this study will incorporate methods that stem from four distinct fields -learning analytics, cognitive science, natural language processing, and inclusion theory -to create an inclusive view of learning to collaborate. From learning analytics, we get a roadmap for developing an automated feedback loop necessary for learning to collaborate, and a variety of methods for detecting collaborative behaviors and operationalizing them into signals for model building. From cognitive science, we have an example for linking psychological theory, model, and real world behaviors, as well as ongoing research on intelligent agents as used for understanding learning and adaptation through feedback. From natural language processing, we have access to the ability of large language models to parse and generate human language, as well as approaches for addressing inclusion in language model building. Lastly, we operationalize tenets of inclusion theory in order to build a learning to collaborate model that detects linguistic bias, thus working towards a more inclusive collaboration environment. All aspects involving human subjects, including Phase 1 data collected via Amazon Mechanical Turk, Phase 2 large language modeling, and Phase 3 interventions will receive full approval of the University's Institutional Review Board (IRB) prior to launching the study. Datasets are either open for research use and cited, or collected and stored as part of the IRB approval process and regulations. Phase 1: Multimodal collaboration detection and dataset creation As part of Phase 1 (multimodal collaboration detection and dataset creation), we will (a) develop a rubric for inclusive collaboration; (b) finalize the process of capturing and preprocessing multimodal data (video and transcribed audio) from collaborative exchanges, and (c) create an evaluation dataset. The inclusive collaboration rubric pulls from existing research on collaboration quality that identifies four collaboration indicators (information sharing, reciprocal interaction, shared understanding, and inclusion) from participants' audio, text, and video data (Cukurova et al., 2018; Praharaj et al., 2021) , and the technical feat of capturing and preprocessing collaborative exchanges is informed by previous scholarship in Multimodal Learning Analytics research (Ochoa et al., 2013; Worsley and Blikstein, 2015) . Automatic distillation of raw data into collaboration features would include: automatic speech recognition, computational linguistic methods to clean, parse, and analyze transcribed dialogue (eg. word counts, duration, general content analysis, inclusive content analysis), detection of non-linguistic audio (speech prosody), and video signal filtering to detect person placement and basic gestures. Following the general dataset collection procedures described in He et al. ( 2017 ), we will gather human annotations according to our collaboration rubric of transcribed audio at the sentence-level and video portions at the frame-level that is captured for collaborative exchanges. We will use representative samples of open source collaboration datasets and datasets collected as part of an approved IRB protocol that contain text-based dialogue, spoken dialogue, and/or video of multi-person collaborative exchanges, including the AMI Meeting Corpus (Carletta et al., 2006) , D64 Multimodal Conversation Corpus (Oertel et al., 2013) How2 Dataset for Multimodal Language Understanding (Sanabria et al., 2018) , Pragmatic Framework for Collaboration (Boothe et al., 2022) , and MutualFriends Corpus (He et al., 2017) . In addition to annotation of the four dimensions of interest, we also have annotators evaluate along the modality (text, image, and video). We integrate recent NLP crowdsourcing research findings (Nangia et al., 2021) by collecting expert annotations that will then inform guidance for generally skilled Amazon Mechanical Turk (MTurk) workers, and and will use the process outlined in Bowman et al. (2015) , and the Fair Work tool (Whiting et al., 2019) to ensure a fair payment structure. The contributions of Phase 1 are multiple: to expand beyond research that analyzes collaborative language at the surface level, such as looking at word counts or temporal durations, and support deeper content-level analysis (Praharaj et al., 2021) ; to map current trends in large language modeling to theoretically-sound learning and inclusion frame-works that extend past pure performance measures and support responsible downstream usage of such models. Phase 2: Multimodal large language models for measuring collaboration quality Phase 2 focuses on formalizing the task specification for inclusive collaboration, a process in which we operationalize human-supplied descriptions into an inclusive collaboration quality classification model. Specifically, we will conduct finetuning experiments with large transformer models to detect collaborative language and behaviors of individual members of a 3-person group. We will utilize several pretrained large language models accessible through HuggingFace ( (Wolf et al., 2020) ), including BERT-base (Sanh et al., 2020) , GPT-2 (Radford and Narasimhan, 2018) , GPT-J, the open source version of GPT-3 (Brown et al., 2020) , and FLAVA (Singh et al., 2022) , a recent multimodal language model pretrained on visual and linguistic data. We will also integrate lessons learned from education-specific research utilizing large language models (Clavi\u00e9 and Gal, 2019; Shen et al., 2021; Suresh et al., 2021) . These pretrained models will be finetuned on a random sample of the multimodal collaboration data (audio, text, and/or video frames) that has been held out of the evaluation dataset step. We will generate finetuned models with unimodal and multimodal collaborative data, and learning rates and batch sizes will be determined according to standard task settings, and we follow the training-test splits and standards articulated by Guo et al. (2020) and Minaee et al. (2021) . For this study, we will limit our datasets and modeling experiments to English-language text and dialogue datasets to supplement those pre-trained models primarily trained on English-language data. We compare the performance of our finetuned models in terms of classification accuracy of our expert and general crowdworker classification scores on the 4 collaboration dimensions. The area under the receiver operating characteristic curve (AU-ROC) metric is used for each dimension. Following Pugh et al. ( 2022 ), we report the chance baseline as a random shuffling of labels within each collaborative session and thus computing accuracy. Comparing different unimodal and multimodal finetuned model performance will serve as an ablation approach to examine the role of additional data modalities in terms of overall model performance, as well as a comparison between unimodal and multimodal models (Singh et al., 2022) . Additionally, we conduct an analysis of random examples to determine points of synergy with, divergence from, and bias markers that differ from human classification. This will serve as essential future directions to frame the use of automated collaboration detection using large language models. Following the design-based protocol outlined in (Praharaj et al., 2018) , we will complete a pilot study within a real classroom. Small groups (of 3 people) conduct a general collaborative task and we use the detection setup established in Phase 1 to detect multimodal signals (eg. speaking duration, pauses, large language model features) correlated to collaboration quality and use our multimodal models to assess quality. We will conduct an additional automated and human evaluation on this real-life scenario. There are two novel aspects of this modeling of collaborative quality. One involves using the large language model to provide a nuanced view of collaborative linguistic exchanges at the content level. According to Praharaj et al. (2021) note that very few studies integrate an analysis of \"verbal audio indicators or the content of the audio for the analysis of [in-person] collaboration quality\" (pg. 2). We leverage the large language model to explore improvements in supervised dialogue detection tasks, and also unsupervised training strategies to explore emergent and content-specific cases of collaboration so that the model can learn without direct supervision. Additionally, we propose a measure on inclusive collaboration and evaluate its association on overall collaboration quality. Phase 3: Language generation to support collaboration learning Since we are ultimately concerned with learning to collaborate, we build a learning analytics cycle with the development of a robust feedback loop. The feedback system will take the form of an intelligent agent that can monitor and detect aspects of the collaboration process, focusing on the measurement of collaboration quality. The key behavior is for our model to detect differences in collaboration, in order to pinpoint disparities in inclusion. The inclusive collaboration models created by generative language models will drive generative behavior of the intelligent agent, which will produce select audio-based feedback during the collaboration exchange based on detected features. The study will take on an experimental setup for higher education course recitations that engage in collaborative problem solving. The three groups -the no feedback control group (i.e. those randomly assigned as the control group with no intervention), the manual feedback experimental group (i.e. those randomly assigned as the manual feedback group which entails an instructor offering general, preparatory guidance on quality collaboration), and the automated feedback experimental group (i.e. those randomly assigned as the automated feedback group) -will engage in a series of four collaborative sessions. During session 1, we will record collaboration exchanges between the randomly assigned groups in order to capture multimodal baseline collaboration data. During sessions 2 and 3, the control group will collaborate in the absence of any explicit feedback, the manual feedback group will collaborate with initial collaboration guidance by the instructor, and the automated feedback group will collaborate while the intelligent agent interjects in real time. Session 4 will record collaboration exchanges between the three groups in the absence of any intervention. The goal is to assess how well all groups perform on inclusive collaboration quality. This study hypothesizes that feedback loops built on top of multimodal large language models will capture the most relevant information associated with collaboration due to their scaled representational qualities. We will extend progress -finetuning; masked language model prompting; contextual prompting; and case-based prompting -made in extracting relevant information from language models to serve as knowledge sources for cognitive agents, and identify the method that maps to encouraging collaboration quality (Huang et al., 2022; Wray et al., 2021; Yousfi-Monod and Prince, 2007) . The development of the agent will use language and simple feedback to offer corrective and encouraging input to students. Initial Results An initial pilot focused on the language modeling portion, and uses IRB-approved data that takes place within recitations of a large, STEM class. Groups of 3 students participated in small group work for the duration of the 75 minute period, and were tasked with solving problems related to the lecture and readings. Audio and video recordings were captured, cleaned, and processed. Transcripts were generated by an Automated Speech Recognition (ASR) software and corrected by hand, and were then paired with video frames. A random sampling of the text-based dialogue and video frames were generated and then mapped to the inclusive collaboration framework by 2 expert annotators and an additional 5 general skill annotators. These data will serve as the evaluation set. BERTbase and GPT-2 were finetuned on a randomized sample (80%) of the AMI collaboration dataset, as well as dialogue (text-based) portions of the Multi-party Collaboration corpus. Results indicate some marginal improvement between the finetuned models, and between BERT and the larger GPT-2 model, but additional analysis and more thorough data preparation and testing are needed. The finetuned GPT-2 model performed better than chance on all except for the inclusion dimension. We anticipate that more thorough finetuning and integration of multimodal finetuning data should improve performance on multimodal classification tasks. Conclusion As an essential 21st century skill, our aim is to utilize the potentials of multimodal large language models to advance our ability to detect and model collaborative behaviors, with the ultimate goal being to offer feedback to learners as they develop these important skills. Importantly, we focus on the tenets of inclusive collaboration, so that collaborators are encouraged to have equitable and inclusive exchanges as they work with each other. This doctoral research project builds an automated end-to-end inclusive collaboration feedback loop, relying on advancements in large language modeling as it is used in downstream tasks, and grounding machine learning methods within theory and real-world practice. ",
    "abstract": "This PhD project leverages advancements in multimodal large language models to build an inclusive collaboration feedback loop, in order to facilitate the automated detection, modeling, and feedback for participants developing general collaboration skills. This topic is important given the role of collaboration as an essential 21st century skill, the potential to ground large language models within learning theory and real-world practice, and the expressive potential of transformer models to support equity and inclusion. We address some concerns of integrating advances in natural language processing into downstream tasks such as the learning analytics feedback loop.",
    "countries": [
        "United States"
    ],
    "languages": [
        "English"
    ],
    "numcitedby": "0",
    "year": "2022",
    "month": "July",
    "title": "Multimodal large language models for inclusive collaboration learning tasks"
}