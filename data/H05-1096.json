{
    "article": "Confidence measures for machine translation is a method for labeling each word in an automatically generated translation as correct or incorrect. In this paper, we will present a new approach to confidence estimation which has the advantage that it does not rely on system output such as Nbest lists or word graphs as many other confidence measures do. It is, thus, applicable to any kind of machine translation system. Experimental evaluation has been performed on translation of technical manuals in three different language pairs. Results will be presented for different machine translation systems to show that the new approach is independent of the underlying machine translation system which generated the translations. To the best of our knowledge, the performance of the new confidence measure is better than that of any existing confidence measure. Introduction The work presented in this paper deals with confidence estimation for machine translation (MT). Since sentences produced by a machine translation system are often incorrect but may contain correct parts, a method for identifying those correct parts and finding possible errors is desirable. For this purpose, each word in the generated target sentence is assigned a value expressing the confidence that it is correct. Confidence measures have been extensively studied for speech recognition, but are not well known in other areas. Only recently have researchers started to investigate confidence measures for machine translation (Blatz et al., 2004; Gandrabur and Foster, 2003; Quirk, 2004; Ueffing et al., 2003) . We apply word confidence measures in MT as follows: For a given translation generated by a machine translation system, we determine a confidence value for each word and compare it to a threshold. All words whose confidence is above this threshold are tagged as correct and all others are tagged as incorrect translations. The threshold is optimized on a distinct development set beforehand. Possible applications for confidence measures include \u2022 post-editing, where words with low confidence could be marked as potential errors, \u2022 improving translation prediction accuracy in trans-type-style interactive machine translation (Gandrabur and Foster, 2003; Ueffing and Ney, 2005) , \u2022 combining output from different machine translation systems: hypotheses with low confidence can be discarded before selecting one of the system translations (Akiba et al., 2004) , or the word confidence scores can be used for generating new hypotheses from the output of different systems (Jayaraman and Lavie, 2005) , or the sentence confidence value can be employed for re-ranking (Blatz et al., 2003) . In this paper, we will present several approaches to word-level confidence estimation and develop a new phrase-based confidence measure which is independent of the machine translation system which generated the translation. The paper is organized as follows: In section 2, we will briefly review the statistical approach to machine translation. The phrasebased translation system, which serves as basis for the new confidence measure, will be presented in section 2.2. Section 3 will give an overview of related work on confidence estimation for statistical machine translation (SMT). In section 4, we will describe methods for confidence estimation which make use of SMT system output such as word graphs and N -best lists. In section 5, we will present the new phrase-based confidence measure. Section 6 contains a short description of an IBM-1 based confidence measure to which we will compare the other measures. Experimental evaluation and comparison of the different confidence measures will be shown in section 7, and section 8 will conclude the paper. Statistical machine translation General In statistical machine translation, the translation is modeled as a decision process: Given a source string f J 1 = f 1 . . . f j . . . f J , we seek the target string e I 1 = e 1 . . . e i . . . e I with maximal posterior probability: \u00ea\u00ce 1 = argmax I,e I 1 P r(e I 1 | f J 1 ) (1) = argmax I,e I 1 P r(f J 1 | e I 1 ) \u2022 P r(e I 1 ) Through this decomposition of the probability, we obtain two knowledge sources: the translation model P r(f J 1 | e I 1 ) and the language model P r(e I 1 ). Both of them can be modeled independently of each other. The translation model is responsible for linking the source string f J 1 and the target string e I 1 , i.e. it captures the semantics of the sentence. The target language model captures the well-formedness or the syntax in the target language. Nowadays, most of the state-of-the-art SMT systems are based on bilingual phrases (Bertoldi et al., 2004; Koehn et al., 2003; Och and Ney, 2004; Tillmann, 2003; Vogel et al., 2004; Zens and Ney, 2004) . Note that those phrases are sequences of words in the two languages and not necessarily phrases in the linguistic sense. A more detailed description of a phrase-based approach to statistical machine translation will be given in section 2.2. Review of phrase-based translation system For the confidence measures which will be introduced in section 5, we use a state-of-the-art phrasebased approach as described in (Zens and Ney, 2004) . The key elements of this translation approach are bilingual phrases, i.e. pairs of source and target language phrases where a phrase is simply a contiguous sequence of words. These bilingual phrases are extracted from a word-aligned bilingual training corpus. We will present the equations for a monotone search here in order to keep the equations simple. Let (j K 0 , i K 0 ) be a segmentation of the source sentence into phrases, with the corresponding (bilingual) phrase pairs ( fk , \u1ebdk ) = (f j k j k\u22121 +1 , e i k i k\u22121 +1 ), k = 1, . . . , K. The phrasebased approach to SMT is then expressed by the following equation: \u00ea\u00ce 1 = argmax j K 0 ,i K 0 ,I,e I 1 I i=1 c 1 \u2022 p(e i | e i\u22121 i\u22122 ) \u03bb 1 (2) \u2022 K k=1 c 2 \u2022 p( fk | \u1ebdk ) \u03bb 2 \u2022 p(\u1ebd k | fk ) \u03bb 3 \u2022 j k j=j k\u22121 +1 p(f j | \u1ebdk ) \u03bb 4 \u2022 i k i=i k\u22121 +1 p(e i | fk ) \u03bb 5 , where p( fk | \u1ebdk ) and p(\u1ebd k | fk ) are the phrase lexicon models in both translation directions. The phrase translation probabilities are computed as a log-linear interpolation of the relative frequencies and the IBM-1 probability. The single word based lexicon models are denoted as p(f j | \u1ebdk ) and p(e i | fk ), respectively. p(f j | \u1ebdk ) is defined as the IBM-1 model probability of f j over the whole phrase \u1ebdk , and p(e i | fk ) is the inverse model, respectively. c 1 is the so-called word penalty, and c 2 is the phrase penalty, assigning constant costs to each target language word/phrase. The language model is a trigram model with modified Kneser-Ney discounting and interpolation (Stolcke, 2002) . The search determines the target sentence and segmentation which maximize the objective function. As equation 2 shows, the sub-models are combined via weighted log-linear interpolation. The model scaling factors \u03bb 1 , . . . , \u03bb 5 and the word and phrase penalties are optimized with respect to some evaluation criterion (Och, 2003) , e.g. BLEU score. Confidence measures for SMT Related work In this paper, we will present a new approach to word-level confidence estimation which makes explicit use of a phrase-based translation model. Most of the word-level confidence measures which have been presented in the literature so far are either based on relatively simple translation models such as IBM-1 (Blatz et al., 2003) or make use of information provided by the SMT system such as N -best lists or word graphs (Blatz et al., 2003; Gandrabur and Foster, 2003; Ueffing et al., 2003) . In contrast to this, our method is based on a state-of-the-art statistical machine translation model, but nevertheless is independent of the machine translation system which generates the translation hypotheses. The word-level confidence measures which showed the best performance in comparative experiments (Blatz et al., 2003) are word posterior probabilities and the IBM-1 based measure. Our new confidence measure will be compared to those approaches in section 7.3. Word posterior probabilities The confidence of a target word can be expressed by its posterior probability, i.e. the probability of the word to occur in the target sentence, given the source sentence. Consider a target word e occurring in the sentence in position i 1 . The posterior probability of this event can be determined by summing over all possible target sentences e I 1 containing the word e in position i: p i (e, f J 1 ) = I,e I 1 : e i =e p(e I 1 , f J 1 ) (3) This value has to be normalized in order to obtain a probability distribution over all possible target words: p i (e | f J 1 ) = p i (e, f J 1 ) e p i (e , f J 1 ) (4) 4 System based confidence measures In this section, we will present confidence measures which are based on N -best lists or word graphs generated by the SMT system. Those are representations of the space of the most likely translations of the source sentence. The summation given in equation 3 is performed over all sentences which are contained in the N -best list or word graph. For a more detailed description, see (Ueffing et al., 2003) . Word graph based approach The word posterior probability p i (e | f J 1 ) can be calculated over a word graph using the forwardbackward algorithm. Let n , n be nodes in a word graph, and (n , n) the directed edge connecting them. The edge is annotated with a target word which we denote by e(n , n) and the probability which this word contributes to the overall sentence probability, denoted by p(n , n). The forward probability \u03a6 i (n , n) of an edge is the probability of reaching this edge from the source of the graph, where the word e(n , n) is the i-th word on the path. It can be obtained by summing the probabilities of all incoming paths of length i \u2212 1, which allows for recursive calculation. This leads to the following formula: \u03a6 i (n , n) = p(n , n) \u2022 n \u03a6 i\u22121 (n , n ) . The backward probability expresses the probability of completing a sentence from the current edge, i.e. of reaching the sink of the graph. It can be determined recursively in descending order of i as follows: \u03a8 i (n , n) = p(n , n) \u2022 n * \u03a8 i+1 (n, n * ) . Using the forward-backward algorithm, the word posterior probability of word e in position i is determined by combining the forward and backward probabilities of all edges which are annotated with e. This yields p i (e, f J 1 ) = (n ,n) : e(n ,n)=e \u03a6 i (n , n) \u2022 \u03a8 i (n , n) p(n , n) . (5) Note that (for computational reasons) the term p(n , n) is included both in the forward and in the backward probability so that we have to divide the product by this term. To obtain a posterior probability, a normalization, as shown in equation 4, has to be performed. The normalization term \u03b1 := e p i (e , f J 1 ) corresponds to the probability mass contained in the word graph and can be calculated by summing the backward probabilities of all outgoing edges leaving the source s of the graph: \u03b1 = (s,n) \u03a8 1 (s, n) . As stated above, the position of word e in the target sentence can vary due to reorderings in the translation process. Therefore, we would like to relax the condition that e has to occur exactly in position i. This can be achieved by introducing a window of size t over the neighboring target positions and computing the sum of the word posterior probabilities over all positions i \u2212 t, . . . , i, . . . , i + t. In our experiments we found that a window over \u00b13 positions yields the best performance. N -best list based approach N -best lists are an alternative representation of the space of translation hypotheses. They have the advantage that the Levenshtein alignment between a hypothesis and all sentences contained in the list can be performed easily. This makes it possible to consider not only target sentences, which contain the word e exactly in a position i (as given in equation 3), but to allow for some variation. Let L(e I 1 , \u1ebd\u0128 1 ) be the Levenshtein alignment between sentences e I 1 and \u1ebd\u0128 1 . Then, L i (e I 1 , \u1ebd\u0128 1 ) denotes the Levenshtein alignment of word e i , i.e. the word in sentence \u1ebd\u0128 1 which e i is Levenshtein-aligned to. The word posterior probability is then calculated by summing over all target sentences containing word e in a position which is Levenshtein-aligned to i: p i (e|f J 1 , I, e I 1 ) = p i (e, f J 1 , I, e I 1 ) e p i (e , f J 1 , I, e I 1 ) , where p i (e, f J 1 , I, e I 1 ) = \u0128,\u1ebd \u0128 1 : L i (e I 1 ,\u1ebd \u0128 1 )=e p(\u1ebd \u0128 1 , f J 1 ) . (6) The confidence of word e then depends on the source sentence f J 1 as well as the target sentence e I 1 , because the whole target sentence is relevant for the Levenshtein alignment. Phrase-based confidence measures In contrast to the approaches presented in section 4, the phrase-based confidence measures do not not use the context information at the sentence level, but only at the phrase level. We want to determine a sort of marginal probability Q(e, f J 1 ). Therefore, we extract all source phrases f j+s j which occur in the given source sentence. For such source phrases, we find the possible translations e i+t i in the bilingual phrase lexicon. The confidence of target word e is then calculated by summing over all phrase pairs (f j+s j , e i+t i ) where the target part e i+t i contains the word e. Let p(e i+t i ) be the language model score of the target phrase together with the word penalty c 1 , i.e. p(e i+t i ) = i+t i =i c 1 \u2022 p(e i | e i \u22121 i \u22122 ) \u03bb 1 . Analogously, define p(f j+s j , e i+t i ) as the score of the phrase pair which consists of the phrase penalty and the phrase and word lexicon model scores (cf. section 2.2). Following equation 2, the (unnormalized) confidence is then determined as: Q(e, f J 1 ) = J j=1 min{smax,J\u2212j} s=0 (7) e i+t i : e \u2208 e i+t i p(e i+t i ) \u2022 p(f j+s j , e i+t i ) , where s \u2264 s max and t are source and target phrase lengths, s max being the maximal source phrase length. In equation 7, the language model only determines the probability of the words within the target part of the phrase, and not across the phrase boundaries, because we consider only the single target phrases without context. Therefore, we assumed that the language model would not have much influence on the confidence estimation and also investigated a model without a language model. The same holds for word and phrase penalty: In the translation process they are useful for adjusting the length of the generated target hypothesis and for assigning more weight to longer phrases. Since this does not make much sense in our setting, we also investigated confidence estimation without word and phrase penalty. Note that the value calculated in equation 7 is not normalized. In order to obtain a word posterior probability, we divide this value by the sum over the (unnormalized) confidence of all target words: p phr (e | f J 1 ) = Q(e, f J 1 ) e Q(e , f J 1 ) . ( 8 ) Unlike the word posterior probabilities presented in the previous section, this value is completely independent of the target sentence position in which the word e occurs. As stated in section 2.2, the scaling factors of the different sub-models and the penalties in the translation system are optimized with respect to some evaluation criterion. But since the values which are optimal for translation are not necessarily optimal for confidence estimation, we perform optimization here as well: We train the probability models on the training corpus, estimate the word confidences on the development corpus, and optimize the scaling factors with respect to the classification error rate described in section 7.2. The optimization is performed with the Downhill Simplex algorithm (Press et al., 2002) . IBM-1 based approach Another type of confidence measure which does not rely on system output and is thus applicable to any kind of machine translation system is the IBM-1 model based confidence measure which was introduced in (Blatz et al., 2003) . We modified this confidence measure because we found that the average lexicon probability used there is dominated by the maximum. Therefore, we determine the maximal translation probability of the target word e over the source sentence words: p IBM\u22121 (e|f J 1 ) = max j=0,...,J p(e|f j ) , ( 9 ) where f 0 is the \"empty\" source word (Brown et al., 1993) . The probabilities p(e|f j ) are word-based lexicon probabilities. Investigations on the use of the IBM-1 model for word confidence measures showed promising results (Blatz et al., 2003; Blatz et al., 2004) . Thus, we apply this method here in order to compare it to the other types of confidence measures. Experiments Experimental setting The experiments were performed on three different language pairs. All corpora were compiled in the EU project TransType2; they consist of technical manuals. The corpus statistics are given in table 1. The SMT systems that the confidence estimation was performed for were trained on these corpora. The same holds for the probability models that were used to estimate the word confidences. We used several (S)MT systems for testing the confidence measures. A detailed analysis will be given for two of them; the so-called alignment template system (Och and Ney, 2004) , (denoted as AT in the tables) and the phrase-based translation system described in section 2.2 (denoted as PBT in the tables). They are both state-of-the-art SMT systems. We produced single best translations, word graphs and N -best lists on all three language pairs using these systems. The translation quality in terms of WER, PER (position independent word error rate), BLEU and NIST score is given in tables 2 and 3. We see that the best results are obtained on Spanish to English translation, followed by French to English and German to English. Two more translation systems were used for comparative experiments: One is a statistical MT system which is based on a finite state architecture (FSA). For a description of this system, see (Kanthak et al., 2005) . Additionally, we used translations generated by Systran 2 . Table 3 presents the translation error rates and scores for all systems on the German \u2192 English test corpus. These hypotheses were used to investigate whether the phrase-based confidence measures perform well independently of the translation system. All three SMT systems (AT, PBT and FSA) show very similar performance on the German \u2192 English test corpus. The fact that Systran generates translations of much lower quality is due to the fact that the technical manuals are very specific in terminology, and the SMT systems have been trained on similar corpora. To determine the true class of each word in a generated translation hypothesis, we use the word error rate (WER). That is, a target word is considered correct if it is aligned to itself in the Levenshtein alignment between hypothesis and reference translation(s). We also investigated PER based classification, but since the tendencies of the results were similar, we omit them here. Evaluation metrics After computing the confidence measure, each generated word is tagged as either correct or false, depending on whether its confidence exceeds the tagging threshold that has been optimized on the devel-opment set beforehand. The performance of the confidence measure is evaluated using the Classification Error Rate (CER). This is defined as the number of incorrect tags divided by the total number of generated words in the translated sentence. The baseline CER is determined by assigning the most frequent class to all translations. In the case that the most frequent class is \"correct\" (meaning at least half of the words in the generated translation are correct w.r.t. to WER), this is the number of substitutions and insertions, divided by the number of generated words. The CER strongly depends on the tagging threshold. Therefore, the tagging threshold is adjusted beforehand (to minimize CER) on a development corpus distinct to the test set. Experimental results Table 4 shows the performance of all different confidence measures on the hypotheses generated by the alignment template system and the phrase-based system. For the baseline CER, we determined the 90%-and 99%-confidence intervals using the bootstrap estimation method described in (Bisani and Ney, 2004) 3 . We see that, in all settings but one, the word graph and the N -best list based method outperform the IBM-1 based confidence measure. On French \u2192 English, the improvement over the baseline is significant at the 1%-level for these methods, whereas on Spanish \u2192 English this is only the case at 10%. The performance of the N -best list based approach is better than that of the word graph based confidence measures for the alignment template system. This is probably due to the fact that the former can take the Levenshtein alignment into account and thus estimate the word confidence more reliably. The phrase-based confidence measures show a performance which is clearly better than that of the other methods. We obtain a relative improvement of up to 7.8% over the best existing method on these language pairs. The improvement over the baseline is significant even at the 1%-level in all cases. When analyzing the impact of the different submodels in the phrase-based approach, we found that the language model does not have much impact on the confidence estimation. There are only slight variations in the CER if the model is omitted. The word and phrase penalty on the other hand seem to be important (with one exception in the first setting). The evaluation of the system-independent confidence measures (i.e. those based on IBM-1 and the new phrase-based method we presented) for four different translation systems is shown in table 5. We see that, for all of them, the phrase-based approach outperforms the IBM-1 based method significantly. The largest gain in terms of CER is achieved for the Systran translations: 23.8% relative over the IBM-1 based measure. Conclusion and outlook We presented a new approach to word-level confidence estimation for machine translation which makes use of bilingual phrases. By using models from a state-of-the-art phrase-based statistical machine translation system, the word confidences are estimated only on the basis of single best system output. Unlike other confidence measures, this does not rely on information from the machine translation system which generated the translation. Experimental evaluation on three different language pairs and on output from structurally different translation systems showed that the new confidence measures perform better than existing confidence measures in all cases. The application on output from different MT systems yielded a significant reduction of the error rate over the existing measures. This proves that the method is well-suited for word confidence estimation on statistical as well as non-statistical MT systems. The task investigated in this work was a text translation task in the domain of technical manuals. We are currently investigating the use of word-level confidence measures on data from the European parliament. It will be interesting to see whether a similar performance can be achieved on this large vocabulary speech translation task. Acknowledgement This work was partly funded by the European Union under the RTD project TransType2 (IST-2001-32091), and under the integrated project TC-STAR -Technology and Corpora for Speech to Speech Translation (IST-2002-FP6-506738).",
    "abstract": "Confidence measures for machine translation is a method for labeling each word in an automatically generated translation as correct or incorrect. In this paper, we will present a new approach to confidence estimation which has the advantage that it does not rely on system output such as Nbest lists or word graphs as many other confidence measures do. It is, thus, applicable to any kind of machine translation system. Experimental evaluation has been performed on translation of technical manuals in three different language pairs. Results will be presented for different machine translation systems to show that the new approach is independent of the underlying machine translation system which generated the translations. To the best of our knowledge, the performance of the new confidence measure is better than that of any existing confidence measure.",
    "countries": [
        "Germany"
    ],
    "languages": [
        "French",
        "German",
        "Spanish",
        "English"
    ],
    "numcitedby": "55",
    "year": "2005",
    "month": "October",
    "title": "Word-Level Confidence Estimation for Machine Translation using Phrase-Based Translation Models"
}