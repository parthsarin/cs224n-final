{
    "article": "We made a test set for Japanese-to-English discourse translation to evaluate the power of context-aware machine translation. For each discourse phenomenon, we systematically collected examples where the translation of the second sentence depends on the first sentence. Compared with a previous study on test sets for English-to-French discourse translation (Bawden et al., 2018) , we needed different approaches to make the data because Japanese has zero pronouns and represents different senses in different characters. We improved the translation accuracy using context-aware neural machine translation, and the improvement mainly reflects the betterment of the translation of zero pronouns. Introduction Translation accuracy for sentences has been greatly improved by neural machine translation (Cho et al., 2014; Sutskever et al., 2014; Bahdanau et al., 2015; Luong et al., 2015; Vaswani et al., 2017) . Although the accuracy of sentence-level machine translation is approaching human parity (Hassan et al., 2018) , human evaluators prefer the translations of human translators over those of machine translation in document-level evaluations (Samuel L\u00e4ubli, 2018) . For further improvement, research using discourse information is gaining attention (Tiedemann and Scherrer, 2017; Bawden et al., 2018; Voita et al., 2018; Maruf and Haffari, 2018; Miculicich et al., 2018; Voita et al., 2019a) . The easiest method to use discourse information is to concatenate both the previous and current sentences with a special token <CONCAT> as a separator and translate them using an ordinary sentence-based translation system (Tiedemann and Scherrer, 2017) . This method, which is called 2-to-2, is known to be a reasonably strong baseline for discourse translation (Bawden et al., 2018; Voita et al., 2018) . In this context, ordinary sentence-based translation is called 1-to-1. Some recent proposals have focused on multiple-encoders, where the input sentence and the context have different encoders. Bawden et al. (2018) used an RNN-based encoder-decoder and Voita et al. (2018) used the Transformer (Vaswani et al., 2017) for multipleencoders. Others used a cache-based model to exploit document-level information (Wang et al., 2017; Kuang et al., 2018; Tu et al., 2018) . One problem in the study of discourse translation is that by only using automatic accuracy measures such as BLEU, we cannot distinguish between what is solved and not solved by the proposed method. Bawden et al. (2018) therefore proposed discourse test sets for English-to-French translation to evaluate the power of generating appropriate sentences based on the context information using the framework of a contrastive test set (Sennrich, 2017) . For discourse phenomena, they targeted coreference and coherence, and manually created a test set based on real examples in bilingual corpora. Voita et al. (2019b) made a contrastive test set for English-to-Russian discourse translation. To make Japanese-to-English discourse translation test sets, we also targeted on coreference and coherence. We first looked for examples in bilingual corpora. However, since we found that this approach is inefficient, we chose a different approach using linguistically annotated corpora. The following are this paper's contributions: \u2022 we created a novel test set for Japanese-to-English discourse translation 1 . \u2022 we proposed a novel approach to create discourse translation tests: tests for coreferences were made from monolingual annotated databases and those for coherences were made from bilingual dictionaries. \u2022 using the proposed test set, we show that improvement of the context-aware neural machine translation is mainly brought by the betterment of the translation of Japanese zero pronouns. In the following sections, we first describe our Japaneseto-English discourse translation test set. We then describe our experiment results on discourse translation and analyze them using our proposed discourse test set. Contrastive Test Set for Discourse Translation To make a contrastive test set for Japanese-to-English discourse translation, we first made a pair of Japanese sentences and their English translations, where the English translation of the second Japanese sentence depends on the first Japanese sentence. We then made an English sentence by adding to the second English sentence a minor error caused by ignoring the context provided by the first sentence. We tried to set the correct answer rate of the contrastive test to 50%, which means that the translation model estimates the correct and incorrect choices as equally plausible if it does not know the context. Beside the couch was a wooden chair. Correct: A lens and a forceps was lying upon the seat. Incorrect: A lens and a forceps was lying upon a seat. . Zero Pronouns For the coreferences, we focus on the target linguistic elements without counterparts in the source language (Japanese zero pronouns and English articles) because the generation of such linguistic elements is dependent on the context. In Japanese, when subjects and objects are understood from the context, they are usually omitted. These omitted elements are called zero pronouns because they resemble pronouns without surface forms. To translate a Japanese zero pronoun, we have to determine the person, the number, and the grammatical function of an English pronoun. In the example in Figure 1 (a), the default interpretation of the omitted subject for the action verb is the first person, but the context provided by the previous sentence changes it to the third person. Bawden et al. (2018) created discourse test sets inspired by real examples found in OpenSubtitles. Although we also tried the same procedure, we found it inefficient because correctly analyzing Japanese zero pronouns is difficult, even for native Japanese speakers. We therefore adopted the following procedure. First, we selected a Japanese sentence with zero pronouns from a corpus with annotation on zero pronouns, such as Keyaki Treebank 2 (Butler et al., 2012) . We then translated the sentence by Google Translate to obtain the most likely English translation for the Japanese zero pronoun because their En-Ja dataset is larger than ours 3 . We then selected an English pronoun for an incorrect English translation and made two preceding Japanese sentences, one for the correct English pronoun and another for the incorrect one. For coreference, Bawden et al. (2018) defined \"semicorrect\" to denote when second sentence's translation is correct in terms of the target side context when the first sentence's translation is incorrect. They made a set of four sentences for a test: correct/incorrect, semi-correct/incorrect. We only made two sentences (correct/incorrect) because the consistency on the target side context can be evaluated by coherence tests. Articles Figure 1 (b) shows an example of a test for an article. Since the same entity is mentioned in the first sentence, the article in the second sentence must be the definite article \"the\". Note that the surface forms of \u6905\u5b50 on the Japanese side are identical, while those on the English side are different: chair and seat 4 . We made the following tests for articles (definite/indefinite) with two types of previous sentences: with antecedents (including bridge reference) and without. We tried to make their proportion 50:50. As in the case for coreference, since looking for examples from the translation corpus is inefficient, we used annotated corpora for grammatical error correction (GEC) such as the Cambridge Learner Corpus First Certificate (CLC FCE) dataset 5 and coreference resolution such as OntoNotes 5.0 (Hovy et al., 2006) . In particular, we found GEC examples useful when \"the\" was changed to \"a\" for making a natural pair of sentences without a definite reference: In our country, there are rules that everyone has to follow, and recently a new rule was added. We aren't allowed to use a (*the) mobile phone in class. Finding definite references and their antecedents in the coreference resolution data is easy. However, as we described in the experiment section, it is difficult to make the correct answer rate be 50%, because most articles can be predicted using language models. Coherence and Cohesion For coherence and cohesion, we followed the previously defined classification of disambiguation and alignment (and repetition) (Bawden et al., 2018) because they are language independent. Figure 2 (a) shows an example of a test for disambiguation, where \"\u3059\u3054\u3044\u4eba\" can be translated into either \"a lot of people\" or \"a great man.\" In general, tests for disambiguation must satisfy the following three conditions: \u2022 the source sentence has an ambiguous word; \u2022 its senses are translated into different target words; \u2022 the choice of target words depends on either the source or the previous target sentence. Since Japanese uses Kanji (ideograms imported from Chinese), relatively few Japanese words have multiple senses There are a lot of people. Incorrect: He is a great man. We therefore used multiple Japanese-to-English dictionaries to collect ambiguous Japanese words and created tests from scratch. Figure 2 (b) shows an example of an alignment test, where \"\u6642\u8a08\" can be translated as either \"clock\" or \"watch.\" The conditions for alignment tests are slightly different from those for disambiguation: \u2022 the source sentence has an ambiguous word; \u2022 its senses are translated into different target words that are not interchangeable; \u2022 the previous source sentence has the same ambiguous word and can be translated into the same set of target words depending on the ambiguous source word's Since the target translations of the ambiguous source word are not interchangeable, the target translation must be identical in the first and second sentences. Note that some grounding is required to decide the correct answer. For example in Figure 2 (b), whether it is a clock or a watch depends on the object in the real word referred to by the linguistic expression \"\u6642\u8a08\". Experiments Datasets Table 1 shows the eight Japanese-English datasets used for our discourse translation experiments. They include spoken language datasets of about 2M sentences and written language datasets of about 1M sentences. IWSLT-2017 (Cettolo et al., 2017) is a dataset for Japanese-English Tasks of the International Workshop on Spoken Language Translation and consists of the transcriptions of TED Talks and their translations. OpenSubtitles2018 (Lison et al., 2018) at The Japan News (formerly the Daily Yomiuri), which is the newspaper's English edition. We purchased CD-ROMs published for research purposes 11 , and obtained document and sentence alignments using the algorithm of Utiyama and Isahara (2003) . Tools For preprocessing, the English sentences are tokenized and lowercased by the scripts in Moses toolkit (Koehn et al., 2007) . Japanese sentences were normalized by NFKC (a unicode normalization form) and word segmented by MeCab 12 with UniDic. Both Japanese and English sentences were further tokenized into subwords using byte pair encoding (Sennrich et al., 2016) with 32k shared merge operations. For neural machine translation, we used OpenNMT-lua 13 for RNN encoder-decoder (Luong et al., 2015) and fairseq toolkit 14 for the Transformer (Vaswani et al., 2017) . We used default settings unless otherwise specified. The translation accuracy was measured by BLEU (Papineni et al., 2002) using multi-bleu.perl in the Moses toolkit. Context Boundaries Unlike spoken language datasets, written language datasets have obvious structures including documents, sections, and paragraphs, all of which can be candidates for context boundaries. To the best of our knowledge, scant research has addressed context boundaries in previous works on discourse translation, probably because they are based on spoken language datasets such as OpenSubtitles. As a preliminary experiment, we compared the translation accuracies of two different context boundaries (document (file) and paragraph) with a 2-to-2 discourse translation model and found virtually no differences in translation accuracies. We therefore used document boundaries for the contexts in the following experiments. Translation Accuracies We made 1-to-1 and 2-to-2 translation models from all datasets. Table 2 shows the translation accuracies (BLEUs) of the different test sets and two translation methods. In general, the 2-to-2 models outperformed the 1-to-1 models with a small but statistically significant margin. Transformer's accuracy was significantly higher than attentionbased RNN encoder-decoder. Discourse Test Set Scores We obtained the translation scores (log probability) for the correct and incorrect sentences of the discourse test sets by forced decoding and calculated the proportion of the tests where the scores of the correct sentences exceeded those of the incorrect sentences. Table 3 shows the correct answer rate of each test category for the 1-to-1 and 2-to-2 models of the two translation methods. As for the Transformer, the 2-to-2 models consistently outperformed the 1-to-1 models in all the test categories. In particular, the correct answer rate of pronoun is greatly improved compared with other categories. As for the RNN encoder-decoder, pronoun is the only category with significant improvement. The correct answer rate of the 1-to-1 model for articles was significantly higher than the designed baseline (50%). We assume this is because there are many cases where correct articles can be predicted based on the local context in the current sentence regardless of the previous sentence. For pro-drop languages like Japanese and Chinese, zero pronoun was known to be one of the most difficult problems and many specific extensions for baseline translation methods have been discussed in previous research (Taira et al., 2012; Kudo et al., 2014; Takeno et al., 2016; Wang et al., 2016; Wang et al., 2018) . However, it seems that contextaware neural machine translation can handle Japanese zero pronouns just as effectively as overt pronouns in Englishto-Russian translation (Voita et al., 2018) . To the contrary, there is room to improve the handling of coherence in simple context-aware models, such as the 2-to-2 model. Sample Usage of Test Set Figure 3 shows an example of a test for pronoun translation. In \"Input:\", the previous and current sentences are concatenated by a special token, <CONCAT>. The current sentence has two zero pronouns: subjects of the subordinate clause and the matrix sentence. A zero pronoun is indicated by *pro*, and the subject is indicated by \u304c, which is the Japanese subject case marker. Comparing \"Correct:\" with \"Incorrect:\", the subject of the subordinate clause was changed from \"she\" to \"you.\" Since the log probability (-27.22) for the correct sentence is larger than that for the incorrect sentence (-29.67), the example is categorized as correct. \"Translation:\" is the output of the 2-to-2 model, where both Japanese zero pronouns are correctly translated into English (overt) pronouns. 3 : Examples for input source, correct target, incorrect target, and output target sentences for 1-to-1 and 2-to-2 models with their translation scores For the 1-to-1 model, the log probability (-8.48) of the correct sentence is smaller than the incorrect sentence (-7.44), which is categorized as a wrong answer. The translation output abandons the translation of the subordinate clause, which is a typical behavior of neural machine translation. Conclusions We developed a contrastive test set for evaluating the power of discourse translation models for Japanese-to-English translation and found that the 2-to-2 discourse translation model's improvement is mainly caused by better translation of Japanese zero pronouns. As was also shown in Kimura et al. (2019) , Japanese zero pronouns can basically be effectively handled by context-aware neural machine translation. In future work, we want to build a test set for English-to-Japanese discourse translation to focus on Japanese empathy and honorifics. We also want to develop a more sophisticated context-aware neural machine translation method that can appropriately handle coherence. Moreover, we want to expand our test set to a similar size of a previous work (M\u00fcller et al., 2018) . They built a largescale test set from German-English bilingual texts using coreference resolution and word alignment tools. However, to build a large-scale test set for Japanese zero pronouns, we have to develop accurate tools for Japanese empty category detection (zero pronoun identification) and Japanese coreference resolution, which remains open problems.",
    "funding": {
        "defense": 1.9361263126072004e-07,
        "corporate": 0.0,
        "research agency": 0.0,
        "foundation": 5.51223498068687e-07,
        "none": 1.0
    },
    "reasoning": "Reasoning: The article does not mention any specific funding sources, including defense, corporate, research agencies, foundations, or any other type of financial support for the research conducted or for the development of the test set and methodologies described.",
    "abstract": "We made a test set for Japanese-to-English discourse translation to evaluate the power of context-aware machine translation. For each discourse phenomenon, we systematically collected examples where the translation of the second sentence depends on the first sentence. Compared with a previous study on test sets for English-to-French discourse translation (Bawden et al., 2018) , we needed different approaches to make the data because Japanese has zero pronouns and represents different senses in different characters. We improved the translation accuracy using context-aware neural machine translation, and the improvement mainly reflects the betterment of the translation of zero pronouns.",
    "countries": [
        "Japan"
    ],
    "languages": [
        "German",
        "English",
        "Japanese"
    ],
    "numcitedby": 7,
    "year": 2020,
    "month": "May",
    "title": "A Test Set for Discourse Translation from {J}apanese to {E}nglish",
    "values": {
        "building on past work": "Voita et al. In future work, we want to build a test set for English-to-Japanese discourse translation to focus on Japanese empathy and honorifics. M\u00fcller et al.",
        "novelty": "we proposed a novel approach to create discourse translation tests: tests for coreferences were made from monolingual annotated databases and those for coherences were made from bilingual dictionaries.",
        "performance": "As for the Transformer, the 2-to-2 models consistently outperformed the 1-to-1 models in all the test categories. In particular, the correct answer rate of pronoun is greatly improved compared with other categories. As for the RNN encoder-decoder, pronoun is the only category with significant improvement. The correct answer rate of the 1-to-1 model for articles was significantly higher than the designed baseline (50%)."
    }
}