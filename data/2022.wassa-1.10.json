{
    "article": "Public opinion in social media is increasingly becoming a critical factor in pandemic control. Understanding the emotions of a population towards vaccinations and COVID-19 may be valuable in convincing members to become vaccinated. We investigated the emotions of Japanese Twitter users towards Tweets related to COVID-19 vaccination. Using the WRIME dataset, which provides emotion ratings for Japanese Tweets sourced from writers (Tweet posters) and readers, we fine-tuned a BERT model to predict levels of emotional intensity. This model achieved a training accuracy of M SE = 0.356. A separate dataset of 20,254 Japanese Tweets containing COVID-19 vaccine-related keywords was also collected, on which the fine-tuned BERT was used to perform emotion analysis. Afterwards, a correlation analysis between the extracted emotions and a set of vaccination measures in Japan was conducted. The results revealed that surprise and fear were the most intense emotions predicted by the model for writers and readers, respectively, on the vaccine-related Tweet dataset. The correlation analysis also showed that vaccinations were weakly positively correlated with predicted levels of writer joy, writer/reader anticipation, and writer/reader trust. Code will be made available at https: //github.com/PatrickJohnRamos/ BERT-Japan-vaccination. Introduction Vaccination against COVID-19 has been demonstrated to reduce the spread of the virus (Jones et al., 2021; Hall et al., 2021; Voysey et al., 2021) . However, vaccine hesitancy can prevent vaccine uptake, increasing risk of infection. Searching for and understanding causes of vaccine hesitancy can lead to more effective methodologies in convincing community members to become vaccinated. One possible area of understanding vaccine hesitancy is the emotions felt towards vaccines and the COVID-19 pandemic. For example, fear felt towards vaccination might discourage one from receiving the vaccine. Meanwhile, fear felt towards contracting COVID-19 could encourage one to become vaccinated against it. Leveraging emotions has also been proposed in communication to reduce COVID-19 vaccine hesitancy (Chou and Budenz, 2020) . There have been several attempts at extracting emotions regarding COVID-19 vaccines, particularly from social media. The wealth of information available on social networking services such as Twitter already makes them a popular source for mining sentiment and emotions in other areas such as politics (Bose et al., 2019) and consumerism (Rathan et al., 2018) . Social media information extraction has seen continued research during the COVID-19 pandemic, with multiple works specifically seeking to mine sentiments and emotions surrounding the pandemic and vaccination (Boon-Itt and Skunkan, 2020; Sakti et al., 2021; Ayg\u00fcn et al., 2021; Niu et al., 2022) . Existing emotion analysis studies on COVID-19related Japanese Twitter corpora only focus on the emotions of writers, or those who post Tweets (Lee et al., 2020; Bashar, 2021) . However, the emotions of readers, or those who read Tweets, are not necessarily the same as those of writers. For instance, if a writer expresses disgust towards vaccination, a reader might express anger out of disagreement in response. These reader emotions may also contain useful information in understanding vaccine hesitancy. We contribute to this research area by using a BERT to extract emotions of both writers and readers towards Tweets related to COVID-19 vaccines and comparing the predicted emotions to vaccination uptake. We do this by fine-tuning a BERT (Devlin et al., 2019) to predict intensity scores for Plutchik's eight emotions (Plutchik, 1980) for writers and readers from Tweets containing keywords related to COVID-19 vaccination, and performing a correlation analysis between the mined emotions and a set of vaccination measures in Japan. Note that one limitation of our study is that the dataset of COVID-19 vaccine-related Tweets does not guarantee that COVID-19 or vaccination are the topics of the texts, or are necessarily the object of any inferred emotion. We find that the emotion most prominently predicted by the model for writers on the vaccinerelated Tweet dataset is surprise, with fear being the most intensely predicted emotion for readers. Additionally, writer joy, writer/reader anticipation, and writer/reader trust are weakly positively correlated with vaccinations. Related Work Prior to the adoption of deep learning, emotion analysis of Tweets was performed with a combination of feature engineering, lexicon-based approach, and traditional off-the-shelf classifiers. Balabantaray et al. (2012) and Wang et al. (2012) engineered overlapping sets of features from Tweets, with shared features including n-grams, POS, adjectives, and lexicon-based sentiment polarity scores. Balabantaray et al. (2012) fed the features to an SVM while Wang et al. (2012) used linear and Naive Bayes classifiers. EmpaTweet (2012) used a similar set of features and also an SVM, but exchanged sentiment polarity scores for synonym rings, hypernyms, and LDA topic scores. However, these classical methods have been outperformed by more contemporary and dedicated sequence modelling techniques such as RNNs and LSTMs. Vateekul and Koomsubha (2016) demonstrated the superiority of LSTMs in emotion analysis over SVMs and Naive Bayes on Thai Twitter text, while Colneri\u010d and Dem\u0161ar (2018) showed the effectiveness of character-based RNNs. The introduction of Transformers (Vaswani et al., 2017) as the new state-of-the-art sequence modelling architecture and their increasing ubiquity has also lead to their application in social media emotion analysis for a variety of languages. BERT models can outperform CNNs and BiLSTMs on English Twitter (Harb et al., 2020) ; Naive Bayes, logistic regression, and SVMs on Romanian Twitter (Ciobotaru and Dinu, 2021) ; and TF-IDF and word2vec on Arabic Twitter (Al-Twairesh, 2021). During the COVID-19 pandemic, a RoBERTa (Liu et al., 2019) was fine-tuned on emotion analysis to classify the emotions of Tweets containing hashtags related to the pandemic (Choudrie et al., 2021) . Meanwhile, emotion analyses of Japanese Tweets related to COVID-19 have been conducted using traditional techniques such as lexicon-based methods (Bashar, 2021) and frequency analysis (Lee et al., 2020) . The work most similar to ours is that of Niu et al. (2022) , who perform sentiment analysis of COVID-19-related Japanese Tweets; investigate the correlation of the mined sentiments with infections, deaths, and vaccinations; and conduct additional analyses comparing multiple vaccine brands. Our study differs from this by extracting emotions rather than sentiments from both writers and readers, and comparing these mined features to vaccinations, vaccinated people, and fully vaccinated people. Method Dataset To gauge the emotions of the Japanese public towards COVID-19 vaccines and related topics, a dataset of 20,254 vaccine-related Tweets from December 2021 containing any of the keywords\"\u30ef \u30af\u30c1\u30f3\" (\"vaccine\"), \"\u30e2\u30c7\u30eb\u30ca\" (\"Moderna\"), \"\u30d5\u30a1\u30a4\u30b6\u30fc\" (\"Pfizer\"), or \"\u30aa\u30df\u30af\u30ed\u30f3\" (\"Omicron\") was constructed. \"Moderna\" and \"Pfizer\" were specifically selected as keywords as these are brands of COVID-19 vaccines commonly administered in Japan. The dataset was created by sampling 15 random minutes from each day of December 2021 for each keyword, and scraping all Tweets containing the assigned keyword for each sampled minute. A distribution of the dataset according to keyword is shown in Table 1 . Table 2 compares our constructed dataset against WRIME (Kajiwara et al., 2021) , the fine-tuning dataset we discuss in Section 3.2. Our dataset contains longer texts on average. Postpositional particles, nouns, punctuation marks, and verbs are among the most common parts of speech in both datasets. However, auxiliary verbs are more common in the vaccine-related Tweet dataset while non-punctuation symbols are more common in WRIME. Fine-tuning BERT for Emotion Analysis We used BERT to perform emotion analysis by fine-tuning it to extract writer and reader emotional intensity scores from text, with higher scores indicating higher intensities. Writer emotions refer to emotions felt by the writers of a Tweet as they  write the post, while reader emotions refer to the emotions felt by the readers of a Tweet as they read it. We followed Plutchik's (1980) framework and fine-tuned BERT to extract intensity scores for eight emotions: joy, sadness, anticipation, surprise, anger, fear, disgust, and trust. Using BERT for emotion analysis was straightforward and required only a simple modification to the head of the BERT model. First, input texts were tokenized using MeCab (Kudo et al., 2004) and WordPiece (Wu et al., 2016) . The tokenized inputs were then each prepended with [CLS] classification tokens and fed through the BERT model. After the last layer, each [CLS] token was linearly projected into 16 class scores, representing the 8 emotions of writers and readers. A PyTorch (Paszke et al., 2019) implementation of BERT BASE (110M parameters) pre-trained on Japanese Wikipedia from HuggingFace (Wolf et al., 2020) 2 was fine-tuned on WRIME (Kajiwara et al., 2021) . WRIME is a dataset for emotional intensity estimation comprised of 43,200 Japanese Tweets annotated with Plutchik's 8 emotions by the posts' writers and 3 \"reader\" annotators hired by the dataset authors to read the posts. 3 Each emotion is annotated across 4 levels (0 to 3) of increasing intensity, with 0 referring to no presence and 3 re-ferring to strong intensity. To create only a single set of reader emotion scores per data point, we averaged the scores across the three readers. BERT was then trained with mean squared error loss to directly predict the emotional intensity scores of writers and readers for given Tweets. A sample data point can be seen in Table 3 . Our fine-tuning was inspired by common BERT fine-tuning procedures (Devlin et al., 2019) . We fine-tuned BERT on WRIME for 3 epochs using the AdamW optimizer (Loshchilov and Hutter, 2017) with a learning rate of 2e-5, \u03b2 1 =0.9, \u03b2 2 =0.999, weight decay of 0.01, linear decay, a warmup ratio of 0.01, and a batch size of 32. Training was conducted with an NVIDIA Tesla K80 and finished in 3 hours. The fine-tuned BERT was dubbed \"emotion analysis BERT.\" We evaluated emotion analysis BERT by comparing its mean squared errors to those of two baselines based on Kajiwara et al. (2021) . The first was a bag-of-words and linear regression model (BoW+LinReg). Each text was tokenized using MeCab, vectorized into a bag-of-words using the 2000 most common words in the vocabulary, and then fed into a linear regression model. While Kajiwara et al. (2021) used logistic regression, we used linear regression for a fairer comparison with emotion analysis BERT, which directly predicts intensity scores. The second model we compared to uses fastText (Bojanowski et al., 2017) and an SVM (fastText+SVM). Each word of was embedded using fastText, after which the average of all the embeddings in the sequence were used as input into an SVM that regresses the emotional intensity scores. We used a linear kernel and C = 100. Inferring Emotions from Vaccine-related Tweets Emotions from the vaccine-related Tweet dataset were extracted using emotion analysis BERT following the procedure described in Section 3.2. Tweets were tokenized, prepended with a [CLS] token, and processed through emotion analysis BERT, with the [CLS] token being projected into writer and reader emotion scores after the last layer. Note that this is purely inference and no training is done using the vaccine Tweet data. Tweet \u8eca \u306e \u30bf \u30a4 \u30e4 \u304c \u30d1 \u30f3 \u30af \u3057 \u3066 \u305f \u3002 \u3002 \u3044 \u305f \u305a \u3089 \u306e \u53ef \u80fd \u6027 \u304c \u9ad8 \u3044 \u3093 \u3060 \u3063 \u3066\u3002\u3002( Experimental Results and Discussion Fine-tuning results Results for emotional intensity prediction on WRIME are shown in Table 4 . The only emotion for which we do not achieve the best mean squared error is writer trust, where we still remain competitive a difference of 0.001 MSE from the best performing model. For all other emotions for both writers and readers, emotion analysis BERT outperforms both of the other models. We achieve 0.111 MSE and 0.106 MSE improvements on writer and reader emotion prediction respectively. For overall emotional intensity prediction, we outperform the next best model by 0.090 MSE. Table 5 presents inferred emotions for sample test entries from WRIME. We qualitatively examined these results, which showed that emotion analysis BERT is capable of detecting emotion even when emotions are not explicitly stated, like they would be in a sentence such as \"I am joyful.\" The model was able to infer anger and disgust from texts including phrases like \"I waited for an hour but no one came!!\", and joy and anticipation from \"Haven't had back-to-back holidays in a while. Tomorrow is a weekday break!!\" Emotion inference results Figure 1 presents the distributions of emotions for both writers and readers predicted by emotion anal- ysis BERT. The highest average predicted score was surprise for writers and fear for readers. With the exception of fear, inferred writer scores were more intense, especially in sadness, anger, and trust, where median inferred writer scores were greater than the third quartile of inferred reader scores. Why the emotion intensities predicted for writers differed from those assumed for readers could be of interest to future studies. The distributions of predicted writer and reader emotions are compared in a Q-Q plot in Figure 2 . Anticipation and fear followed similar distributions for both writer and reader inferences, while other emotions showed lower values for readers, especially for trust.  The percentage distributions of emotions for writers and readers inferred by the model for all keywords and per keyword are shown in Figure 3 . While predicted writer emotion scores tended to be higher, this did not necessarily mean the same for the proportion each emotion constituted of the sum of all emotion scores. Although writers had higher predicted average anticipation, surprise, and disgust, these emotions comprised a larger percentage of inferred reader emotions than they did writer emotions. Fear, which was predicted at higher levels for readers, also constituted a larger proportion of total inferred reader emotion. Predicted emotions of Tweets referencing Moderna were compared to those of Tweets referencing Pfizer to identify any differences in emotions towards the two brands of vaccines. The results of a Kolmogorov-Smirnov test for the intensities of emotions towards the two brands are presented in Table 6 . Only differences in predictions for writer joy (Pfizer higher), writer sadness (Moderna higher), and reader sadness (Moderna higher) could be considered attributable to differences in Figure 3 : Distributions of predicted emotions for writers and readers for all keywords and for each keyword. Emotion proportions were calculated by dividing the total score of each emotion by the sum of all emotion scores for the emotion's assigned subject (writer or reader). underlying distributions. Sample emotion inferences can be seen in Table 7 . Like with the qualitative results from WRIME, emotion analysis BERT was capable of detecting emotion even in a lack of explicitly mentioned emotions. The model could identify anger and disgust from Tweets containing phrases such as \"I can't call it anything other than foolish,\" and trust from \"Today, I finally got vaccinated. My arm hurts a little bit, but other than that there are no problems.\" Comparison to vaccinations in Japan Vaccination data was taken from Our World in Data (Mathieu et al., 2021) 4 . The vaccination data was comprised of a set of periodic vaccination measures for several countries. We filtered the dataset to only include entries from Japan in December 2021, matching the collection period of our vaccine-related Tweet dataset. For each date in the dataset, we focused on vaccinations, or the number of vaccinations administered on that date; new people vaccinated, or the number of people who received their first dose on said date; and new people fully vaccinated, or the number of people who received their second dose on that date. One thing to note is that vaccinations have plateaued starting November 2021, resulting from a lower number of vaccinations and a slower uptake of boosters (Mathieu et al., 2021) . Figure 4 compares the average predicted score for each emotion to the number of new vaccinations, people vaccinated, and people fully vaccinated across December 2021. No easily discernible trend common to both emotion scores and vaccination metrics was found. For each writer and reader emotion, we performed a correlation analysis with each vaccination 4 Vaccination data is available at https: //github.com/owid/covid-19-data/tree/ master/public/data/vaccinations. measure by taking the Pearson correlation coefficient between the sums of the particular emotion's predicted intensities and their corresponding vaccination metric for each date recorded in the vaccination dataset. The results are presented in Figure 5 . The only results with satisfactory p-values were under vaccinations, which were positive correlated with writer joy (r = 0.36, p = 0.047), writer anticipation (r = 0.40, p = 0.027), writer trust (r = 0.40, p = 0.025), reader anticipation (r = 0.44, p = 0.013), and reader trust (r = 0.39, p = 0.031). We did not observe any significant correlations between the predicted emotion scores and people vaccinated or people fully vaccinated, as all p-values for these results were greater than or equal to 0.157, which is above the alpha of 0.05. Broader Impact Research into understanding the emotions of a population towards vaccines could hold both positive and negative societal impacts. Any relationship discovered between emotions and vaccinations could be leveraged in campaigns aimed at convincing citizens to receive vaccinations, reducing the spread of COVID-19. On the other hand, knowledge of what emotions could affect vaccine acceptance can be used in efforts to increase vaccination hesitancy and slow down vaccination rates, which could prolong risks of infection. Conclusion We fine-tuned a BERT on the task of emotion analysis, and used the emotion analysis BERT to infer emotion intensities of writers and readers from a corpus of Tweets containing keywords related to COVID-19 and COVID-19 vaccination. Our results revealed that surprise and fear were respectively the most intensely predicted emotions for writers and readers. Furthermore, vaccinations were weakly positively correlated with writer joy, writer anticipation, writer trust, reader anticipation, and reader trust. Future works can extend this study by designing the emotion analysis to be aspect-based with respect to the keywords, as it is possible that the keywords are not the objects of the inferred emotions. Another possible area for further research could be correlation analyses with other COVID-19 metrics, such as infections and reproduction rate. 2 We use the cl-tohoku/bert-base-japanse-v2 Japanese BERT checkpoint available at https://huggingface.co/cl-tohoku/ bert-base-japanese-v2. Acknowledgements This work was supported by JST SICORP Grant Number JPMJSC2107, Japan.",
    "funding": {
        "defense": 0.0,
        "corporate": 0.0,
        "research agency": 1.0,
        "foundation": 0.0,
        "none": 0.0
    },
    "reasoning": "Reasoning: The acknowledgements section of the article explicitly mentions that the work was supported by JST SICORP Grant Number JPMJSC2107, Japan. JST (Japan Science and Technology Agency) is a government-funded organization that provides grants for scientific and technological research, classifying it as a research agency. There is no mention of funding from defense, corporate entities, foundations, or an indication that there were no other funding sources.",
    "abstract": "Public opinion in social media is increasingly becoming a critical factor in pandemic control. Understanding the emotions of a population towards vaccinations and COVID-19 may be valuable in convincing members to become vaccinated. We investigated the emotions of Japanese Twitter users towards Tweets related to COVID-19 vaccination. Using the WRIME dataset, which provides emotion ratings for Japanese Tweets sourced from writers (Tweet posters) and readers, we fine-tuned a BERT model to predict levels of emotional intensity. This model achieved a training accuracy of M SE = 0.356. A separate dataset of 20,254 Japanese Tweets containing COVID-19 vaccine-related keywords was also collected, on which the fine-tuned BERT was used to perform emotion analysis. Afterwards, a correlation analysis between the extracted emotions and a set of vaccination measures in Japan was conducted. The results revealed that surprise and fear were the most intense emotions predicted by the model for writers and readers, respectively, on the vaccine-related Tweet dataset. The correlation analysis also showed that vaccinations were weakly positively correlated with predicted levels of writer joy, writer/reader anticipation, and writer/reader trust. Code will be made available at https: //github.com/PatrickJohnRamos/ BERT-Japan-vaccination.",
    "countries": [
        "Philippines",
        "Japan"
    ],
    "languages": [
        "Arabic",
        "Romanian",
        "English",
        "Thai",
        "Japanese"
    ],
    "numcitedby": 0,
    "year": 2022,
    "month": "May",
    "title": "Emotion Analysis of Writers and Readers of {J}apanese Tweets on Vaccinations"
}