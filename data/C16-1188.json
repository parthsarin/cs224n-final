{
    "article": "Identifying dialogue acts and dialogue modes during tutorial interactions is an extremely crucial sub-step in understanding patterns of effective tutor-tutee interactions. In this work, we develop a novel joint inference method that labels each utterance in a tutoring dialogue session with a dialogue act and a specific mode from a set of pre-defined dialogue acts and modes, respectively. Specifically, we develop our joint model using Markov Logic Networks (MLNs), a framework that combines first-order logic with probabilities, and is thus capable of representing complex, uncertain knowledge. We define first-order formulas in our MLN that encode the inter-dependencies between dialogue modes and more fine-grained dialogue actions. We then use a joint inference to jointly label the modes as well as the dialogue acts in an utterance. We compare our system against a pipeline system based on SVMs on a real-world dataset with tutoring sessions of over 500 students. Our results show that the joint inference system is far more effective than the pipeline system in mode detection, and improves over the performance of the pipeline system by about 6 points in F1 score. The joint inference system also performs much better than the pipeline system in the context of labeling modes that highlight important pedagogical steps in tutoring. Introduction One-on-one instruction, i.e. tutoring, is one of the most effective forms of instruction. Intelligent Tutoring Systems (ITS) (Rus et al., 2013) have the potential to make effective and affordable \"instruction-for-all\" a reality since they do not suffer from traditional constraints such as lack of trained and expensive human tutors, physical teaching facilities, etc. However, in order to build effective automated tutoring systems, i.e. tutoring systems the induce student learning gains, we first need to understand what effective human tutors do. Specifically, we would like to identify specific pedagogical steps that promote effective tutoring. For instance, a good tutor may start by building a rapport with the students, followed by helping the student identify the domain of the problem, and so on. The sequence of steps taken by expert human tutors can in turn be used to improve the performance of ITS by re-enacting such effective tutorial strategies that are likely to promote better learning. Understanding what good tutors do to help students learn has been the subject of much theoretical and empirical research (Chi et al., 2001; Eugenio et al., 2006; Cade et al., 2008; Jeong et al., 2008; Boyer et al., 2010; Lehman et al., 2012) . A standard approach to understanding effective tutoring is to characterize tutor-tutee interactions based on the actions tutors and tutees take and then identify patterns of such actions that are associated with effective tutoring. For instance Cade et al. (Cade et al., 2008) used dialogue acts, which are constructs used to describe the intentions behind speakers' utterances, to model tutor-learner dialogue-based interactions. Boyer et al. (Boyer et al., 2010) modeled interactions as a combination of both task actions, which specify fine-grained steps taken by a user such as opening a file, and dialogue acts. However, dialogue acts only identify individual, isolated acts, e.g. asking a question, associated with a particular utterance lacking to characterize the meaning of a sequence of coherent actions, e.g. by the tutor, that might reveal high level constructs such as pedagogical strategies, e.g. scaffolding. In this work, we present a novel approach to identify higher-level tutorial constructs called modes in tutor-learner dialogue-based interactions. Specifically, dialogue modes are sequences of dialogue acts that map to pedagogical goals such as scaffolding (and sometimes to general dialogue goals such as opening a conversation). An example of the hierarchy of modes, dialogue acts and subacts in utterances is shown in Table 1 . As is often the case in several NLP tasks, a pipeline architecture can be naturally adopted to identify dialogue modes. Specifically, we first label acts in each utterance of the dialogue, then, using the labeled acts, we label subacts, and using both the labeled acts and subacts, we finally label the higher level modes. However, as is the case in general with pipeline based architectures, such a system is bound to have a fair amount of error propagation, where errors in labeling the acts or subacts affect the performance of mode labeling. Therefore, we propose a novel joint inference method for this task where we label modes jointly with dialogue acts and subacts, thereby taking advantage of the inter-dependencies between them. Prior approaches in the ITS research community have largely focused on dialogue act classification (Marineau et al., 2000; Serafin and Di Eugenio, 2004; Moldovan et al., 2011) or on mode labeling given labeled dialogue acts (Cade et al., 2008; Boyer et al., 2010; Rus et al., 2015) . To the best of our knowledge, our work is the first joint inference method for this task. We develop our joint inference system using a modeling language called Markov Logic Networks (MLNs) (Domingos and Lowd, 2009) . MLNs are a powerful representation, where uncertain domainknowledge is encoded as first-order formulas with weights attached to each formula. The weights in an MLN model indicate the uncertainty associated with the formulas. The larger the weight, the more confidence we have in the formula being true. Over the last few years, MLNs have been routinely used for several joint inference tasks in entity resolution (Poon and Domingos, 2008) , event extraction (Poon and Vanderwende, 2010; Venugopal et al., 2014) and question answering (Khot et al., 2015) . The main advantage of MLNs is that it can represent a large, complex probabilistic model through a highly compact, lifted representation specified through first-order formulas. However, at the same time, the compact representation makes scaling up probabilistic inference and learning a huge challenge in MLNs (Domingos and Lowd, 2009; Poon and Domingos, 2007) . More specifically, in our task, the Markov network underlying the MLN turns out to be extremely large with millions of nodes and edges. By systematically exploiting the structure of our MLN model, we scale up MLN learning and inference methods for our task. We evaluate our joint inference model on a dataset of human annotated dialogue transcripts of 500 students with around 32,000 dialogue utterances. To compare against our approach, we build a baseline, pipeline system using Support Vector Machines where we treat utterances as independent instances and sequentially label dialogue acts, subacts and modes in this dataset. We then compare our joint inference model with the baseline and obtain nearly a 6 point increase in F1-score for mode labeling with both higher recall and higher precision, clearly showing the promise of our joint inference approach. The rest of this paper is organized as follows. We first present related work and give a brief overview of MLNs. We then present our joint inference model using MLNs and finally conclude with our evaluation. Related Work Speech-act theory that was developed in in the 1960's (Austin, 1962; Searle, 1969) has been typically used to model speakers' intentions. According to speech-act theory, when we say something, we do something. There are three levels of speech: the locutionary level which is the actual utterance, the illocutionary level which is the intention behind the utterance and perlocutionary level which is the effect of the utterance. Speech acts model the illocutionary level and denote speech acts such as greeting (Hello), questioning (how is the weather?), etc. A speech act could be described as the sum of the illocutionary forces carried by an utterance (Moldovan et al., 2011) . It is worth mentioning that within one utterance, speech acts can be hierarchical, hence the existence of a division between direct and indirect speech acts, the latter being those by which one says more than what is literally said, in other words, the deeper level of intentional meaning. In the phrase, Would you mind passing me the salt?, the direct speech act is the request best described by Are you willing to do that for me? while the indirect speech act is the request I need you to give me the salt. In a similar way, in the phrase, Bill and Wendy lost a lot of weight with a diet and daily exercise. the direct speech act is the actual statement of what happened, i.e., They achieved \"this\" by doing \"that\", while the indirect speech act could be the encouraging, If you do the same, you could lose a lot of weight too. The present study assumes there is one direct speech act per utterance. The task of classifying direct speech acts has been well-studied in the general context (Reithinger, 1995; Stolcke et al., 2000; Reithinger and Maier, 1995; Ries, 1999; Moldovan et al., 2011) as well as in the specific context of ITS (Marineau et al., 2000; Serafin and Di Eugenio, 2004; Samei et al., 2014) . A related problem of generating the next speech act in a dialogue has also been investigated to some extent (Reithinger, 1995; Bangalore and Stent, 2009) . Also, there is work on automatically discovering dialogue acts using data-driven approaches (Moldovan et al., 2011) but it is beyond the scope of this paper to automatically discover the dialogue acts in our tutoring sessions. In the automated speech act classification literature, typically researchers have considered rich feature sets extracted from the utterances such as the actual words (possibly lemmatized or stemmed) and ngrams (sequences of consecutive words) to characterize the type of speech act. Dialogue modes in tutorial dialogues are sequences of dialogue acts that correspond to general conversational segments of a dialogue, e.g. an Opening mode corresponds to the first phase of the dialogue when the conversational partners greet each other, or to segments associated with pedagogical goals, e.g. a Scaffolding mode would correspond to the tutorial dialogue segment when the student works on something and the tutor scaffolds the learners activity. Compared to speech act classification, mode identification has been far less studied. Based on a manual analysis, Cade et al. (Cade et al., 2008 ) defined a set of eight mutually exclusive tutorial modes: introduction, lecture, highlighting, modeling, scaffolding, fading, off-topic, and conclusion. An interesting aspect of their analysis is the granularity at which they defined the pedagogically important modes. In their approach, the modes correspond to either the tutor or the student or both focusing on solving a full problem. In our approach, we used a different definition of modes proposed by Morrison et al. (Morrison et al., 2014) . In this approach, a tutor or student could switch between proposed modes while working on a particular problem. That is, a particular mode is not associated with one problem solving task but rather with parts of such a problem solving task. Finally, Boyer et al. (Boyer et al., 2010) used acts in conjunction with more specific task actions, e.g., opening a specific file, etc., to discover hidden modes using a HMM. In contrast, we assume a pre-defined set of modes (see next section) that generalize across tutors and identify modes and acts jointly. This is similar to the Conditional Random Fields (CRF) approach proposed by Rus and colleagues (Rus et al., 2015) who used a expert-defined set of modes. It should be noted that Rus and colleagues report a best dialogue mode labeling performance of accuracy=57.18% when they used gold, i.e. human-labeled, dialogue acts as input. The accuracy dropped to 28.77% when automatically labeled dialogue acts were provided as input to the CRF-based dialogue mode labeling system. It should be noted that our results reported here are not exactly comparable to the ones reported by Rus and colleagues as they used a different, albeit related, human-labeled dataset to train and test their system. Background In this section, we give a brief overview of MLNs and describe the dataset used in this paper. Markov Logic Networks Markov logic networks (MLNs) unify first-order logic with Markov networks (undirected probabilistic graphical models abbreviated as PGMs). Formally, an MLN consists of a set of weighted first-order formulas, {(f i ; w i )} K i=1 , where f i is a first-order formula and w i is a real-valued weight attached to f i . The weight w i quantifies the uncertainty in f i . Higher the weight of a formula, the more belief we have that the formula is true. If the weight w i is \u221e, then it acts as a hard constraint that f i should always be true, while a weight \u2212\u221e specifies the hard constraint that f i should always be false. MLNs assume Herbrand semantics, i.e., there is a finite number of objects that can be substituted for the variables in the first-order formulas. This set of real-world objects is referred to as the domain. Throughout this paper, we specify constants with capital letters (e.g., A, B, etc.) and variables in the formulas with small letters (e.g., x, y, etc.) A ground atom in the MLN is a first-order predicate where all variables are grounded with constants from the domain. Similarly, a ground formula is an instantiation of a first-order formula, where all variables have been grounded with constants from the domain. Given a domain of interest, MLNs specify a Markov network where a ground atom (a first-order predicate where all variables are grounded with constants) is a binary variable in the network and each ground formula (a first-order formula grounded with constants) is a function over the variables specific to that formula. For example, assume that the domain for the MLN, Smokes(x) \u21d2 Cancer(x); w, is equal to {A, B}. Then, Smokes(A) is a ground atom in the MLN which represents a binary random variable in the Markov network. Similarly, Smokes(A) \u21d2 Cancer(A) represents a function in the Markov network defined over the binary variables corresponding to Smokes(A) and Cancer(A). An assignment (either 0 or 1) to all possible ground atoms in the MLN, Smokes(A), Smokes(B), Cancer(A), Cancer(B), is called a world. The MLN describes a log-linear model where the probability distribution is defined over the set of possible worlds. Specifically, the probability distribution represented by the MLN is given by, Pr(\u03c9) = 1 Z exp i w i N i (\u03c9) (1) where N i (\u03c9) is the number of groundings of the first order formula f i that evaluate to True given a world \u03c9. Since MLNs are simply a compact representation of PGMs, all inference tasks in PGMs are also applicable to MLNs. Specifically, the two main inference tasks for MLNs are, 1) Marginal inference, and 2) MAP inference. In marginal inference, given evidence atoms, i.e., ground atoms whose truth value is known/observed, the task is to compute marginal probabilities over other query atoms. For example, say we are given evidence atoms Smokes(A) and Smokes(B), the task is to compute probabilities such as P (Cancer(A)|Smokes(A), Smokes(B)). In MAP inference, given evidence, we compute the assignment to the non-evidence atoms such that the probability of that assignment is maximized. For instance, given evidence Smokes(A) and Smokes(B), we need to compute the assignment to Cancer(A), Cancer(B) for which the probability is maximum in the joint distribution. Both marginal inference and MAP inference are computationally intractable and therefore typically approximate algorithms are used for both these tasks. Dataset Our dataset consists of dialogue transcripts of 500 tutoring sessions collected from 500 students working on elementary algebra and physics problems. In all, there are 32,368 individual utterances in these tutorial sessions, where we define an utterance as a single dialogue turn by either the student or the tutor. We selected this data from a sample of sessions obtained from an online, commercial tutoring service. These sessions are about problem solving in the context of various Algebra and Physics topics. These are student-initiated sessions, mostly in the context of homework help. We label each utterance with a predefined set of dialogue acts. The dialogue act taxonomy was developed with the assistance of subject matter experts, all experienced tutors and tutor mentors working for an online commercial tutoring service, resulting in a fine-grained 2-level hierarchical taxonomy that includes 17 main act categories. Each main dialog act category consists, in turn, of different subcategories, which we refer to as subacts, resulting in an overall taxonomy of 196 distinct dialog act-subact combinations. The size of the dialogue-act and -subact taxonomy is at least one order of magnitude larger than taxonomies proposed and used by others such as Boyer and colleagues (Boyer et al., 2010) . It should be noted that the dialog acts were defined and refined to minimize overlap between categories and maximize the coverage of distinct acts. There were a set of 17 dialogue modes defined by the experts and each utterance was annotated with the act, subact and the dialogue mode for the utterance by humans. The data was manually annotated by a group of tutoring experts who were trained on both the dialogue act taxonomy and set of dialogue modes. When annotating independently, the inter-annotator agreement was 80.91% and kappa statistic was 0.77 for dialogue acts and 64.90% and kappa of 0.63 for dialogue acts and subacts together. These values correspond to very good agreement among the annotators. For modes, the agreement was lower at 55.03% and kappa of 0.47. The list of modes and the number of times they occur in our labeled data set is shown below. Opening(667), Problem Identification (3177), Assessment (338), Method Identification (126), Method Roadmap (1056), Rapport Building (1006), Process Negotiation (3281), MetaCognition (533), Sensemaking (2889), Fading (2466), Scaffolding (4574), Modeling (1159), Telling (1806), Session (8), ITSupport (1251), WrapUp/Close (871), and Off-topic (4). MLN Model Here, we describe our joint inference model for identifying dialogue modes based on MLNs. We first describe the set of first-order formulas of the joint model. We then discuss how we perform joint inference and learning scalably in our model. MLN Formulas The four main predicates in our MLN are: Act, Subact, Mode and ModeSwitch. We next describe each of these predicates. Act(s, t, a!) is a predicate that asserts that the dialogue act in the tutorial session corresponding to student s, at time step t, is equal to a. When defining our MLN, we refer to \"time\" as the utterance number in a dialogue session between the tutor and student. The \"!\" mark is a special symbol in the MLN language that specifies a hard constraint that for every grounding of s and t, there is exactly one act label. That is, every utterance corresponds to one and only one dialogue act. Similarly, Subact(s, t, u!) asserts that the dialogue subact in the tutorial session for student s at time t is equal to u. Mode(s, t, m!) asserts that the dialogue mode in the tutorial session for student s at time t is equal to m. Finally, ModeSwitch(s, t) asserts that there was a switch in dialogue mode at time t for the tutoring session associated with student s. That is, the mode in the previous time step was different from the mode in the current time step. Since our interest in this task is mode identification, Mode is called as a query predicate and the inference task is to collectively set a 0/1 truth assignment to all groundings of this predicate. Act, Subact and ModeSwitch are called hidden predicates since the truth assignments of their groundings are unknown. Using the above predicates, we define the following formulas. Unless specified, all variables in the below described formulas are assumed to be universally quantified. 1. The first set of hard formulas specify that each act maps to a specific subset of subacts. This formula encodes the two-level hierarchy that we define in our taxonomy. We specify this by implication formulas of the form, Act(s, t, A) \u21d4 Subact(s, t, U 1 ) \u2228 . . . Subact(s, t, U k ) where U 1 . . . U k are possible subacts corresponding to act A. 2. Next, we define hard formulas that encode the rule of mode switching. That is, we specify that mode-switching causes a shift in the dialogue mode using two implications. ModeSwitch(s, t) \u2227 Mode(s, t \u2212 1, m) \u21d2 \u00acMode(s, t, m) \u00acModeSwitch(s, t) \u2227 Mode(s, t \u2212 1, m) \u21d2 Mode(s, t, m) 3. The first and last modes of a dialogue are always fixed. We specify this with a conjunctive hard formula, Mode(s, T 0 , Opening) \u2227 Mode(s, T k , Closing) where T 0 is the first utterance in the dialogue and T k is the last utterance in the dialogue. 4. We encode the inter-dependency between modes, acts and subacts with a set of soft formulas. Specifically, we model this interaction by encoding a formula that connects two successive time-steps of a dialogue. The resulting formulation is similar to encoding Hidden Markov Models using MLNs, where we assert that the dialogue mode at time-step t is influenced by the acts, modes and subacts at the previous time-step. Clearly, this is a formula which would not hold true for all possible instantiations. Therefore, we specify a soft formula of the form, Mode(s, t \u2212 1, +m 1 ) \u2227 Act(s, t \u2212 1, +a) \u2227 Subact(s, t \u2212 1, +u) \u21d2 Mode(s, t, +m 2 ) An important aspect to note about the above soft formula is the \"+\" sign for variables in the formula. The \"+\" sign is a special symbol in MLNs that allows us to define multiple weights for a single formula. Recall that in MLNs, generally, all the groundings of a first-order formula share the exact same weight. However, in several practical cases, we need to decrease the bias of the model by introducing more parameters for it. With the use of a \"+\" sign, we can increase the total number of weights in the MLN and thus induce more complex distributions. Specifically, we can set a different weight for each partially ground formula obtained by grounding all variables in the formula corresponding to the + symbol. For instance, in this case, for each possible grounding of the variables m 1 , m 2 , u and a in the formula, we will define a distinct weight. This allows us more degrees of freedom to model the data rather than using a single weight for the formula. 5. Next, we define several soft formulas that connect features of the dialogue utterances to Mode, Act, Subact and ModeSwitch. Let Feature 1 . . . Feature N denote N features extracted from the utterances (we discuss the actual features in the next section), then, we encode these features using soft formulas of the form, Feature 1 (s, t, +f 1 ) \u2227 Feature 2 (s, t, +f 2 ) . . . Feature N (s, t, +f N ) \u21d2 Mode(s, t, +m) Feature 1 (s, t, +f 1 ) \u2227 Feature 2 (s, t, +f 2 ) . . . Feature N (s, t, +f N ) \u21d2 ModeSwitch(s, t) Feature 1 (s, t, +f 1 ) \u2227 Feature 2 (s, t, +f 2 ) . . . Feature N (s, t, +f N ) \u21d2 Act(s, t, +a) Feature 1 (s, t, +f 1 ) \u2227 Feature 2 (s, t, +f 2 ) . . . Feature N (s, t, +f N ) \u21d2 Subact(s, t, +u) Joint Inference Given the MLN specified in the previous section, the inference task is to jointly compute an assignment to all possible groundings of the query predicate, Mode. Specifically, we compute this assignment as a solution to the following optimization problem max \u03c9 h\u2208H P (Q = \u03c9 ) (2) where H is the set ground atoms of hidden predicates and Q is the set of ground atoms of query predicates, \u03c9 is an assignment on all atoms in Q. However, Eq. ( 2 ) which is an instance of the marginal-MAP (MMAP) inference problem involves both summation (summing out the hidden variables) and maximization, and is well-known to be a very hard problem (Park and Darwiche, 2004) . Instead, we approximate the solution to the MMAP problem with a solution to the following Max a-posteriori (MAP) inference problem which only involves maximization. max \u03c9 P (Q \u222a H = \u03c9) (3) where \u03c9 is an assignment on all atoms in Q \u222a H. To obtain an approximate MMAP assignment for only the atoms in Q, we simply project the complete solution obtained from the MAP problem in Eq. ( 3 ) on the atoms in Q. Note that even the MAP problem in Eq. ( 3 ) is NP-hard. However, several highly efficient off-the-shelf approximate MAP solvers can be used to obtain high-quality approximations. Notable examples include MaxWalkSAT (Kautz et al., 1997) , dual-decomposition based solvers (Sontag and Globerson, 2011) and ILP based solvers such as Gurobi (Gurobi., 2013) . In our experiments, we use Gurobi, a state-of-the-art ILP solver to compute the MAP solution for the MLN (Sarkhel et al., 2014) . However, it turns out that a naive application of approximate MAP solvers to our problem is still infeasible in practice. For instance, suppose we have 500 students' dialogues in our dataset, and each dialogue has on average 100 utterances/time-steps, then, the formula, ModeSwitch(s, t) \u2227 Mode(s, t \u2212 1, m) \u21d2 \u00ac Mode(s, t, m) itself has at least 1 million possible groundings. In other words, grounding the entire MLN and then applying MAP inference on the ground MLN quickly becomes infeasible. However, we notice that our MLN has a decomposable structure, i.e., the ground Markov network obtained by grounding the MLN with a single student's dialogue is independent of the ground Markov network obtained when we ground the MLN with the rest of students' dialogues. This means that we can decompose the MAP problem as, k max \u03c9 k P (Q k \u222a H k = \u03c9 k ) (4) where Q k and H k are the query and hidden atoms specific to the dialogues of student the k-th student and \u03c9 k is an assignment to all atoms in {Q k , H k }. Thus, using Eq. ( 4 ), we can essentially compute the MAP solution independently for each student dialogue using a standard MAP solver which greatly reduces the computational requirements of the solver and allows us to scale up joint inference over our large dataset of dialogues. Next, we describe weight-learning for the soft formulas in our MLN. Specifically, we use gradient ascent to compute weights of the soft formulas that maximize the log-likelihood of our dataset. Note that, our model contains hidden variables that are not observed directly, i.e., atoms corresponding to Act, Subact and ModeSwitch. Due to the presence of these hidden variables in our model, the resulting log-likelihood function is no longer convex. Therefore, gradient ascent can get struck in local optima. We reduce the severity of the problem using random restarts (Selman et al., 1996) . That is, we start gradient ascent from several different initialization points and average all the different weights that gradient ascent converges to when starting from these different initialization points. Note that in each step of gradient ascent, we need to compute the gradient as, E w [N i ] \u2212 E w [N i ] (5) where E w [N i ] is the expected number of groundings of the i-th soft formula that are true given the current set of weights w w.r.t the MLN distribution P (Q|H) and E w [N i ] is the expected number of groundings of the i-th soft formula that are true in the dataset w.r.t the MLN distribution P (Q). Both expectations are intractable to compute exactly. Therefore, we approximate these distributions with their respective MAP values. This means that, for each gradient ascent step, we run MAP inference twice and compute the approximate expectations and from the approximate expectations, we compute the approximate gradient direction. We continue updating the weights with the gradient until the weights converge. In order to reduce computation, we compute the weights only for a feasible set of groundings of the \"+\" variables in the soft formulas. For instance, consider soft formula 4 in the previous section. Here, the number of groundings of the \"+\" variables is equal to the product of |M odes| * |M odes| * |Acts| *  |Subacts|. However, the number of feasible combinations is much lower. That is, several combinations never occur in the training dataset and we assume that for all such cases, the weight is 0 (the likelihood that the formula is true/false is the same). We remove these cases from the set of ground formulas and compute weights only for the remaining set of feasible groundings. Learning Feature Based Formulas Unfortunately, the above weight learning procedure does not work very well to learn weights of the feature-based soft formulas (listed as 5. in the previous section). The number of weights that we need to learn corresponding to the feature-based formulas turns out to be extremely large. Specifically, grounding the \"+\" variables, we will have at least O(N * d * |M odes| * |Acts| * |Subacts|), where N is the number of features, d is an upper-bound on the number of possible feature-values for a feature. For lexical features of the utterances such as unigrams, bigrams, etc. this number is extremely large. Thus, weight-learning for the MLN that includes the feature-based soft formulas is infeasible in our model. Instead, we utilize the flexibility of MLNs to incorporate the feature-based soft formulas implicitly. Specifically, we remove all the feature-based formulas from the MLN and learn the MLN weights using only the other formulas. We then derive weights for the feature-based formulas through a separate model and add this back into the MLN as described next. We train an SVM-based pipeline system to label the acts, subacts, modes and mode-switches in sequence. That is, we use SV M multiclass to first label the acts. Using the labeled acts, we label the subacts, and using both the labeled acts and subacts, we label the modes. We detect mode-switches using a binary SVM classifier. The features used in each of these models are shown in Table 2 . The SVM-based pipeline system yields confidence values in the form of hyper-plane distances for each dialogue utterance for every mode, act, subact and also whether a mode switch occurred. Specifically, given an utterance t for student s, we will have hyper-plane distances for Act(s,t,+a), Subact(s,t,+u), Mode(s,t,+m) and ModeSwitch(s,t) (Note that, these are the atoms in the RHS of the soft formulas specified in 5). We then add to the MLN, a unit clause corresponding to the RHS of each soft formula, with the weight of the unit clause given by the SVM confidence value, which we normalize into the range [\u22121, 1]. Thus, if the SVM classifier is confident that an utterance number t for student s has mode type M , it will output a large confidence value for the type M label, which in turn is encoded into the MLN as the formula Mode(s,t,M ) with a large weight. This will then make it more likely that the atom Mode(s,t,M ) will be set as true when computing the MAP solution for the overall joint model. Experiments This section presents the details of our experimental setup and the results obtained. As already mentioned, we compared a pipeline approach with the MLN joint-inference approach. Setup We evaluate the performance of our joint model by comparing it with the SVM based pipeline system which uses the features outlined in Table 2 . This system is similar to the one presented in Rus et al. (Rus et al., 2015) who used a related, but not identical dataset, except that Rus et al. use Conditional Random Fields to label the modes, while, here we use SVMs. The performance of Rus et al.'s mode identification system that uses the labels of acts and subacts that were detected using a supervised classifier, is similar to ones we present here. For our joint model, we use Gurobi, a state-of-the-art ILP solver, to solve the MAP inference problem. That is, we ground the MLN with dialogue data from each student independently and solve the MAP problem for each such partially ground MLN independently using Gurobi. Note that this problem is embarrassingly parallel since each MAP solution can be computed independently of the others. Using this, we could run a single instance of MAP inference over the entire dataset in just a few minutes using a cluster of 5 8-core machines, each with 8GB RAM. Results Table 3 shows a comparison of the F1-scores, precision and recall obtained by running 5-fold cross validation. The scores are reported for simple average of the scores (average over all mode labels) and for the weighted average (average weighted by instances of a particular label). As seen here, the joint method clearly outperforms the pipeline method in every case, in terms of F1-score, precision and recall. The average F1-score we obtained using the joint method was nearly 6 points higher than the average F1-score obtained using the pipeline SVM classifier. Particularly, both precision and recall of mode identification improved over both metrics. Next, we evaluated statistical significance of our results. Specifically, we ran 5-fold paired t-tests (cf. (Dietterich, 1998) ) to determine if our results were significant. Our results showed that our results attained statistical significance at p \u2264 0.05, i.e., we obtained t = 3.75 with p = 0.009. In our next experiment, we evaluated the performance of our model on hidden predicates. Specifically, Table 4 shows a comparison of how well the systems perform in terms of labeling the hidden ground atoms (ground atoms of the Act and Subact predicates). Since joint inference takes advantage of inter-dependencies between modes, acts and subacts, the accuracy of labeling the hidden variables is also better in the joint model as compared to the pipeline SVM classifier. The improvement in act and subact labeling was slightly smaller than the improvement we got for our main task of mode labeling. However, as shown in Table 4 , here again, we observed significant improvements in both precision and recall as compared to the pipeline system. In our final experiment, we compared results over key pedagogical steps to evaluate the effect of joint inference in these steps. These results are shown in Table 5 . The mode names are quite self-explanatory for Rapport Building, Problem Identification and Assessment. Scaffolding is a concept where the tutor scaffolds the learner who is working through the solution by giving hints. Sense Making is the concept of explanations for understanding purposes. Process Negotiation is discussing/confirming the process of how to go about solving the problem. As we see from the results, in most cases, the joint model is significantly better than the pipeline system. Particularly, in some cases such as Scaffolding, which is an important step that corrects learners when they are going in the wrong direction, there was nearly a 20 percent increase in recall. As such, in almost all modes, we observed improvements in both precision and recall, which clearly illustrates the benefit of our joint model. Conclusion In this paper, we presented a novel joint inference method to detect modes in human-to-human tutoring. Specifically, modes are high level abstractions of dialogue speech acts, which give us a much deeper understanding of the underlying process by which natural language tutoring occurs. This is an important sub-step in designing Intelligent Tutoring Systems since strategies taken by expert human tutors can be adapted to AI-based tutors. In this work, we exploited inter-dependencies between lower-level dialogue acts and the higher-level modes using joint inference. Specifically, we developed a Markov Logic Network (MLN) to encode the the joint dependencies between dialogue acts, subacts and modes using weighted first-order logic formulas. We then developed a scalable MAP inference strategy for our model by partially grounding the MLN in each inference sub-step instead of pre-grounding the full MLN. We demonstrated the effectiveness of our approach on a real-world dialogue-based tutoring dataset collected from 500 students and annotated by multiple expert tutors. We showed that our MLN-based joint model outperforms a pipeline model that we built using SVMs that detects modes, acts and subacts independently of each other. Future work includes mode detection without pre-specifying the dialogue acts and modes, i.e., automatically induce the dialogue acts and modes in the dialogue using non-parametric unsupervised machine learning methods. We will also apply joint inference to other complex sub-problems in Intelligent Tutoring Systems such as semantic similarity matching, automatically generate the best subsequent tutoring strategies, and generating hints to a student based on student response. We will also explore utilizing advanced lifted inference methods (Venugopal and Gogate, 2012; Venugopal and Gogate, 2014) in tutoring systems. This work makes substantial contributions towards discovering effective tutorial strategies using datadriven approaches which in turn will contribute to the development of effective intelligent tutoring systems that could provide affordable, effective, one-on-one instruction to any learner of any age, anytime (24/7), anyhwhere as long as an Internet-connected device is available. The impact of such effective educational technologies will be far-reaching. Acknowledgements The authors would like to thank the University of Memphis for partially supporting this work. This work was also partially supported by a contract from the Advanced Distributed Learning Initiative of the United States Department of Defense (Award W911QY-15-C-0070). The authors would also like to thank the anonymous reviewers for their inputs.",
    "abstract": "Identifying dialogue acts and dialogue modes during tutorial interactions is an extremely crucial sub-step in understanding patterns of effective tutor-tutee interactions. In this work, we develop a novel joint inference method that labels each utterance in a tutoring dialogue session with a dialogue act and a specific mode from a set of pre-defined dialogue acts and modes, respectively. Specifically, we develop our joint model using Markov Logic Networks (MLNs), a framework that combines first-order logic with probabilities, and is thus capable of representing complex, uncertain knowledge. We define first-order formulas in our MLN that encode the inter-dependencies between dialogue modes and more fine-grained dialogue actions. We then use a joint inference to jointly label the modes as well as the dialogue acts in an utterance. We compare our system against a pipeline system based on SVMs on a real-world dataset with tutoring sessions of over 500 students. Our results show that the joint inference system is far more effective than the pipeline system in mode detection, and improves over the performance of the pipeline system by about 6 points in F1 score. The joint inference system also performs much better than the pipeline system in the context of labeling modes that highlight important pedagogical steps in tutoring.",
    "countries": [
        "United States"
    ],
    "languages": [
        ""
    ],
    "numcitedby": "3",
    "year": "2016",
    "month": "December",
    "title": "Joint Inference for Mode Identification in Tutorial Dialogues"
}