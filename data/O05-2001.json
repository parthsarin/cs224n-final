{
    "article": "This article investigates the use of several lightly supervised and data-driven approaches to Mandarin broadcast news transcription. With the special structural properties of the Chinese language taken into consideration, a fast acoustic look-ahead technique for estimating the unexplored part of a speech utterance is integrated into lexical tree search to improve search efficiency. This technique is used in conjunction with the conventional language model look-ahead technique. Then, a verification-based method for automatic acoustic training data acquisition is proposed to make use of large amounts of untranscribed speech data. Finally, two alternative strategies for language model adaptation are studied with the goal of achieving accurate language model estimation. With the above approaches, the overall system was found in experiments to yield an 11.88% character error rate when applied to Mandarin broadcast news collected in Taiwan. Introduction With the continuing growth of the amount of multimedia information accessible over the Internet, large volumes of real-world speech information, such as that in broadcast radio and television programs, digital libraries, and so on, are now being accumulated and made available to the public. Substantial efforts and very encouraging results for broadcast news transcription, retrieval, and summarization have been reported [Woodland 2002; Gauvain et al. 2002; Beyerlein et al. 2002; Chen et al. 2002; Chang et al. 2002; Meng et al. 2004; Furui et al. 2004] . However, in order to obtain better recognition performance, most of the transcription systems require not only large amounts of manually transcribed speech materials for acoustic training in the data preparation phase, but also much time and memory in the recognition phase. Moreover, because the subject domains and lexical regularities of the linguistic contents of news articles are very diverse and often change with time, it is extremely difficult to build well-estimated language models for speech recognition. Hence, in the recent past, several attempts have been made to investigate the possibility of achieving automatic acquisition of speech or language training data for system refinement or for rapid prototyping of a new recognition system to new domains, and very encouraging results have been obtained [Kemp and Waibel 1999; Wessel and Ney 2001; Macherey and Ney 2002; Bacchiani 2003 ]. On the other hand, quite a few studies have also explored ways to improve recognition efficiency, and many good approaches have been proposed [Schuster 2000; Aubert 2002; Evermann and Woodland 2003] . In this paper, several lightly supervised and data-driven approaches to Mandarin broadcast news transcription are presented. First, considering the special structural properties of the Chinese language, a fast acoustic look-ahead technique that employs syllable-level heuristics is integrated into lexical tree search to improve search efficiency. It is used in conjunction with the conventional language model look-ahead technique [Ortmanns and Ney 2000] . Then, a verification-based method for automatic acoustic training data acquisition is proposed to make use of large speech corpora. Finally, two alternative strategies for language model adaptation are studied with the goal of achieving accurate language model estimation. The remainder of this paper is organized as follows. In section 2, we review the major constituents of our broadcast news system and introduce the experimental speech and language data used in this research. The acoustic look-ahead technique using syllable-level heuristics is presented in section 3, while the lightly supervised acoustic model training and language model adaptation approaches are described in sections 4 and 5, respectively. Then, the results of a series of speech recognition experiments are discussed in section 6. Finally, conclusions are drawn in section 7. The NTNU Broadcast News System The major constituent parts of the broadcast news system developed at National Taiwan Normal University (NTNU) as well as the speech and language data used in this paper will be described in this section [Chen et al. 2004] . Figure 1 depicts the overall framework of the broadcast news system. Front-End Processing Front-end processing is conducted with two feature extraction approaches: the conventional MFCC-based (Mel-frequency Cepstral Coefficients) [Davis and Mermelstein 1980] and the data-driven LDA-based (Linear Discriminant Analysis) [Duda and Hart 1973] approaches. In the case of the MFCC-based approach, 13-dimensional cepstral coefficients derived from 18 Mandarin Broadcast News Transcription filter bank outputs are incorporated along with their first-and second-order time derivatives. As for the LDA-based approach, the states of each HMM (Hidden Markov Model) are taken as the units for class assignment. Either the outputs of filter banks or the cepstral coefficients are chosen as the basic vectors. The basic vectors from every nine successive speech frames are spliced together to form supervectors for constructing the LDA transformation matrix, which is then used to project the supervectors to a lower feature space. The dimension of the resultant vectors is set to 39, which is just the same as that used in the MFCC-based approach. Finally, in both the MFCC-and LDA-based feature extraction approaches, utterance-based cepstral mean subtraction and variance normalization are applied. Speech Corpus and Acoustic Modeling The speech data set consists of about 112 hours of FM radio broadcast news, which was collected from several radio stations located in Taipei during 1998-2002 using a wizard FM radio connected to a PC and digitized at a sampling rate of 16 kHz with 16-bit resolution [Chen et al. 2002] . All the speech materials were manually segmented into separate stories, each of which is a news abstract spoken by one anchor speaker. Some of these stories contain background noise and music. For 7.7 hours of speech data, we have corresponding orthographic transcripts. About 4.0 hours of this data collected from 1998 to 1999 was used to bootstrap the acoustic training, and the other 3.7 hours of data collected in September 2002 was used for testing. The remaining 104.3 hours of untranscribed speech data was reserved for lightly supervised acoustic model training, which will be described in more detail in section 4. Lexicon, Text Corpus and Language Modeling In the Chinese language, each character (at least 7,000 characters are commonly used) is pronounced as a monosyllable and is a morpheme with its own meaning. New words are very easily generated by combining a few characters but nevertheless are tokenized into several single-character words or words with fewer characters when the text corpus is processed for language model training. This definitely makes the out-of-vocabulary problem especially serious in the case of Mandarin broadcast news transcription. In order to alleviate the degradation of speech recognition accuracy caused by the out-of-vocabulary problem, compound words must be carefully selected and added to the lexicon according to their statistical properties in the corpus. Hence, we explored the use of the geometrical average of the forward and backward bigrams of any word pair ) , ( j i w w occurring in the corpus for compound word selection [Saon and Padmanabhan 2001; Wang et al. 2002 = = = + + (3) We started with a lexicon composed of 67K words and iteratively used the above measures with varying thresholds to find all possible word pairs which could be merged together. Eventually, a set of about 5K compound words was added to the lexicon to form a new lexicon of 72K words. The n-gram language modeling approach was adopted in the study; thus, the background language models consisted of word-based trigram and bigram models, which were estimated using a text corpus consisting of 170 million Chinese characters collected from Central News Agency (CNA) in 2000 and 2001 (the Chinese Gigaword Corpus released by LDC [LDC 2003] ). On the other hand, a corpus consisting of 50 million Chinese characters in newswire texts collected from the Internet from August to October 2002 [Chang et al. 2003] Mandarin Broadcast News Transcription was used as a contemporary corpus for language model adaptation. The language models were trained with Kneser-Ney backoff smoothing [Kneser and Ney 1995] using the SRI Language Modeling Toolkit (SRILM) [Stolcke 2000 ]. Speech Recognition Our baseline recognizer was implemented with left-to-right frame-synchronous tree search as well as lexical prefix tree organization of the lexicon [Aubert 2002; Beyerlein et al. 2002; Woodland 2002] . Each tree arc (or phonetic arc) in the lexical tree corresponded to the HMM for an INITIAL or FINAL in Mandarin Chinese, and each tree leaf denoted a word boundary for words sharing the same pronunciation. At each speech frame, the so-called word-conditioned method was used to group the path hypotheses that shared the same history of predecessor words (or more precisely, the same search history of n-1 predecessor words for n-gram language modeling) into identical copies of the lexical tree, and they were then expanded and recombined according to the tree structure until a possible next word ending was reached. At word boundaries, the path hypotheses among the tree copies that had equivalent search histories (the same last n-1 words) were recombined and then propagated into the existing tree copies or used to start new ones if none existed. Note that these tree copies were built according to a conceptual view. During the search process, only one lexical tree structure was built for reference purposes, and all path hypotheses were stored in a list structure instead. These path hypotheses were accessed by means of four-dimensional coordinates, each of which represented the history of n-1 predecessor words, the tree arc in the lexical tree, the HMM state, and the speech frame, respectively. At each speech frame, a beam pruning technique, which considered the decoding scores of path hypotheses together with their corresponding language model look-ahead scores, was used to select the most promising path hypotheses. Language model look-ahead was adopted because the search structure was implemented with a lexical prefix tree and the current word identity of a particular path hypothesis could not be determined until it reached a tree leaf. In addition, language model look-ahead has the merit of early application of language model constraints, which can help guide the search process. In this research, unigram language model look-ahead was adopted. The unigram language model look-ahead score for a tree arc was defined as the maximum unigram probability over all the words that could be reached via this specific arc, which could be easily calculated and stored beforehand. Therefore, for a path hypothesis ending at speech frame t , which had a search history h and stayed at tree arc k and HMM state q , its corresponding decoding score, ( ) q k s arc h t D , , , , could be modified via the following equation: ( ) ( ) ( ), log , , , log , , , log 2 1 k LM q k q k arc L m s arc h t D m s arc h t D \u22c5 + \u22c5 = (4) where ( ) k LM arc L is the unigram language model look-ahead score for tree arc k (notice that the HMM states within the same tree arc share the same language model look-ahead score), and ( ) q k s arc h t D , , , \u02c6 is the modified decoding score. m 1 and m 2 are the weighting parameters, which were set to 1 and 8, respectively, in this research. During beam pruning, we first computed the modified decoding score of the best path hypothesis at each speech frame t : ( ) ( ) . , , , log max log , , max q k q k h s arc h t D t D = (5) Then, an unpromising path hypothesis was pruned if the logarithm of its modified decoding score, ( ) q k s arc h t D , , , log , was lower than a predefined threshold: ( ) ( ) , log log , , , log max Thr q k f t D s arc h t D \u2212 < (6) where Thr f is an empirically set pruning factor. Moreover, if the word hypotheses ending at each speech frame had scores that were higher than the predefined threshold, their associated decoding information, such as the word start and end speech frames, the identities of current and predecessor words, and the acoustic score, were kept in order to build a word graph for further language model rescoring [Ortmanns et al. 1997 ]. Once the word graph had been built, as illustrated in Figure 2 , forward-backward search with a more sophisticated language model was conducted to generate the most likely word sequence. In this study, the bigram language model was used in the tree search procedure, while the trigram language model was used in the word graph rescoring procedure. Acoustic Look-Ahead Using Syllable-level Heuristics In a baseline recognizer, language model look-ahead and beam pruning techniques can be incorporated together to help retain the most promising path hypotheses for further expansion. Mandarin Broadcast News Transcription However, the crucial problem with such an approach is that it does not consider the potential likelihood of the unexplored portion of a speech utterance when beam pruning is applied. Thus, many unpromising path hypotheses and ambiguities will unavoidably be included during the search process. Therefore, the search efficiency may be degraded, since a large number of path hypotheses will have to be examined at each speech frame. On the other hand, the Chinese language is well known for its monosyllabic structure, in which each Chinese word is composed of one or more syllables (or characters); thus, syllables are the very important constituent units of Chinese words [Lee 1997; Chen et al. 2002; Meng et al. 2004 ]. In addition, Mandarin Chinese is phonologically compact; an inventory of about 400 base syllables provides full phonological coverage of Mandarin audio data if the tonal information is further ignored. This implies that syllable recognition will be much faster than word recognition. Thus, in this study, we utilized syllable-level heuristics to enhance search efficiency. A compact syllable lattice based on the structural information of words in the lexicon was automatically built and used to estimate the likelihood of the unexplored portion of a speech utterance. Each HMM state in the syllable lattice could be easily related to its corresponding HMM states in the lexical tree, and the relation between them was a one-to-many mapping. In the first pass, the syllable lattice was calculated in a right-to-left time-synchronous manner, and at each speech frame, the acoustic scores for the HMM states in the lattice were stored and taken as the likelihood estimation for acoustic look-ahead. In the second pass, frame-synchronous tree search was performed by incorporating the language model look-ahead scores together with the acoustic look-ahead scores for beam pruning: ( ) ( ) ( ) ( ), , , log log , , , log , , , log 3 2 1 q k AC k LM q k q k s arc t L m arc L m s arc h t D m s arc h t D \u22c5 \u2032 + \u22c5 \u2032 + \u22c5 \u2032 = (7) where ( ) q k AC s arc t L , , is the acoustic look-ahead score, and 1 m\u2032 , 2 m\u2032 and 3 m\u2032 are the weighting parameters, which were set to 1, 8 and 1, respectively, in this research. Though speech recognition was carried out in a two-pass mode, the time spent on calculating acoustic look-ahead scores was almost negligible. The word graph rescoring procedure also could be applied after the second-pass search. Lightly Supervised Acoustic Model Training The purpose of acoustic modeling is to provide a method to calculate the likelihood of a speech utterance occurring given a word sequence. In principle, a word sequence can be decomposed into a sequence of phone-like (subword, or INITIAL or FINAL in Mandarin Chinese) units, each of which is represented by an HMM, and the corresponding model parameters can be efficiently estimated from a corpus of orthographically transcribed training utterances using the Expectation-Maximum (EM) algorithm [Dempster et al. 1977] . Accordingly, in order to obtain acceptable performance in speech recognition, large amounts of manually transcribed speech data are inevitably required, especially when porting the system to new application domains. However, generating manually transcribed data is an expensive process in terms of both manpower and time. Based on this observation, we investigated here the lightly supervised acoustic model training approach for Mandarin broadcast news recognition. Unlike the previous approaches [Lamel et al. 2002; Nguyen and Xiang 2004] , which aligned closed-captions with automatic transcripts and kept only portions that agreed for acoustic training, in this study, we developed a verification-based method for automatic acoustic training data acquisition. The prototype system, initially trained with only 4 hours of manually transcribed speech corpus, was used to recognize the remaining more than one hundred hours of unannotated speech corpus, as described previously in section 2.2. For each candidate word segment generated by the forward-backward search in the word graph rescoring procedure, its associated word-level posterior probability as well as subword-level acoustic verification score, or more specifically, sub-syllable-level verification score, were incorporated together. The word-level posterior probability of a specific word segment w in the word graph with the start and end speech frames s t and e t , respectively, can be defined as [Wessel et al. 2001 ] , ) , ( ) , ( ) | ( 1 1 1 1 1 1 1 1 1 1 1 \u2211 \u2211 \u2211 \u22c5 \u22c5 = \u2212 + + \u2212 T s t T e t e e s s e s W T T T T t t t t T t t Post X W p X W w W p X w P W W (8) where T X 1 is the speech utterance X which starts at speech frame 1 and ends at speech frame T , and speech utterance T X 1 . On the other hand, the subword-level acoustic verification score of word segment w , which starts at speech frame s t and ends at speech frame e t , can be expressed as [Chen et al. 1998] ( ) ( ) [ ] , exp 1 2 1 ) ( 1 \u2211 + \u22c5 \u2212 + = = w e s N i w t t AV i Sub LLR N w Score \u03b7 \u03c4 (9) where w N is the number of subword (INITIAL or FINAL) units involved in the word segment w ; is the likelihood that 2 1 t t X will be generated by the corresponding top 1 subword unit, which acts here as the competing subword unit. From Equations ( 9 ) and ( 10 ), it is clear that the subword-level acoustic verification score for ( ) where c 1 and c 2 are weighting parameters, whose values were set here to be equal, that is, c 1 =c 2 =0.5. Thus, we can use the word confidence measure to locate the most probably correct words. As the word confidence thresholds were varied, different amounts of automatically transcribed data were accordingly selected and used in combination with the original 4-hour manually transcribed corpus to retrain different sets of acoustic models. The LDA transformation matrix employed in the feature extraction process needed to be reestimated, and the acoustic features were recalculated as well, according to the speech data selected for training. ( ) ( ) [ ] \u03b7 \u03c4 + \u22c5 \u2212 + i Sub LLR Language Model Adaptation Statistical language modeling, which aims to capture regularities in human natural language and quantify the acceptance of a given word sequence, has been a focus of active research in speech and language processing over the past two decades. The n-gram modeling (especially the bigram and trigram modeling) approach, which determines the probability of a word given the previous n-1 word history, has been widely used [Rosenfeld 2000; Goodman 2001; Bellegarda 2004 ]. The n-gram probabilities are usually computed based on either the maximum likelihood (ML) principle or the maximum entropy (ME) principle [Berger et al. 1996] . However, to tackle the inevitable data sparseness problems that occur when estimating the n-gram probabilities from a specific text corpus, a variety of smoothing or interpolation techniques have been proposed in the past several years [Chen and Goodman 1999; Chen and Rosenfeld 2000 ]. In addition, statistical language modeling was also introduced to information retrieval (IR) problems in the late 1990s, and research at a number of sites has confirmed that such a modeling paradigm does provide a theoretically attractive and potentially very effective probabilistic framework for building IR systems [Croft and Lafferty 2003; Liu and Croft 2005; Zhai and Lafferty 2004] . However, for complicated speech recognition tasks, such as broadcast news transcription, it is still extremely difficult to build well-estimated language models because the subject domains and lexical characteristics of the linguistic contents of news articles are very diverse and often change with time. Various approaches have been applied to adapt language models by making use of either the contemporary corpus [Federico and Bertoldi 2001] or the recognition hypotheses cached so far [Jelinek et al. 1991] . Two of the most widely-used approaches to language model adaptation are count merging and model interpolation, which can be viewed as maximum a posteriori (MAP) language model adaptation with different parameterizations of the prior distribution and can be easily integrated into the n-gram language modeling framework to capture the local regularities of word usage in the new task domain. The adaptation formulae (e.g., for trigram modeling) for count merging and model interpolation can be, respectively, written as ( ) ( ) ( ) ( ) ( ) , \u02c61 2 1 2 1 2 , 1 2 , 1 2 1 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u22c5 + \u22c5 \u22c5 + \u22c5 = i i Back i i Cont i i i Back d i i i Cont d i i i Adapt w w C w w C w w w C w w w C w w w P \u03b2 \u03b1 \u03b2 \u03b1 (12) and ( ) ( ) ( ) ( ) . 1 \u02c61 2 1 2 1 2 2 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u22c5 \u2212 + \u22c5 = i i i Back i i i Cont i i i Adapt w w w P w w w P w w w P \u03b3 \u03b3 (13) For the count merging formula in Equation ( 12 ), ( ) i i i Cont d w w w C 1 2 , \u2212 \u2212 and ( ) i i i Back d w w w C 1 2 , \u2212 \u2212 are, respectively, the discounted trigram counts [Chen and Goodman 1999 ] accumulated from the contemporary and background text corpora; ( ) 1 2 \u2212 \u2212 i i Cont w w C and ( ) 1 2 \u2212 \u2212 i i Back w w C are, respectively, the bigram counts accumulated from the contemporary and background text corpora; and \u03b1 and \u03b2 are tunable weighting parameters. For the model interpolation formula in Equation (13), ) ( 1 2 \u2212 \u2212 i i i Cont w w w P and ( ) 1 2 \u2212 \u2212 i i i Back w w w P are the trigram probabilities, respectively, estimated from the contemporary and background text corpora, and \u03b3 is a tunable weighting parameter. A more detailed derivation of Equations ( 12 )-( 13 ) also can be found in [Bacchiani and Roark 2003] . In this study, we investigated the use of the above two language model adaptation approaches for Mandarin broadcast news transcription. As mentioned earlier, a corpus of contemporary Internet newswire texts collected from August to October 2002 was used for additional prediction for the linguistic events of the testing broadcast news stories collected in September 2002. Experimental Results In this section, we will present a series of experiments performed to assess recognition performance as a function of the feature extraction approaches, the decoding methods, and the acoustic learning and language adaptation approaches. Mandarin Broadcast News Transcription The Baseline Results The baseline broadcast news system was alternatively configured using the conventional MFCC-based and data-driven LDA-based feature extraction approaches. The results are shown in rows 3 to 5 of Table 1 , where the third (MFCC) row lists the results obtained using MFCC-based approach, and the fourth (LDA-1) and fifth (LDA-2) rows list, respectively, the results obtained when different sets of basic vectors were adopted during the construction of the LDA transformation matrix. In LDA-1, the cepstral coefficients are taken as the basic vector, while in LDA-2, the outputs of filter banks as the basic vector. As can be seen in Table 1 , the character error rates obtained, respectively, using the two variant LDA-based approaches, after either tree search (TS) or word-graph rescoring (WG), were significantly better than those obtained using the standard MFCC-based approach. Moreover, LDA-2, which uses the filter bank outputs directly as the basic vector, was even more efficient than the MFCC-based approach due to the fact that the discrete cosine transform as well as the firstand second-order time derivative operations could be excluded from front-end processing. The LDA-2 features were, thus, chosen as the default acoustic features for the experiments described below. Experiments on Acoustic Look-Ahead Using Syllable-Level Heuristics The recognition performance and efficiency, after the acoustic look-ahead technique was integrated into the system, were evaluated. These results were obtained by using the same beam pruning threshold as that previously reported in section 6.1 and were run on an ordinary 2.6 GHz Pentium IV PC. The search efficiency results are shown in columns 2 to 6 of Table 2 , which list, respectively, the real time factors for feature extraction and HMM state emission probability calculation (FE), acoustic look-ahead (L AC ), tree search (TS), word-graph rescoring (WG), and the overall recognition time (Total), while the recognition accuracy results are shown in the last row of Table 1 . The numbers in the parentheses in the last row of Table 2 are the relative speedups achieved compared to the results shown in the second row. 1 , it can be found that the recognition accuracy was slightly degraded (e.g., the character error rate increased from 19.97% to 20.12% after word-graph rescoring) when acoustic look-ahead was used. However, according to the results shown in Table 2 , the recognition efficiency for tree search improved significantly (a relative improvement of 41.61% was obtained) while the time spent on acoustic look-ahead (0.004 real time factor) was almost negligible. In summary, the acoustic look-ahead method proposed here achieves an overall speedup of more than 31% and enables the whole system to run almost in real time. Experiments on Lightly Supervised Acoustic Model Training Experiments on Language Model Adaptation The language adaptation results obtained using the contemporary text corpus are shown in Table 4 . The second row shows the character error rates and perplexity for the system without language model adaptation. It can be seen that the character error rates are the best ones shown in Table 3 , and that the initially achieved perplexity value was 670.23. This high perplexity value was probably obtained because the local word regularity properties of the tested broadcast news stories were not modeled very well by the background language models. The rest of the rows show, respectively, the results obtained for the systems when either the count merging adaptation strategy or the model interpolation adaptation strategy was adopted. In this study, for count merging, the value of weighting parameter \u03b2 was fixed at 1, and the value of weighting parameter \u03b1 was varied from 1 to 9 with a step size of 2; meanwhile, for model interpolation, the value of weighting parameter \u03b3 was varied from 0.1 to 0.9 with a step size of 0.2. Comparatively the best results for model interpolation ( ), which is just about a half of the original perplexity value. The above results reveal that the local word regularity (or contextual) information that can be obtained from the contemporary corpus is vital for the task of Mandarin broadcast news recognition, whereas the subject domains or topical information embedded in the contemporary corpus may be worth taking into account and exploring further when performing language model adaptation. Conclusions This paper has presented the initial results of a long-term research project on automatic recognition, indexing and summarization of Mandarin speech information. Several improved approaches to Mandarin broadcast news speech recognition have been presented. With the special structural properties of the Chinese language taken into consideration, a fast acoustic look-ahead technique using syllable-level heuristics has been proposed, and an overall speedup of more than 31% has been achieved in experiments. A verification-based method for automatic acoustic data acquisition has also been proposed to make use of large amount of untranscribed speech data, and very encouraging recognition results have been obtained. Two alternative strategies for language model adaptation have also been shown to be helpful in reducing both the character error rate and perplexity. The broadcast news system finally yielded an 11.88% character error rate when applied to a Mandarin broadcast news test set. Acknowledgements The authors are thankful to the National Science Council, R.O.C., for financial supports of this work (grant no. 91-2218-E-003-002 and 92-2213-E-003-008). They also thank the NTU Speech Processing Lab for providing the necessary speech and language data.",
    "abstract": "This article investigates the use of several lightly supervised and data-driven approaches to Mandarin broadcast news transcription. With the special structural properties of the Chinese language taken into consideration, a fast acoustic look-ahead technique for estimating the unexplored part of a speech utterance is integrated into lexical tree search to improve search efficiency. This technique is used in conjunction with the conventional language model look-ahead technique. Then, a verification-based method for automatic acoustic training data acquisition is proposed to make use of large amounts of untranscribed speech data. Finally, two alternative strategies for language model adaptation are studied with the goal of achieving accurate language model estimation. With the above approaches, the overall system was found in experiments to yield an 11.88% character error rate when applied to Mandarin broadcast news collected in Taiwan.",
    "countries": [
        "Taiwan",
        "China",
        "Peru"
    ],
    "languages": [
        "Chinese",
        "Mandarin",
        "Mandarin"
    ],
    "numcitedby": "68",
    "year": "2005",
    "month": "March",
    "title": "Lightly Supervised and Data-Driven Approaches to {M}andarin Broadcast News Transcription"
}