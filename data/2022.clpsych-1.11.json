{
    "article": "There is growing evidence that mobile text message exchanges between patients and therapists can augment traditional cognitive behavioral therapy. The automatic characterization of patient thinking patterns in this asynchronous text communication may guide treatment and assist in therapist training. In this work, we automatically identify distorted thinking in text-based patient-therapist exchanges, investigating the role of conversation history (context) in distortion prediction. We identify six unique types of cognitive distortions and utilize BERT-based architectures to represent text messages within the context of the conversation. We propose two approaches for leveraging dynamic conversation context in model training. By representing the text messages within the context of the broader patient-therapist conversation, the models better emulate the therapist's task of recognizing distorted thoughts. This multi-turn classification approach also leverages the clustering of distorted thinking in the conversation timeline. We demonstrate that including conversation context, including the proposed dynamic context methods, improves distortion prediction performance. The proposed architectures and conversation encoding approaches achieve performance comparable to inter-rater agreement. The presence of any distorted thinking is identified with relatively high performance at 0.73 F1, significantly outperforming the best context-agnostic models (0.68 F1). Introduction Cognitive behavioral therapy (CBT) is an evidence based treatment applicable to a wide range of mental health conditions including depression, anxiety, addiction, bipolar disorder, and schizophrenia spectrum disorders (Yurica and DiTomasso, 2005; Hofmann et al., 2012) . One primary clinical activity of CBT is the identification and re-framing of systematic errors in thinking, termed cognitive distortions, that create a skewed perception of reality (Beck, 1963) . Cognitive distortions are known to exacerbate psychiatric symptoms without intervention (Dudley et al., 2016) ; however, there are many types of cognitive distortions (e.g., overgeneralization or catastrophizing), which can make identification and appropriate intervention by clinicians more complicated (Burns, 1980) . CBT has traditionally been administered through in-person office visits; however, there is increasing need for remote therapy options, to extend provider reach and increase access (Lin and Espay, 2021) . Remote therapy options include internetdelivered therapy, application-based therapy, teletherapy, and text messaging (Lin and Espay, 2021; D'Arcey et al., 2020) . There is growing evidence that asynchronous text-message-based exchanges between patients and therapists can augment conventional synchronous therapy and improve patient outcomes (D'Arcey et al., 2020) . The expansion of text-message-based CBT provides an opportunity to develop clinician supports via novel natural language processing (NLP) methods that can guide patient treatment and assist in therapist training. In this work, we explore the automatic identification and categorization of cognitive distortions in a corpus of text-message conversations between patients with serious mental illness and their therapists. Prior work identifying cognitive distortions in text treats each text sample (e.g. sentence or message) as an independent event without context. However, in this conversational paradigm, the preceding turns in the conversation may provide important contextual cues for recognizing distorted thinking. Here, we utilize state-of-the-art deep learning NLP methods to explore the role of conversation history in identifying cognitive distortions in patient-therapist text message exchanges. By identifying distorted thinking in text messages within the broader context of the dialogue, the dialogue-based prediction architectures emulate the real-world process of mental health clinicians who account for conversation context when assessing for distortions. The dialogue-based architectures also mirror the cognitive distortion annotation process associated with the data set used in this work. We present multiple BERT-based architectures for identifying distortions in multi-turn conversations and propose methods for dynamically representing the conversation context. We demonstrate that leveraging the dialogue context and incorporating the proposed dynamic conversation context yields statistically significant performance improvement, reaching performance levels comparable to interrater agreement. Distorted thinking is identified in the text messages at 0.73 F1. Related Work There is a relatively small body of work exploring the automatic identification and categorization of cognitive distortions in user-generated text. Wiemer-Hastings et al. (2004) explored the identification of dysfunctional thoughts in 188 text examples from the cognitive distortion literature. The authors manually curated linguistic features that were used in a decision tree. Simms et al. (2017) annotated 459 Tumblr blogs for the presence of cognitive distortions. Features were extracted using the Linguistic Inquiry and Word Count (LIWC) tool (Tausczik and Pennebaker, 2010) 1 , and several classifiers were explored with logistic regression (LR) achieving the best performance. Shickel et al. (2020) investigated the identification of cognitive distortions in online journal entries from college students and samples from crowdsourced participants prompted to give examples of defined distortion types. The authors investigated many classification architectures, including LR, Support Vector Machines (SVM), recurrent neural networks (RNN), convolutional neural networks (CNN), and Bidirectional Encoder Representations from Transformers (BERT) (Devlin et al., 2019) . The authors reported the highest performance using LR with with term frequency-inverse document frequency (TF-IDF) features. Shreevastava and Foltz (2021) explored the classification of 10 distinct cognitive distortions in 3,000 therapist question-answer samples. Several classifiers and feature encoding approaches were explored, and the best performance was achieved by an SVM operating on the Sen-tenceBERT encoding, without fine-tuning BERT. We explored the identification of cognitive dis-1 https://www.liwc.app/ tortions in patient-therapist text message exchanges and implemented the best performing models from Shickel et al. (2020) (LR with TF-IDF) and Shreevastava and Foltz (2021) (SVM with Sentence-BERT without fine-tuning) as baselines. We found that fine-tuning BERT for multi-label classification achieves state of the art performance in our cognitive distortion prediction task, so we focus the experimentation in this work on BERT architectures. We are not aware of any cognitive distortion prediction work that leverages conversation history as context for identifying distorted thinking. In this work, we identify cognitive distortions in text-based conversations, exploring the role of conversation history. This distortion prediction task shares similarities with other multi-turn conversational tasks, including retrieval-based dialogue response generation and question answering. Dialogue response and question answering are often approached using hierarchical architectures that first encode each turn, then aggregate the turn embeddings to create a conversation embedding, and lastly generate predictions using the conversation embedding. Conversation turns are frequently mapped to a vector embedding using CNN, RNN, and transformers (e.g. BERT), and conversation embeddings are derived from the turn embeddings using approaches like self-attention, RNN, Markov models, and graphical models (Mensio et al., 2018; Zayats and Ostendorf, 2018; Vickneswaran et al., 2020; Aliannejadi et al., 2020; Zeng et al., 2021) . Drawing inspiration from these hierarchical approaches, we experiment with an approach where each turn is encoded using BERT and then the sequence of turn encodings is mapped to a fixed length vector using a uni-directional RNN. There is also conversation modeling work that encodes multiple turns as a single input sequence to BERT, separating the turns with the [SEP ] token (Huang et al., 2019) , which we also explore here. Lu et al. (2020) explored a retrieval-based response generation task and proposed a data augmentation technique for model training. The authors created additional positive samples by sampling contiguous multi-turn excerpts from conversations and assuming the last turn is a correct response. Additional negative samples were created by sampling contiguous multi-turn excerpts, randomly removing intermediate turns, and assuming the last turn is an incorrect response. We adapt this turn masking approach to our cognitive distor-tion task to create dynamic conversation context in training, as described in Section 3.2. Methods Data This work utilized a corpus of text message exchanges between patients and therapists that was created as part of a randomized controlled trial that augmented routine care for people with serious mental illness using a text-message-based intervention (Ben-Zeev et al., 2020) . The trial was conducted in the Midwest and Pacific Northwest regions of the United States between December 2017 and October 2109. In the intervention, patients participating in standard care engaged with trained clinicians in back-and-forth text-message conversations for 12-weeks. Patients attended an in-person baseline visit to establish rapport and initial goals. Subsequently, clinicians attempted to contact patients up to three times a day to provide support strategies, including reminders, psycho-education, cognitive challenges, self-monitoring prompts, and relaxation techniques. Interactions could be initiated by either patient or clinician each day, and messages could be sent consecutively by a single party in cases where no response was given. The text-message exchanges represent a new model of care that is asynchronous and continuous. The trial demonstrated that augmenting care with mobile texting is logistically feasible, acceptable to patients, safe for patients, and clinically promising. A full description of the trial, including intervention feasibility, acceptability, engagement, and clinical outcomes is available (Ben-Zeev et al., 2020) . The randomized controlled trial was approved by the University of Washington's Institutional Review Board (IRB), and study participants provided informed consent. Here, we utilize the text message data for secondary analysis with patient and therapist identifiers removed. All data were stored on a secure server, with patient and clinician identifiers removed prior to annotation and analysis. The corpus created by the text-message intervention includes messages from 39 patients and 9 therapists with 7,436 patient and 6,959 therapist text messages. The patients who contributed data to the current analysis all had diagnoses of either schizophrenia, schizoaffective disorder, major depressive disorder, or bipolar disorder. The patient demographics were 56% male (N=22), 49% White (N= 17), 29% Black (N=10), 17% multira-cial (N=6), and 8% Hispanic/Latinx (N=3). The patients had a mean age of 45.4 (SD=11.1), 12.8 years of education (SD=2.4), and 2.8 lifetime psychiatric hospitalizations (SD=3.4). Patients had variable levels of engagement in the text-message intervention with the average number of client messages per day ranging from 0.3 messages/day to 12.5 messages/day. The average length for the patient and therapist text messages is 15.9 and 22.0 tokens, respectively. The text message conversations were annotated by a doctoral-level licensed mental health counselor and a masters-level psychologist experienced in working with people with serious mental illness. The corpus is annotated for six cognitive distortion types: \u2022 Catastrophizing (C) -Exaggerating or discounting the importance of an event. \u2022 Jumping to conclusions (J) -Interpreting a situation without facts or evidence, including mind reading and fortune telling. \u2022 Mental filtering (M) -Focusing on one detail of a situation exclusively while ignoring other relevant information. \u2022 Should statements (S) -Motivating oneself with absolute expectations, for example should, must, or ought. \u2022 Overgeneralization (O) -Extending a single occurrence or isolated incident as evidence of an ongoing or never-ending pattern. \u2022 Unspecified (U) -Message included a type of distortion not included in the five categories above or was too incoherent to code specifically. Table 1 presents example text messages for each distortion type. Annotators reviewed text-messages in the context of a full patient-clinician transcript before applying cognitive distortion annotations at the individual message level. The therapist messages were used to interpret the patient messages; however, no cognitive distortion labels were assigned to therapist messages. A patient text message may be annotated for multiple cognitive distortions. An any distortion (A) label was assigned to each patient text message, indicating whether there is at least one distortion type (logical \"or\" of distortion types at the message-level). Distortion Classification Classification Task We interpret this cognitive distortion prediction task as a multi-label binary text classification task, where the distortion label set is V = {A, C, J, M, O, S, U }. For a given distortion type v in V, a value of 1 indicates the presence of the cognitive distortion type in the target message, m i . We explore the role of conversation history (context) in assessing the presence of distorted thinking by including preceding messages (m i\u2212n , . . . m i\u22122 , m i\u22121 ) in modeling, where n indicates the number of context messages or preceding turns used. Classifier Architectures We identify cognitive distortions in patient messages using two BERT architectures, which are presented in Figure 1 . It's ok ...,\" where \"fe2k\" and \"l2kd\" are unique anonymized identifiers for patients and therapists. These approaches did not yield a meaningful performance improvement and are omitted. Message Context We explore the introduction of additional randomness in the context messages (m i\u2212n , . . . , m i\u22121 ) to create dynamic context during model training. We investigate four context representation approaches: none, fixed, random length, and random mask. The For the random mask context, context messages are randomly masked (removed) for each training sample with probability, p mask . Similar to random length, random mask provides target messages with varied context lengths; however, with random mask the context and target messages will not necessarily be contiguous, as some context messages are randomly removed. For the random length and random mask context approaches, n context messages are used in inference, similar to the fixed approach to utilize all available information. The context length, n, was treated as a tuneable hyperparameter, and context lengths from 0 to 4 were explored. Early experimentation demonstrated that prediction performance improves as the context length increases until n = 3, at which point the performance plateaus. All the presented results either include no context (n = 0 for none) or context of n = 3 for fixed, random length, and random mask. Experimental Paradigm Model performance was evaluated using a nested cross-validation procedure, to reduce error estimation bias (Varma and Simon, 2006) . The annotated data set (D) was split into five folds (1, 2, ...5). To ensure each fold contains sequential messages, each patient-therapist conversation for the entirety of the study was arranged chronologically and split into five folds of approximately equal length (\u2248 20% of each patient-therapist conversation in each fold). There was no overlap between the folds, such that a given message was only included as a target or context in a single fold. and so forth. Several of the distortions are very infrequent, and this nested cross validation procedure is intended to better characterize performance across the distortion types. Performance was averaged across the fold iterations and was assessed using F1-score. Hyperparameters were optimized to maximize average F1 across the fold iterations for the any distortion label. To assess final performance with significance testing, each fold iteration was repeated 10 times, to generate a distribution of 10 averaged F1 scores for each distortion type. Significance was evaluated using a two-sided T-test with unequal variance and a significance threshold of p < 0.05. All presented results utilized the pretrained BERT model, MentalBERT (Ji et al., 2021) , which was further pretrained on a Reddit corpus derived Model Context Epochs by fold BERT-only none [4, 4, 4, 6, 4] BERT-only all [6, 4, 4, 4, 4] random length [4, 4, 4, 4, 6] random mask [6, 10, 4, 4, 8] BERT+LSTM all [4, 8, 4, 4, 4 ] random length [4, 4, 4, 6, 4] random mask [4, 4, 6, 6, 4] Table 3 : Tuned hyperparameters by fold ([1, 2, 3, 4, 5] ) from mental health-related subreddits. Other pretrained models may offer performance gains over MentalBERT (Naseem et al., 2022) ; however, we leave this experimentation to future work. The following configuration and parameters were common to all experimentation: optimizer = AdamW, maximum gradient norm = 1.0, learning rate = 5e-5, batch size = 20, BERT dropout = 0.2, and maximum message length = 120 word pieces. For BERT-only, the maximum conversation length was 512 word pieces. For BERT+LSTM, the LSTM hidden size = 768. We experimented with context message counts, n, ranging from 0 to 4. We found that performance plateaus around n = 3. In the random mask experimentation, p mask = 0.2. The number of training epochs was tuned for each fold and model configuration, and Table 3 presents the selected epochs for each configuration. To account for the class imbalance associated with label infrequency, a balanced loss function was used in all experimentation, where the loss weights for each label are inversely proportional to positive class frequency. Distortion clustering To explore the clustering of distortions in time and the role of conversation context, we calculated the pointwise mutual information (PMI) and conditional probability of distortions in the target and context messages. PMI assesses the association between events. To understand the relationship between distortions in the target message and preceding context messages, PMI is defined here as, P M I(x = v, y = A) = log p(x = v, y = A) p(x = v)p(y = A) , where x is the occurrence of distortion type v \u2208 V in the target message, and y is the occurrence of any distortion (A) in the preceding context mes-sages. We also assessed the association between distortions in target and context messages using the conditional probability, P (y = A|x = v), where x and y are defined similarly to the PMI calculation. The inclusion of conversation context in the BERT-only and BERT+LSTM architectures yields an improvement over BERT-only without conversation context for a majority of the distortion labels. Results Prediction Performance The BERT-only model with random length context achieved the best performance, with significance, for any distortion (A) and catastrophizing (C). The BERT-only model with random mask context achieved the best performance, with significance, for jumping to conclusions (J). The BERT+LSTM model with fixed context achieved the best performance, with significance, for unspecified (U). For the remaining distortion types (mental filter (M), overgeneralizing (O), and should statements (S)) there is not a statistically significant difference between the top performing model configurations. The dynamic context approaches, random length and random mask, yield a modest but statistically significant improvement over the fixed context for the more frequent and higher performing distortions (any distortion, catastrophizing, and jumping to conclusions). Error Analysis The results in Table 4 demonstrate the inclusion of preceding messages as context improves cognitive distortion prediction performance for the most frequently occurring distortions. We assessed the relationship between distortions in the target message and distortions in the context messages using the PMI, P M I(x = v, y = A), and conditional probability, P (y = A|x = v), defined in Section 3.2.5. Inter-rater agreement is also presented for the doubly annotated subset of the corpus. 5 : PMI, P M I(x = v, y = A) and conditional probability, P (y = A|x = v), where x is the occurrence of distortion type v in the target message, and y is the occurrence of any distortion in the context messages. Distortion (v) P M I(x = v, y = A) P (y = A|x = v) All Improved \u2206 All Improved \u2206 A 0. tient messages in the annotated corpus. The PMI and conditional probability for All messages indicates that distortions cluster in time, specifically that distortions are more likely to occur in the context messages, if there are distortions in the target message (the reverse is also true). We hypothesized that some of the improved distortion prediction performance associated with the inclusion of context is related with the model implicitly identifying distortions in the context messages. For BERT-only with none context and BERTonly with random length context, we identified the models that achieved median any distortion F1 performance amongst the 10 runs. We then identified all the samples for which the model without context (BERT-only with none) was incorrect in assigning the any distortion label and the model with context (BERT-only with random length) was correct is assigning the any distortion label. The Improved subset in Table 5 includes only the target messages where the model without context was incorrect and the model with context was correct in assigning the any distortion label. The Improved subset includes 535 target messages. In Table 5 , the \u2206 columns indicates the change from All to Improved. The PMI and conditional probability are higher for the Improved partition across all distortion types, suggesting that at least a portion of the performance improvement associated with the inclusion of context is associated with the presence of distorted thinking in the context. The distortion types with the highest conditional probability in the Improved subset in Table 5 (A, C, J, and U) are also the distortion types for which the inclusion of context yielded a statistically significant improvement in prediction performance in  The Improved subset in Table 5 includes messages that were labeled incorrectly without the inclusion of context messages but labeled correctly when preceding messages were included as context. We manually reviewed the messages in this Improved subset to identify themes in the target and context messages. Table 6 presents example conversations that highlight two of the common themes identified during the manual review of the Improved subset. The examples in Table 6 were false negatives for the model without context and true positives for the model with context. In example #1, the target message (m i ) is ambiguous and has no discernible meaning without context. With the inclusion of the context messages (m i\u22123 , ...m i\u22121 ), we can infer that \"they\" refers to auditory hallucinations (voices) and \"are\" affirms that the voices are sometimes incorrect. There are many messages in the Improved subset, where the context messages confer meaning to otherwise ambiguous target messages. In example #2, the target message has interpretable meaning without the preceding messages as context and does not necessarily convey distorted thinking. However, the preceding context messages include distorted thinking by the patient and a description of anxiety by the therapist. This context informs the interpretation of the target message and indicates the target message is a continuation of this distorted thinking. There are many examples where an individual message does not necessarily convey distorted thinking when viewed in isolation, but the broader context of the conversation indicates distorted thinking. Discussion We explored the automatic identification of cognitive distortions in text-based exchanges between patients and therapists, focusing on the role of conversation context. We utilized multiple transformerbased classification architectures and proposed two methods for dynamically utilizing conversation context in training, random length and random mask. Our results demonstrate that the inclusion of context improves cognitive distortion prediction performance for several distortion types, with the best performing architecture encoding the target message and context messages as a single input sequence to BERT (BERT-only). Results also demonstrate that using random length for the context during training improves performance over using a fixed length context, for several distortion types. The performance of the context-aware models approaches the inter-rater agreement for a majority of the distortion types. BERT-only with random length context identifies any distortion with relatively high performance at 0.73 F1; however, lower performance (F1 < 0.5) is achieved in resolving specific distortion types (e.g. catastrophizing or jumping to conclusions). The error analysis suggests that at least a portion of the performance gains associated with the inclusion of context messages is attributable to the tendency for messages expressing cognitive distortions to cluster in time. This work presents context-aware classification approaches that improve performance in identifying cognitive distortions in text messages. The improved performance associated with the inclusion of context will benefit downstream clinical applications, including clinical decision-support systems, therapist training, and clinical research. In the community health setting, the adoption of new treatment modalities and technology for serious mental illness is hindered by the availability of training and expertise among community-based clinicians (Perry et al., 2020) . The adoption of new interventions is resource intensive, and training and supervision for novel interventions may improve the adoption of new interventions, like texting (Moyers et al., 2005) . Our work exploring the automatic identification of cognitive distortions could mediate the development of clinician training and support tools that improve the uniformity and quality of care and reduce required human resources, by flagging patient content that requires intervention. In terms of clinical research, this work may support the implementation of interventions that target cognitive distortions, assess the extent to which such interventions are effective in reducing distortion frequency, and improve understanding of the relationships between distorted thinking, symptom severity and mental status. This study is limited by the number of participating patients and therapists. Text-based therapy conversations are likely heterogeneous and vary by patient-therapist dyad, patient clinical condition, and other factors. Due to the size of the annotated corpus, the data set was split such that each patient appears both in the train and test partitions, although there is no overlap between the messages in the train and test partitions. Additional work with an expanded data set is needed to assess the generalizability of the classifiers to a diverse patient population, including patients not represented in the training data. Similar to prior cognitive distortion work (Shickel et al., 2020) , classification performance is limited by the challenge of manually annotating distortions, including the soft boundaries between distortion types. We are currently adding additional cognitive distortion type labels to the text-message corpus to include more fine-grained distortion categories that can be condensed into functionally related higher-level categories. The inclusion of additional cognitive distortion types and aggregation of individual distortion types into higher-level thought patterns may improve annotation consistency. As part of this annotation effort, we are expanding the annotation guidelines and providing additional annotator training to improve annotation detail and quality. This work investigates the use of preceding conversational turns as context for prediction. There are many other forms of context, and mechanisms for representing it, that may be considered in future work. With a sufficiently large corpus of text con-versations, it may be feasible to learn patient representations that capture important linguistic patterns, thinking styles, and other information relevant to characterizing thought patterns and mental state. The patient representations could take the form of learned patient embeddings, for example special patient-specific BERT tokens. Additional contextual information could include message metadata (e.g. time of day or time between responses) or patient demographics/attributes (e.g. age, gender, tech literacy, or diagnoses). Models incorporating such information may add to our understanding of the contexts in which distortions occur and further improve automated methods to detect them. Conclusions The improvements in performance shown in this work demonstrate that modeling conversational context is important for identifying cognitive distortions in text-based exchanges between patients and therapists. By identifying cognitive distortions in patient messages within the larger context of the conversation, the modeling better emulates the process mental health clinicians use to assess for distortions. Distorted thinking in the patient messages tends to cluster in time, such that distortions are more likely to occur in context messages, if there are distortions in the target message (and vice-versa) . Some of the improved performance associated with the inclusion of context is likely attributable to the model implicitly identifying distortions in the context messages. Additionally, the inclusion of context also captures important cues in therapist messages for the presence of distorted thinking in patient messages. Conversational context is likely to improve performance in identifying cognitive distortions, with implications for the development of decision support tools, and quantification of distortions in observational data. Acknowledgements This work was supported by a UW Medicine Garvey Institute for Brain Health Solutions Innovation Grant, a grant from the National Institute of Mental Health (R56MH109554), and the National Institutes of Health, National Library of Medicine (NLM) Biomedical and Health Informatics Training Program at UW (Grant Nr. T15LM007442). The content is solely the responsibility of the authors and does not necessarily represent the official views of the National Institutes of Health.",
    "abstract": "There is growing evidence that mobile text message exchanges between patients and therapists can augment traditional cognitive behavioral therapy. The automatic characterization of patient thinking patterns in this asynchronous text communication may guide treatment and assist in therapist training. In this work, we automatically identify distorted thinking in text-based patient-therapist exchanges, investigating the role of conversation history (context) in distortion prediction. We identify six unique types of cognitive distortions and utilize BERT-based architectures to represent text messages within the context of the conversation. We propose two approaches for leveraging dynamic conversation context in model training. By representing the text messages within the context of the broader patient-therapist conversation, the models better emulate the therapist's task of recognizing distorted thoughts. This multi-turn classification approach also leverages the clustering of distorted thinking in the conversation timeline. We demonstrate that including conversation context, including the proposed dynamic context methods, improves distortion prediction performance. The proposed architectures and conversation encoding approaches achieve performance comparable to inter-rater agreement. The presence of any distorted thinking is identified with relatively high performance at 0.73 F1, significantly outperforming the best context-agnostic models (0.68 F1).",
    "countries": [
        "United States"
    ],
    "languages": [
        ""
    ],
    "numcitedby": "0",
    "year": "2022",
    "month": "July",
    "title": "Identifying Distorted Thinking in Patient-Therapist Text Message Exchanges by Leveraging Dynamic Multi-Turn Context"
}