{
    "article": "Sentence alignment consists in estimating which sentence or sentences in the source language correspond with which sentence or sentences in a target language. We present in this paper a new approach to aligning sentences from a parallel corpus based on a cross-language information retrieval system. This approach consists in building a database of sentences of the target text and considering each sentence of the source text as a \"query\" to that database. The cross-language information retrieval system is a weighted Boolean search engine based on a deep linguistic analysis of the query and the documents to be indexed. This system is composed of a multilingual linguistic analyzer, a statistical analyzer, a reformulator, a comparator and a search engine. The multilingual linguistic analyzer includes a morphological analyzer, a partof-speech tagger and a syntactic analyzer. The linguistic analyzer processes both documents to be indexed and queries to produce a set of normalized lemmas, a set of named entities and a set of nominal compounds with their morpho-syntactic tags. The statistical analyzer computes for documents to be indexed concept weights based on concept database frequencies. The comparator computes intersections between queries and documents and provides a relevance weight for each intersection. Before this comparison, the reformulator expands queries during the search. The expansion is used to infer from the original query words other words expressing the same concepts. The search engine retrieves the ranked, relevant documents from the indexes according to the corresponding reformulated query and then merges the results obtained for each language, taking into account the original words of the query and their weights in order to score the documents. The sentence aligner has been evaluated on the MD corpus of the ARCADE II project which is composed of news articles from the French newspaper \"Le Monde Diplomatique\". The part of the corpus used in evaluation consists of the same subset of sentences in Arabic and French. Arabic sentences are aligned to their French counterparts. Results showed that alignment has correct precision and recall even when the corpus is not completely parallel (changes in sentence order or missing sentences). Introduction Sentence alignment consists in mapping sentences of the source language with their translations in the target language. Automatic sentence alignment approaches face two kinds of difficulties: robustness and accuracy. A number of automatic sentence alignment techniques have been proposed (Kay and R\u00f6scheisen, 1993; Gale and Church, 1991; Brown et al., 1991; Debili and Samouda, 1992; Papageorgiou et al., 1994; Gaussier, 1995; Melamed, 1996; Fluhr et al., 2000) . The method proposed in (Kay and R\u00f6scheisen, 1993) is based on the assumption that in order for the sentences in a translation to correspond, the words in them must correspond. In other words, all necessary information (and in particular, lexical mapping) is derived from the to-be-aligned texts themselves. In (Gale and Church, 1991) and (Brown et al., 1991) , the authors start from the fact that the length of a source text sentence is highly correlated with the length of its target text translation: short sentences tend to have short translations, and long sentences tend to have long translations. The method proposed in (Debili and Sammouda, 1992 ) is based on the preliminary alignment of words using a conventional bilingual lexicon and the method described in (Papageorgiou et al., 1994) added grammatical labeling based on the assumption that the same parts of speech tend to be employed in the translation. In this paper, we present a sentence aligner which is based on a cross-language information retrieval approach and combines different information sources (bilingual lexicon, sentence length and sentence position). This sentence aligner was first developed for aligning French-English parallel text. It is now ported to Arabic-French and Arabic-English language pairs. We present in section 2 the main components of the cross-language search engine, in particular, we will focus on the linguistic processing. In section 3, the prototype of our sentence aligner is described. We discuss in section 4 results obtained after aligning sentences of the MD (Monde Diplomatique) corpus of the ARCADE II project. Section 5 concludes our study and presents our future work. The Cross-language Search Engine Information retrieval consists to find all relevant documents for a user query in a collection of documents. These documents are ordered by the probability of being relevant to the user's query. The highest ranked document is considered to be the most likely relevant document. Cross-language information retrieval consists in providing a query in one language and searching documents in different languages (Grefenstette, 1998) . The cross-lingual search engine is a weighted Boolean search engine based on a deep linguistic analysis of the query and the documents to be indexed (Besan\u00e7on et al., 2003) . It is composed of a linguistic analyzer, a statistical analyzer, a reformulator and a comparator (Figure 1 ): Figure 1 . The cross-language search engine Linguistic Analysis The linguistic analyzer produces a set of normalized lemmas, a set of named entities and a set of nominal compounds. It is composed of several linguistic resources and processing modules. Each language has its proper linguistic resources which are generally composed of: \u2022 A full form dictionary, containing for each word form its possible part-of-speech tags Linguistic analysis Comparator Statistic analysis Reformulation General lexicons Reformulation lexicons Search engine database (Indexed documents) Documents to be indexed Queries Documents grouped in relevant classes and linguistic features (gender, number, etc) . For languages such as Arabic which presents agglutination of articles, prepositions and conjunctions at the beginning of the word as well as pronouns at the ending of the word, we added two other dictionaries for proclitics and enclitics in order to split the input words into proclitics, simple forms and enclitics. \u2022 A monolingual reformulation dictionary used in query expansion for expanding original query words to other words expressing the same concepts (synonyms, hyponyms, etc.). \u2022 Bilingual dictionaries used in crosslanguage querying. \u2022 A set of rules for tokenizing words. \u2022 A set of part-of-speech n-grams (bigrams and trigrams from hand-tagged corpora) that are used for part-of-speech tagging. \u2022 A set of rules for shallow parsing of sentences, extracting compounds from the input text. \u2022 A set of rules for the identification of named entities: gazetteers and contextual rules that use special triggers to identify named entities and their type. The processing modules are common for all the languages with some variations for some specific languages: \u2022 A Tokenizer which separates the input stream into a graph of words. This separation is achieved by an automaton developed for each language and a set of segmentation rules. \u2022 A Morphological analyzer which searches each word in a general dictionary (Debili and Zouari, 1985) . If this word is found, it will be associated with its lemma and all its morpho-syntactic tags. If the word is not found in the general dictionary, it is given a default set of morpho-syntactic tags based on its typography. For Arabic, we added to the morphological analyzer a new processing step: a Clitic stemmer (Larkey et al., 2002) which splits agglutinated words into proclitics, simple forms and enclitics. If the simple form computed by the clitic stemmer does not exist in the general dictionary, re-write rules are applied (Darwish, 2002) . For example, consider the token \" \" (with their ballon) and the included clitics \u202b\"\u0628\"\u202c (with) and \" \u202b\"\u0647\u202c (their), the computed simple form \u202b\u062a\"\u202c \u202b\"\u0622\u202c does not exist in the general dictionary but after applying one of the dozen re-write rules, the modified simple form \u202b\u0629\"\u202c \u202b\"\u0622\u202c (ballon) is found in the general dictionary and the input token is segmented as: = \u202b\u0628\u202c + \u202b\u0629\u202c \u202b\u0622\u202c + \u202b.\u0647\u202c \u2022 An Idiomatic Expressions recognizer which detects idiomatic expressions and considers them as single words for the rest of the processing. Idiomatic expressions are phrases or compound nouns that are listed in a specific dictionary. The detection of idiomatic expressions is performed by applying a set of rules that are triggered on specific words and tested on left and right contexts of the trigger. These rules can recognize contiguous expressions as the \"white house\" in English, la \"maison blanche\" in French or \" \u064e \u0652 \u064e \u202b\u0627\u202c \u0652 \u064e \u202b\"\u0627\u202c in Arabic. Non-contiguous expressions such as phrasal verbs in English: \"switch\u2026on\" or \"tomber vaguement dans les pommes\" in French are recognized too. \u2022 A Part-Of-Speech (POS) tagger which searches valid paths through all the possible tags paths using attested trigrams and bigrams sequences. The trigram and bigram matrices are generated from a manually annotated training corpus (Grefenstette et al., 2005) . They are extracted from a hand-tagged corpora of 13 200 words for Arabic and 25 000 words for French. If no continuous trigram full path is found, the POS tagger tries to use bigrams at the points where the trigrams were not found in the matrix. The accuracy of the part-ofspeech tagger is around 91% for Arabic and 94% for French. \u2022 A Syntactic analyzer which is used to split word graph into nominal and verbal chain and recognize dependency relations (especially those within compounds) by using a set of syntactic rules. We developed a set of dependency relations to link nouns to other nouns, a noun with a proper noun, a proper noun with the post nominal adjective and a noun with a post nominal adjective. These relations are restricted to the same nominal chain and are used to compute compound words. For example, in the nominal chain \" \u202b\u0627\u202c \u202b\u0632\u06cc\u202c \" (water supply), the syntactic analyzer considers this nominal chain as a compound word ( \u202b\u0632\u06cc\u202c _ \u202b\ufee1\u202c ) composed of the words \" \u202b\u0632\u06cc\u202c \" (supply) and \" \u202b\"\ufee1\u202c (water). \u2022 A Named Entity recognizer which uses name triggers (e.g., President, lake, corporation, etc.) to identify named entities (Abuleil and Evens, 2004) . For example, the expression \u202b\u0631\u0633\"\u202c \u064e \u202b\ufee1\u202c \u0650 \u0652 \u064e \u0650 \u202b\ufee1\u202c \u202b\u0644\u202c \u202b\u064e\u0648\u202c \u202b\"\u0627\u202c (The first of March) is recognized as a date and the expression \" \u064e \u0652 \u202b\u064e\u0648\u202c \u202b\u0627\u202c \u202b\u0652\u0642\u202c \u202b\"\u0627\u202c (The Middle East) is recognized as a location. \u2022 Eliminating Empty Words consists in identifying words that should not be used as search criteria and eliminating them. These empty words are identified using only their parts of speech (such as prepositions, articles, punctuations and some adverbs). \u2022 Finally, words are normalized by their lemma. In the case the word has a set of synonymous lemmas, only one of these lemmas is taken as a normalization. Each normalized word is associated with its morpho-syntactic tag. Statistical Analysis The role of the statistical analysis is to attribute a weight to each word or a compound word according to the information the word or the compound word provides in choosing the document relevant to a query. This weight is computed by an idf formula (Salton and McGill, 1983 ). The weight is maximum for words appearing in one single document and minimum for words appearing in all the documents. This weight is used by the comparator to compute the semantic intersection between query and documents containing different words. A similarity value is associated with each semantic intersection. This value corresponds to the sum of the weights of words present in the documents. The search engine groups documents into classes (semantic intersections) characterized by the same set of words. These classes constitute a discrete partition of the indexed documents. For example, the search engine returns 12 classes for the query \" \u202b\u0627\u202c \u202b\u0627\u0631\u062f\u202c \u202b\ufee1\u202c \u202b\"\u0625\u062f\u0627\u0631\u0629\u202c (water resources management) (Table 1 ). The query term \" Class Query terms 1 \u202b\u0625\u062f\u0627\u0631\u0629\u202c _ \u202b\u0627\u0631\u062f\u202c _ 2 \u202b\u0627\u0631\u062f\u202c _ , \u202b\u0625\u062f\u0627\u0631\u0629\u202c _ \u202b\u0627\u0631\u062f\u202c 3 , \u202b\u0625\u062f\u0627\u0631\u0629\u202c _ \u202b\u0648\u0627\u0631\u062f\u202c 4 \u202b\u0625\u062f\u0627\u0631\u0629\u202c , \u202b\u0627\u0631\u062f\u202c _ 5 \u202b\u0625\u062f\u0627\u0631\u0629\u202c _ \u202b\u0627\u0631\u062f\u202c 6 \u202b\u0627\u0631\u062f\u202c _ 7 \u202b\u0625\u062f\u0627\u0631\u0629\u202c , \u202b\u0627\u0631\u062f\u202c , \u202b\u0625\u062f\u0627\u0631\u0629\u202c _ \u202b\u0627\u0631\u062f\u202c \u202b\ufee1\u202c _ \u202b\ufee1\u202c \" is a compound word composed of three words: \" \u202b\"\u0625\u062f\u0627\u0631\u0629\u202c (management), \u202b\u0627\u0631\u062f\"\u202c \u202b\"\ufee1\u202c (resources ) and \" \u202b\"\ufee1\u202c (water ). This compound word is computed by the syntactic analyzer. Query Reformulation The role of query reformulation is to infer new words from the original query words according to a lexical semantic knowledge. The reformulation can be used to increase the quality of the retrieval in a monolingual interrogation. It can also be used to infer words in other languages. The query terms are translated using bilingual dictionaries. Each term of the query is translated into several terms in target language. The translated words form the search terms of the reformulated query. The links between the search terms and the query concepts can also be weighted by a confidence value indicating the relevance of the translation. Reformulation rules can be applied to all instances of a word or to a word only when it is playing a specific partof-speech. Semantic relations can also be selected: translations, synonyms, word derived from the same root, etc. The cross-language search engine has a monolingual reformulation for French and two bilingual reformulations for Arabic-French and French-Arabic language pairs. Query and Documents Comparison The search engine indexer builds the inverted files of the documents on the basis of their linguistic analysis: one index is built for each language of the document collection. This indexer builds separate indexes for each language. The search engine uses a comparison tool to evaluate all possible intersections between query words and documents, and computes a relevance weight for each intersection. This relevance weight corresponds to the sum of the weights of words present in the documents. The Sentence Aligner Parallel text alignment based on cross-language information retrieval consists in building a database of sentences of the target text and considering each sentence of the source text as a \"query\" to that database (Figure 2 ). Figure 2. Sentence alignment steps To evaluate whether the two sentences are translations of each other, we use three criteria: \u2022 Number of common words between the source sentence and the target sentence (semantic intersection) must be higher than 50% of number of words of the target sentence. \u2022 Position of the sentence to align must be in an interval of 10 compared to the position of the last aligned sentence. \u2022 Ratio of lengths of the target sentence and the source sentence (in characters) must be higher or equal than 1.1 (A French character needs 1.1 Arabic characters): Longer sentences in Arabic tend to be translated into longer sentences in French, and shorter sentences tend to be translated into shorter sentences. The alignment process has four steps: 1. Exact match 1-1 alignment: The goal of this step is to obtain an alignment with a maximum precision by using the three criteria: Number of common words between the source sentence and the target sentence; Position of the sentence to align; Ratio of lengths of the target sentence and the source sentence. 2. 1-2 alignment: This alignment consists in merging an unaligned sentence with one preceding or following already aligned sentence. We use to validate this alignment only the first two criteria. 3. 2-1 alignment: The goal of this alignment is to find for the two sentences following an aligned sentence a sentence in the target language taking into account the position of the last aligned sentence. This alignment is validated by using only the first two criteria. 4. Fuzzy match 1-1 alignment: This alignment proposes for the sentence to align the first sentence of the first class returned by the cross-language search engine. This type of alignment is added to take into account alignments which are partially correct (The source sentence is not completely aligned but some of its words are translated). Cross-lingual Interrogation in French database List of French sentences Cross-lingual Interrogation in Arabic database List of Arabic sentences Arabic sentences to align Check of alignment criteria French aligned sentences We describe below the algorithm of the Exact Match 1-1 alignment which is the base of the other aligners. This algorithm uses the functions of the cross-language search engine API. \u2022 PerformCrosslinguageSearch(Query, Corpus, Source language, Target language): returns the set of relevant classes corresponding to the question \"Query\" in the database \"Corpus\". Each class is composed of a set of sentences in the target language. \u2022 GetNumberOfCommonWords(Class): returns the number of common words between the source sentence and the target sentence (semantic intersection). \u2022 GetNumberOfWords(Sentence): returns the number of words of a sentence. \u202b\u06cc\u202c \u202b\ufee5\u202c \" (In Italy, the order of things persuaded in an invisible way a majority of electors that time of traditional parties was finished), the exact match 1-1 aligner proceeds as follows: \u2022 The Arabic sentence is considered to be a query to the French sentence database using the cross-language search engine. Retrieved sentences for the two first classes are illustrated in Table 2 . Class Number of retrieved sentences Retrieved sentences  The first proposed sentence is the original one and more of 50% of the words are common to the two sentences. Furthermore, the length ratio between the French sentence and the Arabic sentence is superior than 1.1 and positions of these two sentences in the databases are the same. Therefore, the exact match 1-1 aligner considers the French sentence [4/36] as a translation of the Arabic sentence [4/30]. Experimental Results The sentence aligner has been tested on the MD corpus of the ARCADE II project which is composed of news articles from the French newspaper \"Le Monde Diplomatique\" (Chiao et al., 2006) . This corpus contains 5 Arabic texts (244 sentences) aligned at the sentence level to 5 French texts (283 sentences). The test consisted to build two databases of sentences (Arabic and French) and to consider each Arabic sentence as a \"query\" to the French database. To evaluate the sentence aligner, we used the following measures: The results we obtained at sentence level (Table 4 ) show an average precision around 97% and an average recall around 93%. These results do not take into account alignments which are partially correct (Fuzzy match 1-1 alignment). Parallel Text Precision Recall  Analysis of these results shows that our sentence aligner is not sensitive to missing sentences. This is because the first criterion used by our aligner is not related to surface information (sentence position or sentence length) but on the semantic intersection of these sentences. Moreover, we have noted that precision depends on the discriminate terms which can occur in the source and target sentences. Conclusion and Perspectives We have proposed a new approach to sentence alignment based on a cross-language information retrieval model combining different information sources (bilingual lexicon, sentence length and sentence position). The results we obtained show correct precision and recall even when the parallel corpus includes changes in sentence order and missing sentences. This is due to the nonsequential strategy used by the sentence aligner. In future work, we plan to improve the alignment with syntactic structures of source and target sentences and to use the aligned bilingual parallel corpus as a translation memory in a computer-aided translation tool.",
    "abstract": "Sentence alignment consists in estimating which sentence or sentences in the source language correspond with which sentence or sentences in a target language. We present in this paper a new approach to aligning sentences from a parallel corpus based on a cross-language information retrieval system. This approach consists in building a database of sentences of the target text and considering each sentence of the source text as a \"query\" to that database. The cross-language information retrieval system is a weighted Boolean search engine based on a deep linguistic analysis of the query and the documents to be indexed. This system is composed of a multilingual linguistic analyzer, a statistical analyzer, a reformulator, a comparator and a search engine. The multilingual linguistic analyzer includes a morphological analyzer, a partof-speech tagger and a syntactic analyzer. The linguistic analyzer processes both documents to be indexed and queries to produce a set of normalized lemmas, a set of named entities and a set of nominal compounds with their morpho-syntactic tags. The statistical analyzer computes for documents to be indexed concept weights based on concept database frequencies. The comparator computes intersections between queries and documents and provides a relevance weight for each intersection. Before this comparison, the reformulator expands queries during the search. The expansion is used to infer from the original query words other words expressing the same concepts. The search engine retrieves the ranked, relevant documents from the indexes according to the corresponding reformulated query and then merges the results obtained for each language, taking into account the original words of the query and their weights in order to score the documents. The sentence aligner has been evaluated on the MD corpus of the ARCADE II project which is composed of news articles from the French newspaper \"Le Monde Diplomatique\". The part of the corpus used in evaluation consists of the same subset of sentences in Arabic and French. Arabic sentences are aligned to their French counterparts. Results showed that alignment has correct precision and recall even when the corpus is not completely parallel (changes in sentence order or missing sentences).",
    "countries": [
        "France"
    ],
    "languages": [
        "English",
        "French",
        "Arabic"
    ],
    "numcitedby": "10",
    "year": "2007",
    "month": "June",
    "title": "{A}rabic to {F}rench Sentence Alignment: Exploration of A Cross-language Information Retrieval Approach"
}