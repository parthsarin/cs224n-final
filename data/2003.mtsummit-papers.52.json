{
    "article": "In this paper, we present several confidence measures for (statistical) machine translation. We introduce word posterior probabilities for words in the target sentence that can be determined either on a word graph or on an N best list. Two alternative confidence measures that can be calculated on N best lists are proposed. The performance of the measures is evaluated on two different translation tasks: on spontaneously spoken dialogues from the domain of appointment scheduling, and on a collection of technical manuals. Introduction With the rising number of applications of machine translation (MT), the demand for the ability to spot erroneous words also increases. A method for labeling the generated words as either correct or incorrect enables the system to signal possible errors to the user or to propose only those words as translations that are likely to be correct. Confidence measures are widely used in speech recognition (see e.g. (Weintraub et al., 1997; Wessel et al., 2001) ), but until recently they have not been applied in the area of MT. (Gandrabur and Foster, 2003) introduced confidence measures for a translation prediction task in an interactive environment. They estimate confidence for up to four predicted words. Unlike this, our approach allows for the calculation of confidence for each word in a sentence generated by the system. Thus, it can be applied to interactive systems like the one described in (Och et al., 2003) , e. g. to mark words with a low confidence for correction. We present methods for the calculation of confidence measures for MT that rely only on information contained in the output of an MT system. They are based on word graphs and N best lists. For each word in a target sentence, the posterior probability is computed and employed as confidence measure. Furthermore, alternative confidence measures computed on N best lists are introduced and compared to the word posterior probabilities. The remainder of the paper is organized as follows: A short introduction to Statistical Machine Translation (SMT) is given in Section 2; and Section 3 presents the proposed confidence measures. Section 3.2 explains the computation of word posterior probabilities on word graphs, and Section 3.3 that on N best lists. The two alternative N best list based confidence measures are introduced in Section 3.4. In Section 4, the different confidence measures are evaluated on two different translation tasks. The conclusions are given in Section 5. Statistical Machine Translation The goal of machine translation is the translation of an input string f 1 . . . f J in the source language into a target language string e 1 . . . e I . We choose the string that has maximum probability given the source string, P r(e I 1 |f J 1 ). Applying Bayes' decision rule yields the following criterion: \u00eaI 1 = arg max e I 1 P r(e I 1 |f J 1 ) = (1) = arg max e I 1 {P r(e I 1 ) \u2022 P r(f J 1 |e I 1 )} . The correspondence between the words in the source and the target string is described by alignments which can be viewed as mappings B : i \u2192 B i \u2282 {1, . . . , J} assigning a set B i of source positions to each target position i (including the empty position zero). Note that this conception is different from the one introduced in (Brown et al., 1993) where the alignment assigns (exactly) one target position to each source position. The search (denoted by the arg max operation in Eq. 1) explores the space of all possible target language strings e I 1 and all possible alignments B I 0 between the source and the target language string to find the one with maximum probability. Applying the maximum approximation, this yields (\u00ea I 1 , BI 0 ) = arg max e I 1 , B I 0 P r(e I 1 , B I 0 | f J 1 ) . (2) This decision criterion aims at the minimization of the expected number of sentence errors. For descriptions of SMT systems see for example (Och and Ney, 2002; Vogel et al., 2000; Takezawa et al., 1998; Yamada and Knight, 2002) . Confidence Measures For a given translation produced by an MT system, we want to measure the confidence of being correct for each generated word. That is, for each word in the target hypothesis, the confidence is to be calculated and compared to a tagging threshold which has been optimized on a development corpus. All words whose confidence is above this threshold are tagged as correct and all others are tagged as false. Unlike the criterion given in Eq. 2, this approach aims at the minimization of the expected number of word errors instead of sentence errors. Word Posterior Probabilities In speech recognition, confidence measures based on word posterior probabilities as proposed in (Wessel et al., 2001) have proven to be among the very effective methods known. We transfer this concept to the area of machine translation and show that it can be applied successfully as well. We compare two different approaches to the calculation of word posterior probabilities: 1. We regard the target position i in which the word e occurs in a specific hypothesis and determine the word posterior probability p i (e|f J 1 ). 2. Word posterior probabilities p B (e|f J 1 ) are defined for a target word e, considering the set B of source positions that is aligned to this word in a specific hypothesis. The difference between the two approaches is illustrated in the example in Table 1 which will be explained in detail at the end of this subsection. The word posterior probability can be determined by summing up the posterior probabilities of all sentences which contain this specific word in position i or aligned to the source positions B. Let ) is the language model probability. For criterion 1 introduced above, we obtain the word posterior probability by the following summation p(e I 1 , B I 0 , f J 1 ) = = I k=0 p(f B k |e k ) \u2022 p(B k |B k\u22121 ) \u2022 p(e k |e k\u22121 1 ) , where p(f B k |e k ) = j\u2208B k p(f j |e k ) is p i (e|f J 1 ) = (3) = 1 p(f J 1 ) (B I 0 , e I 1 ): e i =e p(e I 1 , B I 0 , f J 1 ) . Applying criterion 2 instead leads to p B (e|f J 1 ) = (4) = 1 p(f J 1 ) (B I 0 , e I 1 ): \u2203i: (e i ,B i )=(e,B) p(e I 1 , B I 0 , f J 1 ) . Table 1 shows a German input sentence together with four different translations. The aligned source positions of each generated target word are given as index. We see that the position of a word in the target sentence can differ due to insertions, deletions and reordering of words. If we want to determine the confidence of the word '?' in Translation 1, the two rightmost columns show the sentences that are taken into account for the summation in Eqs. 3 and 4, respectively. For criterion 2, we have more sentences that match, yielding a more reliable confidence estimation (as the experiments in Section 4 will show). The posterior probability can directly be used as a measure of confidence as described above. We denote these two confidence measures by C target (e) = p i (e|f J 1 ) and C source (e) = p B (e|f J 1 ) . These confidence measures are probabilistic and exploit only information which is contained in the output of an SMT system. Translation 3 what 1 did 2 you 3 just 0 say 4 ? 5  +  Translation 4 what 1 you 3 did 2 say 4 . 5 Word Posterior Probabilities on Word Graphs Using an SMT system, we construct a word graph as described in (Ueffing et al., 2002) : The nodes represent sets of covered source sentence positions and differentiate between different language model histories. An edge is labeled with the target word generated as a translation of the covered source position(s). The edges are also annotated with the probabilities of the different translation submodels. Each path from the source of the graph (i.e. the node with zero covered source sentence positions) to the sink (i.e. the node where all source sentence positions are covered) is an alternative target sentence hypothesis. Thus, the word graph contains the most probable sentence hypotheses that survived the pruning during search and can be used to approximate the word posterior probabilities as defined in Eqs. 3 and 4. The word graphs are then compressed by merging all nodes which have the same coverage vector and the same source position covered last into one. The information relevant for determining the word probabilities of a word e in the best generated target sentence is the following: \u2022 the translation probability p(f B |e), where f B is the set of source words aligned to e, \u2022 for C target : the position i of word e in the target hypothesis, \u2022 for C source : the set B of source positions aligned to e, \u2022 the alignment probability p(B|B ), where B is the set of source positions covered by the predecessor target word of e. The language model probabilities can be calculated on the fly. The computation of word posterior probabilities on word graphs can be performed by applying a forward-backward algorithm. Assume we use a trigram language model. The formulae we are going to present can be extended to capture for longer histories as well, but in order to keep the presentation understandable, we will show them only for trigrams. Target position dependency Let C i be the coverage set of the partial hypothesis \u03a6 i (e i\u22121 , C i\u22121 ; e i , B i ) = (5) = p(f B i |e i ) \u2022 e i\u22122 B i\u22121 p(B i |B i\u22121 ) \u2022 p(e i |e i\u22121 e i\u22122 ) \u2022 \u03a6 i\u22121 (e i\u22122 , C i\u22121 \\ B i\u22121 ; e i\u22121 , B i\u22121 ) , which is calculated recursively in ascending order of i. For the computation of backward probabilities, the probability of completing a sentence from word e in position i is \u03a8 i (e i , B i ; e i+1 , C i ) = (6) = p(f B i |e i ) \u2022 e i+2 B i+1 p(B i+1 |B i ) \u2022 p(e i+2 |e i+1 e i ) \u2022 \u03a8 i+1 (e i+1 , B i+1 ; e i+2 , C i+1 ) . This can be recursively determined in descending order of i. Using the forward-backward algorithm, the word posterior probability can be calculated according to p i (e i |f J 1 ) = 1 p(f J 1 ) e i\u22121 e i+1 C i\u22121 B i p(e i+1 |e i e i\u22121 ) \u2022 \u03a6 i (e i\u22121 , C i\u22121 ; e i , B i ) \u2022 \u03a8 i (e i , B i ; e i+1 , C i ) p(f B i |e) with the normalization term p(f J 1 ) = I e I B I e I\u22121 \u03a6 I (e I\u22121 , B I ; e I , B I ) = e 1 B 1 e 2 \u03a8 1 (e 1 , B 1 ; e 2 , B 1 ) \u2022p(e 2 |e 1 ) \u2022 p(e 1 ) . Here, I is the last position in the generated target sentences. Source position dependency Instead of regarding the position of word e in the target sentence, we determine the posterior probability according to the set B of source positions that e is aligned to. This approach allows for the direct comparison of translation hypotheses of different lengths. Applying this view, we cannot calculate a posterior probability for zero fertility words, because there are no source words that generate them. Therefore, we assign them a posterior probability of one. Analogously to Eq. 5, the forward probability can be computed according to \u03a6 B (e , C ; e) = = p(f B |e) \u2022 e B \u2286C \u03a6 B (e , C \\ B ; e ) \u2022 p(e|e e ) \u2022 p(B|B ) , where B is the set of source positions covered by the predecessor word e , and C \u2286 B. The backward probability is determined as \u03a8 B (e; \u1ebd, C) = = p(f B |e) \u2022 \u1ebd B\u2286 C \u03a8 B (\u1ebd; \u1ebd, C) \u2022 p( \u1ebd|\u1ebde) \u2022 p( B|B) , where C \u2286 B. This yields the word posterior probability formula p B (e|f J 1 ) = 1 p(f J 1 ) e \u1ebd C \u2286B p(\u1ebd|ee )\u2022 \u03a6 B (e , C ; e) \u2022 \u03a8 B (e; \u1ebd, C \u222a B) p(f B |e) with the normalization term p(f J 1 ) = I e I B I e I\u22121 \u03a6 B I (e I\u22121 , B I ; e I ) = e 1 B 1 e 2 \u03a8 B 1 (e 1 ; e 2 , B 1 ) \u2022p(e 2 |e 1 ) \u2022 p(e 1 ) , where B I is the set of source positions covered by the last word of the generated target sentences, and B 1 those covered by the first word, respectively. Word Posterior Probabilities on N Best Lists From a word graph, we can easily extract an N best list containing the N target sentences that obtained the highest probability by the translation and language model. They can be used as a representation of the possible target sentences as well, and we can determine the sum in Eq. 3 over the sentences in the N best list. As mentioned already in Section 3.1, the generated target sentences may have different lengths and the position of a word within different sentences in the N best list might differ due to reorderings, deletions, and insertions. Thus, we determine the Levenshtein alignment (Levenshtein, 1966) on the sentences according to the best target sentence. That is, for each word \u00eai in the best target sentence \u00eaI 1 , we determine the corresponding word w in any of the other sentences in the N best list. We denote the Levenshtein alignment of two sentences \u00eaI 1 and w I n 1 by L = L(\u00ea I 1 , w In 1 ) and that of word \u00eai by L i (\u00ea I 1 , w In 1 ) for n = 2, . . . , N . Using this Levenshtein alignment, we can easily compute word posterior probabilities for each word \u00eai in the best target sentence. We sum over the probabilities of all sentences containing the word in a position that is aligned to i in the Levenshtein alignment: p i (\u00ea i |f J 1 , \u00eaI 1 , L) = = N n=1 p(f J 1 |w In 1 ) \u2022 p(w In 1 ) \u2022 \u03b4(\u00ea i , L i (\u00ea I 1 , w In 1 )) N n=1 p(f J 1 |w In 1 ) \u2022 p(w In 1 ) , where \u03b4(., .) is the Kronecker function. This yields the confidence measure C prob (\u00ea i ) = p i (\u00ea i |f J 1 , \u00eaI 1 , L) . Alternative Confidence Measures on N Best Lists Apart from the word posterior probabilities as presented in Section 3.3, we investigated two simple confidence measures on N best lists: The relative frequency of a word in the list and the sum of the ranks of the target sentences containing this word. Those values can be calculated on N best lists produced by any MT system which does not have to be statistical. Relative Frequency For each word \u00eai in the best target sentence, we determine the number of sentences in the N best list containing this word in a position aligned to i. Then, we take the relative frequency of word \u00eai in the N best list with respect to the Levenshtein alignment directly as a confidence measure: C rel (\u00ea i ) = 1 N N n=1 \u03b4(\u00ea i , L i (\u00ea I 1 , w I n 1 )). Rank sum Another simple confidence measure that can be computed on N best lists is the sum of the ranks of those target sentences containing word \u00eai as L i (\u00ea I 1 , w I n 1 ) (normalized by the total rank sum): C rank (\u00ea i ) = N n=1 (N \u2212 n) \u2022 \u03b4(\u00ea i , L i (\u00ea I 1 , w I n 1 )) N 2 (N + 1) . Since we want ranks near to the top of the list to score better, we sum N \u2212 n instead of the rank n. Scaling of the Probabilities During the translation process, the language model probability is raised to the power of 0.8 in order to give the language model probabilities a higher weight in the decision process. For the calculation of word posterior probabilities, we varied this scaling factor and optimized it on a development corpus in order to minimize the decision errors. Results Corpora We performed experiments on two different corpora. One is the trilingual corpus which is successively built within the LC-STAR project. It comprises the languages English, Spanish, and Catalan. Experiments were carried out for all six translation directions. At the time of our experiments, we had about 13k sentences per language available; the statistics are given in Table 2 . The corpus consists of transcriptions of spontaneously spoken dialogues in the domain of appointment scheduling and travel arrangements. The second task we worked on is the TransType2 corpus. It consists of technical manuals like user guides, operating guides, and system administration guides for different devices. It comprises three language pairs, each of which contains English (E). The other three languages are French (F) , Spanish (S) , and German (G). The corpus statistics can be seen in Table 3 . Experimental Setup We performed translation experiments with an implementation of the IBM-4 translation model (Brown et al., 1993) . A description of the system can be found in (Tillmann and Ney, 2003) . The experimental setup for the two corpora is described in Table 4 . It shows the baseline word error rate (WER), the graph error rate (GER), and the word graph density (WGD) for the different language pairs. The WER is based on the Levenshtein distance and computes the minimum number of substitution, insertion, and deletion operations that have to be performed to convert the generated string into the reference string. The GER is computed by determining the sentence in the word graph that has the minimum Levenshtein distance to a given reference. Thus, it is a lower bound for the word error rate. The WGD is computed as the total number of word graph edges divided by the number of words in the reference sentence. Evaluation Metrics After computing the confidence, each generated word is tagged as either correct or false, depending on whether its confidence exceeds the tagging threshold that has been optimized on the development set beforehand. The performance of the confidence measure is evaluated using two different metrics: \u2022 Confidence Error Rate The CER is defined as the number of incorrectly assigned tags divided by the total number of generated words in the translated sentence. The baseline CER is given by the number of substitutions and insertions, divided by the number of generated words. The CER strongly depends on the tagging threshold. Therefore, the tagging threshold is adjusted beforehand on a development corpus distinct from the test set. \u2022 Detection Error Tradeoff curve The DET curve plots the false rejection rate versus the false acceptance rate for different values of the tagging threshold. The false rejection rate is defined as the number of correctly translated words that have been tagged as wrong, divided by the total number of correctly translated words. It is also referred to as type I error. The false acceptance rate (or type II error) is calculated as the number of incorrect words that have been accepted, divided by the total number of incorrectly translated words. If the type I error is restricted by a given \u03b1 > 0, the type II error usually cannot be restricted; both error rates depend on each other. Experimental Results Confidence Error Rates Table 5 contains the CER for all language pairs of the two tasks. We compared the confidence measures determined on word graphs and those on N best lists. For each language pair, the minimal CER is shown in bold face. We see that C source , the word posterior probabilities calculated on word graphs with respect to the aligned source position(s), outperform C target and the N best list based measures in most of the cases. Nevertheless, the N best list based confidence mea-sure C rank significantly decreases the CER, likewise, and shows best performance among all measures for some of the language pairs. Regarding the results of the confidence measures computed on N best lists, we see that the performance of the word posterior probabilities C prob stays behind that of the simple measures. Here, the rank based criterion C rank produces best results among the N best list based measures. For some of the confidence measures and some language pairs, the CER does not decrease, but even slightly grows compared to the baseline. This is the case for the word graph based measure that depends on the target position of the word, C target , and for the probabilistic N best list measure, C prob . We believe that this is due to the fact that both of the measures refer to the position of the generated word in the target sentence which might differ between alternative hypotheses -even if the N best list method tries to compensate for this by determining the Levenshtein alignment. Detection Error Tradeoff Curves The DET curves for two language pairs are shown in Figures 1 and 2 . They support the analysis presented above: The word graph based confidence measure C source produces best results, closely followed by the N best list based measure C rank . The confidence measure C prob clearly performs worst. Conclusion We presented several concepts of confidence measures for (statistical) MT systems. Applying them, the words in the generated target sentence can be tagged as correct or false, e.g. to facilitate postediting or work in an interactive translation environment. Word posterior probabilities were computed from information contained in the output of an SMT system, either from a word graph or an N best list. Furthermore, two alternative confidence measures computed on N best lists were introduced and their performance was compared with that of the word posterior probabilities. Those two methods are applicable to non-statistical MT systems as well. A systematic evaluation was presented on the LC-STAR corpus which consists of spontaneously spoken dialogues in the domain of appointment scheduling and travel arrangement, and the TransType2 corpus comprising technical manuals. Experiments showed that the word graph based confidence measure C source , depending on the source position(s) covered by the target word, yields best results. Nevertheless, a simple rank based criterion calculated on N best lists also performed well. Both of them significantly reduce the confidence error rate. Acknowledgements This work was partly supported by the projects LC-STAR (IST-2001-32216) and TransType2 (IST-2001-32091) by the European Community.",
    "abstract": "In this paper, we present several confidence measures for (statistical) machine translation. We introduce word posterior probabilities for words in the target sentence that can be determined either on a word graph or on an N best list. Two alternative confidence measures that can be calculated on N best lists are proposed. The performance of the measures is evaluated on two different translation tasks: on spontaneously spoken dialogues from the domain of appointment scheduling, and on a collection of technical manuals.",
    "countries": [
        "Germany",
        "Mauritius"
    ],
    "languages": [
        "German",
        "English",
        "Catalan",
        "Spanish",
        "French"
    ],
    "numcitedby": "78",
    "year": "2003",
    "month": "September 23-27",
    "title": "Confidence measures for statistical machine translation"
}