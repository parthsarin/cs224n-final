{
    "article": "User language data can contain highly sensitive personal content. As such, it is imperative to offer users a strong and interpretable privacy guarantee when learning from their data. In this work, we propose SentDP: pure local differential privacy at the sentence level for a single user document. We propose a novel technique, DeepCandidate, that combines concepts from robust statistics and language modeling to produce high-dimensional, general-purpose \u03f5-SentDP document embeddings. This guarantees that any single sentence in a document can be substituted with any other sentence while keeping the embedding \u03f5-indistinguishable. Our experiments indicate that these private document embeddings are useful for downstream tasks like sentiment analysis and topic classification and even outperform baseline methods with weaker guarantees like word-level Metric DP. Introduction Language models have now become ubiquitous in NLP (Devlin et al., 2019; Liu et al., 2019b; Alsentzer et al., 2019) , pushing the state of the art in a variety of tasks (Strubell et al., 2018; Liu et al., 2019a; Mrini et al., 2021) . While language models capture meaning and various linguistic properties of text (Jawahar et al., 2019; Yenicelik et al., 2020) , an individual's written text can include highly sensitive information. Even if such details are not needed or used, sensitive information has been found to be vulnerable and detectable to attacks (Pan et al., 2020; Abdalla et al., 2020; Carlini et al., 2020) . Reconstruction attacks (Xie and Hong, 2021) have even successfully broken through private learning schemes that rely on encryption-type methods (Huang et al., 2020) . As of now, there is no broad agreement on what constitutes good privacy for natural language (Kairouz et al., 2019) . Huang et al. (2020) argue that different applications and models require different privacy definitions. Several emerging works propose to apply Metric Differential Privacy (Alvim et al., 2018) at the word level (Feyisetan et al., 2019; Feyisetan and Kasiviswanathan, 2021; Carvalho et al., 2021; Qu et al., 2021; Yue et al., 2021; Xu et al., 2021) . They propose to add noise to word embeddings, such that they are indistinguishable from their nearest neighbours. At the document level, however, the above definition has two areas for improvement. First, it may not offer the level of privacy desired. Having each word indistinguishable with similar words may not hide higher level concepts in the document, and may not be satisfactory for many users. Second, it may not be very interpretable or easy to communicate to end-users, since the privacy definition relies fundamentally on the choice of embedding model to determine which words are indistinguishable with a given word. This may not be a clear and precise enough for end-users to grasp. In this work, we propose a new privacy definition for documents: sentence privacy. This guarantee is both strong and interpretable: any sentence in a document must be indistinguishable with any other sentence. A document embedding is sentenceprivate if we can replace any single sentence in the document and have a similar probability of producing the same embedding. As such, the embedding only stores limited information unique to any given sentence. This definition is easy to communicate and strictly stronger than word-level definitions, as modifying a sentence can be changing one word. Although this definition is strong, we are able to produce unsupervised, general embeddings of documents that are useful for downstream tasks like sentiment analysis and topic classification. To achieve this we propose a novel privacy mechanism, DeepCandidate, which privately samples a high-dimensional embedding from a preselected set of candidate embeddings derived from public, non-private data. DeepCandidate works by first pretuning a sentence encoder on public data such that semantically different document embeddings are far apart from each other. Then, we approximate each candidate's Tukey Depth within the private documents' sentence embeddings. Deeper candidates are the most likely to be sampled to represent the private document. We evaluate DeepCandidate on three illustrative datasets, and show that these unsupervised private embeddings are useful for both sentiment analysis and topic classification as compared to baselines. In summary, this work makes the following contributions to the language privacy literature: Background and Related Work Setting. We denote a 'document' as a sequence of sentences. Let s \u2208 S be any finite-length sentence. Then, the space of all documents is X = S * and document x \u2208 X is written as x = (s 1 , s 2 , . . . , s k ) for any non-negative integer k of sentences. In this work, we focus on cohesive documents of sentences written together like reviews or emails, but our methods and guarantees apply to any sequence of sentences, such as a collection of messages written by an individual over some period of time. Our task is to produce an embedding z \u2208 R d of any document x \u2208 X such that any single sentence s i \u2208 x is indistinguishable with every other sentence s \u2032 i \u2208 S\\s i . That is, if one were to replace any single sentence in the document s i \u2208 x with any other sentence s \u2032 i \u2208 S\\s i , the probability of producing a given embedding z is similar. To achieve this, we propose a randomized embedding function (the embedding mechanism) M : X \u2192 R d , that generates a private embedding z = M(x) that is useful for downstream tasks. Differential Privacy The above privacy notion is inspired by Differential Privacy (DP) (Dwork, 2006) . It guarantees thatwhether an individual participates (dataset D) or not (dataset D \u2032 ) -the probability of any output only chances by a constant factor. Definition 2.1 (Differential Privacy). Given any pair of datasets D, D \u2032 \u2208 D that differ only in the information of a single individual, we say that the mechanism A : D \u2192 O, satisfies \u03f5-DP if Pr[A(D) \u2208 O] \u2264 e \u03f5 Pr[A(D \u2032 ) \u2208 O] for any event O \u2286 O. Note that we take probability over the randomness of the mechanism A only, not the data distribution. DP has several nice properties that make it easy to work with including closure under postprocessing, an additive privacy budget (composition), and closure under group privacy guarantees (guarantees to a subset of multiple participants). See Dwork et al. 2014 for more details. When our output space is a discrete and finite set of alternatives to choose from O = (o 1 , o 2 , . . . , o n ), we may use the exponential mechanism to satisfy \u03f5-DP (McSherry and Talwar, 2007) . To do so, we specify a utility function over input/output pairs, u : D \u00d7 O \u2192 R. Related Work Natural Language Privacy. Previous work has demonstrated that NLP models and embeddings are vulnerable to reconstruction attacks (Carlini et al., 2020; Abdalla et al., 2020; Pan et al., 2020) . In response there have been various efforts to design privacy-preserving techniques and definitions across NLP tasks. A line of work focuses on how to make NLP model training satisfy DP (Kerrigan et al., 2020; Bagdasaryan et al., 2019) . This is distinct from our work in that it satisfies central DP -where data is first aggregated non-privately and then privacy preserving algorithms (i.e. training) are run on that data. We model this work of the local version of DP (Dwork et al., 2006) , wherein each individual's data is made private before centralizing. Our definition guarantees privacy to a single document as opposed to a single individual. A line of work more comparable to our approach makes documents locally private by generating a randomized version of a document that satisfies some formal privacy definition. As with the private embedding of our work, this generates locally private representation of a given document x. The overwhelming majority of these methods satisfy an instance of Metric-DP (Alvim et al., 2018) at the word level (Feyisetan et al., 2019; Feyisetan and Kasiviswanathan, 2021; Carvalho et al., 2021; Qu et al., 2021; Yue et al., 2021; Xu et al., 2021) . As discussed in the introduction, this guarantees that a document x is indistinguishable with any other document x \u2032 produced by swapping a single word in x with a similar word. Two words are 'similar' if they are close in the word embeddings space (e.g. GloVe). This guarantee is strictly weaker than our proposed definition, SentDP, which offers indistinguishability to any two documents that differ in an entire sentence. Privacy-preserving embeddings. There is a large body of work on non-NLP privacy-preserving embeddings, as these embeddings have been shown to be vulnerable to attacks (Song and Raghunathan, 2020) . Li and Clifton (2021) attempt to generate locally private embeddings by bounding the embedding space, and we compare with this method in our experiments. Kamath et al. (2019) propose a method for privately publishing the average of embeddings, but their algorithm is not suited to operate on the small number of samples (sentences) a given document offers. Finally, Beimel et al. (2019) propose a method for privately learning halfspaces in R d , which is relevant to private Tukey Medians, but their method would restrict input examples (sentence embeddings) to a finite discrete set in R d , a restriction we cannot tolerate. Sentence-level Privacy We now introduce our simple, strong privacy definition, along with concepts we use to satisfy it. Definition In this work, we adopt the local notion of DP (Dwork et al., 2006) , wherein each individual's data is guaranteed privacy locally before being reported and centralized. Our mechanism M receives a single document from a single individual, x \u2208 X . We require that M provides indistinguishability between documents x, x \u2032 differing in one sentence. Definition 3.1 (Sentence Privacy, SentDP). Given any pair of documents x, x \u2032 \u2208 X that differ only in one sentence, we say that a mechanism M : X \u2192 O satisfies \u03f5-SentDP if Pr[M(x) \u2208 O] \u2264 e \u03f5 Pr[M(x \u2032 ) \u2208 O] for any event O \u2286 O. We focus on producing an embedding of the given document x, thus the output space is O = R d . For instance, consider the neighboring documents x = (s 1 , s 2 , . . . , s k ) and x \u2032 = (s 1 , s \u2032 2 , . . . , s k ) that differ in the second sentence, i.e. s 2 , s \u2032 2 can be any pair of sentences in S 2 . This is a strong notion of privacy in comparison to existing definitions across NLP tasks. However, we show that we can guarantee SentDP while still providing embeddings that are useful for downstream tasks like sentiment analysis and classification. In theory, a SentDP private embedding z should be able to encode any information from the document that is not unique to a small subset of sentences. For instance, z can reliably encode the sentiment of x as long as multiple sentences reflect the sentiment. By the group privacy property of DP, which SentDP maintains, two documents differing in a sentences are a\u03f5 indistinguishable. So, if more sentences reflect the sentiment, the more M can encode this into z without compromising on privacy. Sentence Mean Embeddings Our approach is to produce a private version of the average of general-purpose sentence embeddings. By the post-processing property of DP, this embedding can be used repeatedly in any fashion desired without degrading the privacy guarantee. Our method makes use of existing pre-trained sentence encoding models. We denote this general sentence encoder as G : S \u2192 R d . We show in our experiments that the mean of sentence embeddings, g(x) = s i \u2208x G(s i ) , (1) maintains significant information unique to the document and is useful for downstream tasks like classification and sentiment analysis. We call g(x) the document embedding since it summarizes the information in document x. While there exist other definitions of document embeddings (Yang et al., 2016; Thongtan and Phienthrakul, 2019; Bianchi et al., 2020) , we decide to use averaging as it is a simple and established embedding technique (Bojanowski et al., 2017; Gupta et al., 2019; Li et al., 2020) . Tukey Depth Depth is a concept in robust statistics used to describe how central a point is to a distribution. We borrow the definition proposed by Tukey (1975): Definition 3.2. Given a distribution P over R d , the Tukey Depth of a point y \u2208 R d is TD P (y) = inf w\u2208R d P {y \u2032 : w \u2022 (y \u2032 \u2212 y) \u2265 0} . In other words, take the hyperplane orthogonal to vector w, h w , that passes through point y. Let P w 1 be the probability under P that a point lands on one side of h w and let P w 2 be the probability that a point lands on the other side, so P w 1 +P w 2 = 1. y is considered deep if min(P w 1 , P w 2 ) is close to a half for all vectors w (and thus all h passing through y). The Tukey Median of distribution P , T MED (P ), is the set of all points with maximal Tukey Depth, T MED (P ) = arg max y\u2208R d TD P (y) . (2) We TD Y (y) = inf w\u2208R d |{y \u2032 \u2208 Y : w \u2022 (y \u2032 \u2212 y) \u2265 0}| , and the median, T MED (Y ), maximizes the depth and is at most half the size of our sample n 2 . Generally, finding a point in T MED (Y ) is hard; SOTA algorithms have an exponential dependency in dimension (Chan, 2004) , which is a non-starter when working with high-dimensional embeddings. However, there are efficient approximations which we will take advantage of. DeepCandidate While useful and general, the document embedding g(x) does not satisfy SentDP. We now turn to describing our privacy-preserving technique, DeepCandidate, which generates general, \u03f5-SentDP document embeddings that preserve relevant information in g(x), and are useful for downstream tasks. To understand the nontrivial nature of this problem, we first analyze why the simplest, straightfoward approaches are insufficient. Motivation. Preserving privacy for high dimensional objects is known to be challenging (Kamath et al., 2019; Feyisetan and Kasiviswanathan, 2021; Zhou et al., 2009) . For instance, adding Laplace noise directly to g(x), as done to satisfy some privacy definitions (Feyisetan et al., 2019; Alvim et al., 2018) , does not guarantee SentDP for any \u03f5. Recall that the embedding space is all of R d . A change in one sentence can lead to an unbounded change in g(x), since we do not put any restrictions on the general encoder G. Thus, no matter how much noise we add to g(x) we cannot satisfy SentDP. A straightforward workaround might be to simply truncate embeddings such that they all lie in a limited set such as a sphere or hypercube as done in prior work (Li and Clifton, 2021; Abadi et al., 2016) . In doing so, we bound how far apart embeddings can be for any two sentences, \u2225G(s i ) \u2212 G(s \u2032 i )\u2225 1 , thus allowing us to satisfy SentDP by adding finite variance noise. However, such schemes offer poor utility due to the high dimensional nature of useful document embeddings (we confirm this in our experiments). We must add noise with standard deviation proportional to the dimension of the embedding, thus requiring an untenable degree of noise for complex encoders like BERT which embed into R 768 . Our method has three pillars: (1) sampling from a candidate set of public, non-private document embeddings to represent the private document, (2) using the Tukey median to approximate the document embedding, and (3) pre-training the sentence encoder, G, to produce relevant candidates with high Tukey depth for private document x. Taking advantage of public data: sampling from candidates Instead of having our mechanism select a private embedding z from the entire space of R d , we focus the mechanism to select from a set of m candidate embeddings, F , generated by m public, nonprivate documents. We assume the document x is drawn from some distribution \u00b5 over documents X . For example, if we know x is a restaurant review, \u00b5 may be the distribution over all restaurant reviews. F is then a collection of document embeddings over m publicly accessible documents x i \u223c \u00b5, F = {f i = g(x i ) : x 1 , . . . , x m iid \u223c \u00b5} , and denote the corresponding distribution over f i as g(\u00b5). By selecting documents F to be similar in nature to the private document x, we inject an advantageous inductive bias into our mechanism, which is critical to satisfy strong privacy while preserving meaningful information relevant to x. Approximating the document embedding: The Tukey Median We now propose a novel mechanism M TD , which approximates g(x) by sampling a candidate embedding from F . M TD works by concentrating probability on candidates with high Tukey Depth w.r.t. the set of sentence embeddings S x = {G(s i ) : s i \u2208 x}. We model sentences s i from document x as i.i.d. draws from distribution \u03bd x . Then, S x is k draws from g(\u03bd x ), the distribution of sentences from \u03bd x passing through G. Deep points are a good approximation of the mean under light assumptions. If g(\u03bd x ) belongs to the set of halfspace-symmetric distributions (including all elliptic distributions e.g. Gaussians), we know that its mean lies in the Tukey Median (Zhu et al., 2020) . Formally, M TD is an instance of the exponential mechanism (Definition 2.2), and is defined by its utility function. We set the utility of a candidate document embedding f i \u2208 F to be an approximation of its depth w.r.t. sentence embeddings S x , u(x, f i ) = TD Sx (f i ) . (3) The approximation TD Sx , which we detail in the Appendix, is necessary for computational efficiency. If the utility of f i is high, we call it a 'deep candidate' for sentence embeddings S x . The more candidates sampled (higher m), the higher the probability that at least one has high depth. Without privacy, we could report the deepest candidate, z = arg max f i \u2208F TD Sx (f i ). However, when preserving privacy with M TD , increasing m has diminishing returns. To see this, fix a set of sentence embeddings S x for document x and the i.i.d. distribution over candidate embeddings f i \u223c g(\u00b5). This induces a multinomial distribution over depth, u j (x) = Pr[u(x, f i ) = j], \u230a k 2 \u230b j=0 u j (x) = 1 , where randomness is taken over draws of f i . For candidate set F and sentence embeddings S x , the probability of M TD 's selected candidate, z, having (approximated) depth j * is given by Pr[u(x, z) = j * ] = a j * (x)e \u03f5j * /2 \u230a k 2 \u230b j=0 a j (x)e \u03f5j/2 (4) where a j (x) is the fraction of candidates in F with depth j w.r.t. the sentence embeddings of document x, S x . For m sufficiently large, a j (x) concentrates around u j (x), so further increasing m does not increase the probability of M TD sampling a deep candidate. For numerical intuition, suppose m = 5000 (as in our experiments), \u2265 b candidates have depth \u2265 j * , and all other candidates have depth 0, M TD will sample one of these deep candidates w.p. \u2265 0.95 under the settings in Table 1 . For low \u03f5 < 10 (high privacy), about 1% of candidates need to have high depth (\u2265 3) in order to be  reliably sampled. Note that this is only possible for documents with \u2265 6 sentences. For higher \u03f5 \u2265 10, M TD will reliably sample low depth candidates even if there are only a few. From these remarks we draw two insights on how DeepCandidate can achieve high utility. (1) More sentences A higher k enables greater depth, and thus a higher probability of sampling deep candidates with privacy. We explore this effect in our experiments. (2) Tuned encoder By tuning the sentence encoder G for a given domain, we can modify the distribution over document embeddings g(\u00b5) and sentence embeddings g(\u03bd x ) to encourage deep candidates (high probability u j for deep j) that are relevant to document x. Taking advantage of structure: cluster-preserving embeddings So far, we have identified that deep candidates from F can approximate g(x). To produce a good approximation, we need to ensure that 1) there reliably exist deep candidates for any given set of sentence embeddings S x , and 2) that these deep candidates are good representatives of document x. The general sentence encoder G used may not satisfy this 'out of the box'. If the distribution on document embeddings g(\u00b5) is very scattered around the instance space R 768 , it can be exceedingly unlikely to have a deep candidate f i among sentence embeddings S x . On the other hand, if distribution g(\u00b5) is tightly concentrated in one region (e.g. 'before training' in Figure 3 ), then we may reliably have many deep candidates, but several will be poor representatives of the document embedding g(x). To prevent this, we propose an unsupervised, efficient, and intuitive modification to the (pretrained) sentence encoder G. We freeze the weights of G and add additional perceptron layers mapping into the same embeddings space H : R d \u2192 R d , producing the extended encoder G \u2032 = H \u2022 G. Broadly, we train H to place similar document embeddings close together, and different embeddings far part. To do so, we leverage the assumption that a given domain's distribution over document embeddings g(\u00b5) can be parameterized by n c clusters, visualized as the black circles in Figure 3 . H's aim is to recode sentence embeddings such that document embedding clusters are preserved, but spaced apart from each other. By preserving clusters, we are more likely to have deep candidates (increased probability u j for high depth j). By spacing clusters apart, these deep candidates are more likely to come from the same or a nearby cluster as document x, and thus be good representatives. Note that H is domain-specific: we train separate H encoders for each dataset. Sampling Algorithm The final component of DeepCandidate is computing the approximate depth of a candidate for use as utility in the exponential mechanism as in Eq. (3). We use a version of the approximation algorithm proposed in Gilad-Bachrach and Burges 2012. Intuitively, our algorithm computes the onedimensional depth of each f i among x's sentence embeddings S x on each of p random projections. The approximate depth of f i is then its lowest depth across the p projections. We are guaranteed that TD Sx (f i ) \u2265 TD Sx (f i ). Due to space constraints, we leave the detailed description of the algorithm for the Appendix.  only change depth of f i by one). We expand on this, too, in the Appendix. Experiments Datasets We produce private, general embeddings of documents from three English-language datasets: Good Reads (Wan and McAuley, 2018) 60k book reviews from four categories: fantasy, history, romance, and literature.  20 News Groups (Lang, 1995) 11239 correspondences from 20 different affinity groups. Due to similarity between several groups (e.g. comp.os.ms-windows.misc and comp.sys.ibm.pc.hardware), the dataset is partitioned into nine categories. Train-6743k | Val-2247k | Test-2249k IMDB (Maas et al., 2011) 29k movie reviews from the IMDB database, each labeled as a positive or negative review.  To evaluate utility of these unsupervised, private embeddings, we check if they are predictive of document properties. For the Good Reads and 20 News Groups datasets, we evaluate how useful the embeddings are for topic classification. For IMDB we evaluate how useful the embeddings are for sentiment analysis (positive or negative review). Our metric for performance is test-set macro F 1 score. Training Details & Setup For the general encoder, G : S \u2192 R 768 , we use SBERT (Reimers and Gurevych, 2019) , a version of BERT fine-tuned for sentence encoding. Sentence embeddings are generated by mean-pooling output tokens. In all tasks, we freeze the weights of SBERT. The cluster-preserving recoder, H, as well as every classifier is implemented as an instance of a 4-layer MLP taking 768-dimension inputs and only differing on output dimension. We denote an instance of this MLP with output dimension o as MLP o . We run 5 trials of each experiment with randomness taken over the privacy mechanisms, and plot the mean along with a \u00b1 1 standard deviation envelope. DeepCandidate: The candidate set F consists of 5k document embeddings from the training set, each containing at least 8 sentences. To train G \u2032 , we find n c = 50 clusters with k-means. We train a classifier C dc = MLP r on document embeddings g \u2032 (x) to predict class, where r is the number of classes (topics or sentiments). Baselines We compare the performance of DeepCandidate with 4 baselines: Non-private, Truncation, Wordlevel Metric-DP, and Random Guesser. Non-private: This demonstrates the usefulness of non-private sentence-mean document embeddings g(x). We generate g(x) for every document using SBERT, and then train a classifier C nonpriv = MLP r to predict x's label from g(x). Truncation: We adopt the method from Li and Clifton 2021 to truncate (clip) sentence embeddings within a box in R 768 , thereby bounding sensitivity as described at the beginning of Section 4. Laplace noise is then added to each dimension. Documents with more sentences have proportionally less noise added due to the averaging operation reducing sensitivity. Word Metric-DP (MDP): The method from Feyisetan et al. 2019 satisfies \u03f5-word-level metric DP by randomizing words. We implement MDP to produce a randomized document x \u2032 , compute g(x \u2032 ) with SBERT, and predict class using C nonpriv . Random Guess: To set a bottom-line, we show the theoretical performance of a random guesser only knowing the distribution of labels. Results & Discussion How does performance change with privacy parameter \u03f5? This is addressed in Figures 4a to 4c . Here, we observe how the test set macro F 1 score changes with privacy parameter \u03f5 (a lower \u03f5 offers stronger privacy). Generally speaking, for local differential privacy, \u03f5 < 10 is taken to be a strong privacy regime, 10 \u2264 \u03f5 < 20 is moderate privacy, and \u03f5 \u2265 25 is weak privacy. The truncation baseline mechanism does increase accuracy with increasing \u03f5, but never performs much better than the random guesser. This is to be expected with high dimension embeddings, since the standard deviation of noise added increases linearly with dimension. The word-level MDP mechanism performs significantly better than truncation, achieving relatively good performance for \u03f5 \u2265 30. There are two significant caveats, however. First, is the privacy definition: as discussed in the Introduction, for the same \u03f5, word-level MDP is strictly weaker than SentDP. The second caveat is the level of \u03f5 at which privacy is achieved. Despite a weaker privacy definition, the MDP mechanism does not achieve competitive performance until the weakprivacy regime of \u03f5. We suspect this is due to two reasons. First, is the fact that the MDP mechanism does not take advantage of contextual information in each sentence as our technique does; randomiz-ing each word independently does not use higher level linguistic information. Second, is the fact that the MDP mechanism does not use domainspecific knowledge as our mechanism does with use of relevant candidates and domain specific sentence encodings. In comparison, DeepCandidate offers strong utility across tasks and datasets for relatively low values of \u03f5, even into the strong privacy regime. Beyond \u03f5 = 25, the performance of DeepCandidate tends to max out, approximately 10-15% below the non-private approach. This is due to the fact that DeepCandidate offers a noisy version of an approximation of the document embedding g(x) -it cannot perform any better than deterministically selecting the deepest candidate, and even this candidate may be a poor representative of x. We consider this room for improvement, since there are potentially many other ways to tune G \u2032 and select the candidate pool F such that deep candidates are nearly always good representatives of a given document x. How does performance change with the number of sentences k? This is addressed in Figures 4d to 4f. We limit the test set to those documents with k in the listed range on the x-axis. We set \u03f5 = 10, the limit of the strong privacy regime. Neither baseline offers performance above that of the random guesser at this value of \u03f5. DeepCandidate produces precisely the performance we expect to see: documents with more sentences result in sampling higher quality candidates, confirming the insights of Section 4.2. Across datasets and tasks, documents with more than 10-15 sentences tend to have high quality embeddings. Conclusions and Future Work We introduce a strong and interpretable local privacy guarantee for documents, SentDP, along with DeepCandidate, a technique that combines principles from NLP and robust statistics to generate general \u03f5-SentDP embeddings. Our experiments confirm that such methods can outperform existing approaches even with with more relaxed privacy guarantees. Previous methods have argued that it is \"virtually impossible\" to satisfy pure local DP (Feyisetan et al., 2019; Feyisetan and Kasiviswanathan, 2021 ) at the word level while capturing linguistic semantics. Our work appears to refute this notion at least at the document level. To follow up, we plan to explore other ap-proaches (apart from k-means) of capturing the structure of the embedding distribution g(\u00b5) to encourage better candidate selection. We also plan to experiment with decoding private embeddings back to documents by using novel candidates produced by a generative model trained on F . A.2 Proof of Privacy Theorem 4.1 M TD satisfies \u03f5-Sentence Privacy Proof. It is sufficient to show that the sensitivity, \u2206u = max x,x \u2032 ,f i |u(x, f i ) \u2212 u(x \u2032 , f i )| \u2264 1 . Let us expand the above expression using the terms in Algorithm 1. \u2206u = max x,x \u2032 ,f i | max j\u2208[p] u j (x, f i ) \u2212 max j \u2032 \u2208[p] u j \u2032 (x \u2032 , f i )| = max x,x \u2032 ,f i | min j\u2208[p] h j (x, f i ) \u2212 k 2 \u2212 min j \u2032 \u2208[p] h j \u2032 (x \u2032 , f i ) \u2212 k 2 | \u2264 max f i | min j\u2208[p] h j (x, f i ) \u2212 k 2 \u2212 min j \u2032 \u2208[p] h j \u2032 (x, f i ) \u2212 k 2 \u2212 1 | \u2264 1 Algorithm 1: M TD compute f j i \u2190 f \u22ba i v j 11 / * Compute depth of fi on projection vj * / 12 h j (x, f i ) \u2190 #{s j l : s j l \u2265 f j i , l \u2208 [k]} 13 u j (x, f i ) \u2190 \u2212 h j (x, f i ) \u2212 k 2 14 end for 15 u(x, f i ) \u2190 max j\u2208[p] u j (x, f i ) Pf i \u2190 exp(\u03f5u(x, f i )/2) 16 end for 17 \u03a8 \u2190 m i=1 Pf i 18 for i \u2208 [m] do 19 P f i \u2190 1 \u03a8 Pf i 20 end for 21 return P F The last step follows from the fact that |h j (x, f i ) \u2212 h j (x \u2032 , f i )| \u2264 1 for all j \u2208 [p]. In other words, by modifying a single sentence embedding, we can only change the number of embeddings greater than f j i on projection j by 1. So, the distance of h j (x, f i ) from k 2 can only change by 1 on each projection. In the 'worst case', the distance h j (x, f i ) \u2212 k 2 reduces by 1 on every projection v j . Even then, the minimum distance from k 2 across projections (the worst case depth) can only change by 1, giving us a sensitivity of 1. A.3 Experimental Details Here, we provide an extended, detailed version of section 5. For the general encoder, G : S \u2192 R 768 , we use SBERT (Reimers and Gurevych, 2019) , a version of BERT fine-tuned for sentence encoding. Sentence embeddings are generated by mean-pooling output tokens. In all tasks, we freeze the weights of SBERT. The cluster-preserving recoder, H, as well as every classifier is implemented as an instance of a 4-layer MLP taking 768-dimension inputs and only differing on output dimension. We denote an instance of this MLP with output dimension o as MLP o . We run 5 trials of each experiment with randomness taken over the privacy mechanisms, and plot the mean along with a \u00b1 1 standard deviation envelope. Non-private: For our non-private baseline, we demonstrate the usefulness of sentence-mean document embeddings. First, we generate the document embeddings g(x i ) for each training, validation, and test set document using SBERT, G. We then train a classifier C nonpriv = MLP r to predict each document's topic or sentiment, where r is the number of classes. The number of training epochs is determined with the validation set. DeepCandidate: We first collect the candidate set F by sampling 5k document embeddings from the subset of the training set containing at least 8 sentences. We run k-means with n c = 50 cluster centers, and label each training set document embedding t i \u2208 T G with its cluster. The sentence recoder, H = MLP 768 is trained on the training set along with the linear model L with the Adam optimizer and cross-entropy loss. For a given document x, its sentence embeddings S x are passed through H, averaged together, and then passed to L to predict x's cluster. L's loss is then back-propagated through H. A classifier C dc = MLP r is trained in parallel using a separate instance of the Adam optimizer to predict class from the recoded embeddings, where r is the number of classes (topics or sentiments). The number of training epochs is determined using the validation set. At test time, (generating private embeddings using M TD ), the optimal number of projections p is empirically chosen for each \u03f5 using the validation set. Truncation: The truncation baseline (Li and Clifton, 2021) requires first constraining the embedding instance space. We do so by computing the 75% median interval on each of the 768 dimensions of training document embeddings T G . Sentence embeddings are truncated at each dimension to lie in this box. In order to account for this distribution shift, a new classifier C trunc = MLP r is trained on truncated mean embeddings to predict class. The number of epochs is determined with the validation set. At test time, a document's sentence embeddings S x are truncated and averaged. We then add Laplace noise to each dimension with scale factor 768w k\u03f5 , where w is the width of the box on that dimension (sensitivity in DP terms). Note that the standard deviation of noise added is inversely proportional to the number of sentences in the document, due to the averaging operation reducing sensitivity. Word Metric-DP: Our next baseline satisfies \u03f5word-level metric DP and is adopted from (Feyisetan et al., 2019) . The corresponding mechanism MDP : X \u2192 X takes as input a document x and returns a private version, x \u2032 , by randomizing each word individually. For comparison, we generate document embeddings by first randomizing the document x \u2032 = MDP(x) as prescribed by (Feyisetan et al., 2019) , and then computing its document embedding g(x \u2032 ) using SBERT. At test time, we classify the word-private document embedding using C nonpriv . Random Guess: To set a bottom-line, we show the theoretical performance of a random guesser. The guesser chooses class i with probability q i equal to the fraction of i labels in the training set. The performance is then given by r i=1 q 2 i . A.4 Reproducability Details We plan to publish a repo of code used to generate the exact figures in this paper (random seeds have been set) with the final version. Since we do Acknowledgements KC and CM would like to thank ONR under N00014-20-1-2334. KM gratefully acknowledges funding from an Amazon Research Award and Adobe Unrestricted Research Gifts. We would would also like to thank our reviewers for their insightful feedback. A Appendix A.1 Privacy Mechanism We now describe in detail our instance of the exponential mechanism M TD . Recall from Definition 2.2 that the exponential mechanism samples candidate f i \u2208 F with probability Thus, M TD is fully defined by its utility function, which, as listed in Equation ( 3 ), is approximate Tukey Depth, We now describe our approximation algorithm of Tukey Depth TD Sx (f i ), which is an adaptation of the general median hypothesis algorithm proposed by Gilad-Bachrach and Burges (2012) . Note that we can precompute the projections on line 10. The runtime is O(mkp): for each of m candidates and on each of p projections, we need to compute the scalar difference with k sentence embeddings. Sampling from the multinomial distribution defined by P F then takes O(m) time. Additionally note from lines 13 and 15 that utility has a maximum of 0 and a minimum of \u2212 k 2 , which is a semantic change from the main paper where maximum utility is k 2 and minimum is 0. not train the BERT base model G, our algorithms and training require relatively little computational resouces. Our system includes a single Nvidia GeForce RTX 2080 GPU and a single Intel i9 core. All of our models complete an epoch training on all datasets in less than one minute. We never do more than 20 epochs of training. All of our classifier models train (including linear model) have less than 11 million parameters. The relatively low amount of parameters is due to the fact that we freeze the underlying language model. The primary hyperparameter tuned is the number of projections p. We take the argmax value on the validation set between 10 and 100 projections. We repeat this for each value of \u03f5. Dataset preprocessing: For all datasets, we limit ourselves to documents with at least 2 sentences. IMDB: This dataset has pre-defined train/test splits. We use the entire training set and form the test set by randomly sampling 4,000 from the test set provided. We do this for efficiency in computing the Metric-DP baseline, which is the slowest of all algorithms performed. Since the Metric-DP baseline randomizes first, we cannot precompute the sentence embeddings G(s i ) -we need to compute the sentence embeddings every single time we randomize. Since we randomize for each sentence of each document at each \u03f5 and each k over 5 trials -this takes a considerable amount of time. Good Reads: 20 News Groups: We preprocess this dataset to remove all header information, which may more directly tell information about document class, and only provide the model with the sentences from the main body. We use the entire dataset, and form the Train/Val/Test splits by random sampling.",
    "abstract": "User language data can contain highly sensitive personal content. As such, it is imperative to offer users a strong and interpretable privacy guarantee when learning from their data. In this work, we propose SentDP: pure local differential privacy at the sentence level for a single user document. We propose a novel technique, DeepCandidate, that combines concepts from robust statistics and language modeling to produce high-dimensional, general-purpose \u03f5-SentDP document embeddings. This guarantees that any single sentence in a document can be substituted with any other sentence while keeping the embedding \u03f5-indistinguishable. Our experiments indicate that these private document embeddings are useful for downstream tasks like sentiment analysis and topic classification and even outperform baseline methods with weaker guarantees like word-level Metric DP.",
    "countries": [
        "United States"
    ],
    "languages": [
        "English"
    ],
    "numcitedby": "0",
    "year": "2022",
    "month": "May",
    "title": "Sentence-level Privacy for Document Embeddings"
}