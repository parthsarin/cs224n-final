{
    "article": "Nous pr\u00e9sentons dans cet article la m\u00e9thodologie de constitution et les caract\u00e9ristiques du corpus Sequoia, un corpus en fran\u00e7ais, syntaxiquement annot\u00e9 d'apr\u00e8s un sch\u00e9ma d'annotation tr\u00e8s proche de celui du French Treebank (Abeill\u00e9 et Barrier, 2004) , et librement disponible, en constituants et en d\u00e9pendances. Le corpus comporte des phrases de quatre origines : Europarl fran\u00e7ais, le journal l'Est R\u00e9publicain, Wikip\u00e9dia Fr et des documents de l'Agence Europ\u00e9enne du M\u00e9dicament, pour un total de 3204 phrases et 69246 tokens. En outre, nous pr\u00e9sentons une application de ce corpus : l'\u00e9valuation d'une technique d'adaptation d'analyseurs syntaxiques probabilistes \u00e0 des domaines et/ou genres autres que ceux du corpus sur lequel ces analyseurs sont entra\u00een\u00e9s. Cette technique utilise des clusters de mots obtenus d'abord par regroupement morphologique \u00e0 l'aide d'un lexique, puis par regroupement non supervis\u00e9, et permet une nette am\u00e9lioration de l'analyse des domaines cibles (le corpus Sequoia), tout en pr\u00e9servant le m\u00eame niveau de performance sur le domaine source (le FTB), ce qui fournit un analyseur multi-domaines, \u00e0 la diff\u00e9rence d'autres techniques d'adaptation comme le self-training. Introduction L'analyse syntaxique statistique a fait de grands progr\u00e8s ces quinze derni\u00e8res ann\u00e9es, avec de tr\u00e8s nombreux travaux, majoritairement sur l'anglais, fond\u00e9s sur un apprentissage sur les sections du Wall Street Journal du Penn Treebank (Marcus et al., 1993) . D'autres langues ont b\u00e9n\u00e9fici\u00e9 de ces avanc\u00e9es, \u00e0 la condition, de taille, que soit disponible pour ces langues un corpus arbor\u00e9, en constituants ou en d\u00e9pendances. Cependant, les analyseurs ainsi obtenus, appris sur un corpus bien pr\u00e9cis, ont leur performance maximale sur des textes similaires \u00e0 ce corpus, mais sont peu robustes : ils montrent une qualit\u00e9 nettement d\u00e9grad\u00e9e lorqu'ils sont \u00e9valu\u00e9s sur des textes de domaine ou genre diff\u00e9rents. C'est particuli\u00e8rement vrai pour l'anglais, car le WSJ montre peu de vari\u00e9t\u00e9 de th\u00e8mes : (McClosky et al., 2006) rapporte que l'analyseur de Charniak (Charniak, 2000) obtient une F-mesure en constituants label\u00e9s de 89.7% sur la section de test du WSJ, mais chute \u00e0 82.9% sur le corpus de test du Brown corpus (Francis et Kucera, 1964) , corpus anglais de genres vari\u00e9s. Pour le fran\u00e7ais, le French Treebank (ci-apr\u00e8s FTB) (Abeill\u00e9 et Barrier, 2004 ) a servi de corpus d'entra\u00eenement pour des analyseurs initialement d\u00e9velopp\u00e9s pour l'anglais (voir (Seddah et al., 2009) pour une comparaison de plusieurs analyseurs en constituants, et (Candito et al., 2010b) pour une comparaison d'analyseurs en d\u00e9pendances, pour le fran\u00e7ais). Le FTB est un corpus de phrases du journal Le Monde, annot\u00e9es en morphologie et en constituants. Les \u00e9valuations disponibles des analyseurs appris sur le FTB sont dites intra-domaine : elles sont classiquement faites sur une partie du FTB, non vue \u00e0 l'apprentissage. Les \u00e9valuations dites hors-domaine, c'est-\u00e0-dire simplement sur des phrases d'origine diff\u00e9rente de celles du corpus d'apprentissage se heurtent \u00e0 l'absence de corpus annot\u00e9s dans le m\u00eame sch\u00e9ma que le FTB. Le corpus EASy (Paroubek et al., 2005) comprend des phrases de domaines et genres textuels divers, mais son format mixte entre constituants (chunks) et d\u00e9pendances (d\u00e9pendances entre chunks) rend difficile l'\u00e9valuation des performances d'un analyseur en constituants sur ces textes. Pour cette raison, nous avons entrepris l'annotation syntaxique de quatre corpus en suivant, \u00e0 quelques exceptions pr\u00e8s, le sch\u00e9ma d'annotation du FTB, regroup\u00e9s sous le nom de corpus Sequoia 1 . Nous pr\u00e9sentons ici la m\u00e9thodologie d'annotation et les caract\u00e9ristiques du corpus arbor\u00e9 obtenu, ainsi que l'application sur ces corpus d'une m\u00e9thode d'adaptation \u00e0 de nouveaux domaines d'un analyseur statistique appris sur le FTB 2 . Si l'objectif premier est de pouvoir tester et am\u00e9liorer la robustesse d'analyseurs statistiques, ces corpus, librement disponibles 3 , sont utilisables \u00e0 d'autres fins, en particulier pour des \u00e9tudes linguistiques. Nous d\u00e9crivons section 2 la m\u00e9thodologie d'annotation et les caract\u00e9ristiques du corpus, puis section 3 la m\u00e9thode d'adaptation d'analyseur et les travaux ant\u00e9rieurs dans ce domaine, et en section 4 les exp\u00e9riences r\u00e9alis\u00e9es et les r\u00e9sultats obtenus. Enfin nous concluons en section 5. Les corpus Sequoia Origine et m\u00e9thode de s\u00e9lection Le corpus Sequoia comporte des phrases ou textes de quatre origines diff\u00e9rentes : l'agence europ\u00e9enne du m\u00e9dicament, Europarl, le journal r\u00e9gional l'Est R\u00e9publicain et Wikipedia Fr. Le choix de ces quatre origines est en partie conjoncturel, car li\u00e9 \u00e0 la disponibilit\u00e9 des corpus : nous avons en effet eu le souci que les corpus soient librement disponibles, et qu'ils offrent une 1. Du nom du projet (SEQUOIA ANR-08-EMER-013) ayant financ\u00e9 l'annotation manuelle. 2. Cet article \u00e9tend un article court publi\u00e9 \u00e0 IWPT 2011 (Candito et al., 2011) , relatant des exp\u00e9riences d'adaptation d'analyseurs sur un des quatre sous-corpus aujourd'hui disponibles. 3. https ://www.rocq.inria.fr/alpage-wiki/tiki-index.php ?page=CorpusSequoia diversit\u00e9 variable par rapport au genre journalistique du FTB (diversit\u00e9 \u00e9valu\u00e9e a priori, non pr\u00e9cis\u00e9ment). D'autres crit\u00e8res ont guid\u00e9 notre choix, comme l'existence d'autres annotations pour les phrases s\u00e9lectionn\u00e9es et la disponibilit\u00e9 de gros volume de corpus brut de m\u00eame origine, en vue d'exp\u00e9riences d'apprentissage semi-supervis\u00e9. Domaine m\u00e9dical Nous avons s\u00e9lectionn\u00e9 le domaine m\u00e9dical comme domaine potentiellement tr\u00e8s \u00e9loign\u00e9 de celui du FTB. Plus pr\u00e9cis\u00e9ment, nous avons retenu deux documents provenant de la partie en fran\u00e7ais du corpus EMEA, lui-m\u00eame inclus dans le corpus OPUS (Tiedemann, 2009) Annotation morpho-syntaxique Sch\u00e9ma d'annotation Choix linguistiques Notre objectif est d'obtenir des corpus compatibles avec le FTB, et donc en suivant les choix linguistiques du FTB, caract\u00e9ris\u00e9 comme un sch\u00e9ma syntagmatique surfacique, avec des annotations fonctionnelles pour les d\u00e9pendants des verbes. Ainsi avons-nous suivi autant que possible les guides d'annotation du FTB (Abeill\u00e9 et Cl\u00e9ment, 2006; Abeill\u00e9 et al., 2004; Abeill\u00e9, 2004) . (NC valeurs) (PP (P d') (NP (NC ACT)))))))) (PONCT ,) (NP-SUJ (DET le) (NC produit) (VPpart (VPP reconstitu\u00e9) (COORD (CC et) (VPpart (VPP dilu\u00e9))))) (VN (V doit)) (VPinf-OBJ (VN (VINF \u00eatre) (ADV bien) (VPP m\u00e9lang\u00e9))) (COORD (CC puis) (VN (V doit)) (VPinf (VN (VINF \u00eatre) (VPP administr\u00e9)) (PP-MOD (P en) (NP (NC bolus))) (PP-MOD (P par) (NP (NC pouss\u00e9e) (AP (ADJ intraveineuse)) (AP (ADJ rapide)))))) (PONCT .))) Le jeu de cat\u00e9gories morpho-syntaxiques que nous utilisons est celui mis ou point par (Crabb\u00e9 et Candito, 2008) Conversion en d\u00e9pendances Le corpus annot\u00e9 en constituants a \u00e9t\u00e9 automatiquement converti en d\u00e9pendances en utilisant le convertisseur d\u00e9velopp\u00e9 pour la conversion automatique du FTB (Candito et al., 2010a) . Au final, le corpus Sequoia est donc disponible sous deux formes : un format parenth\u00e9s\u00e9 annot\u00e9 en constituants 10 d\u00e9cor\u00e9 de fonctions syntaxiques, et un format tabul\u00e9 CoNLL 11 pour la version en d\u00e9pendances label\u00e9es. M\u00e9thodologie d'annotation Pour obtenir le corpus Sequoia, nous avons proc\u00e9d\u00e9 en alternant traitements automatiques et validation de ces traitements pour passer \u00e0 l'\u00e9tape suivante. A toutes les \u00e9tapes (segmentation, tagging, parsing, annotations des fonctions), les annotations pr\u00e9c\u00e9dentes pouvaient \u00eatre remises en cause. La s\u00e9quence a \u00e9t\u00e9 la suivante : -Pr\u00e9traitements automatiques : Segmentation en phrases, reconnaissance hors contexte de compos\u00e9s et tokenisation via l'outil Bonsai 12 -Etiquetage morpho-syntaxique en utilisant le tagger MElt (Denis et Sagot, 2009) -Validation manuelle en \u00e9diteur simple, par un seul annotateur expert, du tagging, de la segmentation en phrases, et de la reconnaissance de compos\u00e9s -Pour tous les sous-corpus sauf EMEA : Analyse syntagmatique automatique au moyen de deux parsers statistiques diff\u00e9rents, en guidant les analyseurs avec les tags manuellement valid\u00e9s : les analyses doivent se conformer aux cat\u00e9gories fournies en entr\u00e9e. Les analyseurs sont le parser de Berkeley (Petrov et Klein, 2007) et l'analyseur de Charniak (Charniak, 2000) , tous deux adapt\u00e9s et entra\u00een\u00e9s sur le FTB. Pour EMEA : la validation syntaxique a \u00e9t\u00e9 faite par un annotateur expert. -Validation manuelle ind\u00e9pendante des deux sorties d'analyseurs, via l'outil graphique Word-Freak (Morton et LaCivita, 2003) adapt\u00e9 pour le tagset et le jeu de fonctions du FTB, puis adjudication. -Annotation automatique des fonctions des d\u00e9pendants des verbes finis, en utilisant l'annotateur en fonctions int\u00e9gr\u00e9 \u00e0 Bonsai -Validation manuelle des annotations fonctionnelles par deux annotateurs ind\u00e9pendamment, via WordFreak, puis adjudiction. -V\u00e9rifications syst\u00e9matiques par un expert de points rep\u00e9r\u00e9s comme difficiles 13 ; v\u00e9rification syst\u00e9matique de la coh\u00e9rence du traitement des compos\u00e9s. Evaluation de l'annotation Pour \u00e9valuer l'accord inter-annotateurs, et la distance au corpus de r\u00e9f\u00e9rence apr\u00e8s adjudication et v\u00e9rifications syst\u00e9matiques, nous utilisons l'outil Evalb servant habituellement \u00e0 l'\u00e9valuation des sorties d'un analyseur par rapport \u00e0 des analyses de r\u00e9f\u00e9rence. (Crabb\u00e9 et Candito, 2008) en corpus de test (1235 premi\u00e8res phrases), corpus de d\u00e9veloppement (1235 phrases suivantes) et 9881 phrases restantes comme corpus d'apprentissage. Le corpus original XML est pr\u00e9trait\u00e9 tel que d\u00e9crit dans (Candito et Crabb\u00e9, 2009) . En particulier les compos\u00e9s nominaux et verbaux syntaxiquement r\u00e9guliers sont d\u00e9faits et repr\u00e9sent\u00e9s syntagmatiquement, et chaque occurrence de compos\u00e9 restante trait\u00e9e comme un seul token (par exemple (N (P \u00e0) (N cause) (P de)) est remplac\u00e9 par (N \u00e0_cause_de)). FTB-dev et 28, 1 pour FTB-train), devant m\u00eame Europarl (26, 3). La table fournit \u00e9galement la taille des vocabulaires (de formes fl\u00e9chies), et en leur sein la proportion de formes qui sont absentes du FTB-train. Nous fournissons les chiffres calcul\u00e9s en utilisant tous les tokens (y compris la ponctuation) ainsi que ceux calcul\u00e9s sur les tokens alphanum\u00e9riques minusculis\u00e9s 15 , pour mieux \u00e9valuer la diversit\u00e9 lexicale. On peut constater que le corpus m\u00e9dical comporte de loin le vocabulaire le plus \u00e9loign\u00e9 de celui du FTB (plus d'une forme sur trois est absente du FTB-train). Pour le corpus EMEA-dev, la proportion d'inconnus en comptant tous les types de formes fl\u00e9chies est tr\u00e8s haute, du fait d'un grand nombre de mots enti\u00e8rement capitalis\u00e9s (la proportion passe de 41, 4 \u00e0 36, 6 en ignorant la ponctuation et en minusculisant). Pour le corpus FrWiki, la forte proportion d'inconnus (34, 2%) peut s'expliquer par une grande fr\u00e9quence des noms propres (cf. la ligne % d'occurrences de noms propres : environ une occurrence sur 10 est un nom propre dans FrWiki). Les lignes sur les nombres d'occurrences et le pourcentage d'inconnus parmi ces occurrences donnent une vision plus pr\u00e9cise de la diversit\u00e9 lexicale des corpus. Dans les corpus m\u00e9dicaux, une occurrence sur 5 (et presque une sur 4 pour EMEA-dev) correspond \u00e0 un inconnu du FTB-train, ce qui, avec la faible proportion d'occurrences de noms propres (1, 7 et 2, 7) indique que les mots inconnus sont plut\u00f4t des mots fr\u00e9quemment utilis\u00e9s dans ces corpus. Au contraire, pour FrWiki on voit que, calcul\u00e9e sur les occurrences, la proportion d'inconnus tombe \u00e0 12, 9 (la majorit\u00e9 des inconnus du vocabulaire sont des noms propres, apparaissant rarement). Le corpus le plus proche lexicalement du FTB semble \u00eatre Europarl : seulement 6, 6% des occurrences sont des inconnus, formant un cinqui\u00e8me du vocabulaire, ce qui constitue moins d'occurrences d'inconnus que dans le FTB-dev. Adaptation de domaine par pont lexical Notre objectif est d'explorer une m\u00e9thode d'am\u00e9lioration des performances d'un analyseur statistique sur des textes d'origine diff\u00e9rente de celle du corpus d'entra\u00eenement de l'analyseur, les diff\u00e9rences pouvant relever du domaine et/ou du genre des textes. Pour simplifier, nous utilisons par la suite les termes domaine source pour les caract\u00e9ristiques (domaine, genre, registre) du corpus d'entra\u00eenement, domaines cibles pour celles des textes d'origine diff\u00e9rente et analyse hors-domaine pour l'analyse de textes des domaines cibles. Pour am\u00e9liorer l'analyse hors-domaine, nous proposons d'adapter une technique test\u00e9e au d\u00e9part pour le parsing intra-domaine. S'inspirant de l'utilisation par (Koo et al., 2008) de clusters de mots comme traits d'un analyseur discriminatif en d\u00e9pendances, (Candito et Crabb\u00e9, 2009) ont propos\u00e9 une technique qui, en r\u00e9duisant la dispersion des donn\u00e9es lexicales, am\u00e9liore les performances de parsing intra-domaine. Ils entra\u00eenent un analyseur statistique sur un corpus o\u00f9 les mots sont remplac\u00e9s par des identifiants de clusters de mots, obtenus de mani\u00e8re non supervis\u00e9e sur un corpus brut de grande taille. Le parsing se fait ensuite de la m\u00eame mani\u00e8re, en rempla\u00e7ant chaque mot par leur cluster correspondant, de mani\u00e8re d\u00e9terministe et non contextuelle, puis en r\u00e9ins\u00e9rant les tokens originaux pour obtenir les sorties d'analyse. Plus pr\u00e9cis\u00e9ment, le regroupement de formes fl\u00e9chies en clusters se fait en deux \u00e9tapes : -Les formes fl\u00e9chies sont d'abord group\u00e9es en clusters morphologiques via un lexique morphologique. Il s'agit de ramener un ensemble de formes fl\u00e9chies \u00e0 une forme canonique, dite forme 15. Plus pr\u00e9cis\u00e9ment les tokens comportant au moins une lettre ou un chiffre, et ramen\u00e9s \u00e0 une forme minusculis\u00e9e. d\u00e9fl\u00e9chie, avec comme principe de conserver exactement la m\u00eame ambigu\u00eft\u00e9 de cat\u00e9gories morpho-syntaxiques (contrairement par exemple \u00e0 une lemmatisation). On veut en effet d\u00e9l\u00e9guer la d\u00e9sambiguisation de cat\u00e9gories \u00e0 l'analyseur, et ne pas trancher par pr\u00e9-traitement. Pour cela, pour une forme donn\u00e9e, on r\u00e9cup\u00e8re la liste de ses cat\u00e9gories recens\u00e9es dans le dictionnaire, puis, tant que cette liste de cat\u00e9gories ne varie pas, le pluriel est ramen\u00e9 au singulier, le f\u00e9minin au masculin, et pour les formes verbales conjugu\u00e9es non ambigu\u00ebs, les personnes, mode et temps verbaux sont ramen\u00e9es \u00e0 la deuxi\u00e8me personne pr\u00e9sent pluriel (moyen rapide de trouver une forme n'introduisant pas de nouvelles ambigu\u00eft\u00e9s). Par exemple, analys\u00e9es est ramen\u00e9 \u00e0 analys\u00e9, mais entr\u00e9es est ramen\u00e9 \u00e0 entr\u00e9e, de mani\u00e8re \u00e0 conserver l'ambigu\u00eft\u00e9 nom/participe. Toutes les formes finies de augmenter sont ramen\u00e9es \u00e0 augmentez, mais par exemple joue est inchang\u00e9 pour pr\u00e9server son ambigu\u00eft\u00e9 cat\u00e9gorielle. -Ensuite un algorithme de clustering non supervis\u00e9 (Brown et al., 1992) est appliqu\u00e9 sur gros corpus pr\u00e9alablement segment\u00e9 en phrases, tokenis\u00e9 et d\u00e9fl\u00e9chi (i.e. o\u00f9 les formes fl\u00e9chies sont remplac\u00e9es par leur forme d\u00e9fl\u00e9chie correspondante). On obtient ainsi des clusters de formes d\u00e9fl\u00e9chies. Il s'agit d'un algorithme hi\u00e9rarchique et agglom\u00e9ratif, o\u00f9 le crit\u00e8re de fusion de deux clusters est la perte minimale de vraisemblance dans un mod\u00e8le bigramme de s\u00e9quences de clusters. Dans cet article, nous adaptons cette technique au probl\u00e8me sp\u00e9cifique de la non robustesse des analyseurs statistiques, en utilisant des clusters de mots appris sur la concat\u00e9nation de corpus du domaine source (ou proche du domaine source) et des domaines cibles. L'objectif est d'obtenir que soient group\u00e9s sous le m\u00eame cluster des mots appartenant au domaine source et des mots appartenant aux domaines cibles, de fa\u00e7on \u00e0 r\u00e9aliser un pont entre les vocabulaires respectifs de ces domaines (d'o\u00f9 le nom d'adaptation \u00e0 de nouveaux domaines par \"pont lexical\"). Travaux ant\u00e9rieurs reli\u00e9s Diff\u00e9rentes techniques ont \u00e9t\u00e9 propos\u00e9es pour adapter des mod\u00e8les d'analyse existants \u00e0 de nouveaux genres : -Adaptation au domaine via de l'auto-entra\u00eenement (self-training) (Bacchiani et al., 2006; McClosky et al., 2006; Sagae, 2010) : un analyseur entra\u00een\u00e9 sur le domaine source est utilis\u00e9 pour analyser du domaine cible, et on r\u00e9entra\u00eene un analyseur sur les donn\u00e9es valid\u00e9es source et les donn\u00e9es pr\u00e9dites cibles. Le corpus d'entra\u00eenement ainsi obtenu, bien que bruit\u00e9, capture suffisamment de r\u00e9gularit\u00e9s du domaine cible pour am\u00e9liorer les performances d'analyse sur ce domaine (tout en d\u00e9gradant les performances sur le domaine source) ; -co-entra\u00eenement avec s\u00e9lection d'exemples (Steedman et al., 2003) : deux analyseurs sont it\u00e9rativement re-entra\u00een\u00e9s sur leurs sorties respectives, les phrases du domaine cible \u00e0 utiliser \u00e9tant choisies de mani\u00e8re \u00e0 minimiser les erreurs d'analyse tout en maximisant l'utilit\u00e9 \u00e0 l'entra\u00eenement ; -transformation de treebank et adaptation du domaine cible (Foster, 2010) ; -adaptation m\u00e9ticuleuse du domaine cible \u00e0 la source d'entra\u00eenement (Foster et al., 2007) ; Bien que diff\u00e9rentes, les techniques ici \u00e9voqu\u00e9es sont toutes con\u00e7ues pour combler la variation syntaxique et lexicale entre le domaine source et les domaines cibles. La variation lexicale est en particulier probl\u00e9matique dans le cas d'une langue \u00e0 la morphologie plus riche que l'anglais, la flexion augmentant la dispersion des donn\u00e9es lexicales. Exp\u00e9riences et r\u00e9sultats Clusters de mots Pour calculer les clusters de mots nous utilisons diverses concat\u00e9nations de quatre corpus, avec d'une part le corpus L'Est R\u00e9publicain d\u00e9j\u00e0 cit\u00e9 section 2, de 150 millions de tokens, qui va jouer le r\u00f4le de corpus proche du domaine source malgr\u00e9 des diff\u00e9rences manifestes concernant les sujets trait\u00e9s 16 . Et d'autre part, nous utilisons des tron\u00e7ons de corpus de m\u00eame origine que les sous-corpus Sequoia annot\u00e9s : Europarl, Wikipedia Fr et domaine m\u00e9dical. Cela donne quatre corpus : -ER : 150 millions de tokens L'Est R\u00e9publicain -MED : 12 millions de tokens du domaine m\u00e9dical, dont 5 millions du corpus EMEA fran\u00e7ais 17  cit\u00e9 section 2 et 7 millions de tokens provenant du site doctissimo 18 . -EP : la m\u00eame taille, soit 12 millions de tokens, d'Europarl fran\u00e7ais, -FW : et 12 millions de tokens de Wikipedia Fr Pour le calcul des clusters, les phrases contenues dans le corpus arbor\u00e9 Sequoia ont \u00e9t\u00e9 retir\u00e9es. Le corpus ER, en tant que corpus journalistique r\u00e9gional, est choisi comme corpus proche du FTB, malgr\u00e9 des diff\u00e9rences manifestes concernant les sujets trait\u00e9s. La concat\u00e9nation du corpus ER et du corpus MED+EP+FW va jouer le r\u00f4le de pont lexical entre le domaine source (journalistique) et les domaines cibles. Les corpus bruts ER, MED, EP et FW sont d'abord pr\u00e9trait\u00e9s par l'outil Bonsai (segment\u00e9s en phrases, tokenis\u00e9s, et des mots compos\u00e9s sont reconnus hors-contexte). Puis nous appliquons le processus de d\u00e9fl\u00e9chissement d\u00e9crit section 3, pour remplacer chaque forme fl\u00e9chie par sa forme d\u00e9fl\u00e9chie \u00e9quivalente. Le lexique morphologique utilis\u00e9 est le Lefff (Sagot, 2010) . Enfin nous calculons des clusters de formes d\u00e9fl\u00e9chies 19 en utilisant l'impl\u00e9mentation par (Liang, 2005) de l'algorithme de (Brown et al., 1992) : -les clusters source sont obtenus en appliquant l'outil sur le corpus ER, -les clusters pont mixtes sont obtenus sur la concat\u00e9nation de ER + MED + EP + FW (soit environ 186 millions de tokens). -les clusters pont er-med sont obtenus sur la concat\u00e9nation de ER + MED uniquement (soit environ 162 millions de tokens), pour tester la m\u00e9thode avec des clusters plus cibl\u00e9s sur le vocabulaire m\u00e9dical. Dans les trois cas, le nombre de clusters g\u00e9n\u00e9r\u00e9s est de 1000, et les formes d\u00e9fl\u00e9chies consid\u00e9r\u00e9es sont celles apparaissant au moins 100 fois dans le corpus d'apprentissage 20 . Protocole et exp\u00e9riences Nous r\u00e9alisons ces premiers tests en analyse en constituants sans annotations fonctionnelles. Tous les traitements (entra\u00eenement d'analyseur et tests) se font donc sur des versions des corpus o\u00f9 les annotations fonctionnelles sont supprim\u00e9es 21 . Nous utilisons l'algorithme d'apprentissage et d'analyse de PCFG avec annotations latentes (ci-apr\u00e8s PCFG-LA) de (Petrov et Klein, 2007) , et son impl\u00e9mentation 22 , avec mod\u00e8le de lissage pour les mots rares et inconnus adapt\u00e9 au fran\u00e7ais. Pour cet algorithme, (Petrov, 2010) montre une variabilit\u00e9 des r\u00e9sultats selon les valeurs al\u00e9atoires choisies \u00e0 l'initialisation de l'algorithme EM d'apprentissage des probabilit\u00e9s de r\u00e8gles avec annotations latentes. Aussi, nous r\u00e9alisons pour chaque exp\u00e9rience quatre ex\u00e9cutions de l'apprentissage, avec quatre graines al\u00e9atoires diff\u00e9rentes. Tous les apprentissages se font en utilisant 5 cycles de fission-fusion. Pour l'\u00e9valuation des performances, nous utilisons l'outil Evalb, et fournissons la moyenne des F-mesures de constituants label\u00e9s (moyenne sur les quatre graines al\u00e9atoires) pour les phrases de moins de 40 mots ainsi que pour toutes les phrases. Nous utilisons PCFG-LA pour apprendre quatre analyseurs, sur quatre versions du FTB-train (cf. section 2) diff\u00e9rant par les symboles terminaux utilis\u00e9s (les feuilles lexicales) : -forme fl\u00e9chie : les formes fl\u00e9chies sont laiss\u00e9es telles quelles -forme d\u00e9fl\u00e9chie : chaque forme fl\u00e9chie est remplac\u00e9 par sa forme d\u00e9fl\u00e9chie \u00e9quivalente -cluster source : chaque forme d\u00e9fl\u00e9chie est ensuite remplac\u00e9e par son cluster source \u00e9quivalent (clusters appris sur le corpus ER) -cluster pont mixte : idem mais en utilisant les clusters appris sur ER + MED + EP + FW -cluster pont er-med : idem mais en utilisant les clusters appris sur ER + MED R\u00e9sultats et discussion Nous avons r\u00e9alis\u00e9 des tests en comparant les r\u00e9sultats sur le FTB et sur le corpus Sequoia. Plus pr\u00e9cis\u00e9ment, d'une part avons consid\u00e9r\u00e9 trois \"domaines\" : le domaine source (FTB), un domaine tr\u00e8s \u00e9loign\u00e9 (domaine m\u00e9dical, corpus Emea), et un domaine que nous appelons neutre, regroupant les autres parties du corpus Sequoia (phrases de Wikip\u00e9dia Fr, Europarl et Est R\u00e9publicain). D'autre part, pour chaque domaine (source, m\u00e9dical et neutre) nous avons s\u00e9par\u00e9 corpus de test pour les tests finaux, et corpus de d\u00e9veloppement pour la phase exploratoire, de la mani\u00e8re suivante : -domaine source : FTB-dev et FTB-train tels que d\u00e9crits note 14 -domaine m\u00e9dical : EMEA-dev et EMEA-train, cf. les colonnes 2 et 3 de la Conclusion Nous avons pr\u00e9sent\u00e9 le corpus arbor\u00e9 Sequoia, comportant quatre sous-corpus annot\u00e9s syntaxiquement en suivant le sch\u00e9ma du French Treebank, \u00e0 quelques exceptions pr\u00e8s. Les corpus sont librement disponibles sous forme de constituants et de d\u00e9pendances. varier le corpus brut sur lequel calculer les clusters ne montrent pas d'avantage clair \u00e0 utiliser du texte brut du domaine cible. Remerciements Nous remercions chaleureusement les trois annotatrices Vanessa Combet, Catherine Moreau-Mocquay et Virginie Mouilleron pour leur travail tr\u00e8s consciencieux. L'annotation a \u00e9t\u00e9 financ\u00e9e par l'ANR (projet SEQUOIA ANR-08-EMER-013).",
    "abstract": "Nous pr\u00e9sentons dans cet article la m\u00e9thodologie de constitution et les caract\u00e9ristiques du corpus Sequoia, un corpus en fran\u00e7ais, syntaxiquement annot\u00e9 d'apr\u00e8s un sch\u00e9ma d'annotation tr\u00e8s proche de celui du French Treebank (Abeill\u00e9 et Barrier, 2004) , et librement disponible, en constituants et en d\u00e9pendances. Le corpus comporte des phrases de quatre origines : Europarl fran\u00e7ais, le journal l'Est R\u00e9publicain, Wikip\u00e9dia Fr et des documents de l'Agence Europ\u00e9enne du M\u00e9dicament, pour un total de 3204 phrases et 69246 tokens. En outre, nous pr\u00e9sentons une application de ce corpus : l'\u00e9valuation d'une technique d'adaptation d'analyseurs syntaxiques probabilistes \u00e0 des domaines et/ou genres autres que ceux du corpus sur lequel ces analyseurs sont entra\u00een\u00e9s. Cette technique utilise des clusters de mots obtenus d'abord par regroupement morphologique \u00e0 l'aide d'un lexique, puis par regroupement non supervis\u00e9, et permet une nette am\u00e9lioration de l'analyse des domaines cibles (le corpus Sequoia), tout en pr\u00e9servant le m\u00eame niveau de performance sur le domaine source (le FTB), ce qui fournit un analyseur multi-domaines, \u00e0 la diff\u00e9rence d'autres techniques d'adaptation comme le self-training.",
    "countries": [
        "France"
    ],
    "languages": [],
    "numcitedby": "109",
    "year": "2012",
    "month": "June",
    "title": "Le corpus Sequoia : annotation syntaxique et exploitation pour l{'}adaptation d{'}analyseur par pont lexical (The Sequoia Corpus : Syntactic Annotation and Use for a Parser Lexical Domain Adaptation Method) [in {F}rench]"
}