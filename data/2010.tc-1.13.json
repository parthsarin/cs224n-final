{
    "article": "In recent years, it is becoming more and more clear that the localisation industry does not have the neces-sary manpower to satisfy the increasing demand for high--quality translation. This has fuelled the search new and existing technologies that would increase translator throughput. As Translation Memory (TM) systems are the most commonly employed tool by translators, a number of enhancements are available to assist them in their job. One such enhancement would be to show the translator which parts of the sen-tence that needs to be translated match which parts of the fuzzy match suggested by the TM. For this information to be used, however, the translators have to carry it over to the TM translation themselves. In this paper, we present a novel methodology that can automatically detect and highlight the segments that need to be modified in a TM--suggested translation. We base it on state--of--the--art sub--tree alignment technology (Zhechev, 2010) that can produce aligned phrase--based--tree pairs from unannotated data. Our system operates in a three--step process. First, the fuzzy match selected by the TM and its translation are aligned. This lets us know which segments of the source--language sentence correspond to which segments in its translation. In the second step, the fuzzy match is aligned to the input sentence that is currently being translated. This tells us which parts of the input sentence are available in the fuzzy match and which still need to be translated. In the third step, the fuzzy match is used as an intermediary, through which the alignments between the input sentence and the TM translation are established. In this way, we can detect with precision the segments in the suggested translation that the translator needs to edit and highlight them appropriately to set them apart from the segments that are already good translations for parts of the input sentence. Additionally, we can show the alignments -as detected by our system -between the input and the translation, which will make it even easier for the translator to post--edit the TM suggestion. This alignment information can additionally be used to pre--translate the mismatched segments, further reduc-ing the post--editing load. Introduc&on As the world becomes increasingly interconnected, ideas, products and services need to be communicated to the widest audience possible. This requires localisation for as many languages, cultures and locales as possible, with translation being one of the main parts of the localisation process. Because of this, the amount of data that needs professional high--quality translation is continuing to increase well beyond the ca-pacity of the world's human translators. Current efforts in the localisation industry are mostly directed at the reduction of the amount of data that needs to be translated manually from scratch. Such efforts mainly include the use of Translation Memory (TM) systems, where earlier transla-tions are stored in a database and offered as suggestions when new data needs to be translated. As TM systems were originally limited to providing translations only for (almost) exact matches of the new data, the integration of Machine Translation (MT) techniques is often seen as the only feasible development that has the potential to significantly reduce the amount of manual translation. The system that we present in this paper, however, takes a different approach in that it aims to aid the translators in the process of post--editing TM matches. In par-ticular, the system isolates and marks--up the parts of the TM--suggested translation (henceforth the TM output) that can be judged as good based on automatic align-ment between the segment that needs to be translated (henceforth the input) and the TM fuzzy match. The parts of the TM output that are leftover after this process are the ones that need editing and the system highlights them so that they can be easily spotted by the translator without having to search through the whole TM out-put. The system can further be augmented with a Statistical Machine Translation (SMT) backend to pre--translate the mismatched parts of the TM output, before pre-senting them to the translator for post--editing, thus hopefully reducing post--editing effort. With recent advances in the performance and quality of Statistical Machine Translation (SMT) systems, many commercial TM systems offer the user the option to obtain SMT--generated translations for new data. 1 Such translations, however, are usually only obtained for cases where the TM system could not produce a good-enough translation (cf. Heyn, 1996) . Given that the SMT system used is presented with the \"hard\" translation cases (strings not seen in the TM) and is usually trained only on the data available in the TM, it tends to have only few examples from which to construct the translation, thus often producing fairly low quality output. Because of this, and since translators are used to TMs as an integral part of their working en-vironment but less so to MT, SMT output is still often scorned upon by professional translators. We hope that the system described here presents a use case for SMT in a TM context in which translators may see the benefits this technology can bring. In Section 2, we present the technical details of the design of our system, together with motivation for the particular design choices we took. Section 3 details the ex-periments we performed with pre--translating the mismatched segments of the TM output and the results we achieved. In Section 4, we present out future development plans and conclude. System Framework We present a system that uses state--of--the--art sub--tree alignment techniques to mark--up Translation Memory output highlighting the parts of it that need to be ed-ited manually. Transla&on Memory Backend Although the intention is to integrate the methodology outlined here into a full-scale TM system, to have complete control over the process for this initial research we decided to build a simple prototype TM backend ourselves. We employ a database setup using the PostgreSQL v.8.4.3 2 relational database management (RDBM) system. The segment pairs from a given TM are stored in this database and assigned unique IDs for further reference. When a new sentence is supplied for translation, the database is searched for (near) matches, using a Fuzzy Match Score (FMS) based on character--based Levenshtein edit distance (Levenshtein, 1965) . To speedup the computation, we use a recursive wrapper around the PostgreSQL--internal implementation of the levenstein() function, taken from the TinyTM project. 3  In this way, for each input segment, from the database we obtain the matching segment with the highest FMS, its translation and the score itself. Sub--Tree Alignment The system presented in this paper uses sub--tree alignment (Zhechev, 2010) to dis-cover parts of the input sentence that correspond to parts of the suggested transla-tion extracted from the TM database. This is done in a three--step process. First, the plain TM match and the TM output are aligned, which produces a sub--tree aligned phrase--based tree pair. We call this step bilingual alignment. In the second step, called monolingual alignment, the phrase--based tree-annotated version of the TM match is aligned to the plain--text input sentence. The reuse of the structure for the TM match allows us to use it in the third step as an in-termediary to establish the available sub--tree alignments between the input sentence and the TM output. During this final alignment, we identify matched and mismatched portions of the input sentence and their possible translations in the TM output and, thus, this step is called matching. The alignment process is exemplified in Figure 1 . The tree marked 'I' corresponds to the input sentence, the one marked 'M' to the TM match and the one marked 'T' to the TM output. We only display the node ID numbers of the non--terminal nodes in the phrase--structure trees -in reality all nodes carry the label 'X' . These IDs are used to identify the sub--sentential alignment links. The lexical items corresponding to the leaves of the trees are presented in the table below the graph.  The alignment process can be visually represented as starting at a linked node in the I tree and following the link to the M tree. Then, if available, we follow the link to the T tree and this leads us to the T--tree node corresponding to the I--tree node we started from. In Figure 1 , this results in the I-T alignments I1-T18, I2-T2, I3-T1, I4-T32 and I6-T34. The first three links are matches, because the lexical items covered by the I nodes correspond exactly to the lexical items covered by their M node coun-terparts. Such alignments provide us the direct TM translations for our input. The last two links in the group are mismatched, because there is no lexical correspon-dence between the I and M nodes (node I4 corresponds to the phrase sender email, while the linked node M10 corresponds to sender 's email). Such alignments can only be used to infer reordering information for the experiments presented in Section 3. In particular in this case, we can infer that the target word order for the input sen-tence is address email sender, which corresponds to the translation adresse \u00e9lec-tronique de l' exp\u00e9diteur. The correspondence between the input and the TM output could be presented to the user as shown in Figure 2 . 4 The alignments representing correct translations as inferred from the TM are highlighted in green and alignment lines are drawn to show the translator what the system believes the translational correspondences are. The final words in the French segment are faded out, as an indication from the system that they should probably be deleted. If desired, the system can also present the TM match as the intermediary between the input and the TM output.  (including the TM match) We decided to use sub--tree--based alignment, rather than plain word alignment (e.g. GIZA++ - Och and Ney, 2003) , due to a number of factors. The goal of sub--tree alignment methods is not to align as many lexical items as possible, but to represent structurally the best translational equivalences in the sentences that are being aligned. This allows for the encoding of long--distance translational dependency by means of links between nodes higher up in the tree structures. The alignments produced by a sub--tree alignment model are also precision-oriented, rather than recall--oriented (cf. Tinsley, 2010). This is important in our case, where we want to only extract those parts of the translation suggested by the TM for which we are most certain that they are good translations. Out of the three currently available open--source sub--tree alignment systems, two can only operate when at least one language--side of the data that needs to be aligned is pre--parsed (Ambati et al., 2009 , Tiedemann, 2010) and one of them needs a hand-crafted parallel treebank as training data (Tiedemann, 2010) . As these requirements necessitate the acquisition of human--annotated data be-sides the data available in the TM, we decided to use the system described in (Zhechev, 2010) instead. It can produce aligned phrase--based--tree pairs from unan-notated (i.e. unparsed) data. It can also function fully automatically without the need for any training data. The only resource necessary for the operation of this system is a probabilistic bilingual dictionary covering the data that needs to be aligned. For the bilingual alignment step, such a bilingual dictionary -if not already available -can be gener-ated automatically using a tool like GIZA++ (Och and Ney, 2003) . For the monolin-gual alignment step, the required probabilistic dictionary is generated by simply list-ing each unique token seen in the source--language data in the TM as translating only as itself with probability 1. Experimen&ng with Pre--Transla&on As stated earlier, the design of our system allows for the pre--translation of the mis-matched parts of the TM output using an SMT system. We explore two approaches to handling the translation of these outstanding fragments. The first approach is extremely straightforward, in that the non--translated seg-ments of the input sentence are sent severally to the SMT backend for translation without any context information. The segments translated using TM data and the ones translated using the SMT backend are then simply concatenated in the target-language word order, as determined implicitly by the sub--tree alignment informa-tion. The most serious drawback of this approach is that translating the individual segments out of context might often lead to improper lexical choice by the SMT backend, which could have been properly resolved given the context of the whole input sentence. Also, for certain cases (particularly with low FMS) the target-language word order may not be discernible for all input--sentence segments and the translations of the segments with undetermined placement are simply appended to the end of the generated translation. Still, the simplicity of this approach makes it a good baseline benchmark against which to evaluate improvements. This approach is referred to as comb below. The second approach to handling non--translated input--sentence segments relies on a specific feature of the SMT backend we use, namely the Moses system (Koehn et al., 2007) . We decided to use this particular system as it is the most widely adopted open--source SMT system, both for academic and commercial purposes. In this ap-proach, we annotate the segments of the input sentence for which translations have been found from the TM suggestion using XML tags with the translation corre-sponding to each segment given as an attribute to the encapsulating XML tag. The SMT backend is supplied with a string consisting of the concatenation of the XML-enclosed translated segments and the plain non--translated segments in the target-language word order, as established by the alignment process. The SMT backend is instructed to translate the string as a whole, while keeping the translations supplied via the XML annotation. This mode of operation provides the SMT backend with the necessary context information to come up with proper lexical choice for the non-translated fragments and allows it to introduce reordering on its own, based on the SMT reordering models derived during training. We refer to this approach as xml. A drawback present with this approach is that we need to perform additional align-ment and matching steps to reestablish the alignments between the input and the newly generated translation. Further, we present experiments on pre--translating the mismatched parts of the TM output using the methods described above (comb and xml). Experimental Data We use real--life TM data provided by Symantec Ireland, an industrial partner of CNGL. The TM was generated during the translation of RTF--formatted customer support documentation. The data is in TMX format and originally contains 108 967 English-French translation segments, out of which 14 segments either have an empty language side or have an extreme discrepancy in the number of tokens for each lan-guage side and were therefore discarded. A particular real--life trait of the data is the presence of a large number of XML tags. Running the tag--mapping tool described in Section 2.5, we gathered 2 049 dis-tinct tags for the English side of the data and 2 653 for the French side. Still, there were certain XML tags that included a label argument whose value was translated from one language to the other. These XML tags were left intact so that our system could handle the translation correctly. The TM data also contain a large number of file paths, e--mail addresses, URLs and others, which makes bespoke tokenisation of the data necessary. Our tokenisa-tion tool ensures that none of these elements are tokenised, keeps RTF formatting sequences non--tokenised and properly handles non--masked XML tags, minimising their fragmentation. Due to the nature of TM data, translation segments rarely occur more than once in the data set. This explains the high number of unique tokens (measured after pre-processing) that we observe for the two languages -41 379 for English and 49 971 for French -out of 108 953 segment pairs. The average sentence length is 13.2 for English and 15.0 for French. For evaluation, we use a data set of 4 977 English-French segments that were ob-tained from a different set of documents than the ones, for whose translation the TM presented above was used. The sentences in the test setwith average length 9.2 to-kens for English and 10.9 for French -are significantly shorter compared to the TM. It must be noted that we used SMT models with maximum phrase length of 3 tokens, rather than the standard 5 tokens, and for decoding we used a 3--gram lan-guage model. This results in much smaller models than the ones usually used in mainstream SMT applications, thus making the system more accessible by lowering the system requirements for running it. (The standard for some tools goes as far as 7-token phase--length limit and 7--gram language models.) Evalua&on Results For the evaluation of our system, we used a number of widely accepted automatic MT--quality metrics, namely BLEU (Papineni et al., 2002) , NIST (Doddington, 2002) , METEOR (Banerjee and Lavie, 2005) , TER (Snover et al., 2006) and inverse F--Score based on token--level precision and recall. We setup our system to only fully process input sentences for which a TM match with an FMS over 50% was found, although all sentences were translated directly using the SMT backend for control purposes (marked as direct). The TM output was also evaluated unmodified (tm). comb and xml refer to the two setups described in the beginning of Section 3. The results of the evaluation are given in Figure 4 , where the tm and direct scores are also given for FMS between 0% and 50% and FMS 100%. Across all metrics we see a uniform drop in the quality of TM--suggested translations, which is what we ex-pected, given that these translations contain one or more incorrect words. We believe that the relatively high scores recorded for the TM--suggested translations at the high end of the FMS scale are a result of the otherwise perfect word order and lexical choice. For n--gram--match--based metrics like the ones we used, such a result is ex-pected and predictable. Although the inverse F--score results show the potential of our setup to translate the outstanding tokens in a 90%-100% TM match, it appears that the SMT system produces word order that does not correspond to the reference translation and because of this receives lower scores on the other metrics. The inverse F--score results also confirm our prediction that the comb translation approach is prone to lexical--choice errors due to the lack of context during transla-tion. These errors seem to be the major factor leading to significantly worse perform-ance compared to the xml approach. The unexpected drop in scores for perfect TM matches is due to discrepancies between the reference translations in our test set and the translations stored in the TM. We believe that this issue affects all FMS ranges, albeit to a lower extent for non-perfect matches. Unfortunately, the exact impact cannot be ascertained without hu-man evaluation. We observe a significant drop--off in translation quality for the direct output be-low FMS 50%. This suggests that sentences with such low FMS should be translated either by a human translator from scratch, or by an SMT system trained on different/ more data. The xml setup of our system clearly outperforms the direct SMT translation for FMS between 80% and 100% and has comparable performance between FMS 70% and 80%. Below FMS 70%, the SMT backend has the best performance. Although these results are positive, we still need to investigate why our system has poor per-formance at lower FMS ranges. Theoretically, it should outperform the SMT backend across all ranges, as its output is generated by supplying the SMT backend with good pre--translated fragments. The Inverse F--Score graph suggests that this is due to worse lexical choice, but only manual evaluation can provide us with clues for solv-ing the issue. The discrepancy between the results in the Inverse F--Score graph and the other metrics suggests that the biggest problem for our pre--translation system is producing output in the expected word--order. Future Work and Conclusions First, our main goal is to integrate the presented methodology in a standalone com-mercial or open--source TM system so that it can become a part of a fully integrated localisation workflow. The pre--translation functionality needs to first be evaluated on a small, but rep-resentative, set of data to establish the FMS level at which the system performs at its best and set the appropriate thresholds accordingly for the further use of the system. This can be linked to a translation--quality estimator, when such tools become more widely available. Finally, a user study evaluating the effect of the use of our system on post--editing speeds should be performed. We expect the findings of such a study to show a sig-nificant increase of throughput that will significantly reduce the costs of translation for large--scale projects. The system we developed uses precise sub--tree--based alignments to reliably de-termine correspondences between an input sentence and a TM output and presents them to a translator to facilitate the post--editing process. It can employ an SMT backend to translate the mismatched parts of the input sentence and produce a complete translation with higher quality than the original TM output. Our evaluation of the pre--translation functionality shows that it significantly im-proves the quality of the pure SMT output when using TM matches with FMS above 80% and produces results on par with the pure SMT output for FMS between 70% and 80%. Still, further investigation is needed to properly diagnose the drop in qual-ity for FMS below 70%. Acknowledgements This research is funded under FPs of the EC within the EuroMatrix+ project (grant \u2116231720).",
    "abstract": "In recent years, it is becoming more and more clear that the localisation industry does not have the neces-sary manpower to satisfy the increasing demand for high--quality translation. This has fuelled the search new and existing technologies that would increase translator throughput. As Translation Memory (TM) systems are the most commonly employed tool by translators, a number of enhancements are available to assist them in their job. One such enhancement would be to show the translator which parts of the sen-tence that needs to be translated match which parts of the fuzzy match suggested by the TM. For this information to be used, however, the translators have to carry it over to the TM translation themselves. In this paper, we present a novel methodology that can automatically detect and highlight the segments that need to be modified in a TM--suggested translation. We base it on state--of--the--art sub--tree alignment technology (Zhechev, 2010) that can produce aligned phrase--based--tree pairs from unannotated data. Our system operates in a three--step process. First, the fuzzy match selected by the TM and its translation are aligned. This lets us know which segments of the source--language sentence correspond to which segments in its translation. In the second step, the fuzzy match is aligned to the input sentence that is currently being translated. This tells us which parts of the input sentence are available in the fuzzy match and which still need to be translated. In the third step, the fuzzy match is used as an intermediary, through which the alignments between the input sentence and the TM translation are established. In this way, we can detect with precision the segments in the suggested translation that the translator needs to edit and highlight them appropriately to set them apart from the segments that are already good translations for parts of the input sentence. Additionally, we can show the alignments -as detected by our system -between the input and the translation, which will make it even easier for the translator to post--edit the TM suggestion. This alignment information can additionally be used to pre--translate the mismatched segments, further reduc-ing the post--editing load.",
    "countries": [
        "Ireland"
    ],
    "languages": [
        "English",
        "French"
    ],
    "numcitedby": "0",
    "year": "2010",
    "month": "November 18-19",
    "title": "Highlighting matched and mismatched segments in translation memory output through sub-tree alignment"
}