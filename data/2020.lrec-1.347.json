{
    "article": "In this paper, we present computational resource grammars of Runyankore and Rukiga (R&R) languages. Runyankore and Rukiga are two under-resourced Bantu Languages spoken by about 6 million people indigenous to South Western Uganda, East Africa. We used Grammatical Framework (GF), a multilingual grammar formalism and a special-purpose functional programming language to formalise the descriptive grammar of these languages. To the best of our knowledge, these computational resource grammars are the first attempt to the creation of language resources for R&R. In Future Work, we plan to use these grammars to bootstrap the generation of other linguistic resources such as multilingual corpora that make use of data-driven approaches to natural language processing feasible. In the meantime, they can be used to build Computer-Assisted Language Learning (CALL) applications for these languages among others. Introduction Runyankore & Rukiga (hereafter R&R) are two heavily under-resourced Bantu languages. Their limited presence on the web makes it difficult to develop substantial computational linguistic resources for these languages. Consequently, the lack of such resources makes the use of datadriven Natural Language Processing (NLP) approaches unsuitable for these languages. However, rule-based approaches such as grammars, can be used to bootstrap the creation of such resources. In this paper we present computational resource grammars of these two languages developed using Grammatical Framework (GF). Grammatical Framework (GF) GF is a multilingual grammar formalism, a logical framework and a special-purpose functional programming language for defining grammars of both formal and natural languages (Ranta, 2011; Ranta, 2009a) . We chose GF because it does not need any additional linguistic resources, and being multilingual, it can be used to develop resources for under-resourced languages by using existing linguistic resources of well-resourced languages already covered in its Resource Grammar Library (RGL) (Ranta, 2009a; Kolachina and Ranta, 2016) . Abstract and Concrete Syntax Each grammar in GF consists of an abstract and concrete syntax. The abstract syntax defines a set of abstract syntactic structures, called abstract terms or trees, which are used to define a language-independent or semantic meaning representation. The concrete syntax defines a relation between the abstract structures and their language-specific constructions. This makes it possible to define several sets of concrete \"syntaxes\" for one single abstract syntax. The single abstract syntax then acts as an interlingua between different languages. The concept of a shared abstract syntax is the reason for the multilingual capabilities of GF. Resource & Application Grammars Grammars designed in GF are of two types: resource and application grammars. Resource grammars are broad-coverage grammars developed from scratch for the purpose of formally describing the morphology and syntax of natural languages while application grammars model semantic information about a specific application domain. Using GF's modular system, Resource Grammars are packaged together and exposed by both a common API (that is based on the common abstract syntax) and language specific APIs into what is called the GF Resource Grammar Library (GF-RGL) (Ranta, 2009b) . Application grammars make use of general linguistic functions implemented in resource grammars by accessing them through the GF-RGL. Resource grammars have been used successfully in domain-limited application areas such as Multilingual Document Authoring (Dymetman et al., 2000) , low-coverage multilingual translation (Ranta et al., 2010) , domain specific dialogue systems such as music players (Perera and Ranta, 2007) and Computer-Assisted Language Learning (CALL) (Lange, 2018; Lange and Ljungl\u00f6f, 2018) . Another important use case in the area of localisation is the multilingual dissemination of weather information especially in multilingual societies. Our immediate motivation is therefore to utilise the GF-RGL for R&R to leverage the work done by Lange (2018) on CALL for the Latin language in order to build, localise and improve tools that can be used to create automatic exercises for learning R&R grammar to higher levels of proficiency accessible to all. In the rest of the paper, we discuss related work in Section 2., an overview of R&R, its nominal and verbal morphology in Section 3. followed the GF-RGL implementation of R&R in section 4.. Sections 5.,6. and 7. present Observations through an example, Discussion and lastly Conclusion & Future Work respectively. Related Work Previous work on the computational modelling of the grammar of R&R include: noun and verb morphological analysers by Katushemererwe and Hanneforth (2010b; 2010a) , a Controlled Natural Language for Runyankore (Byamugisha et al., 2016) and a Noun pluralizer (Byamugisha et al., 2018) . However, this work has been limited to small fragments of the languages. Within the GF community, there has been work on computational modeling of Bantu languages: Kikamba (Kituku et al., 2019) , Tswana (Pretorius et al., 2017) , and Swahili (Ng\u00e1ng\u00e1, 2012) . While we consulted the Swahili implementation during initial development, we found that Swahili is morphologically and syntactically less complex than R&R. Additionally, its coverage of the GF-RGL functions was very small. Little insight was generated from that grammar. Likewise the Tswana GF-RGL was limited to modelling the proper verb for declarative sentences which is small in scope. Twsana's use of both a disjunctive and conjunctive orthography as compared to R&R's conjunctive morphology also provided limited insights into how to implement the grammars of R&R. Work on Kikamba and R&R was done during the same timeframe and hence both of us benefited from the sharing of ideas. Runyankore & Rukiga (R&R) R&R are languages spoken in South-Western Uganda by about 6 million people (Simons and Fennig, 2018) . They belong to the JE10 zone (Maho, 2009) of the Niger-Congo Bantu language family. Just like any other Bantu languages, morphologically, R&R are highly agglutinating (e.g., the single word tinkamureebagaho (ti-n-ka-mu-reeb-a-ga-ho) is a sentence meaning \"I have never seen him/her\"), exhibit high instances of phonological conditioning and a large Noun Class System of 17 noun classes (Katushemererwe and Hanneforth, 2010b; Byamugisha et al., 2016) . This noun class system dictates a complex concordial system of agreement among phrasal categories. These properties make the morphology of the languages more complex to computationally model as compared to analytic languages such as English. Since both languages share the same dictionaries (Taylor and Yusuf, 2009; Mpairwe and Kahangi, 2013a) and grammar books (Morris and Kirwan, 1972; Mpairwe and Kahangi, 2013b) their grammar is largely identical while the lexicon differs by 6%-16% (Turyamwomwe, 2011; Simons and Fennig, 2018) . Nominal Morphology The morphological structure of nouns in R&R consists of two parts, a class prefix and a noun stem. The class prefix is further divided into an Initial Vowel (IV) and a Noun Class particle (NCP) (Mpairwe and Kahangi, 2013b) . The noun stem usually bears the bulk of the semantic meaning of the noun. Each Noun in R&R, belongs to a particular Noun Class (NC). The group of possible noun classes is given in Table 1 adapted from Katushemererwe and Hanneforth (2010b) with modifications. The predominant naming scheme of noun classes in Bantu languages (called the Bleek-Meinhoff system) makes use of a combination of a numeral and optionally letters (see column labelled Numbers in Table 1 ). However, we discovered an alternative scheme that uses NCP (refer to \"Particles\" column in the same table) utilised by (Mpairwe and Kahangi, 2013a; Mpairwe and Kahangi, 2013b) in their dictionary and grammar books. Since we make heavy use of these books, we have found it convenient to use the latter scheme in order to avoid an additional step of mapping between the two systems during our implementation of the grammar as explained in section 4. Apart from locative particles -ha-,mu-and -ku-, most of the other particles can be arranged in singular-plural pairs for common nouns. We generalise such a pairing using the notation [\u03b1 \u2212 \u03b2] where \u03b1 & \u03b2 are noun class particles chosen from the sets of singular & plural particles respectively. We borrow the use of the number ZERO (0) from Mpairwe and Kahangi (2013a) in their Runyankore-Rukiga dictionary to denote absence of either singularity or plurality in order to maintain the pairing for such nouns. Hence the pairs [\u03b1 \u2212 0], [0 \u2212 \u03b2] and [0 \u2212 0] which represent nouns that are always singular, plural and those that collectively neither have an IV nor noun class particle respectively. It is important to note that classes 9 10 and 9 in the table are both assigned N N because the set of agreement concords for the two classes are the same. More noun classes are used in our implementation to cater for Numerals which are a special set of nouns for naming entities used to count (ordinals), or encode order (Ordinals). Verbal Morphology In Meeussen's (1967) original construction, the Bantu verbal unit consists of a pre-stem and stem. The stem is further divided into a base and final vowel (FV). The base is also divided into a radical (Rad) and extensions. Further subdivisions in each of these parts results into 11 slots (Katushemererwe and Hanneforth, 2010a; Turyamwomwe, 2011) , with each slot taking a set of morphemes for a particular purpose such as Primary/Secondary negative (Pneg / Sneg), subject (S), object, tense, aspect and other markers. Regular verbs can be classified into four base-forms: Imperatives, Subjunctives, Perfectives and Infinitives. They can be rendered in active or passive voice and within each voice, the verb can take the form of Simple, Prepositional and Causative. In the verbal unit of R&R, Tense and Aspect (T/A) are marked using morphemes which may be simple or compound. However, in our attempt to model the grammar of R&R, we have combined the constructions suggested by Muzale (1998) , Katushemererwe and Hanneforth (2010a) and Turyamwomwe (2011) , based on omissions and coverage made by each. While Muzale (1998) shows how different T/A markers have developed through time (diachronicaly) up to their current forms (as of 1998) among Rutara, Katushemererwe and Hanneforth (2010a) confine their work to Runyakitara and Turyamwomwe (2011) restricts himself to T/A in R&R. Therefore our design was based first on Muzale (1998) followed by Katushemererwe and Hanneforth (2010a) and lastly Turyamwomwe (2011) Reason for lack of resources Despite the initial exposure to learning R&R in the first three years of primary school, English becomes the official language of instruction and examination from the fourth year on, severely limiting the continued study of R&R to higher levels of proficiency. It is also worthy to note that although dictionaries, grammar books and an orthography for R&R exist, R&R just like any other native languages in Uganda largely remain oral as opposed to written even among those literate in English. Only a dismal few study the language to a level sufficient to achieve proficiency in writing which implies lack of continuity in learning the grammar of the language. This explains the nearly zero presence on the web hence the lack of any computational language resources. As a result, the languages are highly under-resourced. It is therefore important to take steps in building language resources, encouraging writing in these languages and their preservation. GF-RGL Implementation of R&R In this section, we explain how the grammars for R&R were implemented using GF. The GF-RGL does not attempt to cover all grammatical and morphological structures in all languages, but instead focus is put on constructions that are common amongst the many languages of the world. 200 construction functions. Because of the expressive module system of GF, it is possible to extend the common GF-RGL with language-specific constructions. The task is to write concrete modules for each abstract module. Lexicon When building an RGL for any language, the first thing to tackle is the lexicon. For each lexical item defined in the abstract module of the GF-RGL lexicon, a concrete mapping must be implemented for the language under investigation. This concrete mapping involves the enumeration of all possible morphological inflectional forms of the lemma provided. It is impossible to have a strict one-toone mapping due to the existence of synonyms and lexical gaps. Synonyms are treated as separate GF lexical categories, so we selected a single word from the set of synonyms and left other synonyms to be catered for by an Extension module for the Lexicon. For lexical gaps in R&R which are a result of cultural differences, modernisation and lack of universality in language, we employed loan words (influenced by English) and adapted them according to the orthography of R&R. For the problem of a lack of a rich notion of adjectives particularly with respect to degree, we used circumscription. Just like GF-RGLs for other languages, we minimised the requirement of explicitly enumerating all the inflectional forms of a lexical item from a given category through the use of morphological paradigms. If a lexical entry \u03c9 of a given lexical type C has surface forms \u03c9 1 , \u03c9 2 . . . \u03c9 n , then these paradigms are special functions that take between one surface form (base form) and at most n \u2212 1 surface forms and other information to produce the full set of inflected word-forms of that lexical entry. Paradigms that take one surface form, called smart paradigms (D\u00e9trez and Ranta, 2012) , are restricted to lexemes whose inflection is regular. Common Nouns and Proper Nouns In R&R, common nouns inherently belong to a noun class. It is possible to use these nouns in either their Complete or Incomplete forms and each of these is inflected for number (refer to Table 3 for an example). We therefore declared parameters for NounState, Number and Gender (lines 2-4), a linearisation type for Nouns (lines 21-22) in code listing 1 on the next page. We also declared paradigms for computing inflection tables for nouns. We used a composite parametric data type similar to algebraic data types from functional programming to encode agreement with respect to noun class, Person and Number in lines 4-12 of listing 1. Under normal circumstances Proper Nouns do not inflect with number. They are all in the third person but belong to different noun classes based on the common noun they give a name to. It was therefore necessary to keep track of information about Agreement and whether the noun refers to a location or place (refer to lines 23-25 in lstlisting 1). The smart-paradigm we implemented for nouns (smartNoun) is a very accurate \"pluraliser\" which handles most of the cases using pattern-matching. Incomplete nouns are used to compose noun phrases from determiners and nouns for example (\"every person\" is realised as \"buri muntu\" with the initial vowel of \"person\" removed). Verbs In R&R verbal inflection depends on tense, 1 Anteriority 2 (2), Polarity (2), Noun Class of Subject, Direct Object and Indirect Object markers (33 * 6 (Person and Number) each) bringing the total possible number of combinations to 124,198,272 inflections which are impractical to enumerate and cannot be handled by the GF compiler at the moment. Apart from the Subject marker (S), Object and Indirect Markers are optional because their use eliminates the need to mention the direct and indirect object(s) in declarative sentences of R&R. We therefore decided to cater for only Subject markers bringing the number down to 3,168 inflections. We found that this number was still prohibitive to successful compilation of the grammar. In light of the above, it was impossible to design a smart-paradigm for verbs. Our solution to the problem involved building the verb at sentence level by designing smaller tables and morpheme-generating operations in Resource modules of both languages. These operations are simply used when necessary as we dynamically built the verb from the radical up to its full form. The operations are of the form \"mkX-Clitics\" and \"mkXCliticTable\" depicted in lines 25-30 & 31-36 of listing 1. The X stands for agreement concords obtained from Mpairwe and Kahangi (2013a) . It should be noted that the verbal template example provided in Table 2 is very trivial because conjugation of the R&R verb reeba i.e. \"to see\" from Universal to Perfective form is easy. You simply replace the final vowel \"a' with the morpheme \"ire\". In actual sense there exists thirty-eight rules for converting a verb in the imperative mood to the perfective mood. The rules depend on the number of sylla-bles in the verb (mono-, di-and tri-syllabic among others), the length of the penultimate vowel and the letters composing or modifying the terminal syllable such as -sa,-sh-,-za,-zya or the semi-vowels -w or -y. This can be encoded as a smart paradigm for verb conjugation but the dictionary already gives the set of terminal letters of the verb that must be replaced with the right perfective ending. For example, the entry for the verb gyenda in the R&R dictionary by (Mpairwe and Kahangi, 2013a ) is marked by da-zire to mean that in order to convert the imperative into perfective, replace the \"da\" in gyenda with \"zire\" to form gyenzire. We did not cover the full spectrum of grammatical aspects possible apart from those required for the languageindependent implementation using the concept of Anteriority in GF-RGL. We aim to provide these aspects in a separate Tense / Aspect system within the GF-RGL as extensions in the future. Determiners In R&R it is impossible to express the definite and indefinite articles as distinct words. However Asiimwe (2007) suggests that definiteness can be expressed morphosyntactically using the Initial Vowel on the noun and other constituents in the noun phrase. Demonstrative determiners are peculiar in that the word used depends on its position on the spatial dexis (Proximal, Medial and Distal), resulting in three words for each noun class. We chose to implement the former two as standard but leave the third form for implementation as an extension. The determiner agrees with number and noun class of the noun. Determiners can be derived from composition of other lexical types (such as Quantifiers and Numerals) via abstract functions: \"De-tQuant\" and \"DetQuantOrd\" in the abstract syntax. This implies that these non-constant functions add complexity to the modelling of the determiner. Different determiners may appear either before or after the noun hence the need to have a field to track the position they take in Noun Phrases constructed for example by \"DetCN\" and \"DetNP\". For the linearisation category type we used a record within another record (refer to lines 3-6 in listing 2) . The string field in the outer record is for determiners that appear before a noun and do not inflect with the Noun while the table of Agreement to Strings inside the inner record is for demonstrative determiners which agree with the noun. The words \"every\"meaning buri and \"much\" meaning -ingi are examples of determiners that take \"Pre\" and \"Post\" positions of a noun. Additionally, we have to track whether the determiner 1) composes with either a Complete or Incomplete noun in the \"nounCat\" field, and 2) is obtained from one of the composing functions. This example for determiners demonstrates the kind of thinking process involved. This process necessitates redesigning types as one encounters new knowledge about the behaviour of Syntactic categories. Adjectives The two languages have two major kinds of adjectives; those that stand alone as their Indo-European counter parts and adjectival stems that require adjectival prefixes derived from the noun class particle of the noun they qualify (Mpairwe and Kahangi, 2013b) . Stand-alone adjectives are of two types, those that require the use of possessive pronouns such as ya (\"of\" in noun class MU BA). Some adjectival stems already exist but a large number can be derived from verbs that bear the same or similar semantic meaning of the adjective in mind. Derivation is done by affixing the conjugated copulative verb \"ri\" i.e. (Subject Prefix + ri) as a prefix to the verb. An example is \"-ri-kutag\u00e1ta\" which is derived from the verb kutag\u00e1ta (to be warm). Lastly, depending on the adjective, it can either occur before or after the nominal (noun/noun phrase). A summary of this information is given in Table 4 and the linearisation category type for Adjective is given on lines 37-38 in listing 1. Adjective Type Example Self-standing Kaganga (Very Large) Self-standing (Genitive Prepositional) kijubwe (green) emotoka ya kijumbwe Adjectival Stem -rungi (nice) -kwostya (others) Numerals We implemented Numerals for R&R by following the abstract syntax designed by Hammarstr\u00f6m and Ranta (2004) . This abstract syntax attempts to give a general yet prototypical representation of numbers of several languages taken from different parts of the world. Since numbers can be nouns, quantifiers, determiners, adjectives or adverbs, modelling them becomes difficult because we have to track agreement concords attributed to gender. Numerals are inherently nouns since they give names to entities used for counting (Ordinals) and order (cardinals). However, Numerals are also quantifiers of nouns i.e. they give an indication of how much or big other nouns are. Being a noun, each numeral belongs to a noun class and therefore has an initial vowel and a noun class particle. When used in quantification of other nouns, the numeral drops the initial vowel and acquires the prefix of the noun or noun phrase it quantifies. The agreement marker (Noun Prefix) acts as a prefix to the last word of the number. For instance, take the example \"two hundred and forty people\". The number \"two hundred and forty\" in R&R is magana abiri na ana while the noun phrase \"two hundred and forty people\" is abantu magana abiri na ba-ana. Some numerals can be pluralised while others cannot for example you can have \"one 6\" (omu-kanga gumwe) and \"two groups of 6\" (emikanga ebiri). The counting system is awash with synonyms attributed to the evolution of the language over time and the influence of English. The surface form of numerals depends on whether the numeral is Cardinal or Ordinal. When numerals are used in noun phrases the surface form of the number depends on the number and noun class of the head noun in the noun phrase. Therefore we modelled the numeral using tables to store the numeral with its various inflectional forms while keeping the gender and number information as record fields. Phrasal Categories Phrasal categories are derived from the combination of one or more lexical items. The rules for creating phrasal categories are declared in the abstract syntax as functions that take lexical categories as arguments. In GF-RGL abstract syntax, common nouns, proper nouns and pronouns by themselves can be noun phrases. They can also be formed from the combination of a determiner with a noun. The linearisation category type of the noun phrase (refer to line 46-47 in listing 1) stores all forms of the surface string dependent on case. A record field is used to store the agreement information for the noun contained in the noun phrase. Verb phrases are formed from verbs and their complements. Complements maybe noun phrases, adverbial phrases and adjectival phrases. The number of complements the verb may take are one, two or none. All this complement information is stored using fields in the record for verb phrase. In GF-RGL, the clause type is used as a phrasal category to store information for various components of a sentence i.e. Subject (usually a noun phrase) and Verb Phrase. We modelled the clause using a record structure that stores: the Subject as a string and agreement information to be used at the sentence level for determining the Subject marker located in the verb. At the sentence level, clauses are converted to strings according to tense, polarity and Simultaneity (GF-RGL way of covering aspect in language neutral way) to form actual strings for the sentence. Since we could not carry around big tables from Verb-level to Sentence level, we kept the different agreement concords in table structures that can be called upon when needed. The formation of sentence is perhaps the most complicated because morphemes for tense, aspect, polarity and subject markers within the verb must be determined and placed in their various positions according to the verbal template given in Table 2 . An Example and Observations In this section, we explain how an example GF abstract syntax tree depicted in figure 1 linearises (linearisation is the process of generating strings in a particular language from a parse tree) to Runyankore and Rukiga. The example was generated from parsing the English sentence \"John drunk A GF concrete syntax tree generated from linearising the parse tree of 1 into English hot water\" using GF for the purpose of generating a parse tree. Actually GF generated three parse trees but we chose just one of them for which we had all syntax functions implemented for both Runyankore and Rukiga in the RGL. GF generates Yohana anywire am\u00e1\u00e0\u00ed\u00eczi aga kwotsya and Yohana az\u00e1\u00e0nywire am\u00e1\u00e0\u00ed\u00eczi aga kwosya as Runyankore and Rukiga linearisations for the abstract tree in figure 1 . The nodes of the parse tree are GF-RGL syntax functions and their return types (the linearisation categories). When we linearised this abstract tree to English, Runyankore and Rukiga, we obtained concrete syntax trees for the languages in figures 2 and 3 for English and Runyankore respectively. We have left out the tree for Rukiga because it it is similar to that of Runyankore. The only difference is the spelling of \"hot\" being kwosya for Rukiga as opposed to kwotsya for Runyankore. The English concrete syntax tree is straight forward with each word from the sentence linearised from the leaves of the abstract syntax tree in figure 1 . For the two R&R, a special bind symbol \"&+\" is used for concatenation i.e combining morphemes without spaces. Translation via GF is direct translation so the translations obtained may not be what a native speaker would use. However, they are grammatical i.e. they follow the syntax rules of the language. We made two observations about Runyankore & Rukiga from the parse trees: 1) concrete syntax trees are similar for the two languages and 2) the parse trees of Runyankore and Rukiga are more complicated in relation to English. The explanation for the first observation is that the grammar of the two languages are nearly identical with the exception of a few grammar rules and lexical items. The second observation stems from the fact that the languages are agglutinating resulting in several morphemes within a given word that are connected with grammatical features such as tense, aspect, mood, grammatical number, Person and noun classes. The function \"play V\" respon- sible for linearisation of the verb play cannot have all its forms conjugated in a paradigm because of the millions of possibilities as discussed already in section 4.2., hence we decided to handle it at sentence level. While implementing the grammar of these languages, we also observed that Runyankore has more resources in terms of grammar books and dictionaries with most books concentrating on Runyankore as opposed to Rukiga. Discussion During the implementation of GF-RGL for Runyankore and Rukiga we observed that the difference between these languages lies only in a few lexical items. We therefore implemented Rukiga and reused its grammar for the implementation of Runyankore. The only changes we had to make were lexical items specific to Runyankore i.e those not shared by the two languages and a few rules for tenses. In total, we have implemented 290 abstract functions of which, 167 are lexical rules while 123 are phrasal rules. The missing rules consist of 400 lexical and 280 phrasal rules. We computed the 50 most used functions on wordnet and found that we implemented 43 of those functions which is not bad coverage. We plan to perform a proper evaluation in the future after compiling huge lexica and building application grammars for language-learning applications based on this GF-RGL. We simplified the verbal template by ignoring the use of the direct and indirect Object-markers because use of such markers would require anaphoric resolution, which occurs at the discourse rather than the syntactic level. GF-RGL's ability to do multilingual translation based on its universal abstract syntax prevented us from implementing all forms of lexical and syntactic categories because it would break multilingual translation. However, GF-RGL is flexible enough to allow the grammarian to implement language specific features as extensions, which we have done for structural words and in-tend to do for other syntactic categories. During the development of the grammar, we used regression tests by repeated linearisation of GF abstract syntax trees to English, Runyankore and Rukiga to check for grammatical correctness and ensure our changes did not break existing functions. Phonological conditioning is a particular problem for R&R which we have managed to solve only in our smart noun paradigm. A global solution would require development of morphological analyser and generator for the two languages. Conclusion and Future Work In this paper, we have described our work on the development and implementation of computational resource grammars for Runyankore & Rukiga Languages. We have succeeded in the modelling and implementation of the morphology and syntax of the languages using GF. The result has been a resource grammar for each language that together have been made freely made available under an open-source licence on GF's Github. In the near future we plan to: complete the Resource Grammar Libraries for the two languages by including language-specific tense and aspectual forms for verbs packaged as additional modules and development of morphological analysers and generators as efficient tools for handling phonological conditioning. We would also like to collect a corpus on which we shall perform an evaluation of the performance of the resource grammars developed. We are currently compiling a large computational lexicon for the two languages which shall increase the coverage of our lexicon. The increase in lexical coverage improves the quality of end user applications developed using resource grammars. Lastly, we will build application grammars in the domain of Computerassisted language Learning for teaching learners of the two languages about the mechanics of the grammars of these languages.",
    "funding": {
        "defense": 0.0,
        "corporate": 0.0,
        "research agency": 0.0,
        "foundation": 5.51223498068687e-07,
        "none": 1.0
    },
    "reasoning": "Reasoning: The article does not mention any specific funding sources, including defense, corporate, research agencies, foundations, or any other type of financial support for the research conducted. Therefore, based on the information provided, it appears there was no disclosed funding.",
    "abstract": "In this paper, we present computational resource grammars of Runyankore and Rukiga (R&R) languages. Runyankore and Rukiga are two under-resourced Bantu Languages spoken by about 6 million people indigenous to South Western Uganda, East Africa. We used Grammatical Framework (GF), a multilingual grammar formalism and a special-purpose functional programming language to formalise the descriptive grammar of these languages. To the best of our knowledge, these computational resource grammars are the first attempt to the creation of language resources for R&R. In Future Work, we plan to use these grammars to bootstrap the generation of other linguistic resources such as multilingual corpora that make use of data-driven approaches to natural language processing feasible. In the meantime, they can be used to build Computer-Assisted Language Learning (CALL) applications for these languages among others.",
    "countries": [
        "Uganda",
        "Sweden"
    ],
    "languages": [
        "English",
        "Runyankore"
    ],
    "numcitedby": 2,
    "year": 2020,
    "month": "May",
    "title": "Towards Computational Resource Grammars for {R}unyankore and Rukiga",
    "values": {
        "building on past work": "In this paper, we present computational resource grammars of Runyankore and Rukiga (R&R) languages. Runyankore and Rukiga are two under-resourced Bantu Languages spoken by about 6 million people indigenous to South Western Uganda, East Africa. We used Grammatical Framework (GF), a multilingual grammar formalism and a special-purpose functional programming language to formalise the descriptive grammar of these languages. To the best of our knowledge, these computational resource grammars are the first attempt to the creation of language resources for R&R. In Future Work, we plan to use these grammars to bootstrap the generation of other linguistic resources such as multilingual corpora that make use of data-driven approaches to natural language processing feasible. Previous work on the computational modelling of the grammar of R&R include: noun and verb morphological analysers by Katushemererwe and Hanneforth (2010b; 2010a) , a Controlled Natural Language for Runyankore (Byamugisha et al., 2016) and a Noun pluralizer (Byamugisha et al., 2018) . However, this work has been limited to small fragments of the languages. Within the GF community, there has been work on computational modeling of Bantu languages: Kikamba (Kituku et al., 2019) , Tswana (Pretorius et al., 2017) , and Swahili (Ng\u00e1ng\u00e1, 2012) . While we consulted the Swahili implementation during initial development, we found that Swahili is morphologically and syntactically less complex than R&R. Additionally, its coverage of the GF-RGL functions was very small. Little insight was generated from that grammar. Likewise the Tswana GF-RGL was limited to modelling the proper verb for declarative sentences which is small in scope. Twsana's use of both a disjunctive and conjunctive orthography as compared to R&R's conjunctive morphology also provided limited insights into how to implement the grammars of R&R. Work on Kikamba and R&R was done during the same timeframe and hence both of us benefited from the sharing of ideas."
    }
}