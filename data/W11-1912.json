{
    "article": "We introduce an incremental model for coreference resolution that competed in the CoNLL 2011 shared task (open regular). We decided to participate with our baseline model, since it worked well with two other datasets. The benefits of an incremental over a mention-pair architecture are: a drastic reduction of the number of candidate pairs, a means to overcome the problem of underspecified items in pairwise classification and the natural integration of global constraints such as transitivity. We do not apply machine learning, instead the system uses an empirically derived salience measure based on the dependency labels of the true mentions. Our experiments seem to indicate that such a system already is on par with machine learning approaches. Introduction With notable exceptions (Luo et al., 2004; Yang et al., 2004; Daume III and Marcu, 2005; Culotta et al., 2007; Klenner, 2007; Rahman and Ng, 2009; Klenner and Ailloud, 2009; Cai and Strube, 2010; Raghunathan et al., 2010) supervised approaches to coreference resolution are often realized by pairwise classification of anaphor-antecedent candidates. A popular and often reimplemented approach is presented in (Soon et al., 2001) . As recently discussed in (Ng, 2010) , the so called mention-pair model suffers from several design flaws which originate from the locally confined perspective of the model: \u2022 Generation of (transitively) redundant pairs, as the formation of coreference sets (coreference clustering) is done after pairwise classification \u2022 Thereby generation of skewed training sets which lead to classifiers biased towards negative classification \u2022 No means to enforce global constraints such as transitivity \u2022 Underspecification of antecedent candidates These problems can be remedied by an incremental entity-mention model, where candidate pairs are evaluated on the basis of the emerging coreference sets. A clustering phase on top of the pairwise classifier no longer is needed and the number of candidate pairs is reduced, since from each coreference set (be it large or small) only one mention (the most representative one) needs to be compared to a new anaphor candidate. We form a 'virtual prototype' that collects information from all the members of each coreference set in order to maximize 'representativeness'. Constraints such as transitivity and morphological agreement can be assured by just a single comparison. If an anaphor candidate is compatible with the virtual prototype, then it is by definition compatible with all members of the coreference set. We designed our system to work purely with a simple, yet empirically derived salience measure. It turned out that it outperformed (for German and English, using CEAF, B-cubed and Blanc) the systems from the 2010's SemEval shared task 1 on 'coreference resolution in multiple languages'. Only with the more and more questioned (Luo, 2005; Cai and Strube, 2010) MUC measure our system performed worse (at least for English). Our system uses real preprocessing (i.e. a dependency parser (Schneider, 2008) ) and extracts markables (nouns, named entities and pronouns) from the chunks and based on POS tags delivered by the preprocessing pipeline. Since we are using a parser, we automatically take part in the open regular session. Please note that the dependency labels are the only additional information being used by our system. Our Incremental Model Fig. 1 shows the basic algorithm. Let I be the chronologically ordered list of markables, C be the set of coreference sets (i.e. the coreference partition) and B a buffer, where markables are stored, if they are not found to be anaphoric (but might be valid antecedents, still). Furthermore m i is the current markable and \u2295 means concatenation of a list and a single item. The algorithm proceeds as follows: a set of antecedent candidates is determined for each markable m i (steps 1 to 7) from the coreference sets and the buffer. A valid candidate r j or b k must be compatible with m i . The definition of compatibility depends on the POS tags of the anaphor-antecedent pair (in order to be coreferent, e.g. two pronouns must agree in person, number and gender etc.). In order to reduce underspecification, m i is compared to a virtual prototype of each coreference set. The virtual prototype bears information accumulated from all elements of the coreference set. For instance, assume a candidate pair 'she .. Clinton'. Since the gender of 'Clinton' is unspecified, the pair might or might not be a good candidate. But if there is a coreference set already including 'Clinton', let's say: {'Hilary Clinton', her, she} then we know the gender from the other members and are more save in our decision. The virtual prototype here would be something like: singular, feminine, human. From the set of candidates, Cand, the most salient ante i \u2208 Cand is selected (step 10) and the coreference partition is augmented (step 11). If ante i comes from a coreference set, m i is added to that set. Otherwise (ante i is from the buffer), a new set is formed, {ante i , m i }, and added to the set of coreference sets. Restricted Accessibility of Antecedent Candidates As already discussed, access to coreference sets is restricted to the virtual prototype -the concrete members are invisible. This reduces the number of considered pairs (from the cardinality of a set to 1). Moreover, we also restrict the access to buffer elements: if an antecedent candidate, r j , from a coreference set exists, then elements from the buffer, b k , are only licensed if they are more recent than r j . If both appear in the same sentence, the buffer element must be more salient in order to get licensed. Filtering based on Anaphora Type There is a number of conditions not shown in the basic algorithm from Fig. 1 that define compatibility of antecedent and anaphor candidates based on POS tags. Reflexive pronouns must be bound in the subclause they occur, more specifically to the subject governed by the same verb. Personal and possessive pronouns are licensed to bind to morphologically compatible antecedent candidates (named entities, nouns 2 and pronouns) within a window of three sentences. We use the information given by CoNLL input data to identify 'speaker' and the person adressed by 'you'. 'I' refers to one of the coreference sets whose speaker is the person who, according to the CoNLL data, is the producer of the sentence. 'You' refers to the producer of the last sentence not being produced by the current 'speaker'. If one didn't have access to these data, it would be impossible to correctly identify the reference of 'I', since turn taking is not indicated in the pure textual data. As we do not use machine learning, we only apply string matching techniques to match nominal NPs and leave out bridging anaphora (i.e. anaphoric nouns that are connected to their antecedents through a semantic relation such as hyponymy and cannot be identified by string matching therefore). Named entities must either match completely or the antecedent must be longer than one token and all tokens of the anaphor must be contained in the antecedent (to capture relations such Definite NPs match with noun chunks that are longer than one token 3 and must be contained completely without the determiner (e.g. 'Recent events ... the events'). From the candidates that pass these filters the most salient one is selected as antecedent. If two or more candidates with equal salience are available, the closest one is chosen. Binding Theory as a Filter There is another principle that help reduce the number of candidates even further: binding theory. We know that 'He' and 'him' cannot be coreferent in the sentence 'He gave him the book'. Thus, the pair 'He'-'him' need not be considered at all. Actually, there are subtle restrictions to be captured here. We have not implemented a full-blown binding theory on top of our dependency parser, yet. Instead, we approximated binding restrictions by subclause detection. 'He' and 'him' in the example above are in the same subclause (the main clause) and are, thus, exclusive. This is true for nouns and personal pronouns, only. Possesive and reflexive pronouns are allowed to be bound in the same subclause. An Empirically-based Salience Measure Since we look for a simple and fast salience measure and do not apply machine learning in our baseline system, our measure is solely based on the grammatical functions (given by the dependency labels) of the true mentions. Grammatical functions have played a major role in calculating salience, especially in rule based system such as (Hobbs, 1976; Lappin and Leass, 1994; Mitkov et al., 2002; Siddharthan, 2003) . Instead of manually specifying the weights for the dependency labels like (Lappin and Leass, 1994) , we derived them empirically from the coreference CoNLL 2011 gold standard (training data). The salience of a dependency label, D, is estimated by the number of true mentions in the gold standard that bear D (i.e. are connected to their heads with D), divided by the total number of true mentions. The salience of the label subject is thus calculated by: N umber of true mentions bearing subject T otal number of true mentions For a given dependency label, this fraction indicates how strong is the label a clue for bearing an antecedent. This way, we get a hierarchical ordering of the dependency labels (subject > object > pobject > ...) according to which antecedents are ranked. Clearly, future work will have to establish a more elaborate calculation of salience. To our surprise, however, this salience measure performed quite well, at least together with our incremental architeture. Evaluation The results of our evaluation over the CoNLL 2011 shared task development set are given in Fig. 2 (development set) and 3 (official results on the test set). The official overall score of our system in the open regular setting is 51.77. Our results are mediocre. There are several rea- sons for that. First and foremost, the scorer requires chunk extensions to match perfectly. That is, even if the head of an antecedent is found, this does not count if the chunk extension of that noun phrase was not correctly Since chunks do not play a major role in depencendy parsing, our approximation might be faulty 4 . Another shortcomming are nominal anaphora that can not be identified by string matching (e.g. Obama ... The president). Our simple salience-based approach does not cope at all with this type of anaphora. 4 Related Work (Ng, 2010) discusses the entity-mention model which operates on emerging coreference sets to create features describing the relation of an anaphor candidate and established coreference sets. (Luo et al., 2004 ) implemented such a model but it performed worse than the mention-pair model. (Yang et al., 2004) presented an incremental model which used some coreference set specific features, namely introducing the number of mentions in a set as a feature besides checking for morphological compatibility with all mentions in a set. They also report that the set size feature only marginally improves or in some combinations even worsens system performance. (Daume III and Marcu, 2005) introduced a wide range of set specific features, capturing set count, size and distribution amongst others, in a joint model for the ACE data. All the above mentioned systems use an incremental model to generate features describing the emerging coreference sets and the anaphor candidate. In contrast, we use an incremental architecture to control pair generation in order to prevent generation of either redundant or irrelevant pairs. Conclusions We have introduced an incremental model for coreference resolution based on an empirically derived salience measure that is meant as a simple and very fast baseline system. We do not use machine learning, nor do we resolve more complex nominal anaphora such as 'Obama ... The president' (but we handle those that can be resolved by simple pattern matching, e.g. Hilary Clinton .. Clinton). Given these restrictions, our system performed well. The central idea of our approach is that the evolving coreference sets should restrict the access to antecedent candidates in a twofold way: by use of virtual prototypes that accumulate the properties of all members of a coreference set (e.g. wrt. animacy), but also by restricting reachable buffer elements (i.e. yet unattached markables). The benefits of our incremental model are: \u2022 due to the restricted access to antecedent candidates, the number of generated candidate pairs can be reduced drastically 5 \u2022 no coreference clustering phase is needed \u2022 the problem of underspecification that exists for any pair-wise model can be compensated by a virtual prototype that accumulates the properties of the elements of a coreference set These benefits are independent of the underlying classification scheme, be it a simple saliencebased one or a more advanced machine learning one. The work presented here thus would like to opt for further research based on incremental architectures. Web demos for English and German are available 6 .",
    "abstract": "We introduce an incremental model for coreference resolution that competed in the CoNLL 2011 shared task (open regular). We decided to participate with our baseline model, since it worked well with two other datasets. The benefits of an incremental over a mention-pair architecture are: a drastic reduction of the number of candidate pairs, a means to overcome the problem of underspecified items in pairwise classification and the natural integration of global constraints such as transitivity. We do not apply machine learning, instead the system uses an empirically derived salience measure based on the dependency labels of the true mentions. Our experiments seem to indicate that such a system already is on par with machine learning approaches.",
    "countries": [
        "Switzerland"
    ],
    "languages": [
        "English",
        "German"
    ],
    "numcitedby": "6",
    "year": "2011",
    "month": "June",
    "title": "An Incremental Model for Coreference Resolution with Restrictive Antecedent Accessibility"
}