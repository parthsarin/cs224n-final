{
    "article": "This paper considers minimum phone error (MPE) based discriminative training of acoustic models for Mandarin broadcast news recognition. We present a new phone accuracy function based on the frame-level accuracy of hypothesized phone arcs instead of using the raw phone accuracy function of MPE training. Moreover, a novel data selection approach based on the frame-level normalized entropy of Gaussian posterior probabilities obtained from the word lattice of the training utterance is explored. It has the merit of making the training algorithm focus much more on the training statistics of those frame samples that center nearly around the decision boundary for better discrimination. The underlying characteristics of the presented approaches are extensively investigated, and their performance is verified by comparison with the standard MPE training approach as well as the other related work. Experiments conducted on broadcast news collected in Taiwan demonstrate that the integration of the frame-level phone accuracy calculation and data selection yields slight but consistent improvements over the baseline system. Introduction Speech is the primary and the most convenient means of communication between individuals. Due to the successful development of much smaller electronic devices and the popularity of wireless communication and networking, it is widely believed that speech will possibly serve as a major human-machine interface for the interaction between people and different kinds of smart devices in the near future. On the other hand, huge quantities of multimedia information, \uff0a Department of Computer Science & Information Engineering, National Taiwan Normal University E-mail: {g93470185, g94470144, g96470198, berlin}@csie.ntnu.edu.tw such as that in broadcast radio and television programs, voice mails, digital archives, and so on are continuously growing and filling our computers, networks, and daily lives. Speech is obviously one of the most important information-bearing sources for the great volumes of multimedia. Based on these observations, it is expected that automatic speech recognition (ASR) technology will play a very important role in human-machine interaction, as well as in organization and retrieval of multimedia content. When considering the development of an ASR system, acoustic modeling is always an indispensable and crucial ingredient we have to carefully manipulate. The purpose of acoustic modeling is to provide a method for calculating the likelihood of a speech utterance occurring given a word sequence. In principle, the word sequence can be decomposed into a sequence of phone-like (subword, e.g. INITIAL or FINAL in Mandarin Chinese) units or acoustic models, each of which is normally represented by a continuous density hidden Markov model (HMM), and the corresponding model parameters can be estimated from a corpus of orthographically transcribed training utterances using maximum likelihood (ML) training [Rabiner 1989 ]. The acoustic models can be alternatively trained with discriminative training algorithms, such as maximum mutual information (MMI) training [Bahl et al. 1986 ] and minimum phone error (MPE) training [Povey 2004; Kuo et al. 2006 ]. These algorithms were developed in an attempt to correctly discriminate the recognition hypotheses for the best recognition results rather than just to fit the model distributions as done by ML training; therefore, they have continuously been a focus of considerable active research in a wide variety of large vocabulary continuous speech recognition (LVCSR) tasks over the past few years. Moreover, in contrast to ML training, discriminative training considers not only the reference (or correct) transcript of a training utterance, but also the competing (or incorrect) hypotheses that are often obtained by performing LVCSR on the utterance. In this paper, we consider minimum phone error (MPE) based discriminative training of acoustic models for Mandarin broadcast news recognition. In order to remedy the defect in the phone accuracy function of the MPE training algorithm, we present a new phone accuracy function based on the frame-level accuracy of hypothesized phone arcs. Moreover, a novel data selection approach based on the frame-level normalized entropy of Gaussian posterior probabilities obtained from the word lattice of the training utterance is explored, which has the merit of making the MPE training algorithm focus much more on the training statistics of those frame samples that center nearly around the decision boundary for better discrimination. The underlying characteristics of the presented approaches are extensively investigated and their performance is verified by comparison with the original MPE training approach as well as other related work. Review of Minimum Phone Error (MPE) Training Given a training set of K acoustic vector sequences { } 1 ,.., ,.., k K O O O O = , the MPE criterion for acoustic model training aims to minimize the expected phone errors of these acoustic vector sequences using the following objective function [Povey and Woodland 2002] : 1 ( ) ( ) ( | ), lat k k K MPE k k k k W F R a w A c c WP WO \u03bb \u03bb = \u2208 = \u2211 \u2211 W (1) where \u03bb denotes a set of phone-like acoustic models; lat k W is the corresponding word lattice [Ortmanns et al. 1997 ] of k O obtained using LVCSR, as graphically illustrated in Figure 1 ; k W is one of the hypothesized word sequences in lat k W ; ( | ) k k P W O is the posterior probability of hypothesis k W given k O ; ( ) k RawAcc W is the \"raw phone accuracy\" of k W in comparison to the corresponding reference transcript, which is typically computed as the sum of the phone accuracy measures of all phone hypotheses in k W . Then, the objective function in Equation ( 1 ) can be maximized by applying the Extended Baum-Welch algorithm [Gopalakrishnan et al. 1989] O O D D \u03b8 \u03b8 \u03c3 \u03bc \u03c3 \u03bc \u03b3 \u03b3 \u2212 + + = \u2212 \u2212 + (3) 1 , ( ) max(0, ), q M PE lat q k e K num k k hm qm q k ts q q h t \u03b3 \u03b3 \u03b3 = = \u2208 = = \u2211 \u2211 \u2211 W (4) 1 , ( ) max(0, ), q M PE lat q k e K den k k hm qm q k ts q q h t \u03b3 \u03b3 \u03b3 = = \u2208 = = \u2212 \u2211 \u2211 \u2211 W (5) ( ) ( ) 1 , ( ) max(0, ) , q MPE lat q k e K num k k hmd qm q t k ts q q h O t od \u03b8 \u03b3 \u03b3 = = \u2208 = = \u2211 \u2211 \u2211 W (6) ( ) ( ) 2 2 1 , ( ) max(0, ) , q MPE lat q k e K num k k hmd qm q t k ts q q h O t o d \u03b8 \u03b3 \u03b3 = = \u2208 = = \u2211 \u2211 \u2211 W (7) ( ) , M PE k k k k q q q a v g c c \u03b3 \u03b3 = \u2212 (8) where , lat k q q h \u2208 = W denotes that a phone q arc belongs to the word lattice lat k W and physically refers to the HMM h ; k avg c is the average phone accuracy over all hypothesized word sequences in the word lattice; k q c is the expected phone accuracy over all hypothesized word sequences containing a phone arc q ; ( ) t o d is the observation vector component at frame t ; q example, the raw phone accuracy for each word sequence k W in the lattice can be calculated in terms of the sum of the accuracy of each phone contained in k W [Povey and Woodland 2002] : ( ) ( ), k k q W R aw A cc W P honeA cc q \u2208 = \u2211 (9) where ( ) PhoneAcc q is the raw phone accuracy for a phone arc q in k W , which can be defined as follows: e z q l z z q PhoneAcc q e z q l z z q \u2208 \u2212 + = \u23a7 \u23ab \u23aa \u23aa = \u23a8 \u23ac \u2212 + \u2260 \u23aa \u23aa \u23a9 \u23ad (10) where k Z is the set of phone labels in the corresponding reference transcript, and ( , ) j e z q is the overlap length in frames (or in time) for a phone label j z in k Z and a hypothesized phone arc q in k W , ) ( j z l is the length in frames for j z . We can observe from Equations ( 4 )-( 8 ), for MPE training, those hypotheses having raw phone accuracies higher than the average can provide positive contributions, and vice-versa for those hypotheses with accuracies lower than the average. Interested readers can refer to [Povey 2004; Kuo et al. 2006] for more derivation details of MPE training. New Accuracy Functions It is known that the standard MPE training approach has some drawbacks [Zheng and Stolcke 2005] . One of them is that MPE training does not sufficiently penalize deletion errors. In general, the original MPE objective function discourages insertion errors more than deletion and substitution errors. Inspired by the work of word lattice rescoring (or decoding) using frame-level accuracy information [Wessel et al. 2001] , in this paper we present an alternative phone accuracy function that can look into the frame-level phone accuracies of all hypothesized word sequences to replace the original raw phone accuracy function for MPE training [Liu et al. 2007a] . The frame-level phone accuracy function (FA) is defined as: ( ) ( , ) ( ) , 1 q q e k t s q q q Z t F ram eA cc q e s \u03b4 = = \u2212 + \u2211 (11) and ( ) ( ) ( ) 1 , ( , ) , , , 0 1 k k k if q Z t q Z t if q Z t \u03b4 \u03c1 \u03c1 = \u23a7 \u23ab \u23aa \u23aa = \u23a8 \u23ac \u2212 \u2260 < < \u23aa \u23aa \u23a9 \u23ad (12) where ( ) k Z t is the phone label of the reference transcript k Z at frame t ; \u03c1 is a tunable positive parameter used to control the penalty if the phone arc q is incorrect in its label; and the value of ( ) FrameAcc q will range from \u03c1 \u2212 to 1. For each frame t , we thus can easily evaluate whether the phone arc of each hypothesized word sequence in the word lattice is identical to that of the reference transcript or not. Actually, the presented frame-level phone accuracy function emphasizes the deletion penalty on the incompletely correct phone arc; whereas the insertion and substitution errors of the hypothesized word sequences, as well as the errors caused by inaccurate time boundaries of the phone arcs, are also taken into consideration evenly. As illustrated in Figure 2 , given the reference phone transcript \"a-b-c\", the first hypothesized phone sequence \"a-b-c\" will be regarded as partially correct (with a score of two) using the original MPE raw phone accuracy function, as shown in Eq. ( 10 ); while the presented frame-level phone accuracy function, as shown in Eq. ( 11 ), will give it a score of 2.56 (with \u03c1 set to 0.1) by similarly taking into account the incorrect time boundaries of the associated phone arcs. On the other hand, for the second hypothesized phone sequence \"a-c\", it is obvious that there exists a deletion error of the phone arc \"b.\" Nevertheless, the original MPE raw phone accuracy function gives the second hypothesized phone sequence a score of two, which is equivalent to that of the first hypothesized phone sequence, and the phone arcs (\"a\" and \"c\") of it will be treated as completely correct. While using our proposed frame-level phone accuracy function, both of the two phone arcs in the second hypothesized phone sequence will instead be treated as partially correct by considering the frame-level substitution errors. Thus, the frame-level phone accuracy function will only assign a total score of 1.27 (with \u03c1 set to 0.1) to the second hypothesized phone sequence. Another frame-level phone accuracy function that uses the Sigmoid function to normalize the phone accuracy value in a range between -1 and 1 is also investigated in this paper (SFA): 2 ( ) 1, 1 exp( ) SigFrameAcc q net \u03b1 = \u2212 + \u2212 \u22c5 (13) and ( ) ( , ), q q e k t s n et q z t \u03b4 = = \u2211 (14) where ( ) ( , ) k q Z t \u03b4 was previously defined in Eq. ( 12 ), \u03b1 is a positive parameter that controls the slope of the Sigmoid function (the larger the value of \u03b1 , the steeper the slope of the function). Notice that, the purpose of the above two new phone accuracy functions is not to Figure 2. An illustration of the frame-level accuracy. The shaded box indicates where the frame-level errors occur. Acoustic Models for Mandarin Large Vocabulary Continuous Speech Recognition approximate the standard Levenshtein distance measure, but instead to sufficiently penalize the frame-level substitution errors of each hypothesized phone arc that may be neglected by the original raw phone accuracy function. From now on, the proposed improved MPE training algorithms, by adopting either one of the two frame-level phone accuracy functions defined in Eqs. ( 11 ) and ( 13 ), are referred to as the maximum frame accuracy training (denoted as MFA) and the maximum Sigmoid-based frame accuracy training (denoted as MSFA), respectively. In recent years, there also has been considerable independent research on the design of new phone accuracy functions for improving MPE training [Zheng and Stolcke 2005; Gibson et al. 2006; Du et al. 2006; Povey et al. 2007] . As one example, the minimum phone frame error (MPFE) criterion [Zheng and Stolcke 2005] simply counts the number of frames of the recognition hypothesis having correct phone labels in comparison to the reference transcript, which is quite similar to our proposed frame-level accuracy functions. The major differences are that MPFE gives a score of zero (but not a negative value as done by MFA and MSFA) to the frames with incorrect phone labels, and the corresponding phone accuracy value is not normalized by the phone duration or the Sigmoid function. As another example, the state-level minimum Bayes risk (sMBR) criterion [Gibson et al. 2006; Povey et al. 2007 ] uses the HMM state-level information to fulfill label matching. As still another example, the minimum divergence (MD) criterion [Jun Du et al. 2006 ] defines phone accuracy on the basis of the Kullback-Leibler divergence between the corresponding acoustic models of the reference and hypothesized phone labels. More detailed elucidation and comparison of these alternative phone accuracy functions can be found in [Povey et al. 2007 ]. Although a discriminative training approach using the finite state transducer, retaining the corresponding recognition hypotheses of the training acoustic vector sequence, for calculating the exact Levenshtein distance based word error rate was also proposed recently [Heigold et al. 2005] , no improved results but only degraded results were demonstrated by the approach. Frame-Level Training Data Selection In this section, we elucidate the theoretical roots of frame-level training data selection using the entropy information, as well as two variant implementations to achieve this goal. Normalized Frame-Level Entropy We propose the use of the entropy information to select the frame-level training statistics for the MPE training. The normalized entropy of a training frame sample i can be defined as [Liu et al. 2007b] : 1 1 ( ) ( ) log , log ( ) lat k k k q m k m q q t qm E t t N t \u03b3 \u03b3 \u2208 \u2208 = \u22c5 \u2211 \u2211 W (15) where ) (t k qm \u03b3 is the posterior probability for mixture component m of phone arc q at frame t , which is calculated from the word lattice; t N is the number of Gaussian mixtures which have nonzero posterior probabilities at frame t ( 0 ) ( > t k qm \u03b3 ); and the value of ( ) k E t will range from zero to one [Misra and Bourlard 2005] . Here, we use a hypothetical example of binary classification to illustrate the relationship between the decision boundary and the normalized entropy. As shown in Figure 3 , the decision boundary constructed based on the posterior probability of the class 1 C can discriminate most of the samples belonging to 1 C (depicted as squares) from those belonging to 2 C (depicted as circles). In general, the decision boundary is at the value of 0.5 for the posterior probability of 1 C and the class posterior probabilities can be used to calculate the normalized entropies of the samples. Thus, the samples (solid circles or squares) located near the decision boundary will have normalized entropies close to one, while those (hollow circles or squares) located far away from the decision boundary will have normalized entropies close to zero. For the speech recognition task, two extreme cases are considered as follows. First, if the normalized entropy measure of a frame sample i is close to zero, it means that the corresponding frame-level posterior probabilities will be dominated by one specific mixture component. From the viewpoint of frame sample classification using posterior probabilities, the difference of probabilities between the true (correct) mixture component and the competing (incorrect) ones is larger. That is, the frame sample i is actually located far from the decision boundary. On the other hand, if the normalized entropy measure is close to one, it Acoustic Models for Mandarin Large Vocabulary Continuous Speech Recognition means that the posterior probabilities of mixture components tend to be uniformly distributed. Then, the frame sample i is instead located near the decision boundary. In a word, the normalized entropy measure to some extent can define a kind of margin for the selection of useful training frame samples. Therefore, we may take advantage of the normalized entropy measure to make the MPE training focus much more on the training statistics of those frame samples that center near the decision boundary for better sample discrimination and model generalization [Jiang et al. 2006; Li et al. 2006 ]. Hard Version of Frame Sample Selection (HS) A straightforward implementation of frame-level training data selection is to define a threshold of the normalized entropy measure then completely discard the training statistics of those frame samples whose normalized entropy values fall below it. This can be viewed as a \"hard version\" of data selection. Figure 4 shows a histogram describing the relationship between the normalized entropy and the number of training speech frame samples used in this study. For example, the leftmost vertical bar denotes the number of training speech frame samples whose normalized entropy values are in the range of 0 to 0.05. The large number of frame samples belonging to the leftmost vertical bar also reveals that most of the training frame samples in fact are located far from the decision boundary; thus, they can be discarded if the threshold is appropriately set. Soft Version of Frame Sample Selection (SS) We also attempt an alternative implementation (or a \"soft version\") of frame-level training data selection to emphasize the training statistics of those frame samples that are located near the decision boundary according to their normalized entropy values using the following formula: (1 ( )), MPE MPE k k q q k E t \u03b3 \u03b3 \u03c9 \u2032 = \u22c5 + \u22c5 ( 16 ) where \u03c9 is tunable positive parameter whose value ranges from 0 to 1. As indicated by Equation ( 16 ), if the normalized entropy value ( ) k E t of a training frame sample i is higher, then its corresponding training statistics will be emphasized. On the contrary, for a frame sample with a lower entropy value, its training statistics will be deemphasized when compared to those of the frame samples with higher normalized entropy values. Experiment Setup In this section, we describe the speech and text data, as well as the large vocabulary continuous speech recognition system, employed in this paper. Speech Corpus and Acoustic Model Training The speech corpus consisted of approximately 198 hours of MATBN (Mandarin Across Taiwan Broadcast News) Mandarin television news content [Wang et al. 2005] Lexicon and N-gram Language Modeling Initially, the recognition lexicon consisted of 67K words. A set of about 5K compound words was automatically derived using forward and backward bigram statistics [Saon and Padmanabhan 2001] and added to the lexicon to form a new lexicon of 72K words. The background language models used in this experiment were trigram and bigram models, which were estimated according to the ML criterion using a text corpus consisting of 170 million Chinese characters collected from the Central News Agency (CNA) in 2001 and 2002 (the Chinese Gigaword Corpus released by LDC). In implementation, the n-gram language models were trained with the SRI Language Modeling Toolkit [Stolcke 2000 ]. Speech Recognition System The front-end processing for speech recognition was performed with the HLDA-based (Heteroscedastic Linear Discriminant Analysis) data-driven Mel-frequency feature extraction approach [Kumar 1997 ] then processed by MLLT (Maximum Likelihood Linear Transformation) transformation [Saon et al. 2000] for feature de-correlation. In addition, utterance-based feature mean subtraction and variance normalization were applied to all the training and test speech. The speech recognizer was implemented with a left-to-right frame-synchronous Viterbi tree-copy search and a lexical prefix tree of the lexicon [Aubert 2002 ]. For each speech frame, a beam pruning technique, which considered the decoding scores of path hypotheses together with their corresponding unigram language model look-ahead scores and syllable-level acoustic look-ahead scores [Chen et al. 2005] , was used to select the most promising path hypotheses. Moreover, if the word hypotheses ending at each speech frame had higher scores than a predefined threshold, their associated decoding information, such as the word start and end frames, the identities of current and predecessor words, and the acoustic score, were kept to build a word lattice for further language model rescoring. We used the word bigram language model in the tree search procedure and the trigram language model in the word lattice rescoring procedure [Ortmanns et al. 1997 ]. Experiment Results As it is known that there are no explicit marks, such as spaces or blanks, separating words in the Chinese language, the Chinese language often suffers from word tokenization problems. The performance evaluation metric used in Mandarin speech recognition usually is the character error rate (CER) rather than the word error rate (WER). Baseline System The acoustic models were trained with about 25 hours of speech utterances. The MPE training started with the acoustic models trained by 10 iterations of the ML training, and used the information contained in the associated word lattices of training utterances to accumulate the necessary statistics for model training. The ML-trained acoustic models yields a CER (Chinese Character Error Rate) of 23.64%, while the standard MPE training (denoted as MPE) indeed can provide a great boost to the acoustic models initially trained by ML consistently at all training iterations, as the curve \"MPE\" depicted in Figure 4 or the results shown in the leftmost column of Table 1 . In the following experiments, for fair comparison between our proposed methods and the baseline MPE training, the smoothing constant (i.e., the \u03c4 value of I-smoothing) [Povey and   Woodland 2002; Povey 2004; Kuo et al. 2006] is set to be the same as that used in the baseline MPE training. It is known that this smoothing constant can be regarded as a kind of prior information which forces the HMM parameters estimated by the MPE training to center around that estimated by the ML training [Povey et al. 2007 ]. Experiments on Proposed Frame-level Phone Accuracy Functions We first evaluate the performance of our proposed two frame-level phone accuracy functions, FA (corresponding to the MFA training) and SFA (corresponding to the MSFA training), as previously described in Section 3. As can be seen from Figure 5 , both MFA and MSFA Table 1. CER results (%) obtained for different parameter settings of the MPE training using two variant phone accuracy functions (MFA and MSFA) . Acoustic Models for Mandarin Large Vocabulary Continuous Speech Recognition outperform the standard MPE at higher training iterations, and MSFA is slightly better than MFA, though the difference between them is negligible at lower training iterations. On the other hand, we have observed from a series of experiments that, using the two variants of frame-level phone accuracy functions with different settings of the value of their parameter \u03c1 will give different penalties for insertions and deletions. For example, if the value of \u03c1 is set to be larger, insertion errors will be discouraged; while, if the value of \u03c1 is set to be smaller, the number of deletion errors will be decreased. More concretely, we can trade off insertion and deletion errors by appropriately adjusting the penalty parameter \u03c1 . Table 1 shows the results obtained for different parameter settings of the two variant phone accuracy functions, where the optimum setting for MFA is \u03c1 =0.5, while for MSFA is \u03c1 =0.1 and \u03b1 = 0.5. MFA ( \u03c1 =0.5) trained with 10 iterations (20.46%) leads to an absolute CER reduction of 0.31% over MPE trained with the same iterations (20.77%), which is equivalent to a condition where about 81 of the character recognition errors have been corrected. A significance test based on the standard NIST MAPSSWE [Gillick and Cox 1989 ] also indicates the statistical significance of such an improvement (p-value <0.001). Iterations MPE MFA \u03c1 =0.1 MFA \u03c1 =0.3 MFA \u03c1 =0.5 MFA \u03c1 =0.8 MSFA \u03c1 =0.1 = \u03b1 0.5 MSFA \u03c1 =0.5 = \u03b1 0.5 MSFA \u03c1 =0.1 = \u03b1 1 MSFA \u03c1 =0.5 = \u03b1 1 Comparison of Proposed and Other Phone Accuracy Functions We (i.e., the \u03c4 value of I-smoothing) is a very important factor and should be properly scaled on the basis of the ML training statistics [Povey 2004 ]. Owing to the different dynamic ranges of the phone accuracy values of the other three modified phone accuracy functions, the smoothing constant is suggested to be scaled accordingly when different training criteria (or phone accuracy functions) are being used. For example, the dynamic range of the phone accuracy values of MPFE training is apparently far larger than that of the standard MPE training, so the smoothing constant for the MPFE training should be empirically set to be larger than that of the standard MPE training. As evidenced by Figure 6 , the recognition results of MD training are slightly worse than the standard MPE training for most of the training iterations. One possible reason for this is that the MD objective function is not well optimized, since the statistics for computing the KL divergence between any two HMM state-level probability distributions are fixed during the training process. Similar observations were also made in [Povey et al. 2007 ]. Furthermore, the corresponding results of the MPFE and sMBR training are also worse than those of the standard MPE training, which could be analyzed as follows. The statistics MPE k q \u03b3 of MPE training mainly depend on two parts (cf. Eq. ( 8 )). One is the posterior probability k q \u03b3 of a phone arc q , while the other is the difference between the expected phone accuracy k q c over all hypothesized phone sequences containing q and the average phone accuracy   As evidenced by Table 2 , data selection (either MPE+HS or MPE+SS) will improve the performance of MPE when the acoustic models are trained at the lower iterations, and achieve comparable results to that of MPE trained at higher iterations. This means that data selection can help reduce the time consumed in training but retain the same performance. However, when the acoustic models of the frame-level data selection method are trained at higher iterations (e.g., 9 and 10 iterations), the corresponding performance, especially for MPE+HS, will become slightly worse than the standard MPE training. One possible reason for this is that the normalized entropy value and the amount of data selected by the hard-version data selection method (MPE+HS) would decrease through the training iterations, which has the side effect of making the training to some extent suffer from the data sparseness problem that makes the acoustic models over-trained. Therefore, one of our future research directions is to study the analysis of such an effect in more detail and try to dynamically adjust the selection threshold value through the iterations. On the other hand, we also apply random frame-level training sample selection to the MPE training, which randomly selects about 45% of the frame-level training samples for the MPE training at each training iteration, and the corresponding results are depicted in Table 2 (MPE+Random). The selecting capacity of our proposed frame-level data selection method can be verified again by comparison with random selection. The above results indeed justify our postulation that, with proper integration of data selection into the acoustic model training process, we can make the discriminative training algorithms focus much more on the useful training samples to achieve a better discrimination capability on the new test set. Experiments on Combination of Frame-level Accuracy Function and Data Selection Finally, we attempt to combine our proposed frame-level accuracy function and frame-level data selection. The two frame-level training data selection approaches, i.e., HS and SS, respectively, are integrated with the MSFA training. The corresponding results are shown in Table 3 . Actually, the data selection approaches are simply based on the entropy information of the Gaussian posterior probabilities of phone arcs, without taking any phone accuracy information into consideration. Thus, such a combination can be viewed as a loosely coupled approach, which to some extent would make the effect of the combination less pronounced. As can be seen from Conclusions In this paper, we have the explored the use of frame-level information for improved MPE training of acoustic models for Mandarin broadcast news recognition. A new phone accuracy function directly based on the frame-level accuracy has been presented. Moreover, a novel data selection approach using the normalized frame-level entropy of Gaussian posterior probabilities has been proposed as well. Promising and encouraging results on the recognition of Mandarin broadcast news speech were demonstrated. More in-depth investigation of the proposed training data selection, as well as its integration with other discriminative acoustic model training algorithms, is also currently being undertaken.",
    "funding": {
        "defense": 0.0,
        "corporate": 0.0,
        "research agency": 1.9361263126072004e-07,
        "foundation": 0.0,
        "none": 1.0
    },
    "reasoning": "Reasoning: The article does not mention any specific funding sources from defense, corporate entities, research agencies, foundations, or otherwise. Without explicit mention of funding, it is not possible to determine the involvement of any of these sources based on the provided text alone."
}