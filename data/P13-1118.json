{
    "article": "Derivational models are still an underresearched area in computational morphology. Even for German, a rather resourcerich language, there is a lack of largecoverage derivational knowledge. This paper describes a rule-based framework for inducing derivational families (i.e., clusters of lemmas in derivational relationships) and its application to create a highcoverage German resource, DERIVBASE, mapping over 280k lemmas into more than 17k non-singleton clusters. We focus on the rule component and a qualitative and quantitative evaluation. Our approach achieves up to 93% precision and 71% recall. We attribute the high precision to the fact that our rules are based on information from grammar books. Introduction Morphological processing is generally recognized as an important step for many NLP tasks. Morphological analyzers such as lemmatizers and part of speech (POS) taggers are commonly the first NLP tools developed for any language (Koskenniemi, 1983; Brill, 1992) . They are also applied in NLP applications where little other linguistic analysis is performed, such as linguistic annotation of corpora or terminology acquisition; see Daille et al. (2002) for an informative summary. Most work on computational morphology has focused on inflectional morphology, that is, the handling of grammatically determined variation of form (Bickel and Nichols, 2001) , which can be understood, overimplifying somewhat, as a normalization step. Derivational morphology, which is concerned with the formation of new words from existing ones, has received less attention. Exam-ples are nominalization (to understand \u2192 the understanding), verbalization (the shelf \u2192 to shelve), and adjectivization (the size \u2192 sizable). Part of the reason for the relative lack of attention lies in the morphological properties of English, such as the presence of many zero derivations (the fish \u2192 to fish), the dominance of suffixation, and the relative absence of stem changes in derivation. For these reasons, simple stemming algorithms (Porter, 1980) provide a cheap and accurate approximation to English derivation. Two major NLP resources deal with derivation. WordNet lists so-called \"morphosemantic\" relations (Fellbaum et al., 2009) for English, and a number of proposals exist for extending WordNets in other languages with derivational relations (Bilgin et al., 2004; Pala and Hlav\u00e1\u010dkov\u00e1, 2007) . Cat-Var, the \"Categorial Variation Database of English\" (Habash and Dorr, 2003) , is a lexicon aimed specifically at derivation. It groups English nouns, verbs, adjectives, and adverbs into derivational equivalence classes or derivational families such as ask V asker N asking N asking A Derivational families are commonly understood as groups of derivationally related lemmas (Daille et al., 2002; Milin et al., 2009) . The lemmas in CatVar come from various open word classes, and multiple words may be listed for the same POS. The above family lists two nouns: an event noun (asking) and an agentive noun (asker). However, CatVar does not consider prefixation, which is why, e.g., the adjective unasked is missing. CatVar has found application in different areas of English NLP. Examples are the acquisition of paraphrases that cut across POS lines, applied, for example, in textual entailment (Szpektor and Dagan, 2008; Berant et al., 2012) . Then there is the induction and extension of semantic roles resources for predicates of various parts of speech (Meyers et al., 2004; Green et al., 2004) . Finally, CatVar has been used as a lexical resource to generate sentence intersections (Thadani and McKeown, 2011) . In this paper, we describe the project of obtaining derivational knowledge for German to enable similar applications. Even though there are two derivational resources for this language, IMSLEX (Fitschen, 2004) and CELEX (Baayen et al., 1996) , both have shortcomings. The former does not appear to be publicly available, and the latter has a limited coverage (50k lemmas) and does not explicitly represent derivational relationships within families, which are necessary for fine-grained optimization of families. For this reason, we look into building a novel derivational resource for German. Unfortuantely, the approach used to build CatVar cannot be adopted: it builds on a collection of high-quality lexical-semantic resources such as NOMLEX (Macleod et al., 1998) , which are not available for German. Instead, we employ a rule-based framework to define derivation rules that cover both suffixation and prefixation and describes stem changes. Following the work of \u0160najder and Dalbelo Ba\u0161i\u0107 (2010) , we define the derivational processes using derivational rules and higher-order string transformation functions. The derivational rules induce a partition of the language's lemmas into derivational families. Our method is applicable to many languages if the following are available: (1) a comprehensive set of lemmas (optionally including gender information); (2) knowledge about admissible derivational patterns, which can be gathered, for example, from linguistics textbooks. The result is a freely available high-precision high-coverage resource for German derivational morphology that has a structure parallel to Cat-Var, but was obtained without using manually constructed lexical-semantic resources. We conduct a thorough evaluation of the induced derivational families both regarding precision and recall. Plan of the paper. Section 2 discusses prior work. Section 3 defines our derivation model that is applied to German in Section 4. Sections 5 and 6 present our evaluation setup and results. Section 7 concludes the paper and outlines future work. Related Work Computational models of morphology have a long tradition. Koskenniemi (1983) was the first who analyzed and generated morphological phenomena computationally. His two-level theory has been applied in finite state transducers (FST) for several languages (Karttunen and Beesley, 2005) . Many recent approaches automatically induce morphological information from corpora. They are either based solely on corpus statistics (D\u00e9jean, 1998) , measure semantic similarity between input and output lemma (Schone and Jurafsky, 2000) , or bootstrap derivation rules starting from seed examples (Piasecki et al., 2012) . Hammarstr\u00f6m and Borin (2011) give an extensive overview of stateof-the-art unsupervised learning of morphology. Unsupervised approaches operate at the level of word-forms and have complementary strengths and weaknesses to rule-based approaches. On the upside, they do not require linguistic knowledge; on the downside, they have a harder time distinguishing between derivation and inflection, which may result in lower precision, and are not guaranteed to yield analyses that correspond to linguistic intuition. An exception is the work by Gaussier (1999) , who applies an unsupervised model to construct derivational families for French. For German, several morphological tools exist. Morphix is a classification-based analyzer and generator of German words on the inflectional level (Finkler and Neumann, 1988) . SMOR (Schmid et al., 2004 ) employs a finite-state transducer to analyze German words at the inflectional, derivational, and compositional level, and has been used in other morphological analyzers, e.g., Morphisto (Zielinski and Simon, 2008) . The site canoonet 1 offers broad-coverage information about the German language including derivational word formation. Framework In this section, we describe our rule-based model of derivation, its operation to define derivational families, and the application of the model to German. We note that the model is purely surface-based, i.e., it does not model any semantic regularities beyond those implicit in string transformations. We begin by outlining the characteristics of German derivational morphology. German Derivational Morphology As German is a morphologically complex language, we analyzed its derivation processes before implementing our rule-based model. We relied on traditional grammar books and lexicons, e.g., Hoeppner (1980) and Augst (1975) , in order to linguistically justify our assumptions as well as to achieve the best possible precision and coverage. We concentrate on German derivational processes that involve nouns, verbs, and adjectives. 2 Nouns are simple to recognize due to capitalization: stauen V -Stau N (to jam -jam), essen V -Essen N (to eat -food). Verbs bear three typical suffixes (-en, -eln, -ern). An example of a derived verb is fest A -festigen V (tight -to tighten), where -ig is the derivational suffix. Adjectivization works similarlty: Tag N -t\u00e4glich A (day -daily). This example shows that derivation can also involve stem changes in the form of umlaut (e.g., a \u2192 \u00e4) and ablaut shift, e.g., sieden V -Sud N (to boil -infusion). Other frequent processes in German derivation are circumfixation (Haft N -inhaftieren V (arrest -to arrest)) and prefixation (heben V -beheben V (to raise -to remedy)). Prefixation often indicates a semantic shift, either in terms of the general meaning (as above) or in terms of the polarity ( klar A -unklar A (clear -unclear)). Also note that affixes can be either Germanic, e.g., \u00f6len -\u00d6lung (to oil -oiling), or Latin/Greek, e.g., generieren -Generator (to generate -generator). As this analysis shows, derivation in German involves transformation as well as affixation processes, which has to be taken into account when modeling a derivational resource. A Rule-based Derivation Model The purpose of a derivational model is to define a set of transformations that correspond to valid derivational word formation rules. Rule-based frameworks offer convenient representations for derivational morphology because they can take advantage of linguistic knowledge about derivation, have interpretable representations, and can be finetuned for high precision. The choice of the framework is in principle arbitrary, as long as it can conveniently express the derivational phenomena of a language. Typically used for this purpose are two-level formalism rules (Karttunen and Beesley, 1992) or XFST replace rules (Beesley and Karttunen, 2003) . In this paper, we adopt the modeling framework proposed by \u0160najder and Dalbelo Ba\u0161i\u0107 (2010) . The framework corresponds closely to simple, human-readable descriptions in traditional gram-mar books. The expressiveness of the formalism is equivalent to the replacement rules commonly used in finite state frameworks, thus the rules can be compiled into FSTs for efficient processing. The framework makes a clear distinction between inflectional and derivational morphology and provides separate modeling components for these two; we only make use of the derivation modeling component. We use an implementation of the modeling framework in Haskell. For details, see the studies by \u0160najder and Dalbelo Ba\u0161i\u0107 (2008) and \u0160najder and Dalbelo Ba\u0161i\u0107 (2010) . The building blocks of the derivational component are derivational rules (patterns) and transformation functions. A derivational rule describes the derivation of a derived word from a basis word. A derivational rule d is defined as a triple: d = (t, P 1 , P 2 ) ( 1 ) where t is the transformation function that maps the word's stem (or lemma) into the derived word's stem (or lemma), while P 1 and P 2 are the sets of inflectional paradigms of the basis word and the derived word, respectively, which specify the morphological properties of the rule's input and output. For German, our study assumes that inflectional paradigms are combinations of part-of-speech and gender information (for nouns). A transformation function t : S \u2192 \u2118(S) maps strings to a set of strings, representing possible transformations. At the lowest level, t is defined in terms of atomic string replacement operations (replacement of prefixes, suffixes, and infixes). The framework then uses the notion of higher-order functions -functions that take other transformations as arguments and return new transformations as results -to succinctly define common derivational processes such as prefixation, suffixation, and stem change. More complex word-formation rules, such as those combining prefixation and suffixation, can be obtained straightforwardly by functional composition. Table 1 summarizes the syntax we use for transformation functions and shows two example derivational rules. Rule 1 defines an English adjectivization rule. It uses the conditional try operator to apply to nouns with and without the -ion suffix (action -active, instinct -instinctive). Infix replacement is used to model stem alternation, as shown in rule 2 for German nominalization, e.g., vermacht A -Verm\u00e4chtnis N (bequethed -bequest). N and A denote the paradigms for nouns (without gender restriction) and adjectives, respectively. Induction of Derivational Families Recall that our goal is to induce derivational families, that is, classes of derivationally related words. We define derivational families on the basis of derivational rules as follows. Given a lemma-paradigm pair (l, p) as input, a single derivational rule d = (t, P 1 , P 2 ) generates a set of possible derivations L d (l, p) = {(l 1 , p 1 ), . . . , (l n , p n )}, where p \u2208 P 1 and p i \u2208 P 2 for all i. Given a set of derivational rules D, we define a binary derivation relation \u2192 D between two lemma-paradigm pairs that holds if the second pair can be derived from the first one as: (l 1 , p 1 ) \u2192 D (l 2 , p 2 ) (2) iff \u2203d \u2208 D. (l 2 , p 2 ) \u2208 L d (l 1 , p 1 ) Let L denote the set of lemma-paradigm pairs. The set of derivational families defined by D on L is given by the equivalence classes of the transitive, symmetric, and reflexive closure of \u2192 D over L. Note that in addition to the quality of the rules, the properties of L plays a central role in the quality of the induced families. High coverage of L is important because the transitivity of \u2192 D ranges only over lemmas in L, so low coverage of L may result in fragmented derivational families. However, L should also not contain erroneous lemma-paradigm pairs. The reason is that the derivational rules only define admissible derivations, which need not be morphologically valid, and therefore routinely over-generate; L plays an important role in filtering out derivations that are not attested in the data. Building the Resource Derivational Rules We implemented the derivational rules from Hoeppner (1980) for verbs, nouns, and adjectives, covering all processes described in Section 3.1 (zero derivation, prefixation, suffixation, circumfixation, and stem changes). We found many derivational patterns in German to be conceptually simple (e.g., verb-noun zero derivation) so that substantial coverage can already be achieved with very simple transformation functions. However, there are many more complex patterns (e.g., suffixation combined with optional stem changes) that in sum also affect a considerable number of lemmas, which required us to either implement low-coverage rules or generalize existing rules. In order to preserve precision as much as possible, we restricted rule application by using try instead of opt, and by using gender information from the noun paradigms (for example, some rules only apply to masculine nouns and produce female nouns). As a result, we end up with high-coverage rules, such as derivations of person-denoting nouns (Schule N -Sch\u00fcler N (school -pupil)) as well as high-accuracy rules such as negation prefixes (Pol N -Gegenpol N (pole -antipole)). Even though we did not focus on the explanatory relevance of rules, we found that the underlying modeling formalism, and the methodology used to develop the model, offer substantial linguistic plausibility in practice. We had to resort to heuristics mostly for words with derivational transformations that are motivated by Latin or Greek morphology and do not occur regularly in German, e.g., selegieren V -Selektion N (select -selection). In the initial development phase, we implemented 154 rules, which took about 22 personhours. We then revised the rules with the aim of increasing both precision and recall. To this end, we constructed a development set comprised of a sample of 1,000 derivational families induced using our rules. On this set, we inspected the derivational families for false positives, identified the problematic rules, and identified unused and redundant rules. In order to identify the false negatives, we additionally sampled a list of 1,000 lemmas and used string distance measures (cf. Section 5.1) to retrieve the 10 most similar words for each lemma not Table 2 shows the distribution of rules with respect to the derivational processes they implement and the part of speech combinations for the basis and the derived words. All affixations occur both with and without stem changes, mostly umlaut shifts. Suffixation is by far the most frequently used derivation process, and noun-verb derivation is most diverse in terms of derivational processes. Process N-N N-A N-V A-A A-V V-V Zero derivation - 1 5 - - - We also estimated the reliability of derivational rules by analyzing the accuracy of each rule on the development set. We assigned each rule a confidence rating on a three-level scale: L3 -very reliable (high-accuracy rules), L2 -generally reliable, and L1 -less reliable (low-accuracy rules). We manually analyzed the correctness of rule applications for 100 derivational families of different size (counting 2 up to 114 lemmas), and assigned 55, 79, and 24 rules to L3, L2 and L1, respectively. Data and Preprocessing For an accurate application of nominal derivation rules, we need a lemma list with POS and gender information. We POS-tag and lemmatize SDEWAC, a large German-language web corpus from which boilerplate paragraphs, ungrammatical sentences, and duplicate pages were removed (Faa\u00df et al., 2010) . For POS tagging and lemmatization, we use TreeTagger (Schmid, 1994) and determine grammatical gender with the morphological layer of the MATE Tools (Bohnet, 2010) . We treat proper nouns like common nouns. We apply three language-specific filtering steps based on observations in Section 3.1. First, we discard non-capitalized nominal lemmas. Second, we deleted verbal lemmas not ending in verb suffixes. Third, we removed frequently occurring erroneous comparative forms of adjectives (usually formed by adding -er, like neuer / newer) by checking for the presence of lemmas without -er (neu / new). An additional complication in German concerns prefix verbs, because prefix is separated in tensed instances. For example, the 3rd person male singular of aufh\u00f6ren (to stop) is er h\u00f6rt auf (he stops). Since most prefixes double as prepositions, the correct lemmas can only be reconstructed by parsing. We parse the corpus using the MST parser (Mc-Donald et al., 2006) and recover prefix verbs by searching for instances of the dependency relation labeled PTKVZ. Since SDEWAC, as a web corpus, still contains errors, we only take into account lemmas that occur three times or more in the corpus. Considering the size of SDEWAC, we consider this as a conservative filtering step that preserves high recall and provides a comprehensive basis for evaluation. After preprocessing and filtering, we run the induction of the derivational families as explained in Section 3 to obtain the DERIVBASE resource. Statistics on DERIVBASE The preparation of the SDEWAC corpus as explained in Section 4.2 yields 280,336 lemmas, which we cover with our resource. We induced a total of 239,680 derivational families from this data, with 17,799 non-singletons and 221,881 singletons (most of them due to compound nouns). 11,039 of the families consist of two lemmas, while the biggest contains 116 lemmas (an overgenerated family). The biggest family with perfect precision (i.e., it contains only morphologically related lemmas) contains 40 lemmas, e.g., halten V , erhalten V , Verh\u00e4ltnis N (to hold, to uphold, relation), etc. For comparison, CatVar v2.1 contains only 82,676 lemmas in 13,368 non-singleton clusters and 38,604 singletons. The following sample family has seven members across all three POSes and includes prefixation, suffixation, and infix umlaut shifts: taub A (numb A ), Taubheit Nf (numbness N ), bet\u00e4uben V (to anesthetize V ), Bet\u00e4ubung Nf (anesthesia N ), bet\u00e4ubt A (anesthetized A ), bet\u00e4ubend A (anesthetic A ), Bet\u00e4uben Nn (act of anesthetizing N ) 5 Evaluation Baselines We use two baselines against which we compare the induced derivational families: (1) clusters obtained with the German version of Porter's stemmer (Porter, 1980) 3 and (2) clusters obtained using string distance-based clustering. We have considered a number of string distance measures and tested them on the development set (cf. Section 4.1). The measure proposed by Majumder et al. (2007) turned out to be the most effective in capturing suffixal variation. For words X and Y , it is defined as D 4 (X, Y ) = n \u2212 m + 1 n + 1 n i=m 1 2 i\u2212m (3) where m is the position of left-most character mismatch, and n + 1 is the length of the longer of the two strings. To capture prefixal variation and stem changes, we use the n-gram based measure proposed by Adamson and Boreham (1974) : Dice n (X, Y ) = 1 \u2212 2c x + y (4) where x and y are the total number of distinct ngrams in X and Y , respectively, and c is the number of distinct n-grams shared by both words. In our experiments, the best performance was achieved with n = 3. We used hierarchical agglomerative clustering with average linkage. To reduce the computational complexity, we performed a preclustering step by recursively partitioning the set of lemmas sharing the same prefix into partitions of manageable size (1000 lemmas). Initially, we set the number of clusters to be roughly equal to the number of induced derivational families. For the final evaluation, we optimized the number of clusters based on F 1 score on calibration and validation sets (cf. Section 5.3). Evaluation Methodology The induction of derivational families could be evaluated globally as a clustering problem. Unfortunately, cluster evaluation is a non-trivial task for which there is no consensus on the best approach (Amig\u00f3 et al., 2009) . We decided to perform our evaluation at the level of pairs: we manually judge for a set of pairs whether they are derivationally related or not. We obtain the gold standard for this evaluation by sampling lemmas from the lemma list. With random sampling, the evaluation would be unrealistic because a vast majority of pairs would be derivationally unrelated and count as true negatives in our analysis. Moreover, in order to reliably estimate the overall precision of the obtained derivational families, we need to evaluate on pairs sampled from these families. On the other hand, in order to assess recall, we need to sample from pairs that are not included in our derivational families. To obtain reliable estimates of both precision and recall, we decided to draw two different samples: (1) a sample of lemma pairs sampled from the induced derivational families, on which we estimate precision (P-sample) and ( 2 ) a sample of lemma pairs sampled from the set of possibly derivationally related lemma pairs, on which we estimate recall (R-sample). In both cases, pairs (l 1 , l 2 ) are sampled in two steps: first a lemma l 1 is drawn from a non-singleton family, then the second lemma l 2 is drawn from the derivational family of l 1 (P-sample) or the set of lemmas possibly related to l 1 (R-sample). The set of possibly related lemmas is a union of the derivational family of l 1 , the clusters of l 1 obtained with the baseline methods, and k lemmas most similar to l 1 according to the two string distance measures. We use k = 7 in our experiments. This is based on preliminary experiments on the development set (cf. Section 4.1), which showed that k = 7 retrieves about 92% of the related lemmas retrieved for k = 20 with a much smaller number of true negatives. Thus, the evaluation on the R-sample might overestimate the recall, but only slightly so, while the P-sample yields a reliable estimate of precision by reducing the number of true negatives in the sample. Both samples contain 2400 lemma pairs each. Lemmas included in the development set (Section 4.1) were excluded from sampling. Gold Standard Annotation Two German native speakers annotated the pairs from the P-sample and R-samples. We defined five categories into which all lemma pairs are classified as shown in Table 3 . We count R and M as positives and N, C, L as negatives (cf. Section 3). 4 Note that this binary distinction would be sufficient to compute recall and precision. However, the more  fine-grained five-class annotation scheme provides a more detailed picture. The separation between R and M gives a deeper insight into the semantics of the derivational families. Distinguishing between C and N, in turn, allows us to identify the pairs that are derivationally unrelated, but compositionally related, e.g., Ehemann N -Ehefrau N (husbandwife). We first carried out a calibration phase in which the annotators double-annotated 200 pairs from each of the two samples and refined the annotation guidelines. In a subsequent validation phase, we computed inter-annotator agreements on the annotations of another 200 pairs each from the P-and the R-samples. Table 4 shows the proportion of identical annotations by both annotators as well as Cohen's \u03ba score (Cohen, 1968) . We achieve substantial agreement for \u03ba (Carletta, 1996) . On the P-sample, \u03ba is a little lower because the distribution of the categories is skewed towards R, which makes an agreement by chance more probable. In our opinion, the IAA results were sufficiently high to switch to single annotation for the production phase. Here, each annotator annotated another 1000 pairs from the P-sample and R-sample so that the final test set consists of 2000 pairs from each sample. The P-sample contains 1663 positive (R+M) and 337 negative (N+C+L) pairs, respectively, the R-sample contains 575 positive and 1425 negative pairs. As expected, there are more positive 6 Results Quantitative Evaluation Table 5 presents the overall results. We evaluate four variants of the induced derivational families: those obtained before rule refinement (DERIVBASE initial), and three variants after rule refinement: using all rules (DERIVBASE-L123), excluding the least reliable rules (DERIVBASE-L23), and using only highly reliable rules (DERIVBASE-L3). We measure the precision of our method on the P-sample and recall on the R-sample. For the baselines, precision was also computed on the R-sample (computing it on P-sample, which is obtained from the induced derivational families, would severely underestimate the number of false positives). We omit the F 1 score because its use for precision and recall estimates from different samples is unclear. DERIVBASE reaches 83% precision when using all rules and 93% precision when using only highly reliable rules. DERIVBASE-L123 achieves the highest recall, outperforming other methods and variants by a large margin. Refinement of the initial model has produced a significant improvement in recall without losses in precision. The baselines perform worse than our method: the stemmer we use is rather conservative, which fragments the families and leads to a very low recall. The string distance-based approaches achieve more balanced precision and recall scores. Note that for these methods, precision and recall can be traded off against each other by varying the number of clusters; we chose the number of clusters by optimizing the F 1 score on the calibration and validaton sets. All subsequent analyses refer to DERIVBASE- Analysis by frequency. We cross-classified our rules according to high/low accuracy and high/low coverage based on the pairs in the P-sample. We only considered directly derivationally related (\u2192 D ) pairs and defined \"high accuracy\" and \"high coverage\" as all rules above the 25th percentile in terms of accuracy and coverage, respectively. The results are shown in Table 6 : all high-coverage rules are also highly accurate. Most rules are accurate but infrequent. Only 21 rules have a low accuracy, but all of them apply infrequently. Analysis by parts of speech. Table 7 shows precision and recall values for different part of speech combinations for the basis and derived words. High precision and recall are achieved for N-A derivations. The recall is lowest for V-V derivations, suggesting that the derivational phenomena for this POS combination are not yet covered satisfactorily. Error analysis Table 8 shows the frequencies of true positives and false positives on the P-sample and false negatives on the R-sample for each annotated category. True negatives are not reported, since their analysis gives no deeper insight. True positives. In our analysis we treated both R and M pairs as related, but it is interesting to see how many of the true positives are in fact semantically unrelated. Out of 1,663 pairs, 90% are semantically as well as morphologically related (R), e.g., Among the M true positives, we observe prefixation derivations in 66% of the cases, often involving prefixation at both lemmas, e.g., Erdenkliche N -bedenklich A (imaginable -questionable). False positives. We observe many errors in pairs involving short lemmas, e.g., Gen N -genieren V (gene -to be embarrassed), where orthographic context is unsufficient to reject the derivation. About 64% of the 337 incorrect pairs are of class N (unrelated lemmas). For example, the rule for deriving nouns denoting a male person incorrectly links Morse N -M\u00f6rser N (Morse -mortar). Transitively applied rules often produce incorrect pairs; e.g., Speiche N -speicherbar A (spoke -storable) results from the rule chain Speiche N \u2192 Speicher N \u2192 speichern V \u2192 speicherbar A (spoke \u2192 storage \u2192 to store \u2192 storable). Chains that involve ablaut shifts (cf. Section 3.1) can lead to surprising results, e.g., Erringung N -rangiert A (achievementshunted). Meanwhile, some pairs judged as unrelated by the annotators might conceivably be weakly related, such as schl\u00fcrfen V and schlurfen V (to sip -to shuffle), both of which refer to specific long drawn out sounds. About 20% out of these unrelated lemma pairs is due to derivations between proper nouns (PNs) and common nouns. This happens especially for short PNs (cf. the above example of Morse). However, since PNs also participate in valid derivations (e.g., Chaplin -chaplinesque), one could investigate their impact on derivations rather than omitting them. Errors of the category L -34% of the false positives -are caused during preprocessing by the lemmatizer. They cannot be blamed on our derivational model, but of course form part of the output. False negatives. Errors of this type are due to missing derivation rules, erroneous rules that leave some lemmas undiscovered, or the absence of lemmas in the corpus required for transitive closure. About 64% of the 167 missed pairs are of category R. About half of these pairs result from a lack of prefixation rules -mainly affecting verbs -with a wide variety of prefixes (zu-, um-, etc.), including prepositional prefixes like herum-(around) or \u00fcber-(over). We intentionally ignored these derivations, since they frequently lead to semantically unrelated pairs. In fact, merely five of the remaining 36% false negative pairs (M) do not involve prefixation. However, this analysis as well as the rather low coverage for verb-involved rules (cf. Table 7 ) shows that DERIVBASE might benefit from more prefix rules. Apart from the lack of prefixation coverage and a few other, rather infrequent rules, we did not find any substantial deficits. Most of the remaining errors are due to German idiosyncrasies and exceptional derivations, e.g., fahren V -Fahrt N (drivetrip), where the regular zero derivation would result in Fahr. Conclusion and Future Work In this paper, we present DERIVBASE, a derivational resource for German based on a rule-based framework. A few work days were enough to build the underlying rules with the aid of grammar textbooks. We collected derivational families for over 280,000 lemmas with high accuracy as well as solid coverage. The resource is freely available. 5  Our approach for compiling a derivational resource is not restricted to German. In addition to the typologically most similar Germanic and Romance languages, it is also applicable to agglutinative languages like Finnish, or other fusional languages like Russian. Its main requirements are a large list of lemmas for the language (optionally with further morphological features) and linguistic literature on morphological patterns. We have employed an evaluation method that uses two separate samples to assess precision and 5 http://goo.gl/7KG2U; license cc-by-sa 3.0 recall to deal with the high number of false negatives. Our analyses indicate two interesting directions for future work: (a) specific handling of proper nouns, which partake in specific derivations; and (b) the use of graph clustering instead of the transitive closure to avoid errors resulting from long transitive chains. Finally, we plan to employ distributional semantics methods (Turney and Pantel, 2010) to help remove semantically unrelated pairs as well as distinguish automatically between only morphologically (M) or both morphologically and semantically (R) related pairs. Last, but not least, this allows us to group derivation rules according to their semantic properties. For example, nouns with -er suffixes often denote persons and are agentivizations of a basis word (Bilgin et al., 2004) . Acknowledgments The first and third authors were supported by the EC project EXCITEMENT (FP7 ICT-287923). The second author was supported by the Croatian Science Foundation (project 02.03/162: \"Derivational Semantic Models for Information Retrieval\"). We thank the reviewers for their constructive comments.",
    "abstract": "Derivational models are still an underresearched area in computational morphology. Even for German, a rather resourcerich language, there is a lack of largecoverage derivational knowledge. This paper describes a rule-based framework for inducing derivational families (i.e., clusters of lemmas in derivational relationships) and its application to create a highcoverage German resource, DERIVBASE, mapping over 280k lemmas into more than 17k non-singleton clusters. We focus on the rule component and a qualitative and quantitative evaluation. Our approach achieves up to 93% precision and 71% recall. We attribute the high precision to the fact that our rules are based on information from grammar books.",
    "countries": [
        "Germany",
        "Croatia"
    ],
    "languages": [
        "German"
    ],
    "numcitedby": "66",
    "year": "2013",
    "month": "August",
    "title": "{DE}riv{B}ase: Inducing and Evaluating a Derivational Morphology Resource for {G}erman"
}