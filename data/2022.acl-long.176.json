{
    "article": "Simultaneous machine translation (SiMT) outputs translation while reading source sentence and hence requires a policy to decide whether to wait for the next source word (READ) or generate a target word (WRITE), the actions of which form a read/write path. Although the read/write path is essential to SiMT performance, no direct supervision is given to the path in the existing methods. In this paper, we propose a method of dual-path SiMT which introduces duality constraints to direct the read/write path. According to duality constraints, the read/write path in source-totarget and target-to-source SiMT models can be mapped to each other. As a result, the two SiMT models can be optimized jointly by forcing their read/write paths to satisfy the mapping. Experiments on En\u2194Vi and De\u2194En tasks show that our method can outperform strong baselines under all latency. Introduction Simultaneous machine translation (SiMT) (Cho and Esipova, 2016; Gu et al., 2017; Ma et al., 2019; Arivazhagan et al., 2019) , which outputs translation while reading source sentence, is important to many live scenarios, such as simultaneous interpretation, live broadcast and synchronized subtitles. Different from full-sentence machine translation which waits for the whole source sentence, SiMT has to decide whether to wait for the next source word (i.e., READ action) or translate a target word (i.e., WRITE action) to complete the translation. The sequence of READ and WRITE actions in the translation process form a read/write path, which is key to SiMT performance. Improper read/write path will bring damage to translation performance as compared to the following WRITE actions too many but not necessary READ actions  will result in high translation latency while too few but not sufficient READ actions will exclude indispensable source information. Therefore, an ideal read/write path is that the READ actions compared to the following WRITE actions are just sufficient and necessary, which means the source words covered by consecutive READ actions and the target words generated by the following consecutive WRITE actions should be semantically equivalent. Ensuring sufficiency and necessity between READ/WRITE actions will lead to a proper read/write path and thereby good SiMT performance. But unfortunately, the existing SiMT methods, which employ a fixed or adaptive policy, do not consider the sufficiency or necessity in their policy. The fixed policy performs SiMT based on a pre-defined read/write path (Dalvi et al., 2018; Ma et al., 2019) , where the number of READ actions before WRITE is fixed. The adaptive policy (Gu et al., 2017; Zheng et al., 2019b; Arivazhagan et al., 2019; Zheng et al., 2019a; Ma et al., 2020; Liu et al., 2021) dynamically decides to READ or WRITE guided by translation quality and total latency, but skips the evaluation of sufficiency and necessity between READ/WRITE actions. Under these grounds, we aim at introducing the evaluation of sufficiency and necessity between READ/WRITE actions to direct the read/write path without involving external information. As mentioned above, in an ideal read/write path, the source segment (i.e., source words read by the consecutive READ actions) and the corresponding target segment (i.e., target words generated by the following consecutive WRITE actions) are supposed to be semantically equivalent and thus translation to each other, which constitutes a separate segment pair. Hence, an ideal read/write path divides the whole sentence pair into a sequence of segment pairs where the source sentence and the target sentence should be translation to each other segment by segment. That means if the translation direction is reversed, an ideal read/write path for target-to-source SiMT can also be deduced from the same sequence of segment pairs. For example, according to the alignment in Figure 1 (a), the ideal read/write paths should be 'RRWWW|RW|RW' in De\u2192En SiMT and 'RRRWW|RW|RW' in En\u2192De SiMT, as shown in Figure 1 (b), both of which share the same segment pair sequence of \u27e8Fand ich, I fount it\u27e9, \u27e8super, great\u27e9 and \u27e8., .\u27e9. Therefore, agreement on the segment pairs derived from read/write paths in source-to-target and targetto-source SiMT, called duality constraints, can be a good choice to evaluate sufficiency and necessity between READ/WRITE actions. Based on the above reasoning, we propose a method of Dual-Path SiMT, which uses the SiMT model in the reverse direction to guide the SiMT model in the current direction according to duality constraints between their read/write paths. With duality constraints, the read/write paths in sourceto-target and target-to-source SiMT should reach an agreement on the corresponding segment pairs. Along this line, our method maintains a source-totarget SiMT model and a target-to-source SiMT model concurrently, which respectively generate their own read/write path using monotonic multi-head attention (Ma et al., 2020) . By minimizing the difference between the segment pairs derived from the two read/write paths, the two SiMT models successfully converge on the segment pairs and provide supervision to each other. Experiments on IWSLT15 En\u2194Vi and WMT15 De\u2194En SiMT tasks show that our method outperforms strong baselines under all latency, including the state-ofthe-art adaptive policy. Background We first briefly introduce SiMT with a focus on monotonic multi-head attention (Ma et al., 2020) . For a SiMT task, we denote the source sentence as Read/write path can be represented in multiple forms, such as an action sequence of READ and WRITE (e.g., RRWWWRW\u2022 \u2022 \u2022 ), or a path from (0, 0) to (I, J) in the attention matrix from the target to source, where moving right (i.e., \u2192) means READ action and moving down (i.e., \u2193) means WRITE action, as shown in Figure 1(b) . x = {x 1 , \u2022 \u2022 \u2022 , x J } Mathematically, a read/write path can be represented by a monotonic non-decreasing sequence {g i } I i=1 of step i, where the g i represents the number of source words read in when writing the i th target word y i . The value of {g i } I i=1 depends on the specific SiMT policy, where monotonic multi-head attention (MMA) (Ma et al., 2020) is the current state-of-the-art SiMT performance via modeling READ/WRITE action as a Bernoulli variable. Monotonic multi-head attention MMA processes the source words one by one, and concurrently predicts a selection probability p ij to indicates the probability of writing y i when reading x j , and accordingly a Bernoulli random variable z ij is calculated to determine READ or WRITE action: p ij =Sigmoid m j V K (s i\u22121 V Q ) \u22a4 \u221a d k , (1) z ij \u223c Bernoulli (p ij ) , (2) where V K and V Q are learnable parameters, d k is dimension of head. If z ij = 0, MMA performs READ action to wait for the next source word x j+1 . If z ij = 1, MMA sets g i = j and performs WRITE action to generate y i based on x \u2264g i . Therefore, the decoding probability of y with parameters \u03b8 is p(y | x; \u03b8) = I i=1 p (y i | x \u2264g i , y <i ; \u03b8) , (3) where x \u2264g i are first g i source tokens, and y <i are previous target tokens. Note that when integrated into multi-head attention, all attention heads in decoder layers independently determine the READ/WRITE action. If and only when all heads decide to perform WRITE action, the model starts translating, otherwise the model waits for the next source word. Expectation training Since sampling a discrete random variable z ij precludes back-propagation, MMA applies expectation training Raffel et al. (2017) to replace z ij with a expected writing probability, denoted as \u03b1 = (\u03b1 ij ) I\u00d7J , (4) where \u03b1 ij calculates the expectation probability of writing y i when reading x j . Then, the attention distribution and context vectors are accordingly calculated in the expected form. To trade-off between translation quality and latency, MMA introduces a latency loss L g to the training loss: L (\u03b8) = \u2212 (x,y) log p (y | x; \u03b8) + \u03bbL g , (5) where L g measures the total latency, and \u03bb is the weight of latency loss. Please refer to Arivazhagan et al. (2019) and Ma et al. (2020) for more detailed derivation and implementation. The Proposed Method Our dual-path SiMT model employs a source-totarget (forward) model and a target-to-source (backward) model, called single-path SiMT, which generate their own read/write path based on MMA. According to duality constraints that the read/write paths of the two single-path SiMT models should share the same segment pair sequence, the two read/write paths should be transposed to each other in principle as shown in Figure 1 . But in practice, after transposing one of the read/write paths, there is always a gap between the transposed read/write path and the original one in the reverse translation direction. By closing the gap between the In what follows, we will introduce how to get the transposed read/write path (Sec.3.1) and how to reduce the gap (Sec.3.2). Transposing the Read/Write Path The purpose of transposing a read/write path is to get a new read/write path in the reverse direction based on the same segment pairs as the original path. As the transposing process works in the same way for the two directions, we just introduce the process for the forward single-path SiMT. Since there is no explicit read/write path in the training of single-path SiMT model, the transposing process can only use the expected writing probability matrix \u03b1 as the input, shown in Eq.( 4 ). Similarly, the output of the transposing process is the transposed writing probability matrix \u03b3 = (\u03b3 ji ) J\u00d7I calculated from the transposed read/write path, which will be used to guide the backward single-path SiMT. The transposing process consists of three steps. First, derive the read/write path from the expected writing probability matrix \u03b1 and segment the sentence pair into a sequence of segment pairs. Second, transpose the sequence of segment pairs into the corresponding one for the backward SiMT. Last, merge the transposed segment pairs to get the transposed path and then project it to \u03b3. In the following, we will introduce the steps of segment, transpose and merge in details.  Segment Given the expected writing probability matrix \u03b1, to get the read/write path, we first find out the source position d i that the WRITE action for each target position i corresponds to, which is 1 0 0 0 0 0 0 1 0 R R R W W R R W R W W R R W W W R W W R R W R R R W W R R W R W W R R W W W R W W R R W Segment (a) d i = argmax j \u03b1 ij . (6) According to the property of monotonic attention, there are some consecutive WRITE actions that corresponds to the same source position, so the target words generated by the consecutive WRITE actions form a target segment. Formally, we assume there are K target segments in total, denoted as y = {\u0233 1 , \u2022 \u2022 \u2022 , \u0233k , \u2022 \u2022 \u2022 , \u0233K }. For each target segment \u0233k = (y b y k , \u2022 \u2022 \u2022 , y e y k ), where b y k and e y k are its beginning and end target positions, we can get the corresponding source segment as xk = (x b x k , \u2022 \u2022 \u2022 , x e x k ) where b x k = 1 k = 1 d e y k\u22121 + 1 otherwise (7) and e x k = d b y k . ( 8 ) Thus the sentence pairs \u27e8x, y\u27e9 can be segmented into the sequence of segment pairs as \u27e8x 1 , \u02331 \u27e9 | \u2022 \u2022 \u2022 | \u27e8x K , \u0233K \u27e9. By replacing the source words with READ actions and target words with WRITE actions, we can get the action segment pairs. Then, the read/write path is formed by concatenating all the action segment pairs, where the length of the read/write path is equal to the total number of source words and target words. Transpose After getting the sequence of segment pairs, the transposed read/write path can be derived from it. As the transposed read/write path is in the form to fit the backward single-path SiMT, the sequence of segment pairs should also be transposed to fit the another direction. According to duality constraints, the sequence of segment pairs is shared by forward and backward SiMT, so we only need to exchange the source segment and target segment in each segment pair, that is from \u27e8x k , \u0233k \u27e9 to \u27e8\u0233 k , xk \u27e9, where the beginning and end positions of each source/target segment remain the same. Then, we get the corresponding transposed action segment pairs by replacing target words with READ actions and source words with WRITE actions. In this way, we accomplish the transposing of segment pairs. Let's review the example in Figure 3 We employ the 0 \u2212 1 distribution to set the value of elements in \u03b3, where the elements corresponding to WRITE actions are set to 1 and others are set to 0. This is equivalent to the situation that the selection probability for the Bernoulli distribution (in Eq.( 2 )) is 1. Training Assuming the expected writing probability matrix for the forward single-path SiMT is \u03b1 F and its transposed expected writing probability matrix is \u03b3 F , and similarly in the backward single-path SiMT, the matrices are \u03b1 B and \u03b3 B , respectively. We reduce the gap between the read/write path with the transposed path of read/write path in another direction by minimizing L 2 distance between their corresponding expected writing probability matrix as follows: \u2126 F = \u03b1 F \u2212 \u03b3 B 2 (9) \u2126 B = \u03b1 B \u2212 \u03b3 F 2 . ( 10 ) Two L 2 distances are added to the training loss as a regularization term and final training loss is L = L \u03b8 F + L \u03b8 B + \u03bb dual (\u2126 F + \u2126 B ), (11) where L \u03b8 F and L \u03b8 B are the loss function of the forward and backward single-path SiMT model respectively, calculated as Eq.( 5 ). \u03bb dual is a hyperparameter and we set \u03bb dual = 1 in our experiments. In the inference time, the forward and backward single-path SiMT models can be used separately, depending on the required translation direction. Related Work Dual learning is widely used in dual tasks, especially machine translation. For both unsupervised (He et al., 2016; Artetxe et al., 2019; Sestorain et al., 2019) and supervised NMT (Xia et al., 2017; Wang et al., 2018) , dual learning can provide additional constraints by exploiting the dual correlation. Unlike most previous dual learning work on NMT, which use the reconstruction between source and target sequences, we focus on SiMT-specific read/write path and explorer its intrinsic properties. SiMT policy falls into two categories: fixed and adaptive. For fixed policy, the read/write path is defined by rules and fixed during translating. 2020 ) applied metalearning in wait-k. Zhang et al. (2021) proposed future-guided training to apply a full-sentence MT model to guide wait-k policy. Zhang and Feng (2021a) proposed a char-level wait-k policy. Zhang and Feng (2021b) proposed a universal SiMT with mixture-of-experts wait-k policy to perform SiMT under arbitrary latency levels. For adaptive policy, the read/write path is learned and adaptive to the current context. Early adaptive policies used segmented translation (Bangalore et al., 2012; Cho and Esipova, 2016; Siahbani et al., 2018) . Gu et al. (2017) rule-based sequences to guide the read/write path (Zheng et al., 2019a; Zhang et al., 2020; Wilken et al., 2020; Alinejad et al., 2021) . However, these methods rely too much on heuristic rules, and thus their performance is not comparable to jointly optimizing read/write path and translation. Our method internally explorers the duality between the read/write paths in two directions, and accordingly uses the duality to constrain the read/write paths, thereby obtaining better SiMT performance. Experiments Datasets We evaluated our method on four translation directions of the following two public datasets. IWSLT15 1 English\u2194Vietnamese (En\u2194Vi) (133K pairs) (Cettolo et al., 2015) We use TED tst2012 (1553 pairs) as validation set and TED tst2013 (1268 pairs) as test set. Following Raffel et al. (2017) and Ma et al. (2020) , we replace tokens that the frequency less than 5 by \u27e8unk\u27e9. After replacement, the vocabulary sizes are 17K and 7.7K for English and Vietnamese, respectively. WMT15 2 German\u2194English (De\u2194En) (4.5M pairs) Following Ma et al. (2020) , we use new-stest2013 (3000 pairs) as validation set and new-stest2015 (2169 pairs) as test set. BPE (Sennrich et al., 2016) is applied with 32K merge operations and the vocabulary is shared across languages. System Setting We conducted experiments on following systems. Offline Conventional Transformer (Vaswani et al., 2017) model for full-sentence translation. Wait-k Wait-k policy, the widely used fixed policy Ma et al. (2019) , which first reads k source 1 nlp.stanford.edu/projects/nmt/ 2 www.statmt.org/wmt15/ tokens and then writes a target word and reads a word alternately. MMA 3 Monotonic multi-head attention (MMA) proposed by (Ma et al., 2020) , the state-of-the-art adaptive policy for SiMT, which applies monotonic attention on each head in Transformer. Single Path SiMT model of one translation direction based on monotonic multi-head attention. To avoiding outlier heads 4 that are harmful for the read/write path, we slightly modified MMA for more stable performance. We no longer let the heads in all decoder layers independently determine the READ/WRITE action, but share the READ/WRITE action between the decoder layers. Dual Paths Dual-path SiMT described in Sec.3. The implementations of all systems are adapted from Fairseq Library (Ott et al., 2019) , based on Transformer (Vaswani et al., 2017) , where we apply Transformer-Small (4 heads) for En\u2194Vi, and Transformer-Base (8 heads) for De\u2194En. For 'Dual Paths', the forward and backward models are used to complete the SiMT on two translation directions at the same time. To perform SiMT under different latency, we set various lagging numbers 5 k for 'Wait-k', and set various latency weights 67 \u03bb for 'MMA', 'Single Path' and 'Dual Paths'. We evaluate these systems with BLEU (Papineni 3 github.com/pytorch/fairseq/tree/ master/examples/simultaneous_translation 4 Since MMA requires all heads in decoder layers to independently decide READ/WRITE action and starts translating only when all heads select WRITE action, some outlier heads that perform too many READ actions will result in higher latency. Ma et al. (2020) try to control this phenomenon by adding some loss functions, but it still cannot avoid some outlier heads waiting for too many words, which seriously affects the impair the necessity between the READ/WRITE actions in read/write path (Ma et al., 2020; Zaidi et al., 2021) . 5 For both En\u2194Vi and De\u2194En: k = 1, 3, 5, 7, 9 6 For En\u2194Vi: \u03bb = 0.01, 0.05, 0. AL = 1 \u03c4 \u03c4 i=1 g i \u2212 i \u2212 1 |y| / |x| , (12) where \u03c4 = argmax Main Results Figure 4 shows the comparison between our method and the previous methods on 4 translation directions. 'Dual Paths' outperforms the previous methods under all latency, and more importantly, the proposed duality constraints can improve the SiMT performance on both source-to-target and target-to-source directions concurrently. Compared to 'Wait-k', our method has significant improvement, especially under low latency, since the read/write path in 'Wait-k' is fixed and cannot be adjusted. Compared to 'MMA', the state-of-the-art adaptive policy, our 'Single Path' achieves comparable performance and is more stable under high latency. 'MMA' allows each head of each layer to independently predict a read/write path, where some outlier heads will affect the overall performance, resulting in a decline in translation quality under high latency (Ma et al., 2020) . Our method applies a common read/write path instead of the heads in each layer to predict READ/WRITE, thereby reducing the possibility of outlier heads. Based on 'Single Path', 'Dual Paths' further improves the SiMT performance by modeling the duality constraints between read/write paths, especially under low latency. Besides, our method improves the SiMT performance even close to the full-sentence MT on En\u2194Vi, which shows that the more precise read/write path is the key to SiMT performance. Additionally, under the same latency weight \u03bb, our method tends to have lower latency than 'MMA' on De\u2194En. The 'Single Path' reduces the unnecessary latency caused by outlier heads, and the duality constraints further improve the necessity of reading source content, thereby achieving lower latency. Analysis We conducted extensive analyses to understand the specific improvements of our method. Unless otherwise specified, all results are reported on De\u2192En. Ablation Study We conducted ablation studies on the duality constraints, where we use direct transposition to replace transposing process of read/write path, only constrain the forward single-path model or remove the duality constraints. As shown in Table 1 , the proposed method of transposing the read/write path is critical to translation quality, showing the importance of the segment operation. Besides, mutual constraining between forward and backward single-path model is more conducive to SiMT performance than only constraining one of them or removing constraints. Evaluation of Read/Write Path The read/write path needs to ensure sufficient content for translation and meanwhile avoid unnecessary latency, where the aligned source position 8 is always considered as the oracle position to perform WRITE in previous work (Wilken et al., 2020; Arthur et al., 2021) . Therefore, we propose two metrics A Suf and A N ec to measure the sufficiency and necessity between the READ/WRITE actions in a path via alignments. We denote the groundtruth aligned source position of the i th target word as a i , and the read/write path is represented by g i , which is the number of source words read in when writing the i th target word. For sufficiency, A Suf is used to evaluate whether the aligned source word is read before writing the target word, calculated as  where 1 a i \u2264g i counts the number of a i \u2264 g i , and I is the target length. For necessity, A N ec is used to measure distance between the output position g i and the aligned source position a i , calculated as A Suf = 1 I I i=1 1 a i \u2264g i , (13) A N ec = 1 |a i \u2264 g i | i,a i \u2264g i a i g i , ( 14 ) where the best case is A N ec = 1 for g i = a i , performing WRITE just at the aligned position and there is no unnecessary waiting. The more detailed description please refers to Appendix A. As shown in Figure 5 , we evaluate the A Suf and A N ec of read/write path on RWTH De\u2192En alignment dataset 9 , whose reference alignments are manually annotated by experts. The read/write paths of all methods perform similarly in sufficiency evaluation and our method performs slightly better at low latency. Except that the fixed policy 'Wait-k' may be forced to start translating before reading the aligned source word under the lower latency, 'MMA' and our method can almost cover more than 85% of the aligned source word when starting translating. In the necessity evaluation, our method surpasses 'Wait-k' and 'MMA', and starts translation much closer to the aligned source word, which shows that duality constraints make read/write path more precise, avoiding some unnecessary waiting. Note that while avoiding unnecessary waiting, our method also improves the translation quality (see Figure 4 ) under the same latency, which further shows the importance of a proper read/write path for SiMT performance. Effect of Duality Constraints To verify that our method improves the duality of two read/write paths, we conduct duality evaluation between source-to-target and target-to-source read/write paths. Specifically, we first express both the original read/write path on target-to-source and the transposed path of source-to-target read/write path in the form of matrices, and then calculate the Intersection over Union score (IoU) between the area below them (see Figure 6 ), which is regarded as the duality between the read/write path in the two directions. The higher IoU score indicates that the two paths are more consistent on common segment pairs, i.e., stronger duality. Appendix B gives the detailed calculation of IoU score. The results of duality evaluation are reported in Table 2 , where our method effectively enhances the duality of source-to-target and target-to-source read/write paths under all latency levels. This shows that with dual-path SiMT, the read/write paths in source-to-target and target-to-source are more in agreement on the sequence of segment pairs between the sentence pair. Dual Read/Write Paths Visualization Figure 6 shows the read/write path visualization of a De\u2194En example. In 'Dual Paths', there is a Figure 6 : Read/write path visualization of a De\u2194En example (De: 'die Lehr@@ er@@ bildung fand in Bam@@ berg statt .' \u2194 En: 'the teacher training course was in Bam@@ berg .'). shows the transposed path of the source-to-target read/write path. '\u2192': READ action to wait for a source word, '\u2193': WRITE action to generate a target word. Note that 8 sub-figures respectively represent 8 read/write paths, assigned to 8 heads and shared between decoder layers, and the attention is averaged on all decoder layers.  strong duality between the read/write paths in two translation directions, where the target-to-source read/write path (Figure 6 (c)) and the transposed path of the source-to-target read/write path (Figure 6 (b)) have a high degree of overlap. In particular, the read/write paths in our method exhibit a clear division on segment pairs. Systems Analysis on Forward/Backward Latency To analyze the relationship between the forward and backward single-path SiMT model in terms of the latency setting, we set the latency weight (\u03bb in Eq.( 5 )) of the forward and backward single-path SiMT model to different values, denoted as \u03bb F and \u03bb B respectively (the greater the latency weight, the lower the model latency). Table 3 reports the effect of different settings of \u03bb B on the performance of the forward single-path model. After applying backward model and the duality constraints, our method has a much lower la-tency and similar translation quality compared with 'MMA' and 'Single Path'. As the latency of the backward model decreases (\u03bb B becomes larger), the latency of the forward model also gradually decreases, which shows that the latency of the forward and backward models are strongly correlated. Overall, regardless of the setting of \u03bb F and \u03bb B , 'Dual Paths' obtains a better trade-off between latency and translation quality. Furthermore, we can get a slightly larger or smaller latency by adjusting the combination of \u03bb F and \u03bb B . Conclusion In this paper, we develop the dual-path SiMT to supervise the read/write path by modeling the duality constraints between SiMT in two directions. Experiments and analyses we conducted show that our method outperforms strong baselines under all latency and achieves a high-quality read/write path. The black line indicates the ground-truth alignments between the target and source. g i is the number of source words read in when generating the i th target word. a i is the ground-truth aligned source position of the i th target word. a i > g i (numbers colored in red) means that the i th target word is forced to be translated in advance before reading its aligned source word. A Evaluation Metrics of Read/Write Path In Sec.6.2, we propose two metrics A Suf and A N ec to measure the sufficiency and necessity of the read/write path using alignments. Here, we give a more detailed calculation of them. Given the ground-truth alignments, we denote the aligned source position of the i th target word as a i . Specifically, for one-to-many alignment from target to source, we choose the furthest source word as it aligned source position. For a read/write path, we denote the number of source words read in when generating the i th target word as g i . Figure 7 gives an example of the calculation of a i and g i . Sufficiency A Suf measures how many aligned source words are read before translating the target word (i.e., a i \u2264 g i ), which ensures the faithfulness of the translation, calculated as A Suf = 1 I I i=1 1 a i \u2264g i , (15) where 1 a i \u2264g i counts the number that a i \u2264 g i . Taking the case in Figure 7 as an example, the sufficiency is calculated as A Suf = 1 5 \u00d7 (0 + 1 + 1 + 0 + 1) = 3 5 , where the 1 st and 4 th target word are translated before read their aligned source word (a i > g i ). Necessity A N ec measures how far the output position g i is from the aligned position a i , where the closer output position to the alignment position indicates that the read/write path outputs earlier, and there is less unnecessary latency. A N ec is calculated as Note that A N ec only focuses on aligned positions that are read before output position (i.e., a i \u2264 g i ). A N ec = 1 |a i \u2264 g i | i,a i \u2264g i a i g i , (16) In the case shown in Figure 7 , the necessity is calculated as A N ec = 1 3 \u00d7 2 2 + 1 4 + 4 5 = 41 60 , where we only consider the the 2 th , 3 rd and 5 th target word. B IoU Score for Duality Evaluation To verify that our proposed method does make the read/write path of source-to-target and target-tosource more dual, we calculate the Intersection over Union score (IoU) to evaluate the duality in Sec.6.3. Following, we describe the detailed calculation of IoU score. Figure 8 gives an example of calculating the IoU score. Given the source-to-target and target-tosource read/write path P s2t and P t2s in the binary matrix form, we first generate the transposed path TP s2t of P t2s with proposed method of transposing the read/write path in Sec.3.1. Then, we calculate the intersection over union score between binary matrices P s2t and TP s2t : IoU = Sum P s2t \u2229 TP s2t Sum P s2t \u222a TP s2t , (17) where the larger IoU score means that the sourceto-target and target-to-source read/write path are much more dual.  which means the source-to-target and target-tosource read/write path are exactly in the dual form and reach the agreement on the sequence of segment pairs. In the calculation of IoU score, for 'MMA' and 'Single Path', the source-to-target and target-tosource read/write paths come from independent models in the two directions respectively. For 'Dual Paths', the source-to-target and target-to-source read/write paths come from the forward and backward single-path SiMT model concurrently. C Hyperparameters All systems in our experiments use the same hyperparameters, as shown in Table 4 . D Numerical Results with More Metrics We also compare 'Dual Paths' and 'Single Path' with previous methods on the latency metrics Average Proportion (AP) (Cho and Esipova, 2016) and Differentiable Average Lagging (DAL) (Arivazhagan et al., 2019) . In this section, we first give the definition of AP and DAL, and then report the expanded results and numerical results of the main experiment (Sec.5.3), using AP, AL, DAL as latency metrics. D.1 Latency Metrics Average Proportion (AP) (Cho and Esipova, 2016) measures the proportion of the area above a read/write path. Given the read/write path g i , AP is calculated as AP = 1 |x| |y| |y| i=1 g i . ( 18 ) Differentiable Average Lagging (DAL) (Arivazhagan et al., 2019) is a differentiable version of average lagging, which can be integrated into training. Given the read/write path g i , DAL is calculated as g \u2032 i = g i i = 1 max g i , g \u2032 i\u22121 + |x| |y| i > 1 , ( 19 ) DAL = 1 |y| |y| i=1 g \u2032 i \u2212 i \u2212 1 |x| / |y| . (20) D.2 Expand Results Figure 9 , 10, 11, 12 respectively show the expanded results on IWSLT15 En\u2194Vi and WMT15 De\u2192En, measured by AP and DAL. D.3 Numerical Results Acknowledgements We thank all the anonymous reviewers for their insightful and valuable comments. This work was supported by National Key R&D Program of China (NO. 2017YFE0192900).",
    "funding": {
        "defense": 0.0,
        "corporate": 0.0,
        "research agency": 0.0,
        "foundation": 0.0,
        "none": 0.9989338175767956
    },
    "reasoning": "Reasoning: The provided text does not mention any specific funding sources, including defense, corporate, research agency, foundation, or an absence of funding. Therefore, without explicit information, it's not possible to determine the funding sources for the article.",
    "abstract": "Simultaneous machine translation (SiMT) outputs translation while reading source sentence and hence requires a policy to decide whether to wait for the next source word (READ) or generate a target word (WRITE), the actions of which form a read/write path. Although the read/write path is essential to SiMT performance, no direct supervision is given to the path in the existing methods. In this paper, we propose a method of dual-path SiMT which introduces duality constraints to direct the read/write path. According to duality constraints, the read/write path in source-totarget and target-to-source SiMT models can be mapped to each other. As a result, the two SiMT models can be optimized jointly by forcing their read/write paths to satisfy the mapping. Experiments on En\u2194Vi and De\u2194En tasks show that our method can outperform strong baselines under all latency.",
    "countries": [
        "China"
    ],
    "languages": [
        "Vietnamese",
        "German",
        "English"
    ],
    "numcitedby": 2,
    "year": 2022,
    "month": "May",
    "title": "Modeling Dual Read/Write Paths for Simultaneous Machine Translation",
    "values": {
        "novelty": "   As a result, the two SiMT models can be optimized jointly by forcing their read/write paths to satisfy the mapping.",
        "performance": "our method can outperform strong baselines under all latency. our method outperforms strong baselines under all latency and achieves a high-quality read/write path."
    }
}