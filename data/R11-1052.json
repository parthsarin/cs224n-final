{
    "article": "This paper demonstrates a web-based online system, called META-DARE 1 . META-DARE is built to assist researchers to obtain insights into seed-based minimally supervised machine learning for relation extraction. META-DARE allows researchers and students to conduct experiments with an existing machine learning system called DARE (Xu et al., 2007). Users can run their own learning experiments by constructing initial seed examples and can monitor the learning process in a very detailed way, namely, via interacting with each node in the learning graph and viewing its content. Furthermore, users can study the learned relation extraction rules and their applications. META-DARE is also an analysis tool which gives an overview of the whole learning process: the number of iterations, the input and output behaviors of each iteration, and the general performance of the extracted instances and their distributions. Moreover, META-DARE provides a very convenient user interface for visualization of the learning graph, the learned rules and the system performance profile. Introduction Seed-based minimally supervised machine learning within a bootstrapping framework has been widely applied to various information extraction tasks (e.g., (Hearst, 1992; Riloff, 1996; Brin, 1998; Agichtein and Gravano, 2000; Sudo et al., 2003; Greenwood and Stevenson, 2006; Blohm and Cimiano, 2007) ). The power of this approach is that it needs only a small set of examples of either patterns or relation instances and can learn and discover many useful extraction rules and relation instances from unannotated texts. Within this framework, Xu et al. (2007) develop a learning approach, called DARE, which learns relation extraction rules for dealing with relations of various complexity by utilizing some relation examples as semantic seed in the initialization and has achieved very promising results for the extraction of complex relations. In the recent years, more and more researchers are interested in understanding the underlying process behind this approach and attempt to identify relevant learning parameters to improve the system performance. Xu (2007) investigates the role of the seed selection in connection with the data properties in a careful way with our DARE system. Xu (2007) and Li et al. (2011) describe the applications of DARE system in different domains for different relation extraction tyes, for example, the Nobel-Prize-Winning event, management succession relations defined in MUC-6, marriage relationship, etc. Uszkoreit et al. (2009) describe a further empirical analysis of the seed construction and its influence on the learning performance and show that size, arity and distinctiveness of the seed examples play various important roles for the learning performance. Thus, the system demonstrated here, called META-DARE, serves as a monitoring and analysis system for conducting various experiments with seed-based minimally supervised machine learning. META-DARE is also aimed to assist researchers to understand the DARE algorithm and its rule representation and the interaction between rule learning and relation instance extraction. It allows users to construct different seed sets with respect to size, arity and specificity to start experiments on the example domains. Moreover, it provides a detailed survey of all learning iterations including the learned rules and extracted instances and their respective properties. Finally, it delivers a qualitative analysis of the learning per-formance. As a web service, it offers a very user-friendly visualization of the learning graph and allows users to interact with the learning graph and study the interaction between learning rules and extracted relation instances. Each rule and extracted instance is presented in a feature structure format. Furthermore, the wrong instances extracted by DARE are visually extra marked so that users can investigate them and learn lessons from them. As a side effect, META-DARE is a very useful and effective tool for teaching information extraction. The paper is organized as follows: Section 2 outlines the overall architecture, while Section 3 explains the experiment corpus. Section 4 describes the DARE system and the learning algorithm. In Section 5, we introduce the seed selector. Section 6 reports the visualization functions of META-DARE. Section 7 gives a conclusion and discusses future ideas.  \u2022 Offline linguistic annotation: This component automatically annotates the corpus texts with named entity information and dependency tree structures using standard NLP tools. All annotations are stored in XML format. META-DARE: Overall Architecture \u2022 Web services: This part is responsible for user interaction and visualization of learning, extraction and evaluation results. The component Seeds Selector allows users to choose their own initial seed set for their experiments. The visualization tools present the learning graph and allow users to view learned rules, extracted instances and their interactions. Furthermore, evaluation results of the extracted instances are presented in tabular form. Experiment Corpus In META-DARE, we use the standard Nobel-Prize corpus described in (Xu et al., 2007) , which contains mentionings of the Nobel Prize award events. The target relation for our experiment domain is a quaternary tuple about a person obtaining Nobel Prize in a certain year and in a certain area, described as follows: Person, Prize, Area, Year . There are 3312 domain related documents (18MB) from online newspapers such as NYT, BBC and CNN. To facilitate our learning, the corpus is preprocessed with several NLP tools (see component \"offline linguistic annotation\"). We utilize the named entity recognize tool SProUT to annotate seven types of named entities: Person, Location, Organization, Prize, Year, PrizeArea (Drozdzynski et al., 2004) . Furthermore, we apply the dependency parser MiniPar for obtaining grammatical functions (Lin, 1998) . Users can access the annotations via the system web page where the named entities are highlighted and the dependency structures are presented in a tree format. DARE: Bootstrapping Relation Extraction with Semantic Seed The core engine in META-DARE is DARE (Domain Adaptive Relation Extraction), a minimally supervised machine learning framework for extracting relations of various complexity (Xu et DARE learns rules basically from the dependency tree structures and proposes a novel compositional rule representation model which supports bottom-up rule composition. A rule for a n-ary relation can be composed of rules for its projections, namely, rules that extract a subset of the n arguments. Furthermore, it defines explicitly the semantic roles of linguistic arguments for the target relation. Let us look at the following example in our experiment domain. Given the following example (1) as our seed which describes a person Ahmed Zewail won the Nobel Prize in the area of Chemistry in the year of 1999, all four arguments occur in the following sentence (2) in our experiment corpus. The dependency tree structure of sentence (2) is showed in Figure 3 . (1) Ahmed Zewail, Nobel, Chemistry, 1999 (2) Ahmed Zewail won the 1999 Nobel Prize for Chemistry. The rule extracted from example (2) is illustrated in Figure 4 , headed by the verb \"win\". This rule extracts all four arguments for the target relation, where the two arguments Prize and Year are extracted by its binary projection rule specified as the value of the feature HEAD belonging to the grammar function OBJ (object). The binary rule detects the Prize and Year arguments in a complex NP such as \"the 1999 Nobel Prize\".  META-DARE offers users a web interface for seed construction 2 . Figure 5 illustrates a seed construction example. Users can choose their seed examples according to the following parameters: \u2022 Size: users can select as many winning events as available. \u2022 Year: users can choose winners belonging to a certain year. \u2022 Area: users can add their preferred area. \u2022 Person name: users are allowed to select their preferred person name. Given a valid email address from the user, the system is able to dispatch a notification automatically when the experiment ends. Visualization for Monitoring META-DARE allows users to access and monitor the following elements of the bootstrapping process: \u2022 Learning graph: Users have access to the whole learning graph and can also zoom in the graph and interact with each node and view its content. \u2022 Learned rule: Each learned rule is presented as a feature structure and is linked to its seeds and sentences from which it is extracted. \u2022 Evaluation results: The distribution of the extracted instances and their precision is presented in tabular form.   match the seeds and then extract pattern rules (e.g, r 1 , r 2 , r 3 ). Figure 6 represents the extraction and learning process as a growing graph (Uszkoreit et al., 2009) . The learning graph visualized in META-DARE mainly focuses on the interaction between the learned rules and their seed instances 3 . Figure 7 shows that all three learned rules rule 0, rule 1 and rule 5 detect the same relation instance relation 3 as follows: (3) Robert Mundell, Nobel, Economics, 1999 which further helps to learn many new rules including rule 18 and rule 19 etc. The nodes not framed by dashed lines, such as rule 23 and rule 24 are rules that cannot discover any new relation instances. The foreground colors of the nodes indicate the evaluation information (see Section 6.2). If users click one of these rules, they can view the rule presentation as depicted in Figure 4 . The sentences mentioning extraction rules or instances are also presented on the web page. The following example shows two sentences from which relation 3 is extracted. Visualization of Evaluation Results With the help of the gold standard database about the Nobel prize winners, we are able to automatically evaluate the extracted instances. In our evaluation, we take following aspects into account: \u2022 overall performance of the relation extraction: precision and recall \u2022 detailed analysis of the extracted instances: distribution of relation instances with various arities and their precision. \u2022 highlighting of the wrong instances and indications of error sources Table 1 lists the extraction results and their evaluations after one experiment run with only one example as seed. This seed is mentioned in example (1). We classify the extracted relation instances into different groups depending on their argument combinations. The overall precision of this experiment is 80.05% with 297 correct instances. The precision of instances with all four arguments given is pretty high, namely, 91.61%. They cover almost half of extracted instances. Among the instances with three arguments, there are two argument combinations where W stands for winners, P for prize names, Y for years and A for areas. The combination (W.P.Y) has achieved a very good precision but contains only few instances. In our experiment, we consider only instances at least containing a person name as instance candidates. This experiment confirms our observation that instances which cover more arguments of the target relation have in general better precision values. In Table 2 and Table 3 3 , all four experiments do not differ too much from each other. However, with more examples in the fourth run, the system needs only five iterations. As reported in (Uszkoreit et al., 2009) , the Nobel corpus owns a data property close to a small world. With one single example, the system can achieve very good performance. Therefore, all four experiments share similar performance in our evaluations. As illustrated in Figure 7 and 8, META-DARE also highlights the dangerous or bad rules and wrong relation instance. As described in Xu et al. (2010) , the acquired rules are divided into four groups according to the extraction results: \u2022 useless, if the rule does not extract any instances. \u2022 good, if the rule extracts only correct instances. \u2022 dangerous, if the rule extract both correct and wrong instances. \u2022 bad, if the rule extract only bad instances. In the learning graph, the rules from different group are colored in the following way: \u2022 useless rules: not framed by dashed lines \u2022 good rules: black foreground \u2022 dangerous or bad rules: red foreground In a similar way, the extracted instances are colored as follows: \u2022 correct instance: blue foreground \u2022 wrong instance: red foreground \u2022 not evaluable: black foreground, such as instance about other prize-winning events but not noble-prize-winning \u2022 useless seed: not framed by dashed lines. With these instances no rules are learned. For example, in Figure 7 rule 23 and rule 24 are the useless rules, while rule 20 and rule 22 have extracted the wrong instances. Rule 0, rule 1 and rule 5 are the dangerous rules. In Figure 8 Relation 9 is a wrong instance but it does not contribute more errors. rule 5 is a dangerous rule. The users can study the rule and the corresponding sentences from which this rule is learned. Conclusion and Future Work We demonstrate the META-DARE system which implements the minimally supervised machine learning approach DARE for learning rules and extracting relation instances. META-DARE provides a user-friendly web interface to allow researchers to conduct their own experiments and to obtain insights in the bootstrapping process such as the learning graphs, the learned rules and the iteration behaviors. Furthermore, the evaluation results and the highlighting of the errors are very useful to investigate the learning algorithms and to develop improvement solutions. META-DARE is an initial approach to an online monitoring system of seed-based minimally supervised machine learning approaches. We plan to integrate more domains and target relations as described in (Xu, 2007; Li et al., 2011) . Since DARE is domain adaptive, the META-DARE can be easily customized if users might provide additional corpora and definitions of new relations for a new domain. It might be also useful if META-DARE can display the ranking information computed by the confidence estimation component (Xu et al., 2010) for the instances and the rules. Furthermore, in addition to seed construction, we would like to allow more interactions with the DARE system in the near future, such as adding or selecting negative examples for learning negative rules (Uszkoreit et al., 2009) , evaluating the instances or rules during the bootstrapping or correcting the linguistic annotation of NLP tools. An even ambitious plan is to integrate other similar rule learning systems and compare their performance with each other. Acknowledgements This research was conducted in the context of the DFG Cluster of Excellence on Multimodal Computing and Interaction (M2CI), projects Theseus Alexandria and Alexandria for Media (funded by the German Federal Ministry of Economy and Technology, contract 01MQ07016), and project TAKE (funded by the German Federal Ministry of Education and Research, contract 01IW08003).",
    "funding": {
        "defense": 0.0,
        "corporate": 0.0,
        "research agency": 1.0,
        "foundation": 0.0,
        "none": 0.0
    },
    "reasoning": "Reasoning: The acknowledgements section of the article mentions funding from the DFG Cluster of Excellence on Multimodal Computing and Interaction (M2CI), the German Federal Ministry of Economy and Technology, and the German Federal Ministry of Education and Research. These are all government or publicly-funded organizations, indicating research agency support. There is no mention of defense, corporate, foundation funding, or an absence of funding."
}