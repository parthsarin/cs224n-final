{
    "article": "The paper presents a system for querying (in natural language) a set of text documents from a limited domain. The domain knowledge, represented in description logics (DL), is used for filtering the documents returned as answer and it is extended dynamically (when new concepts are identified in the texts), as result of DL inference mechanisms. The conceptual hierarchy is built semi-automatically from the texts. Concept instances are identified using shallow natural language parsing techniques. Introduction The increasing amount of texts available in electronic format (Web pages, CD-ROMs) from limited domains requires precise answers from Information Retrieval (IR) systems. Users have various expectations about the result provided by IR systems for various corpora: medical corpus contains information about precise diagnostic or treatment, while the news corpora contain information about persons, places, names. The main goal of this project is to investigate several approaches of integrating semantic information into an Information Retrieval system, for querying in natural language a set of documents from a limited domain. Purely statistical search engines provide bad recall and low precision (the answers contain an important amount of irrelevant information), because they ignore hyponyms, hyperonyms and synonyms. We consider that the use of semantics is a good solution for improving IR systems performances. We integrate a dynamically-modified ontology extracted from texts into an IR system, for investigating the possible improvements of recall or precision. The information extracted from the text is used for building semi-automatically a hierarchy of domain concepts. The domain hierarchy is represented in description logic (DL), providing efficiency and fault tolerance when incomplete or erroneous data are processed. Logic inference mechanisms provided by DL reasoner are used to extend dynamically the domain model, and to complete and to correct missing information extracted from the user query. The system could be easily ported for another domain, due to the dynamic maintenance of the domain knowledge base. Other systems consulting DL ontologies used fixed, manually build domain hierarchies (Welty, Ide, 1999) , and they accept searches on a few fields (author, title, book). NLP techniques have been applied for eliminating some of the drawbacks of IR systems. NLP tools are used to extract index terms, or to develop linguistic resources dedicated to IR systems. Terms are identified by robust methods: finite state automata, POS taggers, shallow syntactic parsers (S.Ait-Mokhtar, J.-P. Chanod, 1997) . Another solution for extracting a better interpretation of the user query and documents is based on the use of semantic resources (as filters or for identifying index terms) for improving search results: multiple-word terms ((Riloff, Lorenzen, 1998) , (Zhou, 1999) ), their semantic variations (Jacquemin, 1998 ), thesauri (Corelex (Buitelaar, 1998 ), EuroWordnet (Vossen, 1998) ) or lists of synonyms (Read, Barcena, 1998 ), concepts (Ambroziak, Woods, 1998) . (Jacquemin, 1998) proposes a small grammar for term identification. Existing semantic resources (WordNet, MRD, CoreLex) contain redundant information, but are often incomplete. These resources are useful for general search, on unrestricted texts, but must be reorganised to be integrated into an IR system. Searching a text base for a given domain requires domain-dependent resources. Domain-specific ontologies might help in understanding user queries and documents. Words might have specific senses, not available in general-purpose resources. For these reasons, we proposed a method for extracting the ontology from texts and several possibilities of integrating it into an IR system. Description Logics Description logics (DL) are formalisms dedicated to knowledge representation (Baader, Hollunder, 1991) , more flexible than frame systems, but providing rigurous semantics and syntax. DL structures the domain knowledge on two levels: a terminological level (T-Box), containing the classes of domain objects (concepts), with their properties (roles) and an assertional level, (A-Box), containing individuals of the abstract objects (instances). The terminological level provides some powerful inference tests: the satisfiability of a concept definition (there is an interpretation of the concept which is true in the set of domain facts), the detection of the subsumption relation between two concepts (detecting which concept is more general than the other one) and classification (ordering the new concepts in the hierarchy). The A-Box provides consistency test (i.e. contradiction-free) or instantiation test (i.e. concept subsuming the instance) for the individual descriptions, or retrieval inference (retrieving for a given concept all its individuals). Among knowledge representation formalisms, Description Logics (DL) are suitable for IR applications because they handle erroneous or incomplete data, together with the possibility of organising hierarchically the knowledge (used for ). CLASSIC has been used for indexing a digital library (Welty, Ide, 1999) , but it requires manual indexation and limited search on some fields. The ontology was fixed and it was built off-line. Some methods based on DL mechanisms were applied to extract terms or relations between terms (Capponi and Toussaint, 2000) , but no IR system integrates a DL ontology, updated dynamically. DLs handle semi-structured data, they do not define the exclusive list of roles for their individuals (they accept implicit definitions). DL accepts also incomplete definitions. \u00a1 \u00a3\u00a2 \u00a5\u00a4 \u00a7\u00a6 \u00a7\u00a2 \u00a9 \u00a5 \u00a5 \u00a7 \u00a2 \u00a5 \u00a7\u00a6 \u00a7\u00a6 ! \u00a5\" $# \u00a3\u00a2 % \u00a3 & ' ( \u00a5) 0 $1 \u00a32 \u00a3 3 \u00a2 4 3 \u00a2 \u00a35 ' ( ) 0 $1 \u00a32 \u00a3 6 \u00a5\u00a1 \u00a2 2 47 \u00a3 \u00a6 8 9 @\u00a6 \u00a33 \u00a35 5 5 \u00a6 \u00a7 \u00a32 \u00a5 \u00a7 \u00a2 4A \u00a3B C ! \" $ \u00a3 @\u00a6 @\u00a6 & ' ( ) 0 $1 \u00a32 \u00a3 3 \u00a2 4D \u00a3B 5 5 5 In the example, the instance y0 of the concept Alpinist defines only the role hasAge, while the concept has some other roles, like hasIdeal. The concepts are defined by define-concept and the logical operators AND, OR, NOT and the DL operators SOME (existential quantifier) and ALL (the universal quantifier). A specific DL, CICLOP 1 (Rudloff et all, 1998), was chosen for representing the domain knowledge because it deals with role hierarchy, inverse roles and transitive roles. It accepts reasoning simultaneously in several hierarchies (multiple T-Boxes) and implements an A-Box. Some of the expressiveness (the features defining concepts and roles, role hierarchy, transitive roles) are necessary for representing domain knowledge into an IR system. Some tests like are useful for checking inferred facts. System Architecture The prototype integrates several natural language processing modules (Figure 1 ) as well as the DL classifier. We implement the prototype and we use for tests small experimental French corpora on heart surgery -MENELAS (83600 words), newspaper articles (300000 words) and NLP articles (250000 words). The system is partially implemented in Java, in Perl and in CLIPS (the rules combining domain-specific terms). The aim of these modules is to identify domainspecific terms and eventually relations between terms. From the set of terms and relations, the system updates a domain-specific hierarchy. The automatic extraction of ontologies was the object of the TAI group (Terminology for Artificial Intelligence), defining principles for ontologies (Bouaud and all, 2000) , and developping tools for identifying terms and relations. A bottom-up approach for building a hierarchy was adopted by several systems: identifying terms and assigning them to concepts (Bachimont, 2000) , generalising predicate structures to DL concepts (Capponi and Toussaint, 2000) . Our ontology definition is a simplified hierarchical model of the terminological knowledge from a given domain. Our approach starts also from texts in order to identify terms. Cue phrases (functional words, clause markers) are used to identify potential relations between terms (and also between concepts). A link between candidate terms and DL representations is proposed, and the conceptual representations are validated by DL tests. We adopt a shallow, fault-tolerant approach for identifying term candidates; we need to recognize only the most relevant pieces of information in the text, even if some small errors occur in the input. NLP Modules Semantic chunk identification Semantic chunk identification The main goal of this module is to identify the word sequences corresponding to the most significant domain concepts (semantic chunks). A semantic chunk contains a simple syntactic pattern (simple noun phrase, verb) and it is delimited by two border words. Border words are functional words, auxiliaries, some prepositional syntagms. The semantic chunk, as we defined in our system, might contain some errors, which are ignored by the processing modules. Example. \"la victime, emport\u00e9e par l'avalanche\" [the victim, taken from the avalanche] In this example, \"la victime\" and \"l'avalanche\" are semantic chunks, containing the relevant information. This module uses several tools: a POS tagger, a sense tagger, a border identifier and a pattern matcher. The identification of the semantic chunks is based on lexical information, provided by the POS tagger. a) The POS tagging (using WinBrill, trained for French with a set of data provided by Institut National pour la Langue Franc \u00b8aise (Lecomte, 1998)) identifies the content words (nouns, adjectives, verbs) and functional words (prepositions, conjunctions etc.). Brill's tagger uses a set of contextual and lexical rules (based on prefixes and suffixes identification) learned from annotated texts, for guessing the POS for the unknown words. It was chosen because it provides good results (95 %) and it was available, with the French language model. b) The sense tagger contains a pattern matcher, consulting a set of idiomatic phrases (their sense could not be composed from the component parts) and their conceptual descriptions assigned by a human expert. The sense is represented by DL conceptual descriptions. The pattern matcher annotates each known word or idiomatic phrase with its semantic description. c) A module for border identification. It identifies the words and the syntactic constructions delimiting the semantic chunks. This module uses the output of POS tagger (identifying the functional words), as well as a set of cue phrases (syntactic phrases containing auxiliaries, composed prepositions). The set of cue phrases is built as a result of studies on experimental corpora. The determiners and prepositions are best candidates for chunk border. d) Pattern matcher. The goal of this module is to identify the core of the semantic chunks, which is represented by simple noun phrases and verb phrases, between two consecutive borders. Examples. A simple noun phrase is identified by the following rules: \u00a2\u00a1 \u00a4\u00a3 \u00a5 \u00a7\u00a6 , \u00a9 \u00a7 \u00a7\u00a1 \u00a3 \u00a7\u00a6 , \u00a7 \u00a1 \u00a3 \u00a5 \u00a7\u00a6 Errors might occur between two consecutive borders, and these cases are handled by patterns like the last one. '*' replaces anything in the input text, so errors might be ignored. e) DLgen interprets the information provided by the POS tagger and generates automatically a concept definition. A human expert must check the output of this module. A few examples of rules proposed for generating simple DL descriptions: -S1/N S2/ADJ is associated to the definition \u00a5! #\" $ % ! & #' #( % )' 0! 01 #2 \u00a43 54 6 \u00a53 #7 \u00a2 8 #9 #@ A3 54 \u00a4 3 #B 0C #D E F G 8 #2 \u00a5H I 3 #7 )I P \u00a5P #P Q R 5S T 0U VR W 0T 0U U YX a`b dc #b b e \u00a5f `c 0g h i pg e Yg q h ri h s 5t `g `e #t ! 0\" 5$ % 5! \u00a5& \u00a5' 0( 0% 5' #! 1 \u00a52 \u00a43 4 3 \u00a5B C \u00a5D E 5F \u00a5G 9 F 0u ! I 3 \u00a57 5I 0P #P Q R 5S T 0v w yx VR W 0T 0U `b \u00a7c 0b b e \u00a5f `c g h i Vg e g q h i h s 5t `g `e #t ! 0\" 5$ % 5! \u00a5& \u00a5' 0( 0% 5' #! 1 \u00a52 \u00a43 #7 \u00a56 #3 54 \u00a4 8 #9 #@ 3 #7 3 \u00a5B C \u00a5D E F G 8 #2 \u00a5H I 3 4 I P \u00a5P #P Q rq h Y #h b c 0 h Yg c #t b c g h i `t 0g e e # h Yt c # h b rR 5S T Y V`b rc 0b b e \u00a5f `c g h i g e g q h y e 0 h hasS1 There are also some simple patterns for describing phenomena like negation, in particular, even if it is impossible to enumerate all the possibilities, to detect correctly the scope of the negation: -sans/ADV S1/N is associated to the definition \u00a5! #\" $ % ! & #' #( % )' 0! 01 #2 A% 5( 2 56 #3 54 9 B 3 4 #P #P Q c 0 f t 5T v Yw R 5S 0T U d`b c 0b b e \u00a5f `c g h i ag e \u00a7g q h b c # h i h s 5t `g `e #t ! 0\" 5$ % 5! \u00a5& \u00a5' 0( 0% 5' #! 1 \u00a52 A% 5( 2 56 #3 54 9 B 3 54 0P \u00a5P Of course, not all the negations might be handled. The output of DLgen module provides only 61 % right annotations. Its output is checked by the human expert with the use of the DL classifier to see if the concept definitions generated automatically are correct or not, due to input errors: determiners starting the sentence, some patterns which are not coded by the system. Relations between terms This module applies DL inference mechanisms, as well as syntax-based rules, in order to combine the conceptual descriptions associated to each semantic chunk. 1) Relevance chunker. We consider two classes of chunks: main chunks and secondary chunks. Main chunks are similar to the notion of heads proposed by classical linguistic theories. Secondary chunks play the role of a modifier, which just add more information to the sense of the head, which might be absent. We interpreted the order and the position of the chunks in the sentence, used for combining concepts. Some examples of rules defines various chunks: -semantic chunks following after a gerund verb, an auxiliary plus a past participle verb or a preposition are secondary chunks; -verbs are always Main chunks; -chunks following after a conjunction are annotated by the same tag as the previous one. Example. '[Main Les contrebandiers Main] [Main ont commenc\u00e9 Main] [Second \u00e1 utiliser ces \" monstres \" Second]' 'The trafficants have started to use monsters' The main chunks identified here are \"les contrebandiers\" (the first chunk in the sentence), and the \"ont commenc\u00e9\" (comme verb principal). The last chunk is marked as secondary because it follows after the preposition \"\u00e0\". 2) Heuristic rules. The rules are established by a human expert as a result of corpora studies. The corpora were POS tagged and manually annotated with conceptual descriptions. The set of heuristic rules is established after a list of patterns extracted from corpora. Example of syntactic heuristic rules: if a preposition is a delimiter between two semantic chunks and the preposition is relating a noun to its modifier, then we can combine the conceptual descriptions of the two chunks into a more complex semantic description. \u00a1 \u00a3\u00a2 \u00a4 \u00a5 \u00a7\u00a6 \u00a7 \u00a7\u00a9 \u00a4 \"! # $ % # & \u00a4 ' % \u00a7( \u00a9 \") 0 1 \u00a6 $ 2\u00a2 3 \u00a7! 4 5\u00a5 \"\u00a6 \u00a9 0 1 \u00a6 $ 2\u00a2 \u00a5 \"! $ \" \u00a1 \" % # 4 4' % \u00a7( \u00a9 \") 1 6 \u00a7% 4( ! 7 8 \" \u00a7% 9\u00a2 @ % 7 A\u00a2 \u00a5 \"\u00a6 \u00a9 0 1 &B C@ % 7 D\u00a2 ' % \u00a7( \u00a9 \") 1 1 E DF G H PI \u00a7F Q Q R S T PU V WF T PF G Q U X F Q U Y T `G Y T \u00a7a \u00a7U Q U Y T cb Y S dQ H \u00a7R eS f \u00a7g R h pi DS R I Y V U Q U Y T \u00a7V q I \u00a7F V Q eI \u00a7F S Q U G U I \u00a7g R WX R S r \u00a7V q F S R WV Y s tR pR u \u00a7F s tI \u00a7g R V AY b 9r \"Y S a \u00a7R S Av AY S a \u00a7V q \"U T \u00a7G g f \u00a7a \u00a7R a cU T tQ H \u00a7R pF G Q U X F Q U Y T tG Y T \u00a7a \u00a7U Q U Y T \u00a7V AY b 0Q H \u00a7R pH \u00a7R f \u00a7S U V Q U G S f g R V h ti 9F Q Q R S T \u00a7V eF V V Y G U F Q R a Pv dU Q H wF cx U X R T PQ S U x x R S dv yY S a H \u00a7F V eF V V Y G U F Q R a wF v yR U x H Q q 9R u Q S F G Q R a b S Y s 4G Y S I Y S F \u00a7h 9 5T f \u00a7s er R S AY b & eS f \u00a7g R V AH \u00a7F V Ar \"R R T a \u00a7R V G S U r R a U T A & i A \"h \" Y s tR dS f \u00a7g R V d G Y T Q F U T \u00a7U T \u00a7x I \u00a7S R I \"Y V U Q U Y T \u00a7V 0Y S 0x R S f \u00a7T \u00a7a \u00a7V 0F S R Ds tY S R &b S R f \u00a7R T Q &Q H \u00a7F T pQ H \u00a7Y V R 9Q S U x x R S R a pr eG Y T f \u00a7T \u00a7G Q U Y T \u00a7V q V Y yX F S U Y f \u00a7V V F g U R T \u00a7G R V yF S R pF V V U x T \u00a7R a Q Y Q H \u00a7R V R pS f \u00a7g R V h CICLOP classifier. R yf \u00a7V R yQ H \u00a7R dR u \u00a7I \u00a7S R V V U X R T \u00a7R V V yF T \u00a7a Q H \u00a7R dg Y x U G F g U T b R S R T \u00a7G R V 9b Y S 9G H \u00a7R G U T \u00a7x pQ H \u00a7R X F g U a \u00a7U Q pY b \"Q H \u00a7R AT \u00a7R v CU T b R S S R a pb F G Q V h 9 yH \u00a7R yY f Q I \u00a7f Q DY b \"H \u00a7R f \u00a7S U V Q U G DS f \u00a7g R V &U V &S R \"T \u00a7R a F T \u00a7a eG g F V V U \"R a eF T \u00a7a \u00a1 \u00a3\u00a2 \u00a3\u00a4 \u00a3\u00a5 \u00a6 \u00a8 \u00a7 \u00a9 \u00a1 \u00a7 \u00a4 \u00a7 \u00a6 \"! # \u00a8 $ # % \u00a8& (' ($ )$ 0 \u00a7 0 \u00a5 \u00a4 \u00a3 \u00a9 \u00a7 \u00a4 \u00a9 1 \u00a4 \u00a7 $ \u00a8 2 \u00a32 3 \u00a9 \u00a6 \"\u00a9 \u00a7 0 ) $ \u00a4 \u00a3 )\u00a4 42 \u00a3 \u00a1 \u00a7 ) \u00a5 \u00a4 \u00a3 \u00a9 \u00a3\u00a1 \u00a8! 5 3 \u00a1 \" $ 3 \u00a9 1 \u00a7 \u00a9 \u00a3\u00a1 \u00a7 & 76 5 \u00a7 8 # \u00a1 2 9 $ \u00a5 \u00a4 \u00a9 \u00a1 3 $ \u00a1 @ $ \" 0 \u00a5 1\u00a4 \u00a3 \"\u00a6 A B\u00a1 \u00a6 C% 1 \u00a4 \u00a3\u00a1 9 \u00a9 D$ \u00a4 \u00a2 \"\u00a4 E \u00a8\u00a9 8 \u00a6 \u00a9 \u00a3% 1\u00a4 \u00a1 F \u00a6 B \u00a1 \u00a6 \u00a1 4 0 \u00a5 & HG PI G PQ SR 7T \u00a1 8 \u00a1 \u00a7 \u00a8% 1 \u00a7 $ \u00a4 \u00a1 % 1 9\u00a4 \u00a80 \u00a6 @ \u00a9 E A B\u00a1 4 $ \u00a8 \u00a9 \u00a5 4\u00a6 A B\u00a1 \u00a9 \u00a3\u00a1 5U P \u00a7 $ \u00a7 V \u00a1 2 E $ \u00a8 \u00a7 \u00a9 \u00a1 \u00a7 1\u00a4 \u00a1 \u00a6 $ ( 0 ! 0 % 1 \u00a5 \u00a4 \u00a3 \u00a6 \u00a8! # 4 $ \u00a9 \u00a3\u00a5 & W % 1\u00a9 \u00a3\u00a1 2 \u00a8 $ 1 0 \u00a5 \u00a9 \u00a2 \u00a6 \u00a6 D! # X $ 4$ 0 \u00a7 0 \u00a5 U Y\u00a9 \u00a3\u00a1 \u00a5 # Ea \"b c\u00a4 1\u00a4 \u00a3 \u00a7 \u00a7 \u00a6 @! \u00a3# E $ 1d 7Q \u00a7 \u00a5 \u00a4 \u00a3 A B U ! B \u00a7 \u00a4 0 ( \u00a9 \u00a3% 1 P\u00a9 \u00a38 B $ P \u00a1 8 \u00a6 9 \u00a7 \u00a9 \u00a3\u00a1 \u00a7 e\u00a4 \u00a3 (\u00a1 \u00a9 e \u00a7 \u00a9 \u00a3\u00a1 \u00a1 \u00a3 3 $ $ ( f \u00a1 2 7\u00a6 A B\u00a1 F \u00a9 \u00a1 U \u00a3\u00a9 \u00a3 Y! B \u00a7 \u00a4 0 e $ Pd 7Q \u00a8$ \u00a4 \u00a3 \u00a7 $ # ) S \u00a5 \u00a5 \u00a1 \u00a7 \u00a9 \u00a3% 1 \u00a5 & S' ($ ( 0 \u00a5 \u00a1 2 7 \u00a7 \u00a9 \u00a1 \u00a7 Y\u00a4 \u00a3 e\u00a2 \u00a3\u00a4 \u00a5 \u00a6 \u00a4 \u00a6 ! \u00a3# 4 $ f \u00a1 2 9V \u00a1 \u00a9 3 \u00a5 \u00a6 2 \u00a9 \u00a3\u00a1 \u00a5 # \u00a8 8 S $ \u00a9 \u00a3\u00a1 \u00a9 \u00a3\u00a5 \u00a9 2 # 4 ( \u00a7 \u00a9 \u00a3% 1 \u00a5 & 3.3 Functionality ' ($ 9g 7Q hT i% 1\u00a9 \u00a6 0 \u00a5 7\u00a6 \u00a7 ! B \u00a6 X\u00a4 ! B\u00a9 \u00a2 1 \u00a9 \u00a7 70 p 0 \u00a9 \u00a3 7\u00a6 \u00a9 \u00a7 0 % 1 \u00a1 \u00a9 \u00a8! B 9 \u00a1 \u00a7 \u00a5 0 \u00a6 \u00a6 X \u00a1 $ ! \u00a4 & ' ($ 9\u00a6 \u00a9 \u00a7 0 % 1 \u00a1 \u00a3 ) (A B \u00a9 \u00a7 \u00a6 E! \u00a3# X\u00a4 4 \u00a9 \u00a3V \u00a3 \u00a1 q U h \u00a6 \u00a1 8 # \u00a1 2 1 $ 9\u00a5 7\u00a9 8 e $ 9% 1\u00a9 \u00a3 78 p 0 \u00a1 \u00a3 3 \u00a9 \u00a6 & )r B\u00a9 \u00a4 \u00a3 \u00a7 $ 3 \u00a9 \u00a6 \"8 \u00a9 % s $ 9\u00a5 U 3 9 f \u00a4 \u00a3 \u00a7 7 $ 9\u00a5 8 7\u00a4 \u00a1 \u00a6 \" $ 9 2 \u00a3$ 7 \u00a7 \u00a9 \u00a3\u00a1 f 1t \u00a4 \u00a8\u00a5 % 1 \u00a6 \u00a1 0 % 9! B 7\u00a9 \u00a38 3 \u00a9 \u00a6 F 7u 9 \u00a9 Xv w x & r B \u00a9 \u00a3% y $ 7\u00a5 U 3 9 f \u00a4 \u00a3 \u00a7 7 $ 9% 1\u00a9 \u00a3 78 p 0 \u00a1 \u00a3 ) \u00a7 \u00a9 \u00a3\u00a1 \u00a1 3 \u00a9 \u00a3 \u00a6 t \u00a1 \u00a9 0 \u00a1 U \u00a4 \u00a6 \u00a7 \u00a2 U 5\u00a4 \u00a3\u00a1 \u00a6 4\u00a2 ! x & P' ($ 7 \u00a7 \u00a9 \u00a3\u00a1 f \u00a9 8 S $ \u00a7 \u00a9 \u00a1 \u00a3 \u00a1 \u00a3 3 \u00a9 \u00a6 (\u00a4 7 \u00a9 \u00a7 \u00a6 \"! \u00a3# 4 $ g Q hT X% 1\u00a9 \u00a6 0 \u00a5 58 \u00a9 h\u00a1 3 \u00a7 \u00a9 \u00a3\u00a1 \u00a7 Y \u00a6 \u00a1 \u00a3 A B \u00a7 \u00a4 \u00a9 \u00a1 5& S' ($ ed 7Q 4% 1\u00a9 \u00a6 0 \u00a5 S\u00a2 \u00a3\u00a4 \u00a5 \u00a6 \u00a4 5 $ e\u00a1 3 \u00a7 \u00a9 \u00a3\u00a1 \u00a7 0 \u00a4 \u00a5 \u00a6 A B\u00a1 \u00a9 \u00a3\u00a1 (\u00a4 \u00a3\u00a1 \u00a6 \u00a8 $ # \"\u00a4 \u00a3 \u00a4 \u00a3\u00a6 \u00a6 \u00a6 4 \u00a9 9 $ \u00a6 \u00a9 \u00a3% 1\u00a4 \u00a1 4$ \u00a4 \u00a3 \u00a7 $ # \u00a3& r Y U $ \u00a4 \u00a3 \u00a1 \"% 1\u00a4 \u00a3 \u00a7 $ \u00a6 \u00a1 A B ( $ 5 \u00a7 A B \u00a7 $ \u00a4 7 \u00a1 4 $ \u00a1 0 f U B\u00a4 \u00a1 \u00a6 \u00a8 $ \u00a1 \u00a4 \u00a32 \u00a32 S\u00a5 \u00a4 ! B \u00a5 h $ PV \u00a1 \u00a9 3 \u00a1 3 \u00a9 \u00a6 Y\u00a4 \u00a3\u00a1 \u00a6 ) $ P \u00a6 \u00a1 A B \u00a6 9 $ \u00a4 \u00a3 3 $ $ ( \u00a7 \u00a9 \u00a1 \u00a7 0 \u00a4 \u00a3\u00a5 \u00a6 \u00a7 \u00a9 \u00a3\u00a1 & Q h f \u00a7 \u00a4 \u00a5 5 \u00a1 8 \u00a9 % 1\u00a4 \u00a9 \u00a1 1 (\u00a4 2 \u00a3\u00a1 \u00a6 4 \u00a9 1 \u00a4 \u00a7 $ 3 \u00a9 \u00a6 \u00a8! # 4 $ T PR 6 1 \u00a4 2 \u00a32 & g f U S $ 4 % 1\u00a4 \u00a1 \u00a3 \u00a7 1 \u00a7 $ 0 \u00a1 V 1\u00a4 \u00a3 1 \u00a6 \u00a1 \u00a3 A B \u00a6 D \u00a1 X $ 4 \u00a1 0 f & Xr B\u00a9 \u00a3 \u00a4 \u00a3 \u00a7 $ @ \u00a7 $ 0 \u00a1 V BU 3 1$ \u00a4 \u00a2 4\u00a4 \u00a7 \u00a9 \u00a3\u00a1 \u00a7 0 \u00a4 \u00a5 e\u00a6 \u00a7 \u00a9 \u00a3\u00a1 5& \u00a8' ($ 1$ 0 \u00a7 9 0 \u00a5 3 \u00a5 \u00a5 e! B 10 \u00a6 E8 \u00a9 \u00a3 \u00a7 \u00a9 \u00a3% 9! \u00a1 \u00a1 2 \u00a8 \u00a4 \u00a3 \u00a4 \u00a5 Y % 1\u00a4 \u00a1 \u00a3 \u00a7 \u00a6 \u00a7 \u00a9 \u00a1 & \" D \u00a8 \u00a6 \u00a1 8 # E\u00a4 X 1\u00a9 \u00a38 \u00a1 3 \u00a7 \u00a9 \u00a1 \u00a7 0 \u00a4 \u00a3\u00a5 (\u00a6 \u00a7 \u00a9 \u00a3\u00a1 4t \u00a4 9\u00a4 \" 0 \u00a5 9\u00a9 \u00a38 $ 0 \u00a7 0 \u00a5 x U h \u00a7 $ \u00a7 V \u00a3 \u00a6 @! \u00a3# X $ 9d 7Q \u00a7 \u00a5 \u00a4 A B & 9I 8 3 1\u00a4 \u00a3 9 \u00a9 \u00a7 \u00a1 2 \"0 \u00a1 0 U h $ \u00a1 X $ 1 \u00a1 \u00a4 \u00a3\u00a1 \u00a7 \u00a9 8 Y $ 9 \u00a7 \u00a9 \u00a1 \u00a7 7\u00a4 ) \u00a2 \u00a6 5& I 8 P\u00a1 3 \u00a6 \u00a9 \u00a7 0 % 1 \u00a1 \u00a3 3 9 \u00a9 \u00a7 \u00a6 X \u00a9 4! B 9\u00a4 \u00a3\u00a6 \u00a6 \u00a6 \" \u00a9 1 $ f ! \u00a4 \u00a3 U $ \u00a6 \u00a9 % 1\u00a4 \u00a3 \u00a1 \u00a8$ \u00a4 \u00a7 $ \u00a3# \u00a8 ( f \u00a1 \u00a6 \u00a6 3 $ \u00a8\u00a1 3 \u00a7 \u00a9 \u00a1 \u00a7 & 4 DL for Indexing d 7Q X \u00a9 \u00a2 \u00a6 ( 5\u00a9 3 8 0 \u00a5 5 \u00a1 8 \u00a1 \u00a7 7% 1 \u00a7 $ \u00a4 \u00a1 % 1 e8 \u00a9 P$ \u00a4 \u00a1 \u00a6 \u00a5 \u00a1 2 ) \u00a1 \u00a7 \u00a9 % 1 \u00a5 7\u00a4 \u00a3\u00a1 \u00a6 \u00a8 % 1 F 0 \u00a7 0 \u00a6 \u00a6 \u00a4 \u00a4 U (\u00a4 3 \u00a5 \u00a5 \u00a4 9\u00a2 \u00a3\u00a4 \u00a3\u00a5 \u00a6 # D 18 \u00a9 1\u00a1 3 \u00a1 8 \u00a6 @8 \u00a4 \u00a7 & R 7\u00a1 @ $ \"\u00a9 $ 1$ \u00a4 \u00a1 \u00a6 5U (I y # % 1 $ \u00a4 \u00a3\u00a1 \u00a6 \u00a5 7 \u00a1 \u00a7 \u00a9 % 1 \u00a5 7\u00a9 \u00a3 ( \u00a9 \u00a3\u00a1 \u00a9 \u00a30 \u00a1 0 (\u00a6 \u00a4 \u00a3 \u00a4 9\u00a4 3 \u00a5 \u00a5 5\u00a4 P8 0 q q # \u00a8\u00a6 \u00a9 \u00a3% 1\u00a4 \u00a1 4V \u00a1 \u00a9 3 \u00a5 \u00a6 2 \u00a3 \u00a3& er B\u00a9 e $ \u00a4 \u00a3 \u00a9 \u00a1 U d 7Q X e \u00a7 $ \u00a9 \u00a3 \u00a1 1\u00a4 e\u00a4 \u00a6 \u00a9 % 1\u00a4 \u00a3 \u00a1 1V \u00a1 \u00a9 3 \u00a5 \u00a6 2 \u00a3 \u00a1 \u00a4 \u00a9 \u00a1 98 \u00a9 % 1\u00a4 \u00a3\u00a5 % 8 \u00a9 \u00a3 e\u00a9 \u00a30 eI # % \u00a8& ' ($ 4 \u00a1 \u00a6 f \u00a1 2 X% 1 $ \u00a9 \u00a6 D )\u00a4 XQ h\u00a4 \u00a3 \u00a1 16 % 1\u00a4 \u00a3\u00a1 \u00a7 1I \u00a1 \u00a6 f \u00a1 2 X\u00a9 \u00a1 Xt d 70 % 1\u00a4 \u00a3 U (v \u00a3x U 3 $ 1 % 1 $ \u00a4 \u00a2 7! 5 \u00a1 \" \u00a5 \u00a4 \u00a7 \u00a6 \u00a8! # \u00a8 \u00a7 \u00a9 \u00a1 \u00a7 & P' ($ % 1\u00a4 \u00a3 f 4\u00a9 8 Y\u00a6 \u00a9 \u00a7 0 % 1 \u00a1 (\u00a4 \u00a1 \u00a6 \u00a8 \u00a7 \u00a9 \u00a3\u00a1 \u00a7 ( \u00a6 0 \u00a7 \u00a6 \" \u00a7 \u00a9 % 9F 0 \u00a1 2 1 0 ! 0 % 1 \u00a9 \u00a1 \" \u00a5 \u00a4 \u00a9 \u00a1 (! 5 3 \u00a1 X \u00a7 \u00a9 \u00a3\u00a1 \u00a7 \u00a4 \u00a3\u00a1 \u00a6 \u00a8 $ ) \u00a7 \u00a9 \u00a3\u00a1 \u00a7 3 2 $ \u00a3 9t \u00a5 \u00a9 \u00a7 \u00a4 \u00a5 h\u00a9 \u00a3 2 \u00a5 \u00a9 \u00a3! \u00a4 \u00a5 8 p 0 \u00a1 \u00a7 x & \u00a2\u00a1 \u00a4\u00a3 \u00a5 \u00a6 \u00a7\u00a3 \u00a9 \u00a3 \u00a9 \u00a3 \u00a1 \u00a9 \u00a7 ! \" #\u00a9 $ % & ' !( \u00a1 \u00a4\u00a3 \" !\u00a1 )$ !\u00a5 \u00a1 0 1 \u00a5 \u00a1 \u00a9 \u00a3 & 2 !3 4 ! \u00a9 & 2 \" !& \u00a1 \u00a5 \u00a9 \u00a5 \" \u00a6 5 !' ! \u00a3 6 \u00a4\u00a1 2 !\u00a1 \u00a1 4 7\u00a9 \u00a7 \u00a9 ( ( % \u00a1 \u00a3 0 8$ !\u00a5 & & \u00a3 & 9 \u00a1 2 ! \u00a1 $ \u00a3 \u00a4\u00a3 \u00a3 \u00a9 \u00a5 \u00a3 )\u00a1 @ \u00a3 \u00a1 2 !4 !& 2 !3 & \u00a3 A 4.1.1 Manual building B \u00a4\" \u00a1 C )D E\" !& \u00a1 \u00a5 \u00a9 \u00a5 \" \u00a6 F0 G\u00a3 \" !\u00a1 4 ! \u00a9 & 2 7\" !\u00a9 H\u00a9 H& \u00a3 H \u00a5 \u00a1 \u00a7\u00a9 I \u00a9 2 !\u00a9 ( ( \u00a6 F' ! !& ( \u00a3 H& 2 !& \u00a3 & \u00a9 ( 1\" !& \u00a1 \u00a5 \u00a9 \u00a5 \" \u00a6 A B \u00a4\" !\u00a1 & 2 & \u00a3 & \u00a9 ( 2 ! \u00a1 $ \u00a3 G\u00a9 \u00a5 \u00a1 & 4 !\u00a1 2 \u00a3 & P Q\u00a1 4 \u00a7' \u00a6 \u00a9 H\" ! \u00a9 2 \u00a1 @ $ %\u00a1 \u00a5 \u00a3 & 2 H\u00a3 \" !\u00a1 ( & \u00a3 G\u00a80 %\u00a5 \u00a1 $ %\u00a1 \u00a9 \u00a3 \u00a1 4 \u00a7 \u00a1 3 \u00a1 2 \u00a3 G\u00a1 @ \u00a3 \u00a5 \u00a9 \u00a3 \u00a1 4 0 \u00a5 R\u00a9 \u00a1 \u00a3 \u00a4\u00a80 1& 2 !& \u00a3 & \u00a9 ( \u00a3 \u00a1 @ \u00a3 A GB \u00a4\" !\u00a1 )& 2 !& \u00a3 & \u00a9 ( \u00a3 \u00a1 @ \u00a3 G6 \u00a4\u00a1 \u00a5 \u00a1 ) \u00a1 ( \u00a1 \u00a3 \u00a1 4 # \u00a9 2 !\u00a9 ( ( \u00a6 \u00a70 \u00a5 S\u00a9 \u00a1 \u00a3 \u00a40 T\u00a5 \u00a1 !( \u00a3 \u00a80 U \u00a1 \u00a6 6 \u00a4\u00a5 4 \u00a2 \u00a1 \u00a9 \u00a5 \" EV $ !\u00a5 $ Q \u00a1 4 W' \u00a6 F\u00a3 \" !\u00a1 \u00a1 @ !$ Q\u00a1 \u00a5 \u00a3 )\u00a3 \u00cf' Q\u00a1 \u00a5 \u00a1 $ !\u00a5 \u00a1 \u00a1 2 \u00a3 \u00a9 \u00a3 & 9 \u00a1 \u00a70 \u00a5 \u00a3 \" !\u00a1 4 ! \u00a9 & 2 QX \u00a4\u00a5 \u00a1 \u00a3 !\u00a5 2 !\u00a1 4 ' \u00a6 `Y )3 ( \u00a1 A FB \u00a4\" !\u00a1 #\u00a1 @ $ %\u00a1 \u00a5 \u00a3 4 !\u00a1 P Q2 !\u00a1 \u00a9 ( 7\u00a3 \" !\u00a1 #\u00a5 \u00a1 ( \u00a9 \u00a3 & 2 ! ' %\u00a1 \u00a3 6 \u00a1 \u00a1 2 `\u00a3 \" !\u00a1 # 2 ! \u00a1 $ \u00a3 A \u00a2B \u00a4\" !\u00a1 0 ( ( \u00a86 & 2 !3 \u00a3 \u00a9 ' !( \u00a1 )$ !\u00a5 \u00a1 \u00a1 2 \u00a3 9 \u00a9 \u00a5 & ! \u00a4\" !& \u00a1 \u00a5 \u00a9 \u00a5 \" \u00a6 I & a \u00a1 )0 \u00a5 9 \u00a9 \u00a5 & ! \u00a4 \u00a5 $ ! ! b 4.1.2 Modifying the hierarchy c\" \u00a1 2 W\u00a9 I2 !\u00a1 6 S4 ! ! \u00a1 2 \u00a3 & )\u00a9 4 !4 !\u00a1 4 W\u00a3 #\u00a3 \" !\u00a1 \u00a7& 2 !4 !\u00a1 @ W' !\u00a9 \u00a1 5 TP Q\u00a5 \u00a3 & \u00a3 & )$ !\u00a5 \u00a1 $ !\u00a5 \u00a1 \u00a1 4 \u00a2' \u00a6 W\u00a9 I 4 ! !( \u00a1 \u00a1 @ \u00a3 \u00a5 \u00a9 \u00a3 & 2 !3 \u00a3 \" !\u00a1 \u00a3 0 \u00a5 \u00a1 d !\u00a1 2 \u00a3 H 2 \u00a3 \u00a1 2 \u00a3 )6 \u00a4\u00a5 4 ! \u00a7V 2 ! !2 %5 %\u00a9 4 e \u00a1 \u00a3 & 9 \u00a1 5 Q9 \u00a1 \u00a5 ' ! X \u00a9 2 !4 I\u00a3 \" !\u00a1 & \u00a5 2 \u00a3 \u00a1 @ \u00a3 A B \u00a4\" \u00a1 f D 1g c 4 ! !( \u00a1 )$ !\u00a9 \u00a5 \u00a1 \u00a7\u00a3 \" !\u00a1 \u00a7 2 \u00a3 \u00a1 @ \u00a3 V h i p h 6 \u00a4\u00a5 4 ! X )\u00a9 2 !4 F\u00a1 @ \u00a3 \u00a5 \u00a9 \u00a3 2 !\u00a1 6 S 2 ! \u00a1 $ \u00a3 A q Q\u00a5 )\u00a1 \u00a9 \" 2 ! \u00a1 $ \u00a3 5 Q\u00a9 C )D \u00a24 !\u00a1 \u00a5 & $ \u00a3 & 2 I& ' ! !& ( \u00a3 \u00a4\u00a9 2 !4 I& \u00a3 & \u00a4\u00a9 4 !4 !\u00a1 4 #\u00a3 \u00a7\u00a3 \" !\u00a1 H\u00a1 @ !& \u00a3 & 2 !3 \u00a7\" !& \u00a1 \u00a5 \u00a9 \u00a5 \" \u00a6 A r \u00a1 2 ! \u00a1 \u00a3 \u00a9 3 3 & 2 !3 7\u00a9 & 3 2 ! H6 \u00a5 4 ! \u00a7\u00a9 2 !4 `& 4 !& \u00a9 \u00a3 & \u00a7$ !\" !\u00a5 \u00a9 \u00a1 6 & \u00a3 \" W\u00a3 \" !\u00a1 & \u00a5 C )D c4 !\u00a1 \u00a5 & $ \u00a3 & 2 ! A Fg 8\u00a9 \u00a5 \u00a3 & \u00a9 ( \u00a1 \u00a9 2 \u00a3 & )4 !\u00a1 \u00a5 & $ \u00a3 & 2 ! \u00a4\u00a9 \u00a5 \u00a1 H ' !& 2 !\u00a1 4 I' \u00a6 I\u00a9 $ !$ !( \u00a6 !& 2 !3 \u00a7\u00a5 !( \u00a1 \u00a4\u00a1 2 ! 4 !& 2 !3 \u00a6 2 \u00a3 \u00a9 \u00a3 & U 2 !\u00a86 ( \u00a1 4 !3 \u00a1 A q Q\u00a5 \u00a1 @ \u00a9 $ !( \u00a1 5 Q& \u00a3 \u00a4& \u00a4$ % & ' !( \u00a1 )\u00a3 \u00a7 \u00a7' !& 2 !\u00a1 ) 2 ! \u00a1 $ \u00a3 !\u00a9 ( T4 !\u00a1 \u00a5 & $ \u00a3 & 2 ! 0 \u00a5 \u00a4\u00a9 2 ! !2 I\u00a9 2 !4 7& \u00a3 \u00a4 4 !& P Q\u00a1 \u00a5 A \u00a2\u00a1 \u00a4\u00a3 \u00a6\u00a5 \u00a7 \u00a9\u00a9 \u00a2 \u00a9 \u00a9 \u00a2 \u00a9 \u00a9 \u00a2 ! \"\u00a5 \u00a7 \u00a9# # $ % %& ' \u00a9( ) 0 \u00a9 $ %1 ) 2# % 3 \u00a9 \u00a94 \u00a2 5 6 \u00a97 % & \u00a28 8 9 @\u00a3 \u00a6\u00a5 \u00a7 \u00a9\u00a9 \u00a2 \u00a9 \u00a9 \u00a2 \u00a9 \u00a9 \u00a2 ! \"\u00a5 ' \u00a9A B \u00a9C D$ \u00a2 & \u00a9' ( \u00a9) \u00a90 \u00a9$ \u00a21 ) E\u00a5 %A F 2# \u00a93 4 % %5 6 7 % \u00a9 %& G8 \u00a98 8 H PI Q SR T VU XW %Q Y \u00a2%a R a U %b Evaluation H U XI %c \u00a9Q c hd Q c \u00a9s a Xc \u00a9 Q fU R I %Q Q d Xe a Q %e g y GT VQ %Q Q W R U XR Q b R SR I %Q fb g %b R Q qU \u00a9s c d \u00a9Q fe U \u00a9d p \u00a2U \u00a9d c w uH PI %Q e uf g DR U U s b %b Q W h U \u00a9d fa W %Q R a g %a % hR Q d Xb fc \u00a9%W id Q s c R a U %b f GQ R T VQ Q \u00ecR Q d Xb fT PQ d Q hQ c \u00a9s %c R Q W U \u00a9d fc b Q R VU j XU \u00a9W % %s Q ip %d U %a W %Q b c b Q R iU up s q qU ud a I \u00a9R c %%U R c R a U \u00a9%b y GQ e c %b Q ha R p %d U \u00a9p \u00a2U \u00a9b Q b c b Q R iU uc W I %U e d s Q b w H PI %Q d Q b %s R X Xa I \u00a9R i \u00a2Q ha Xp %d U \u00a9Q W ia ue U \u00a9 Xp %s Q id %s Q b i %b R i GQ hW %Q b e d a \u00a2Q W Gw ht \u00a9u q \"U PR I %Q d Q b %s R a % e U %e Q p R F.Baader, B.Hollunder A terminological Knowledge Representation systems with Complete Inference Algorithms \u00a1 \u00a2 \u00a4\u00a3 \u00a6\u00a5 \u00a7 \u00a6\u00a8\u00a9 \u00a3 \u00a6 \u00a3 \u00a5 \u00a3 \u00a8\u00a8! \" $# % & ' \u00a6\u00a5 ' ( ! ) \u00a6 10 1 \u00a3 2 3& 4 \" \u00a6 \u00a1 # %0 65 7 8 9",
    "abstract": "The paper presents a system for querying (in natural language) a set of text documents from a limited domain. The domain knowledge, represented in description logics (DL), is used for filtering the documents returned as answer and it is extended dynamically (when new concepts are identified in the texts), as result of DL inference mechanisms. The conceptual hierarchy is built semi-automatically from the texts. Concept instances are identified using shallow natural language parsing techniques.",
    "countries": [
        "Romania"
    ],
    "languages": [
        "French"
    ],
    "numcitedby": "3",
    "year": "2001",
    "month": "July",
    "title": "Ontologies for Information Retrieval"
}