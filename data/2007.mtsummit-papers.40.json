{
    "article": "In this paper, we compare the rulebased and datadriven approaches in the context of SpanishtoBasque Machine Translation. The rulebased system we consider has been developed specifically for SpanishtoBasque machine translation, and is tuned to this language pair. On the contrary, the datadriven system we use is generic, and has not been specifically designed to deal with Basque. SpanishtoBasque Machine Translation is a challenge for datadriven approaches for at least two reasons. First, there is lack of bilingual data on which a datadriven MT system can be trained. Second, Basque is a morphologicallyrich agglutinative language and translating to Basque requires a huge generation of morphological information, a difficult task for a generic system not specifically tuned to Basque. We present the results of a series of experiments, obtained on two different corpora, one being \"indomain\" and the other one \"outofdomain\" with respect to the datadriven system. We show that ngram based automatic evaluation and editdistance based human evaluation yield two different sets of results. According to BLEU, the datadriven system outperforms the rulebased system on the indomain data, while according to the human evaluation, the rulebased approach achieves higher scores for both corpora. Introduction Datadriven Machine Translation is nowadays the most prevalent approach carried out in Machine Translation (MT) research; translation results obtained with this approach have now reached a high level of accuracy, especially when the target language is English. Data driven MT systems base their knowledge on bilingually aligned corpora, and the accuracy of their output depends strongly on the quality and the size of these corpora. Consequently, when pointing out the success of data driven MT, we also need to make two additional remarks: (i) large and reliable bilingual corpora are unavailable for lots of languagepairs, (ii) translating into a morphologically rich target language makes the task of datadriven systems a lot more difficult. When translating into Basque, we are confronted with both problems at the same time. First, few bilingual corpora are available which include Basque, which obviously limits to some extent the application of data driven approaches. Second, Basque is a morphologically rich agglutinative language that is difficult to translate into, in particular because of the morphological information we need to generate. In this paper, we compare the rulebased and datadriven approaches in the context of SpanishtoBasque translation. The rulebased system we consider has been developed specifically for SpanishtoBasque MT, and is tuned to this language pair. On the contrary, the data driven system we use is generic, and has not been specifically designed to deal with either of these languages. The generation of the Basque morphemes poses a particular problem for a system untuned to this language. We present the results of a series of experiments, obtained on two different corpora, one being \"indomain\" and the other one \"outofdomain\" with respect to the datadriven system. We show that ngram based automatic evaluation and editdistance based human evaluation yield two different sets of results. According to BLEU, the data driven system outperforms the rulebased system on the indomain data, while according to the human evaluation, the rulebased approach achieves higher scores for both corpora. The remainder of this paper is organized as follows. In Section 2, we introduce Matxin, a rulebased MT system designed for SpanishtoBasque translation. In Section 3, we present MaTrEx, a datadriven MT system that we trained on a SpanishtoBasque bilingual corpus extracted from magazines. In Section 4, we describe how to work at the morpheme level for Basque. In Section 5, we evaluate the two approaches mentioned above, and report and discuss our experimental results. Section 6 concludes the paper and gives avenues for future work. Matxin: a RuleBased MT System In this section, we describe Matxin, the main rulebased MT system developed at the University of the Basque Country. Matxin is an open source RBMT engine, whose first goal is to translate from Spanish into Basque, using the traditional transfer model. The transfer component of the translation system is based on both shallow and dependency parsing. 1  Matxin is a classical transfer system consisting of three main components: (i) analysis of the source language into a dependency tree structure, (ii) transfer from the source language dependency tree to a target language dependency structure, and (iii) generation of the output translation from the target dependency structure. These three components are described in more detail in what follows. Analysis The analysis of the Spanish source sentences into dependency trees is performed using an adapted version of the FreeLing toolkit (Carreras et al., 2004) . 2 FreeLing contains a partofspeech tagger and a shallow parser (or chunker) for Spanish. In Freeling, tagging and shallow parsing are performed using the Machine Learning AdaBoost models (Freund & Schapire, 1997) . The shallow parses provided by Freeling are then augmented with dependency information, using a set of rules that identify the dependencies in the sentence. First, the relationships between chunks is established, based on their labels. As an example, consider the chunked Spanish sentence in (1): (1) [np] Un triple atentado ||| [verbchain] sacude ||| [np] Bagdad (a three-pronged attack rocked Baghdad) Here the dependency parser identifies the verbchain as the head of the sentence, and the two noun phrases as its children. Then, the dependencies are labelled using a second set of rules. In the previous example \"Un triple atentado\" and \"Bagdad\" are recognised to be the subject and the object respectively of the main verb \"sacude\". The analysis of this sentence is displayed in (2): (2) sacude subj. obj. Un triple atentado Bagdad Transfer The transfer component consists of lexical transfer and structural transfer. Lexical transfer is performed using a SpanishtoBasque dictionary compiled into a finitestate transducer. This dictionary is based on the widecoverage dictionary Elhuyar. corpora. This extraction was performed using the Consumer and EITB corpora (see Section 5 for a detailed description of these corpora). Moreover, some Spanish words (such as articles, conjunctions, etc.) do not translate into Basque words, and are translated as morphemes that will be concatenated to other words. Note that in the actual version of the engine no word sense disambiguation is performed (we plan to solve semantic ambiguities within a concrete domain in the near future), but a large number of multiword units representing collocations, named entities and complex terms are included in the bilingual dictionary in order to reduce the influence of this limitation. In the case of prepositions, we adopt another strategy: we decide on the proper translation using some information about verb argument structure extracted automatically from the corpus. Structural transfer is applied to turn the source dependency tree structure into the target dependency structure. This transformation follows a set of rules that will copy, remove, add, or reorder the nodes in the tree. In addition, specialized modules are included to translate verb chains (Alegria et al., 2005) . Generation Generation, like transfer, is decomposed into two steps. The first step, referred to as syntactic generation, consists of deciding in which order to generate the target constituents within the sentence, and the order of the words within the constituents. The second step, referred to as morphological generation, consists of generating the target surface forms from the lemmas and their associated morphological information. In order to determine the order of the constituents in the sentence, a set of rules is defined that state the relative order between a node in the dependency tree and its ancestors. For example, a prepositional phrase is generated before its ancestors if the latter is a noun phrase. The order of the words within the chunks is solely based on the PartofSpeech information associated with the words. In Basque, the declension case, number case and other features are assigned to a whole NP as a suffix of the last word of the phrase. Consequently, when generating Basque, the main inflection of a noun phrase is added to its last word. In the case of a verb chain phrase, morphological generation needs to be applied to every word in the phrase. In order to perform morphological generation, we use the morphological generator for Basque described in (Alegria et al., 1996) . This generator makes use of the morphological dictionary developed in Apertium, which establishes correspondences between surface forms and lexical forms for Basque. It is used in morphological generation to produce the inflected forms of Basque words. In particular, this dictionary contains: \u2022 A definition of Basque paradigms (sets of correspondences between partial surface forms and partial lexical forms). Those paradigms are similar to continuation classes in twolevel morphology (Koskeniemmi, 1983 ). \u2022 Lists of surface form to lexical form correspondences for complex lexical units (including multiword units). This dictionary is compiled into a finitestate transducer which is used to perform the morphological generation of Basque words. A more detailed description of this process can be found in (ArmentanoOller et al., 2005) . 3 MaTrEx: a DataDriven System The MaTrEx system (Stroppa & Way, 2006) used in our experiments is a modular datadriven MT engine, which consists of a number of extendible and reimplementable modules, the most important of which are: \u2022 Word Alignment Module: takes as its input an aligned corpus and outputs a set of word alignments. \u2022 Chunking Module: takes in an aligned corpus and produces source and target chunks. \u2022 Chunk Alignment Module: takes the source and target chunks and aligns them on a sentenceby sentence level. \u2022 Decoder: searches for a translation using the original aligned corpus and derived chunk and word alignments. The Word Alignment and the Decoder modules are wrappers around existing tools, namely Giza++ (Och & Ney, 2003) , and Moses (Koehn et al., 2007) . The chunking and alignment strategies are described in more detail below. The translation process can be decomposed as follows: the aligned sourcetarget sentences are passed in turn to the word alignment, chunking and chunk alignment modules, in order to create our chunk and lexical example databases. These databases are then given to the decoder to translate new sentences. These steps are displayed in Figure 1 . Chunking In the case of Spanish, the extraction of chunks relies on the shallow parser described above (as part of Freeling). This shallow parser enables us to identify the main constituents in the sentence: noun phrases, verb phrases, prepositional phrases, etc. In Note that, since each module of the system can be changed independently of the others, it is possible to use a variety of chunkers, including those of the Markerbased approach, used in other works (Gough & Way, 2004; Stroppa et al., 2006; Stroppa & Way, 2006) . Word alignment Word alignment is performed using the Giza++ statistical word alignment toolkit and we followed the \"refined\" method of (Koehn et al., 2003) to extract a set of highquality word alignments from the original uni directional alignment sets. These along with the extracted chunk alignments were passed to the translation decoder. Chunk alignment In order to align the chunks obtained by the chunking procedures introduced in Section \"Chunking\", we make use of an \"editdistance style\" dynamic programming alignment algorithm, as described in (Stroppa et al., 2006) . This algorithm works as follows. First, a \"similarity\" measure is determined for each pair of sourcetarget chunks. Then, given these similarities, we use a modified version of the editdistance alignment algorithm to find the optimal alignment between the source and the target chunks. The modification consists of allowing for jumps in the alignment process (Leusch et al., 2006) , which is a desirable property for translating between languages showing significant syntactic differences. This is the case for Spanish and Basque, where the order of the constituents in a sentence can be very different. To compute the \"similarity\" between pair of chunks, we rely on the information contained within the chunks. More precisely, we relate chunks by using the wordto word probabilities that were extracted from the word alignment module. The relationship between a source chunk and a target chunk is computed thanks to a model similar to IBM model 1 (Stroppa et al., 2006) . Integrating SMT data Since its inception, EBMT has recommended the use of both lexical and phrasal information (Nagao, 1984) ; current SMT models now also use phrases in their translation models (Koehn et al., 2003) . Actually, it is possible to combine elements from EBMT and SMT to create hybrid datadriven systems capable of outperforming the baseline systems from which they are derived, as shown in (Groves and Way, 2005) . Therefore, we also make use of SMT phrasal alignments, which are added to the aligned chunks extracted by the chunk alignment module. The SMT phrasal alignment follows the procedure of (Koehn et al., 2003) . Decoder The decoding module is capable of retrieving already translated sentences and also provides a wrapper around Moses, a phrasebased decoder. This decoder also implements MinimumErrorRate Training (Och, 2003) within a loglinear framework (Och & Ney, 2002) . The BLEU metric (Papineni et al., 2002) is optimized on a development set. We use a loglinear combination of several common feature functions: phrase translation probabilities (in both directions), wordbased translation probabilities (lexicon model, in both directions), a phrase length penalty and a target language model. The decoder also relies on a target language model. The Basque language model is a simple 3gram language model trained on the Basque portion of the training data, using the SRI Language Modeling Toolkit, 4 with modified KneserNey smoothing. MorphemeBased Machine Translation Basque is an agglutinative language in which words may be made up of a large number of morphemes. For example, suffixes can be added to the last word of a noun phrase; these suffixes can represent some morpho syntactic information associated to the noun phrase, such as number, definiteness, grammatical cases and postpositions. As a consequence, most words only occur once in the training data, leading to serious sparseness problems when extracting statistics from the data. In order to limit this problem, one solution is to working at a different representation level, namely morphemes (cf. (Stroppa et al., 2006) ). By segmenting each word into a sequence of morphemes, we reduce the number of tokens that occur only once (cf. (Agirre et al., 2006) ). Furthermore, as many Basque words correspond to several Spanish words (for example, the Basque \"etxeko\" translates to \"de la casa\" in Spanish), lots of 1 ton alignments have to be defined when working at the word level. Although 1ton alignments are allowed in IBM model 4, training can be harmed when the parallel corpus contains many such cases. Working at the morpheme level within MaTrEx is straightforward: we only need to segment the Basque side of the training (and development) data. The MaTrEx system trained on these new data will generate a sequence of morphemes as output. In the experiments we carried out, we report results obtained when working at both the word and morpheme levels. From Words to Morphemes Working at the morpheme level does, however, have some drawbacks. In particular, if we want to be able to generate surface word forms from morphemes, then we need to include some additional information to the morphemes. In (Agirre et al., 2006) , a segmentation strategy is proposed, which does not include this information. In this paper, we build upon this strategy, but we also include the required information to recover the surface words from the morphemes. To From Morphemes to Words When working at the morpheme level, the translation of a (source) sentence obtained using MaTrEx is a sequence of morphemes. If we want to produce a Basque text, then we need to recover the words from this sequence of morphemes; the output of MaTrEx is thus postprocessed to produce the final Basque translation. This postprocessing consists of using the morphological generation module of Matxin. This module uses the same lexicon and two level rules as Eustagger. However, in the context of generation, we are faced with two new additional problems: \u2022 Unknown lemmas: some lemmas do not occur in the Eustagger lexicon, such as unknown proper names. To solve this problem, the synthesis component has been enriched to generate words from unknown lemmas using default rules defined for each part of speech. \u2022 Invalid sequences of tags: the output of MaTrEx (a sequence of morphemes) is not necessarily a wellformed sequence from a morphological point of view. For example, the correct tags might be generated, but in the wrong order. In some cases, a nominal tag is assigned to verb; sometimes, required tags are missing. In the current work, we do not try to correct these mistakes: we simply output the lemma, and remove the inappropriate tag information. A more refined treatment is left to future work. Experimental Results Data and Evaluation The experiments were carried out using two different test sets. The first, referred to as ConsumerTest, contains 1500 bilingually aligned sentences extracted from the Consumer Eroski Parallel Corpus. 5 The Consumer Eroski Parallel Corpus is a collection of 1036 articles written in Spanish (January 1998 to May 2005, Consumer Eroski magazine, http://revista.consumer.es) along with their Basque, Catalan, and Galician translations. It contains more than one million Spanish words for Spanish and more than 800,000 Basque words. This corpus is aligned at the sentence level. The second, referred to as EitbTest, also contains 1500 bilingually aligned sentences extracted from the EITB corpus. This corpus is a collection of news (Basque News and Information Channel, http://www.eitb24.com/en), available in Spanish, Basque, and English. 6 This corpus contains approximately 1,500,000 Spanish words and 1,200,000 Basque words. While Eitb is a general news corpus (politics, economy, sport, etc.), Consumer is a corpus of articles comparing the quality and prices of commercial products and brands. They are consequently from two different terminological \"domains\". Table 1 summarizes the various statistics related to these corpora. Since the Matxin system is rulebased, it does not need any kind of training, and can be directly applied to translate into Basque the Spanish test sentences. However, Matxin's bilingual lexicon was enriched with 1129 entries (entities and multiword terms) that were automatically extracted form the ConsumerTrain bilingual corpora. In order to train the MaTrEx system, which is data driven and relies on bilingually aligned training material, we used approximately 50,000 aligned sentences from the ConsumerTrain dataset, which was extracted in a similar manner to the Consumer dataset. In order to tune the parameters of the MaTrEx system, we use an additional development set of 1292 sentence pairs (referred to as ConsumerDev). Training MaTrEx on ConsumerTrain makes the ConsumerTest dataset \"in domain\", and the Eitb dataset \"outofdomain\". We thus expect the MaTrEx system to perform better on the ConsumerTest set than on the EitbTest set. In order to assess the quality of the translation obtained using both systems, we used automatic evaluation metrics as well as human evaluation. As for automatic evaluation, we report the following accuracy measures: BLEU (Papineni et al., 2002) , and NIST (Doddington, 2002) . For each testset, we have access to one Basque reference translation per sentence. Evaluation is performed in a caseinsensitive manner. Because of the specific nature of Basque, we perform two types of evaluation: a wordbased evaluation, and a morpheme based evaluation. Since human evaluation is an expensive process, we selected 50 sentences from the ConsumerTest corpus to be human evaluated; this corpus is referred to as ConsumerTestHuman. The same applies to EitbTest, yielding EitbTestHuman. We used the editdistance metric (Przybocki et al., 2006) called HTER or Translation Error Rate with humantargeted references (Snover et al., 2006) . Edit distance is defined as the number of modifications a native Basque professional translator has to make so that the resulting edited translation is an easily understandable Basque sentence that contains the complete meaning of the source sentence. We used the software described in (Snover et al., 2006) to compute HTER. The postediting work took 6 hours in total. Automatic Evaluation Results For the ConsumerTest corpus, the results obtained with the MaTrEx system are higher than those obtained with the Matxin system. With respect to the BLEU score, this difference is 1.58 points absolute for the word based evaluation (27% relative increase), and 2.47 points absolute for the morphemebased evaluation (21% relative increase). These differences are statistically significant, with a pvalue < 0.002, computed using approximate randomisation (Riezler & Maxwell, 2005) . For the EitbTest corpus, the results obtained with the MaTrEx system are much lower than those obtained with the Matxin system. The differences are also statistically significant, with a pvalue < 0.002, for both BLEU and NIST scores. This is consistent with our intuition since with respect to MaTrEx, the EitbTest corpus is \"outofdomain\" (cf. (Koehn & Monz, 2006) for a comparison between indomain and outofdomain results of datadriven systems). These results show that a (generic) datadriven system can be very competitive with a (specialized) rulebased system, if suitable training data is available. The argument in favour of rulebased systems is stronger when no relevant bilingual training data are available. Given the globally low scores obtained, it is important to make two additional remarks. First, it shows the difficulty of the task of translating to Basque, which is due to the strong syntactic differences with Spanish, and the morphological properties of this language. Second, even if a morphemebased translation is more appropriate than a wordbased translation, ngram based metrics are not suited to the comparison between sequences of morphemes. In particular, the absence of morphological tags that may not affect the global understanding of a sentence are penalised: if such a tag is missing in the system's output, all the ngrams that could have contained it would be cut. Table 2 : Automatic evaluation results. The results obtained for the SpanishtoBasque translation task using the ConsumerTest and EitbTest datasets are summarized in Table 2 , in which WB and MB denote respectively the wordbased evaluation and the morphemebased evaluation. For the morpheme based evaluation, we segment the reference sentences into morphemes with which we compare the output of each system (which is also a sequence of morphemes). Human Evaluation Results The human evaluation results, obtained using HTER, are reported in These results are consistent with the domain independence of the rulebased system, which achieves a comparable translation quality for the two corpora. The datadriven approach is domaindependent by construction and, as expected, it performs better on the indomain corpus. According to the subjective evaluation, the translation quality of Matxin is better, irrespective of the corpus. However, it must be stressed that Matxin has been specifically developed and designed to translate from Spanish to Basque over a number of years, while MaTrEx is generic and the cost of adapting it to SpanishBasque translation is several orders of magnitude lower. Conclusions and Future Work In this paper, we have compared a rulebased MT system (Matxin) and a datadriven MT system (MaTrEx) in the context of SpanishtoBasque translation. While the rulebased system we consider has been developed specifically for SpanishtoBasque machine translation, the datadriven system we use is generic, and has not been specifically tuned to Basque. We have introduced a translation scheme based on morphemes instead of words, in order to be able to deal with the particular agglutinative nature of Basque. This allows for the generation of the morphological information required to recover the full Basque surface word forms. We have presented experimental results comparing the two types of approaches on two different corpora containing magazine and news articles respectively. Objective evaluation metrics such as BLEU and NIST yield different results to subjective evaluation metrics such as HTER. The automatic metrics indicate that the datadriven system outperforms the rulebased system on the indomain data. On the contrary, the subjective evaluation indicates that the rulebased system outperforms the datadriven approach for both corpora. Note that these results are also consistent with the findings of (CallisonBurch et al., 2006) concerning objective and subjective evaluation. Moreover, both types of evaluation confirm that Matxin, the rulebased system, is domainindependent while MaTrEx, the datadriven system, is more domain dependent. Accordingly, if a different domain were selected which was quite different from the magazine or news articles used here (weather forecasts, say), then we would expect MaTrEx to win out. That said, having invested a large number of personyears in its development, it is encouraging to see the good performance of Matxin on outofdomain data. Future work consists of building upon the respective strength of both approaches, by exploring various hybridity strategies focused on the problem of Basque translation. One avenue that we would expect to bear fruit is adding into MaTrEx the bilingual lexicon from Matxin. We also plan to use automatic evaluation metrics that would be more suited to the evaluation of morphemebased translation (cf. (Owczarzak et al., 2006) ). Acknowledgments This work is partially supported by Science Foundation Ireland (grant number OS/IN/1732), Spanish M.E.C. (OpenMT project, TIN200615307C0301), and the Basque Government (AnHitz project, eIE06185). Our colleagues I\u00f1aki Alegria, Arantza D\u00edaz de Ilarraza, Mikel Lersundi, and Aingeru Mayor are kindly acknowledged for providing their expertise on the Matxin system and the evaluation of the output.",
    "abstract": "In this paper, we compare the rulebased and datadriven approaches in the context of SpanishtoBasque Machine Translation. The rulebased system we consider has been developed specifically for SpanishtoBasque machine translation, and is tuned to this language pair. On the contrary, the datadriven system we use is generic, and has not been specifically designed to deal with Basque. SpanishtoBasque Machine Translation is a challenge for datadriven approaches for at least two reasons. First, there is lack of bilingual data on which a datadriven MT system can be trained. Second, Basque is a morphologicallyrich agglutinative language and translating to Basque requires a huge generation of morphological information, a difficult task for a generic system not specifically tuned to Basque. We present the results of a series of experiments, obtained on two different corpora, one being \"indomain\" and the other one \"outofdomain\" with respect to the datadriven system. We show that ngram based automatic evaluation and editdistance based human evaluation yield two different sets of results. According to BLEU, the datadriven system outperforms the rulebased system on the indomain data, while according to the human evaluation, the rulebased approach achieves higher scores for both corpora.",
    "countries": [
        "Spain",
        "Ireland"
    ],
    "languages": [
        "Spanish",
        "Basque"
    ],
    "numcitedby": "38",
    "year": "2007",
    "month": "September 10-14",
    "title": "Comparing rule-based and data-driven approaches to {S}panish-to-{B}asque machine translation"
}