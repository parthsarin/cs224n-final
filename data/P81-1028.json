{
    "article": "Central to this approach is the idea that the processing of an utterance involves producing an expression or structure that is in some sense a representation of the literal meaning of the utterance. It is often maintained that understanding what an utterance literally means consists in being able to recover this representation. In philosophy and linguistics this sort of representation is usually said to display the~ form of an utterance, so we will refer (somewhat loosely-~--to the representations themselves as \"logical forms,\" This paper surveys what we at SRI view as some of the key problems encountered in defining a system of representation for the logical forms of English sentences, and suggests possible approaches to their solution. We will first look at some general issues related to the notion of logical form, and then discuss a number of problems associated with the way information involving certain key concepts is expressed in English. Although our main concern here is with theoretical issues rather than with system performance, this paper is not merely speculative. The DIALOGIC system currently under development in the SKI Artificial Intelligence Center parses English sentences and translates them into logical forms embodying many of the ideas presented here. II THE NATURE OF LOGICAL FORM pieces of the logical form of the utterance that constitute referring expressions. Having logical forms be semantically compositional is the ultimate expression of this kind of decomposability, as it renders ev,ery well-formed subexpression a locus of meanlng--and therefore a potential locus of meanlng-dependent processing. This is probably a more telling argument for semantic composltlonality in designing languageprocessing systems than in analyzing human language, but it can be reasonably argued that such design principles must be followed by any system, whether natural or artificial, that has to adapt to a complex environment (see [Simon, 1969] , especially Chapter 4). I Logical form, therefore, is proposed as a level of representation distinct from surface-syntactlc form, because there is apparently no direct way to semantically interpret natural language sentences in a compositional fashion. Some linguists and philosophers have challenged this assumption [Montague, 1974a] [Barwlse and Cooper, 1981] , but the complexity of their proposed systems and the limited range of syntactic forms they consider leave serlous doubt that the logical-form level can be completely bypassed. 2 Beyond being co~positiouel, it is desirable--though perhaps not essential--that the meaning of a logical form also be independent of the context in which the associated utterance occurs. (The meaning of an expression in natural language, of course, is often context-dependent.) A language-processing system must eventually produce a context-independent representation of what the speaker means by an utterance because the content of the utterance will normally be subjected to further processln E after the original context has been lost. In the many cases in which the speaker's intended meaning is simply the literal meaning, a contextindependent logical form would give us the representation we need. There is little doubt that some representation of this sort is required. For example, much of our general knowledge of the world is derived from simple assertions of fact in natural language, but our situation would be hopeless if, for every fact we knew, we had to remember the context in which it was obtained before we could use it appropriately. Imagine trying to decide what to do with a tax refund by having to recall whether the topic of conversation was rivers or financial institutions the first time one heard that banks were good places in which to keep money. The first question to ask is, why even have a level of logical form? After all, sentences of natural languages are themselves conveyers of meaning; that is what natural languages are for. The reason for having logical foznns is to present the literal meanings of sentences more perspicuously than do the sentences themselves. It is sometimes said that natural-language sentences do not '~ear their meanings on their sleeves\"; logical forms are intended to do exactly that. From this perspective, the main desideratum for a system of logical form is that its semantics be compositional. That is, the meaning of a complex expression should depend only on the meaning of its subexpresslons. This is needed for meanlnE-dependent cou~utational processes to cope with logical forms of arbitrary complexity. If there is to be any hope of maintaining an intellectual grasp of what these processes are doing, they must be decomposable into smaller and smaller meanlng-dependent subprocesses operating on smaller and smaller meaningful pieces of a logical form. For instance, if identifying the entities referred to by an utterance is a subprocess of inferring the speaker's intentions, there must be identifiable As this example suggests, context independence is closely related to the resolution of ambiguity. For any given ambiguity, it is possible to find a case in which the information needed tO resolve it is derived from the context of an utterance. Therefore, if the meanlnEs of logical forms are to be context-lndependent, the system of logical forms must provide distinct, unambiguous representations for all possible readings of an ambiguous utterance. The question remains whether logical form should also provide ambiguous representations to handle cases in which the dlsamblguatlng information is obtained later or is simply general world knowledge. The pros and cons of such an approach are far from clear, so we will generally assume only unembIEuous logical forms. Although it is sometimes assumed that a contextindependent representation of the literal meaning of a sentence can be derived by using syntactic and semantic knowledge only, some pragmatic factors must also be taken into account. To take a concrete example, suppose the request \"Please llst the Nobel Prize winners in physics,\" is followed by the question '~dho are the Americans?\" The phrase \"the Americans\" in the second utterance should almost certainly be interpreted as referring to American winners of the Nobel Prize in physics, rather than all inhabitants or citizens of the United States, as It might be understood in isolation. If the logical form of the utterance is to reflect the intended interpretation, processes that are normally assigned to praSmatlcs must be used to derive it. One could attempt to avoid thls consequence by representing \"the Americans\" at the level of logical form as literally meaning all Americans, and have later pragmatic processing restrict the interpretation co American winners of the Nobel Prize in physics. There are other cases, however, for which thls sort of move is not available. Consider more carefully the adjective \"American.\" American people could be either inhabitants or citizens of the United States; American cars could be either manufactured or driven in the United States; American food could be food produced or consumed in or prepared in a style indigenous Co the United States. In short, the meaning of \"American\" seems to be no more than \"bearing some contextually determined relation to the United States.\" Thus, there is n~o deflnlte contextindependent mesnlng for sentences containing modifiers llke \"American.\" The same is true for many uses of \"have,\" \"of,\" possessives, locative prepositions [Herskovits, 1980] and compound nominals. The only way to hold fast to the position that the construction of loglcal-form precedes all pragmatic processing seems to be to put in \"dummy'* symbols for the unknown relations: This m@y in fact be very useful in building an actual system, ~ but It is hard to imagine that such a level of representation would bear much theoretical weight. The problem confronting the hearer is to answer the question, 'Why would the speaker say that in this situation?\" Practically any relevant knowledge chat the speaker and hearer mutually possess [Clark and Marshall, 1981] [Cohen and Perrault, 1981] is to recover the literal content of the utterance, i.e., that the speaker is getting cold, and to infer from this chat the speaker would llke him co do something about It. We In summary, the notion of logical form we wish to capture is essentially that of a representation of the \"literal meaning in context\" of an utterance. To facilitate further processing, it is virtually essential that the meaning of Ioglcal-form expressions be compositional and, at the same time, it is highly desirable that they be conCext-lndependenc. The latter condition requires that a system of logical form furnish distinct representations for the dlfferenc readings of ambiguous natural-language expressions. The only place in which our logical language differs sigulflcancly from more familiar syscezs is In the treatment of quantiflers. Normally the English determiners \"every\" and \"some\" are translated as logical quantlfiers that bind a single variable in an arbitrary formula. This requires using an appropriate logical connective co combine the contents of the noun phrase governed by the determiner with the contents of the rest of the sentence. Thus '~very P is q\" becomes (EVERY X (IMPLIES (P X) (q X))), and \"Some P is Q'* becomes (SOME X (AND (e X) (q X))) It seems somewhat inelegant to have to use different connectives to Join (P X) and (~ X) in the two cases, but semantically it works. In an extremely interesting paper, Barwise and Cooper [1981] point out (and, in fact, prove) that there are :any determiners in English for which this approach does not work. The transformations employed in standard logic co handle \"every\" and \"some\" depend on the fact that any statement about every P or some P is logically equivalent to a statement about everything or something; for example, \"Some P is Q\" is equivalent to \"Something is P and Q.\" What Barwlse and Cooper show is that there is no such transformation for determiners like \"msst\" or \"more than half.\" That iS, statements about most P's or more than half the P's cannot be rephrased as statements about most things or more than half of all things. (HOST X (F X) (q X)). Following thls convention gives us a uniform treatment for determined noun phrases: \"Most men are mortal\" \"Some man is mortal\" \"Every man Is mortal\" \"The man iS mortal\" \"Three men are mortal\" Note that we treat (MOST X (4 X) (MORTAL X)) (SOME X (MAN X) (MORTAL X)) (EVERY X (MAN X) (MORTAL X)) (THE X (MAN X) (MORTAL X)) (3 x (HA. X) (MORTJU. X)) \"the\" as a quantifier, on a par wlth \"some\" and \"every.\" \"The\" is often treated formally as an operator chat produces a complex singular term, but thls has the disadvantage of not indicating clearly the scope of the expression. A final point about our basic framework Is that most common nouns will be interpreted as relations rather than functions in logical form. That is, even If we know that a person has only one height, we will represent \"John's height is 6 feet\" as (HEIGE'\u00a3 JOHN (FEET 6)) rather than (EQ (HEIGHT JOHN) (FEET 6)) 5 (soME E (EVENT E) (GO E JOHN mY)) Davidson's arguments for this analysis are that (1) many adverbial modifiers such as \"quickly\" are best regarded as predicates of the events and that 42) it is possible co refer to the event explicitly in subsequent discourse. (\"John is going co New York. Th...~e trip will take four hours.\") The problem wlth Davidson's proposal is that for sentences in which these phenomena do not arise, the representation becomes unnecessarily complex. We therefore suggest introducing an event abstraction operator, EVABS, chat will allow us to introduce event variables when we need them: (P Xl ... X.) <-> (SOME E (EVENT E) ((gVABS F) E xl ... xn)) In simple cases we can use the more straightforward form. The logical form of \"John is kissing Mary\" would simply be (KISS JOHN MARY). The logical form of \"John is gently kissing Mary,\" however, would be (SOME Z (EVENT E) (AND ((EWSS KZSS) Z JoHN ~Y) (GENTLE E)))) If we let EVABS apply to complex predicates (represented by LAMBDA expressions), we can handle other problems as well. Consider the sentence \"Being a parent caused John's nervous breakdown.\" \"Parent\" Is a relational noun; thus, if John is a parent, he must he the parent of someone, but if John has several children we don't want to he forced into asserting chat beinS the parent of any particular one of them caused the breakdown. If we had PARENTI as the monadic properry of bein S a parent, however, we could say (SOME E (EVENT E) (Am) ((EVABS PARENTL) E JOHN) (CAUSE E \"John's nervous breakdown\"))) We don't need tO introduce PARENTI explicitly, however, if we simply substitute for It the expression, (LAMBDA X (SOME Y (PERSON Y) (PARENT X Y))), which would give us (SOME E (EVENT E) (AND ((EVANS (LAMBDA X (SOME Y (PERSON Y) (PARZNT x z)))) Z JOHN) (CAUSE E \"John's nervous breakdown\"))) Another important question is whether actions---chat is, events wlth agents--should be treated differently from events without agents and, if so, should the agent be specially indicated? The point is that, if John kissed Mary, that \u00a3s somethln S he did, but not necessarily something sh....~e did. Zt is not clear whether this distinction should be represented at the level of logical form or is rather an inference based on world knowledge.. Finally, most AS work on actions and events assumes that they can be decomposed into discrete steps, and that their effects can be defined in terms of S final state. Neither of these assumptions is appropriate for continuous processes; e.g., \"The flow of water continued to flood the basement.\" What the logical form for such statements should look like seems co be a completely open question. 6 VI TIME AND SPACE We believe that information about time is best represented primarily by sencential operators, so that the logical form of a sentence like \"John is in New York at 2:00\" would be somethln S likm (AT 2:00 (LOt JOHN NY)). There are two main reasons for following chls approach. First, current time can be indicated simply by the lack of any operator; e,g. , \"John owns Fido\" becomes simply (OWNS JOHN FIDO)o This is especially advantageous in baslcsily static dowalns in which tlme plays a minimal role, so we do not have to put someChln S into the logical form of a sentence chat will be systemetically ignored by lower-level processing. The other advantage of this approach is that temporal operators can apply Co a whole sentence, rather than Just to a verb. For instance, in the preferred reading of \"The President ha8 lived in the White House since 1800,\" the referent of \"the President\" changes with the time contexts involved in evaluatin S the truth of the sentence. The other reading can be obtained by allowing the quanclfier \"the\" in \"the President\" to assume a wider scope than that of the temporal operator. What temporal operators will be needed? We will use the operator AT to assert that a certain condition holds at a certain time. PAST and FUTURE will be predicates on points in time. Sinq~le past tense statements with sCaCive verbs, such a8 \"John was in New York,\" could mean either that John was in New York at some unspecified time In the past or at a coutexcua/ly specific time in the past: (SOME T (PAST T) (AT T (LOt JOHN NY))) (TME T (PAST T) (AT T (LOC JOHN NY))) (For the second expression to be an \"official\" lo~tcalform representation, the incomplete definite reference would have to be resolved.) Simple future-tense statements with sCaCive verbs are parallel, with PUTI~ replacing PAST. Explicit temporal modifiers are generally treated as additional restrictions on the time referred to. \"John was in New York on Tuesday\" aright be (on at least one interpretation): (SOME T (AND (PAST T) (DURING T TUESDAY)) (AT ~ (C0C JoHN ~)))) For action verbs we get representations of tkts 8oft for past and future progressive tenses; e.g., \"John was kissing Mary\" becomes (THE T (PAST T) (AT T (KISS JOHN ~.lY))) When we use event abstraction to introduce individual events, the interactions with time become somewhat tricky. Since (KISS JOHN MAEY) means \"John is (presently) klns\u00a3ns Mary,\" so must (SOME E (EVENT E) ((EVABS KZSS) E JOHN MAEY)) Since logically this formal expression means something llke \"There is (presently) an event which is a kissing of Mary by John,\" we will interpret the prnd\u00a3caCe EVENT as being true at s particular time of the events in progress at that time. To tie all this together, \"John was kissing Mary gently '' would be represmnced by (THE T (PAST T) (AT T (soME E (EVY~T E) (AND ((EVABS KISS) ~. JoHN MAltY) (GENTLE E))))) Tha and Urquhart, 1971 ] [McCawley, 1981] , but almost all of thls work see s: to be concerned wlth evaluating the truth of sentences at points, which, as we have seen, cannot be immediately extended to handle sentences about intervals. We include space under the same heading as tlme because a major question about space Is the extent to which Its treatment should parallel that of time. From an objective standpoint, it is often convenient to view physical space and time together as a four-dlmenslonal Euclidean space. Furthermore, there are naturallanguage constructions that seem best interpreted as asserting that a certain condition holds in a particular place (\"In California it is legal to make a right turn on a red light\"), Just as time expressions often assert that a condition holds at a particular time. The question is how far this analogy between space and time can be pushed. VlI COLLECTIVE ENTITIES AND SUBSTANCES Most representation schemes are designed to express information about such discrete, well-individuated objects as people, chairs, or books. Not all objects are so distinct, however; collections and substances seem to pose special difficulties, Collections are often indicated by conjoined noun phrases. If we say \"Newell and Simon wrote Human Problem Solving,\" we do not mean that they each did it individually (cf. \"Newell and Simon have PhDs.\"), rather we mean that they did it as a unit. Furthermore, if we want the treatment of this sentence to be parallel to chat of \"~ulne wrote Word and Object,\" we need an explicit representation of the unit \"Newell and Simon,\" so that It can play the same role the individual \"~ulne\" plays in the latter sentence. These considerations create difficulties in sentence interpretation because of the possibility of ambiguities between collective and distributed readings. Thus, \"Newell and Simon have written many papers,\" might mean that individually each has written many papers or that they have jointly coauthored many papers. The problems associated with conjoined noun phrases also arise with plural noun phrases and singular noun phrases that are inherently collective. \"John, Bill, Joe, and Sam,\" \"the Jones boys,\" and \"the Jones String Quartet\" may all refer to the same collective entity, so that an adequate logical-form representation needs to treat them as much alike as possible. These iss,--S are treated in detail by Webber [1978] . The problem is that in context this may refer to some particular set of American ships; hence, we need to recognize it as a definite reference that has to be resolved. Following Weber [1978] , We will use the notation (SET X P) to express a predicate on sets that is satisfied by any set, all of whose members satisfy (LAMBDA X P). Then \"the P's\" would be the contextually determined set, all of whose members are P's: (THE S ((SET X (P X)) S) ...) It might seem that, to properly capture the meaning of plurals, we would have to limit the extension of (SET X P) to sets of two or more elements. This is not always appropriate, however. Although \"There are ships in the Med,\" might seex to mean \"The set of ships in the Med has at least two members,\" the question \"Are there any ships in the Med?\" does not mean \"Does the set of ships in the Mad have at least two members?\" The answer to the former question is yes, even if there is only one ship in the Mediterranean. This suggests Chat any presupposition the plural carries to the effect that more than one object is involved may be a matter of Gricean lmplicature (\"If he knew there was only one, why didn't he say so?\") rather than semantics. Similarly, the plural marking on verbs seams to be Just a syntactic reflex, rather than any sort of plural operator. On the latter approach we would have to take \"Who killed Cock Robin?\" as amblBuous between a singular and plural reading, since sinBular and plural verb forms would be semantically distinct. To illustrate the use of our notation, we will represent \"Every one of the men who defeated Hannibal (EEAVE x) ))) Note Chat we can replace the plural noun phrase \"the men who defeated Hannibal\" by the singular collective noun phrase, \"the Roman army,\" as in \"Everyone in the Romeo army was brave\": (SOME T (PAST T) (AT T (EVERY X (THE S (AND (ARMY S) (ROMAN S)) ( [Hayes, 1978] Is a notable exception.) (Mz~ x s)) (BRAVE X)))) In a sentence like \"All Eastern coal contains soma sulfur,\" it see,.\" tb\u2022[ \"coal\" and \"sulfur\" refer to properties of samples or pieces of \"stuff.\" We might paraphrase thls sentence as \"All pieces of stuff that are Eastern coal contain soue stuff that Is sulfur.\" If we take this approach, then, In interpreting a sentence like \"The Universe Ireland Is carrying |00,000 barrels of Saudi light crude,\" we need co indicate that the \"piece of stuff\" being described is the maximal \"piece\" of Saudl light crude the shlp is carrying. In other cases, substances seem to be more llke abstract individuals, e.g., \"Copper is the twentyninth element in the periodic (WHAT X (AND (SHIP X) ~.MERICAN X)) (LOC x ~zD)) WHAT is conveniently mnemonic, since we can represent \"who\" as (WHAT X (PERSON X) .... ), \"when\" as (WHAT X (TZHZ X) .... ), and so forth. \"How many\" questions will be treated a\u2022 questioning the quantifier. '~lov many men \u2022re mortal?\" would be represented a \u2022 (WHAT N (Nb~mZR N) (N X (MAN X) (MOZTAL X))) Yes/no questions can be handled (\"Go to every room in the house\"), and negation (\"Don't go\"). A third approach, which we feel is actually the most promising, is to treat the semantic content of an imperative as being a unary predlcace. The force of an imperative 18 that the person to whom the command is directed is supposed to satisfy the predlcaCe. According to this theory the role of \"make\" is clear--it converts any proposition into a unary predicate. If the assertion \"John Is making glll go Co NOw York\" is represented as (MAKE JOHN (GO BILL MY)), we can form a unary predicate by LAMBDA abstraction: (LAMBDA X (MAKE X (GO gILL mY)), which would be the semantic content of the command \"Make Bill go to New York.\" This approach does away wlth the problem concerning adverbial modifiers or quantlflers In commands; they can simply be part of the proposition from which the predicate is formed. A final piece of evidence favoring thls approach over a theory based on the notion of action is that some imperatives have nothing at all to do wlth actions directly. The semantic content of commands llke \"Be good\" or \"Don't be a fool\" really does seem to consist exclusively of a predicate. X CONCLUSION In a paper that covers such a wide range of disparate topics, it is hard to reach any sweeping general conclusions, but perhaps a few remarks about the nature and current status of the research program are in order. First, it should be clear from the issues discussed that at least as many problems remain in the quest for logical form as have already been resolved. Considering the amount of effort that has been expended upon natural-language semantics, this is somewhat surprising. The reason may be that relatlvely few researchers have worked in thls area for its own sake. Davldeon's ideas on action sentences, for instance, raised some very interesting points about logical form-but the major debate Ic provoked in the philosophical llcerature was about the metaphysics of the concept of action, noc about the semantics of action sentences. Even when semantics is a major concern, as in the work of Montague, the emphasis is often on showing chat relatively well-understood subareas of semantics (e.g., quantificaclon) can be done in a parClcular way, rather than on attempting to take on really new problems. An additional difficulty is that so much work has been done in a fragmentary fashion. It is clear that the concept of action is closely related to the concept of time, but it is hard to find any work on either concept that takes the other one seriously. To build a language-processlng system or a theory of language processing, however, requires an integrated theory of logical form, not Just a set of incompatible fragmentary theories. Our conclusion, then, is chac if real progress is to be made on understanding the logical form of natural-language utterances, it must be studied in a unified way and treated as an important research problem in its own right. are chiefly responsible for the implementaClon of the DIALOGIC system, building on earlier systems co which Ann Robinson and Bill Paxcon made major contributions. (2) giving the semantics of that language, and (3) interpreting English indirectly by showing in a rigorous way how to translate it into the artificial language. This Is the procedure we shall adopt;...\" [Montague, 1974b, p.256] . duracioo, etc., as basic conceptual categories. Following Hayes [1979] , unlCs such as feet, pounds, gallons, and hours are considered to be functions from numbers,to quantities. Thus (FEET 3) and (YARDS l) denote the same distance. Halations llke length, weight, size, and duration hold between an entity and a quantity of an appropriate type. Where a word llke \"welghc\" serves in English to refer co both the relaClon and the quantity, we must be careful Co dlsClngulsh between chem. To see the dlscincCion, note Chac length, beam, and draft are all relaclons between a ship and a quanClcy of the same type, discance. We treat comparatives llke \"greater than\" as molcidomain relaclons, working with any two quanciCles of the same type (or wich pure numbers, for chac matter). 6 Hendrix [1973] , Rieger [1975] , Hayes [1978], and McDermott [1981] have all dealt with conClnuous processes co some extent, buc none of them has considered specifically how language expresses information about processes. 7 This point was impressed upon me by Pat Hayes. ACKNOWLEDGEMENTS The ideas in this paper are the collective result of the efforts of a large number of people at SRI, particularly Barbara Grosz, SCan Rosenscheln, and Gary dendrix. Jane Robinson, Jerry Hobbs, Paul Martin, and Norman Haas [Kaplan, 1977] , calls the content of a sentence, as opposed to Its character. Kaplan introduces the content/character distinction to sort out puzzles connected wlth the use of demonstratives and Indaxlcals. He notes that there are at least two different notions of \"the meaning of a sentence\" that conflict when indexical expressions are used. If A says to B, \"I am hungry,\" and g says to A, \"~ am hungry,\" they have used the same words, but in one sense they mean different things. After all, it may be the case that what A said is true and what B said is false. If A says to g, \"~ am hungry,\" and B says to A, \"You are hungry,\" they have used different words, but mean the same thing, that A is hungry. This notion of \"meaning different things\" or \"meaning the same thing\" is one kind of meaning, which Kaplan calls \"content.\" There Is another sense, though, In which A and g both use the words \"I am hungry\" with the same meanlng, namely, that the same rules apply to determine, in context, what content is expressed. For thls notion of meaning, Kaplan uses the term \"character.\" Kaplan's notion, therefore, is that the rules of the language determine the character of a sentence--whlch, in turn, together wlth the context of utterance, determines the content. If ~ broaden the scope of Kaplan's theory to include the local pragmatic indetermlnacles we have discussed, it seems Chec the way they depend on context would also be part of the character of a sentence and Chat our logical form is thus a representation of the content of the sentence-ln-context. 5 It should be obvious from the example that nouns referring to unlCs of measure--e.g., \"feet\"--are an exception co the general rule. We treat types of quanCitles, such as distance, weight, volume, time",
    "abstract": "",
    "countries": [
        "United States"
    ],
    "languages": [
        "English"
    ],
    "numcitedby": "78",
    "year": "1981",
    "month": "June",
    "title": "Problems in Logical Form"
}