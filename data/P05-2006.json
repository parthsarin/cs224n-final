{
    "article": "Semantic relations between text concepts denote the core elements of lexical semantics. This paper presents a model for the automatic detection of INTENTION semantic relation. Our approach first identifies the syntactic patterns that encode intentions, then we select syntactic and semantic features for a SVM learning classifier. In conclusion, we discuss the application of INTENTION relations to Q&A. Introduction Problem description Intentions comprise of semantic relationships that express a human's goal-oriented private states of mind, including intents, objectives, aims, and purposes. As a relation, it encodes information that might not be explicitly stated in text and its detection might require inferences and human judgment. The answer to the question What was Putin trying to achieve by increasing military cooperation with North Korea? is found in the sentence Putin is attempting to restore Russia's influence in the East Asian region. Extracting the exact answer to restore Russia's influence in the East Asian region becomes easier if this is recognized as Putin's intention which matches the question's expected answer. In this paper, we describe a method that identifies intentions in domain independent texts. We employed two machine learning algorithms to create models that locate intentions in a given paragraph using a set of six syntactic and semantic features. Motivation The current state-of-the-art NLP systems cannot extract intentions from open text and, as we saw in the example, their detection benefits Question Answering. An intention is the answer to general questions like What is the goal of X?, What does X plan to do?, or What does X aim for? The INTENTION semantic relation is one of the most challenging relations because text fragments may convey unstated intentions. These are most pervasive in dialogues, communication specific to humans. For example, in the following conversation, the vendor infers the client's unstated intention of buying the cups. Customer: Where do you have the $1 cups? Salesman: How many do you want? Intentions are closely related to other semantic relations such as beliefs, motives, desires, or plans. In the above example, the context tells us that this takes place in a superstore, well-known as a place where people buy things from. The clerk's answer emerges from our common beliefs and background knowledge as well as from his desire to help a customer. Intentions are the framework for plans. Many philosophers and artificial intelligence researchers studied the intentions as parts of coordinating plans (Bratman, 1987; Pollack, 1990) because people establish plans for future times. In this paper, we regard intentions as expressions of a particular action that shall take place in the future, in which the speaker is some sort of agent (Anscombe, 1957) . For example, the sentence Mary is going to buy a TV set shows Mary's intention. Anscombe (1957) considers intentions as a subclass of predictions, besides commands and prophecies. John is going to be sick is usually a prophecy, John, go for a walk! is an order, and John plans to take a walk expresses an intention. Previous work Various methodologies have been proposed and used over the years for the task of extracting semantic relations from text. Purely probabilistic models, empirical methods, or hand-coded constraints were some of the approaches that do not use machine learning algorithms. Later on, methods that use decision tree, neural networks, memory-based learning, or support vector machines were introduced. Currently, there is also a increased interest in shallow semantic parsing of open texts and automatic labeling of semantic roles. Wiebe et al. (2004) focused on the detection of subjective language such as opinions, evaluations, or emotions in text. Using clues of subjectivity (low-frequency words, collocations), they identify opinion piece texts such as editorials, letters to the editor, or arts and leisure reviews. There exists an immense literature in philosophy about the different types of intentions and their characteristics. Bratman (1987) tries to find the relationship between the two distinct phenomena of doing something intentionally and intending to do something. Numerous philosophical studies discuss how intentions relate to other psychological concepts, such as, beliefs, desires, hopes, or expectations (Audi, 1973; Bratman, 1981; Bratman, 1987) . Intentions are consistent with the person's beliefs, and, unlike ordinary desires, require consistency (Bratman, 1987) . They can generate reasons for or against future intentions (Bratman, 1981; Bratman, 1987) . As plan elements, intentions require a certain stability. Their side effects need not be intended, even if they were taken into consideration in the first place 1 (Bratman, 1990) . Syntax and Semantics of Intention Syntactic patterns Because, in all the cases that we encountered, intentions were conveyed by phrases, we took a closer look at how intentions can be expressed in the written text. For our investigations, we chose the Sem-1 Due to space limitations, we couldn't include detailed examples. Please see the cited articles for examples. Cor text collection (Miller et al., 1993) Semantics of intentions From the semantic point of view, an intention may be very specific, it may contain a future time or a location (John intends to meet Mary today), but every intention must specify a future action. Hence, we propose the following representation for the IN- TENTION semantic relation: INT( \u00a3 \u00a3 ! \u00a6 ) where \u00a3 is the event denoting the intention, \u00a3 denotes the person that has the intention and \u00a6 is the intended action or event. If the intention is more specific then we will identify instances of other semantic re- $\u00a3 intends to perform action \u00a6 and this action has a purpose R , then we can say that \u00a3 intends to do R 3 . Formally, we can express the above relations 2 The list of semantic relations that can specialize an INT includes THEME, LOCATION, TEMPORAL, MANNER, INSTRU-MENT, SOURCE, MEANS, and FREQUENCY. Their arguments are U WV , the intention verb, and a corresponding X `Y . 3 Similar statements can be made for the ENTAIL and ISA with the following set of implications 4 : INT U \u00a2\u00a1 \u00a4\u00a3 4X \u00a5\u00a1 \u00a6\u00a3 4U V \u00a8 \u00a7 \u00a9 PURPOSE U WV \u00a3 U \u00a7 INT U \u00a3 4X \u00a5\u00a1 \u00a6\u00a3 4U \u00a6 \u00a7 INT U \u00a1 \u00a3 4X \u00a1 \u00a3 4U V \u00a7 \u00a9 ENTAIL U V \u00a3 U \u00a7 INT U \u00a3 4X \u00a1 \u00a3 U \u00a7 INT U \u00a1 \u00a3 4X \u00a1 \u00a3 4U V \u00a7 \u00a9 IS-A U V \u00a3 U \u00a7 INT U \u00a3 X \u00a1 \u00a3 U \u00a7 INT U \u00a2\u00a1 \u00a4\u00a3 4X \u00a5\u00a1 \u00a6\u00a3 4U V \u00a8 \u00a7 \u00a9 PURPOSE U \u00a3 U WV \u00a6 \u00a7 \"! INT U \u00a3 4X \u00a5\u00a1 \u00a6\u00a3 4U \u00a6 \u00a7 INT U \u00a1 \u00a3 4X \u00a1 \u00a3 4U V \u00a7 \u00a9 CAUSE U V \u00a3 U \u00a7 \"! INT U \u00a3 X \u00a1 \u00a3 U \u00a7 The first three implications formalize the above inference rules. If John intends to start his car to go to the park, then John intends to go to the park. Similarly, if John intends to buy a car, then we can say that he intends to pay for it. The sentences John intends to go to the park. He's starting his car right now express John's intention to go to the park ( \u00a6 ). The purpose of starting the car ( R ) is to go to the park. We cannot say that John intends to start his car. This is just an intentional action done to achieve his objective. The fifth rule tries to eliminate the effects ( R ) of an intention ( \u00a6 ) from being considered as intentions or objectives. If John intends to swim in the pool ( \u00a6 ) even if he knows that he is going to catch a cold ( R ) because the water is too cold, we cannot say that John intends to catch a cold. 5 The traditional relational properties (reflexivity, symmetry, or transitivity) do not hold for the INTENTION semantic relation. Learning Model Experimental data We applied the most frequent syntactic pattern that expresses intentions in text ( \u00a5\u00a1 \u00a3 to \u00a5\u00a1 \u00a6 ) on the first 10,000 sentences of the SemCor2.0 collection and we extracted 1,873 sentences. These sentences contain 115 intentions (manually identified by a graduate student, not the author). 4 U #\u00a1 and U represent different intentions of the same person. 5 A more detailed example can be found in (Bratman, 1990) . Features for intention After analyzing our training data, we pinpointed a set of features to help us identify the intentions encoded by the pattern \u00a1 \u00a3 to \u00a5\u00a1 \u00a6 . The WordNet senses needed to extract the semantic features were taken from SemCor. We will use Mary intends to revise the paper to show each feature's value. The semantic class of the the \u00a5\u00a1 \u00a3 verb's agent or specializations of it. Intentions and objectives are specific to humans. Thus, the semantic class of the \u00a5\u00a1 \u00a3 agent bears a high importance. We used an in-house semantic parser to retrieve the AGENT of the \u00a1 \u00a3 verb. The feature's value is its WordNet semantic class. Mary names a person. Thus, the semantic class that we are seeking is entity#1. We chose this semantic generalization because nouns and verbs belong to open part-of-speech classes. There can be an enormous number of possibilities and any models built using them as feature values will not be able to generalize beyond the training examples. Therefore, we introduce a bias in our learning framework based on the assumption: noun and verb concepts will semantically behave as the concepts that subsume them in the WordNet structures. But, by generalizing concepts, we lose some of their semantic properties. Hence, we specialize the semantic class $ of a concept % by replacing it with its immediate hyponym (% ) that subsumes % . We can further increase the semantic level by specializing % . We note that the number of values is still finite even though we specialized the general concepts. As the specialization level increases, there will be words % that cannot be further specialized (entity#1 cannot be specialized even once). In such cases, we add % to the set of feature values. The semantic class of the \u00a5\u00a1 \u00a3 verb or its specializations. The intention phrase is subordinated to a verb ( \u00a5\u00a1 \u00a3 ). The semantic class of this verb is the system's second feature. In our example, \u00a1 \u00a3 (intend#1) semantic class is wish#3. The semantic class of the \u00a2\u00a1 \u00a2\u00a6 verb's agent, if this agent differs from the \u00a5\u00a1 \u00a3 verb's agent; otherwise, a common value (equal) is given. We identify the AGENT of the \u00a5\u00a1 \u00a6 verb. The specializations of its semantic class will be used if the top noun proves to be too general. In the sample sentence, the agent of revise is Mary. We can have a different agent for verb (Mary intends John to revise the paper). Let's assume that Mary is John's supervisor and she can make him revise the document. The sentence expresses Mary's intention of persuading John to revise the paper, but this objective is not encoded by the pattern we considered. The semantic class of the \u00a5\u00a1 \u00a6 verb or its specializations. The \u00a5\u00a1 \u00a6 verb expresses the future action or behavior that the agent intends. We extract this feature using WordNet hierarchies. Revise#1 belongs to the act#1 semantic class. A flag indicating if the \u00a1 \u00a3 verb has an affirmative or a negative form. We want to differentiate between sentences like John wants to go for a walk and John doesn't want to go for a walk. The first sentence expresses John's intention, while, in the second one, no intention can be identified. The type of the analyzed sentence. This feature is primarily concerned with questions. A question like Where do you plan to go for a walk? indicates the intention of going for a walk, unlike the question Do you plan to go for a walk? which might express an intention if the answer is \"yes\". This feature's values are the wh-words that begin a question or n/a for the other types of English sentences. We did not analyze the affirmative versus the negative form of the \u00a2\u00a1 \u00a6 verb because it does not affect the objective attribute of the intention. The sentence John intends not to go for a walk expresses a negative intention. This sentence is much stronger than John doesn't intend to go for a walk. In the former context, John has set a goal for himself , while in the second sentence, the objective does not exist. Experimental Results Impact of specialization The first experiment was performed using the LIB-SVM package 6 and the WordNet semantic classes. From our experiments, we noticed that the specialization of the \u00a1 3\u00a6 's agent semantic class does not influence the performance. Out of the 27 experiment triplets in which this specialization level changes, in only 4, it influences the result and, in 3 of them, the accuracy increases with the specialization level. Thus, our third feature is the second specialization level of the \u00a5\u00a1 \u00a6 's agent class. Table 3 shows the results obtained when the values of the radial kernel parameters were chosen to optimize the 5-fold-cross-validation on the training data. The best models are described in Table 4 .  Table 5 : The improvement (%) brought by each feature to the three best SVM models size and validated the new models using our previous test set. Figure 1 shows the performance variation of three models that use feature sets identical in terms of specialization levels to the ones of the A, B, and C classifiers. All three models exhibit a similar behavior with respect to the change in the training set size. Therefore, our features create a stable algorithm. The highest accuracy models use all 300 training examples. Thus, we did not reach the saturation point, but, considering the performance curve, this point is not very far. All our previous experiments used the entire set of features. Now, we investigate the relative contribution of each feature. We performed experiments that use only five out of the six features. In Table 5 , we list the accuracy increase that is gained by the inclusion of each feature. The most influential attribute is the \u00a5\u00a1 \u00a3 verb's semantic class or its specializations. Model The intention's description verb does not influence the classification result. Because intentions consist of a future action and verbs express actions, there are very few verbs, such as dream or snore (involuntary actions) that cannot occupy the \u00a2\u00a1 \u00a6 verb's position. The syntactic features bring an average increase in accuracy of 3.50%. Impact of word sense disambiguation Perfect word sense disambiguation might be a too strong assumption. In this section, we examine the effects of weaker disambiguation. Table 6 shows the accuracies of the best three models when each concept is tagged with its first WordNet sense (No WSD) and when the senses are given by an in-house WSD system with an accuracy of 69% computed on the SemCor data (Automatic WSD). No C5 results After examining the SVM results, we applied the C5 machine learning algorithm (Quinlan, 2004) to the same training data annotated with the same feature set, in a similar manner. Again, we specialized the four semantic classes, independently, and tested the decision trees against the testing data. Table 7 shows their accuracy. The highest values were obtained for the first level of specialization of the \u00a2\u00a1 \u00a3 verb semantic class. The specialization levels of the other semantic classes do not influence the accuracy of the decision trees. The most tested attribute is the \u00a5\u00a1 \u00a3 verb. This further substantiates our observation, made during our SVM models analysis, that this feature has the greatest importance in the intention classification process. Our error analysis of the C5 results indicates that, because of the relatively small numbers of training instances, C5 ignores some of the features and makes wrong decisions. Application to Question Answering Questions involving intentions cannot be answered only by keyword-based or simple surface-level matching techniques.  location as its answer type and the correct answer is one which involves al Qaeda intending to purchase weapons of mass destruction. The candidate answer text (P \u00a6 ) reveals the organization's past intent to buy (synonym with purchase) weapons in Russia. Because the two intentions have the same agent, future action and theme, the two semantically enhanced logic forms can now be unified and we can pin down the location of the intent (Russia). Conclusions We proposed a method to detect the INTENT relation encoded by the sentence-level pattern \u00a5\u00a1 \u00a3 to \u00a5\u00a1 \u00a6 with a 90.41% accuracy. We plan to investigate the other INTENTION patterns as well as other semantic relations such as MOTIVE, IMPLICATION, or MEANING which, currently, cannot be identified by the state-of-the-art NLP systems. These relation-ships need to be analyzed to provide a complete coverage of the underlying semantics of text documents. We intend to incorporate our INTENTION detection module into a Question Answering system and show its impact. Semantic class of the Semantic class of the Semantic class of the Semantic class of the",
    "abstract": "Semantic relations between text concepts denote the core elements of lexical semantics. This paper presents a model for the automatic detection of INTENTION semantic relation. Our approach first identifies the syntactic patterns that encode intentions, then we select syntactic and semantic features for a SVM learning classifier. In conclusion, we discuss the application of INTENTION relations to Q&A.",
    "countries": [
        "United States"
    ],
    "languages": [
        "English"
    ],
    "numcitedby": "9",
    "year": "2005",
    "month": "June",
    "title": "Automatic Discovery of Intentions in Text and its Application to Question Answering"
}