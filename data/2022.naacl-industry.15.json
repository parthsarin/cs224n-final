{
    "article": "Unsupervised word alignments offer a lightweight and interpretable method to transfer labels from high-to low-resource languages, as long as semantically related words have the same label across languages. But such an assumption is often not true in industrial NLP pipelines, where multilingual annotation guidelines are complex and deviate from semantic consistency due to various factors (such as annotation difficulty, conflicting ontology, upcoming feature launches etc.); We address this difficulty by constraining the alignment model to remain consistent with both source and target annotation guidelines, leveraging posterior regularization and labeled examples. We illustrate the overall approach using IBM 2 (fast_align) as a base model, and report results on both internal and external annotated datasets. We measure consistent accuracy improvements on the MultiATIS++ dataset over AWESoME, a popular transformer-based alignment model, in the label projection task (+2.7% at word-level and +15% at sentence-level), and show how even a small amount of target language annotations helps substantially. Introduction The task of aligning words in parallel sentences (i.e bitexts) originates from statistical machine translation (Brown et al., 1990) , where semantic identification was performed based on context similarity in accordance to the well-known distributional hypothesis. The most commonly used statistical aligners are built on top of the so-called IBM models (Brown et al., 1993) , a series of structured probabilistic models that, while fully unsupervised, often rely on additional assumptions (such as close-todiagonal alignment) to reach acceptable accuracies. These approaches have since been superseded by neural networks and pretrained embeddings. They nonetheless enjoy a wide popularity across many Figure 1 : Example of word alignment with notations from English to French. While the identity map is semantically very natural in this example, it conflicts with the ground-truth label. The whole group l'appli is labelled as Type in French, possibly to reduce friction with human annotators. NLP domains owing to their execution speed, dataefficiency and self-contained implementations. Cheap multilingual word alignments are appealing as they provide a transparent and interpretable way to transfer features from a source language to a target language (see Fig. 1 ). They have been used in the past to transfer costly annotations such as part-of-speech (Yarowsky and Ngai, 2001) or coreference information from high-to low-resource languages (Postolache et al., 2006) . However, the reliability of such a strategy depends on the use case at hand and we argue that it can lead to subtle but systematic failures in downstream tasks. In our industrial use case (that of a voice assistant), multilingual named-entity annotation guidelines factor in a great number of aspects (country launches, available features, human-friendly rules for annotators e.t.c) and end up surprisingly riddled with inconsistencies across languages (see table 1 ). In such cases, even a slight mismatch between semantics and annotation guidelines will lead to systematic errors: annotation guidelines of the source language \"bleed\" into the target language. This in turn generates friction for NLP pipelines that rely heavily on annotated resources, such as task oriented dialog systems. In this work, we show how to guide word alignments produced by structured models to conform to the annotation guidelines of the target language, extending them so that they do not solely rely on semantic relatedness. We use the posterior regularization technique of Ganchev et al. (2010) , a general framework that allows integrating information coming from a variety of features as optimization constraints. We illustrate our approach using IBM 2 as the base alignment algorithm. To model the label constraints, we construct n-gram tables that count the frequency of labels assigned to n-grams in the target language. These label ngrams, constructed using the same training data, are then used to bias the alignments so they comply with the annotation scheme. We use an EM-like iterative procedure to train the resulting modellabel transfer is done by assigning to targets words the label of their aligned source words. We evaluate our method on two annotated datasets and show that it combines the strengths of both approaches: the inferred alignments produce better labels than either the baseline aligners or the n-gram models alone. It also remains fast, interpretable, self-contained and data-efficient, which makes it easy to integrate into industrial NLP pipelines. However, it has the same drawbacks that IBM model 2 has (no fertility modelling -i.e cannot handle a single source word generating multiple words in the target language, N-1 source-target mapping, danger of local optima during training). We release our implementation as FastLabel 1 . Related Work Statistical word alignment models continue to be widely used to transfer labels from high-to low-resource languages owing to their speed, low memory footprint and interpretability. Their most famous exponents are the IBM models 1 to 4 (Brown et al., 1993; Och and Ney, 2003) , a Bayesian models hierarchy of increasing sophistication. fast_align (Dyer et al., 2013) is a fast reparameterization of IBM Model 2 that significantly cuts down training and inference time. Eflomal (\u00d6stling and Tiedemann, 2016) augments IBM model 1 with priors on word order and fertility, and uses Markov Chain Monte Carlo (MCMC) to do inference. Much of the recent work depart from the Bayesian modeling tradition by relying on contextual embeddings to perform the alignment (Pourdamghani et al. 2018 , Alkhouli et al. 2018 , Sabet et al. 2021) . AWESoME (Dou and Neubig, 2021) uses multilingual BERT (Devlin et al., 2019) to extract word alignments, and allows fine-tuning the underlying BERT model on parallel corpora to improve alignment quality. While very accurate, they leverage embeddings from computationally expensive neural networks, and as such, they are not self-contained and the errors made by these models are arguably less interpretable than the simpler statistical models presented here. Mann and McCallum (2007) introduced expectation regularization as a way to encourage unsupervised model predictions to match an expectation from an external prior. Chang et al. (2007) developed the constraint driven learning (CODL) framework that is capable of allowing different levels of constraint violation. Their formulation, however, did not allow for tractable inference and the authors used beam search to solve the optimization problem. The posterior regularization framework introduced by Ganchev et al. (2010) allows constraint violations while remaining tractable. Applications of statistical word alignment to label projection are numerous. Label projection using word alignments is discussed in Yarowsky, Ngai, and Wicentowski (2001) , Hwa et al. (2005) , \u00d6stling (2016) , Das and Petrov (2011) and Duong et al. (2013) . The last three models use the stanford POS tagger (Toutanova et al., 2003) on a high resource source-language and transfer the labels to the target language. Model Formulation We start with the notations and closely follow (Dyer et al., 2013) for clarity. The source (target) sentence is denoted f (e), of length n (m). The aim is to infer, from bitexts, an alignment a a a = \u27e8a 1 , a 2 , \u2022 \u2022 \u2022 , a m \u27e9 from source to target: each a i refers to the position of the source sentence word aligned to the ith word in the target sentence (see Figure 1 ). We will assume that each target target word is associated to at most one source word: this N \u2212 1 mapping limitation is not a concern in the context of label projection. In the NER (Named Entity Recognition) setup, both source and target sentences may be annotated with NER labels, and we write L the set of possible labels, and \u2113 e i (resp. \u2113 f j ) the label attached to e i (resp. f j ) ; \u2113 e and \u2113 f refer to the label sequences of the whole sentences e and f . The parameters of the popular IBM models are usually inferred through maximum likelihood (ML)  The examples from our internal dataset show some of the discrepancies present in annotation guidelines across languages -for example, the English token-label pair \"and|o\" corresponds to \"et|length\" in French. We also observe inconsistencies arising due to word fertility and tokenization choices -\"what\" corresponds to \"che c' \u00e8\" (i.e 3 different tokens) in Italian and the two words \"turn off\" corresponds to the single word \"desligue\" in Portuguese. \u03b8 * = arg max \u03b8 L(\u03b8) = arg max \u03b8 P (e, f |\u03b8). The parametric family over which inference is performed depends on the IBM models. In what follows, we illustrate our approach on IBM-2 (as used in fast_align), which comes with a diagonal prior and a set of lexical probabilities representing translations: p F A (e i , a i |m, n) = \u03b4(a i |i, m, n) \u00d7 \u03b8(e i |f a i ) p F A (e i |m, n) = n j=0 p F A (e i , a i = j|m, n) where \u03b4(\u2022) models the diagonal prior and the null alignment probability (Dyer et al., 2013) . Because alignments are hidden variables, the ML optimization can only be performed approximately, for example with an Expectation Maximization (EM) iterative scheme. EM can be formulated as an ELBO coordinate ascent (Neal and Hinton, 1998): F (q, \u03b8) = log L(\u03b8) \u2212 D KL (q||p F A (\u2022|e, f , m, n)) E-step : q (t) = arg max q F (q, \u03b8 t ) M-step : \u03b8 (t+1) = arg max \u03b8 F (q t , \u03b8) where q is a reference distribution and is used to inject external knowledge into the optimization, and maximization of the E-step is performed over an arbitrary family of alignments probability distribution. For label projection however, we would like to bias the ELBO optimization so as to favor alignments compatible with the target annotation guidelines, without losing information obtained from the bitexts. The posterior regularization (Ganchev et al., 2010) framework offers an elegant solution, by noting that the E-step above can be easily solved over a constrained set of distributions Q, as long as those constraints are defined in terms of moments of q \u2208 Q: E-step (PR) : q (t) = arg max q\u2208Q F (q, \u03b8 t ) Q = {q : E q [\u03d5(e, f , m, n)] = b} where \u03d5 is an arbitrary function. In the context of label projection, we wish to match the projected label distribution P (\u2113 e |e, f , m, n) to a reference distribution r(\u2113 e ), that can be defined quite arbitrarily. Given an alignment a, target words receive the same label as their aligned source words \u2113 e i = \u2113 fa i \u2200i \u2208 [e]. We can therefore rewrite such matching condition as: P (\u2113 e |e, f , m, n) = a P (\u2113 e |e, f , a)P (a|e, f , m, n) (1) 123 = E q [1 (\u2113 e = \u2113 fa )] \u2261 r(\u2113 e ), 1 (\u2113 e = \u2113 fa ) = 1, if \u2113 e = \u2113 fa 0, otherwise (2) The set of contraints, one per label configuration per target sentence, is denoted C. In this case, the E-step admits a dual formulation and the optimal alignment distribution q * has a simple expression in terms for the unconstrained p F A : q * (a) = p F A (a|e, f )e \u2212 c\u2208C \u03bb * c v a c Z({\u03bb * c }) (3) v a c = 1 (\u2113 fa = \u2113 c ) \u2212 r(\u2113 c ) (4) \u03bb * c = arg max \u03bbc [\u2212 log (Z({\u03bb * c }))] \u2200c \u2208 C (5) where \u03bb c , c \u2208 C is a family of Lagrange multipliers enforcing the constraints over label space. The iterative algorithm closely mimics the classical EM coordinate ascent, with the addition of solving the Lagrange multipliers (see Appendix A). The value of the Lagrange multipliers \u03bb * c are computed through gradient ascent over Z({\u03bb * c }). IBM model 2 enjoys the property that its alignment probability p F A factors over the words of each target sentence. It is therefore convenient to split C accordingly: to each word e i and each possible \u2113 \u2208 L, are attached a Lagrange multiplier \u03bb e i \u2113 and the cost v e i \u2113 of labelling e i with \u2113. In such case, Z({\u03bb * c }) further decomposes: Z({\u03bb * c }) = e\u2208corp. e i \u2208s Z e i ({\u03bb * c }) Z e i ({\u03bb * c }) = n j=1 p F A (a i = j|e, f ) e \u2212 \u2113 \u03bb e i \u2113 v e i \u2113 v e i \u2113 = 1 \u2113 fa i = \u2113 \u2212 r(\u2113) and its derivative w.r.t \u03bb e i \u2113 : \u2202Z e i \u2202\u03bb e i \u2113 = \u2212 n j=1 p F A (a i = j|e, f ) v e i \u2113 e \u2212 \u2113 \u03bb e i \u2113 v e i \u2113 The stationary points is reached when v e i \u2113 = 0, selecting alignments for which the transferred label distribution matches r(\u2113). Experiments Baselines Eflomal 2 and AWESoME 3 were run using the respective authors' publicly released code. The hyperparameter settings used to run these models The third column indicates how much longer (or shorter) the sentences in a particular language are compared to their English translations. Unlike MultiATIS++, the English sentences paired with each of languages in our internal dataset are different (i.e the English sentences in the pair en-it are different from those in en-fr), resulting in slightly different average sentence lengths. The translations in both MultiATIS++ and our internal dataset were done by humans. are described in Appendix C. Since our work is an extension of fast_align, we ported the original fast_align 4 code to Python and extended it to support posterior regularization. Just like the original fast_align implementation, we did 5 iterations of expectation-maximization to train the model. The trained alignment model (i.e q * in equation 3) is then evaluated on a held out set of bitexts. For each aligned word pair, the label of the source word (usually from an English sentence) is transferred to the aligned target word. All target words aligned to the \"null\" token are given a label of \"o\" (for \"other\"). We then compare the transferred labels to the true labels of the target sentence to calculate the accuracy. Though the label transfer happens at a word level, we report accuracies at the sentence level as well since perfectly annotated sentences are crucial for our industrial use case. The n-gram classifiers in the tables are simple frequency-based classifiers trained on the target language -for a particular ngram in the test set, the classifier annotates the nth word with the most frequent label assigned to that n-gram in the training data. For n-grams that were not present in the training data (even after backingoff to unigrams), the classifier outputs the label \"o\" (for \"other\"). These simple classifiers are essentially the same models that are used to do posterior regularization in our experiments -when used as classifiers, they only output the most likely label for a given n-gram while during regularization we use their entire label distribution. 1 ), the diagonal prior used by fast_align (i.e the assumption that words in target sentence are aligned to the words in relatively the same position in the source sentence) can be problematic. The superior performance of FastLabel (table 3 ) can be attributed to its ability to overcome fast_align's diagonal prior. Datasets We ran our experiments on two different datasets -a publicly available corpus of annotated bitexts called MultiATIS++ (Xu et al., 2020) and an internal corpus of annotated bitexts. MultiATIS++ is a multilingual extension of the ATIS (Price, 1990) dataset, which is a transcript of flight information requests to automated airline travel inquiry systems and contains approximately 5000 samples. The queries in ATIS were originally in English and the MultiATIS++ dataset contains annotated human translations of the English queries into six other languages. Our internal dataset consists of queries to a task-oriented dialogue system and contains ten thousand pairs of annotated English-Italian, English-French and English-Portuguese bitexts. The English sentences in the different language pairs in our internal dataset are not the same -this means that there is considerable variation in the distribution of intents across different language pairs in this dataset. The scheme for certain type of queries vary across languages (see table 1 ) as well. For the set of constraints, we compute a frequency based n-gram model on the annotated monolingual data: the probability of label \u2113 i depends on the word e i to be labelled, its context of length n \u2212 1 and the intent of the sentence: P (\u2113 i |e) = P (\u2113 i |e i , e i\u22121 , \u2022 \u2022 \u2022 e i\u2212n+1 , intent). We include the intent in the counts since labels may strongly depend on it: for example, \"play frozen\" will be different depending on whether the overall intent is \"Music\" (resulting in \"play|action frozen|album) or \"Video\" (resulting in \"play|action frozen|movie). We construct the n-grams based on the same data that was used to train the word alignment model, and during inference apply the same back-off strategy used by the n-gram classifiers described in the previous section.  was not observed in the training data, we leave finding the alignment of the corresponding target word unconstrained. Though we stick to simple frequency-based n-gram models for the sake of speed and interpretability, posterior regularization can accommodate any model that can predict a label distribution, including neural networks. Results Our results are reported in Table 3 . Apart from fast_align, we include eflomal, a more sophisticated statistical alignment model, and AWESoME, a strong model that leverages recent advances in pre-trained language models, as additional baselines. On the MultiATIS++ dataset, FastLabel outperforms AWESoME, our strongest baseline, by around 2.7% at word-level label transfer accuracy and gave around a 15% increase in the amount of perfectly annotated target sentences (averaged across all languages). On our internal dataset, FastLabel resulted in an improvement of around 7% (compared to eflomal, which performed better than AWESoME, averaged across all languages) in the amount of perfectly annotated target sentences. The simple n-gram classifiers perform reasonably well on MultiATIS++. After a deeper inspection, we find that most of the words in this dataset receive the label \"O\", and entities with richer labels (such as city names) are usually present in both the train and test sets, and makes MultiATIS++ easier to annotate correctly. Our internal dataset is more complex, comprising of 185 intents (eg: \"Appli-ance\", \"Music\") and 211 different label types (i.e \"o\" or \"date\" or \"song\") (for comparison, Multi-ATIS++ has 23 intents and 122 label types). This is reflected in the much poorer performance of the n-gram classifiers on our internal dataset. Though poor as independent annotators, the same n-gram label distributions are beneficial to FastLabel when used for posterior regularization, indicating that our regularization framework is successful in incorporating the right amount of information from the external prior. We observe a large drop in performance for fast_align when aligning language from different families (such as English-Chinese bitexts), due to the well-known limitations of the diagonal prior assumption. Moreover, as observed in table 2, Hindi and Chinese sentences are usually slightly shorter than their English counterparts, while the sentences from the other European languages tend to be longer. For example, the Italian translation of the phrase \"personalize my echo\" could be \"personalizza il mio echo\" -here the two tokens \"my echo\" generate three tokens in Italian (high word fertility), while a non-Indo-European language might have the opposite problem with respect to English (low word fertility). Despite these challenges, FastLabel performs comparatively well on these languages thanks to its ability to overcome the diagonal prior of the underlying fast_align algorithm. Figure 2 illustrates the effect of posterior regularization on word-alignments. All subplots show alignments between English-Hindi bitexts in the MultiATIS++ dataset. The plot to the left (fast_align) clearly from the FastLabel evaluated on the English-French bitexts in our internal test dataset. 1) Alignments away from the diagonalthe French word corresponding to \"wet\" (\"mouill\u00e9e\") appear at the end of the sentence. 2) Fertility -\"report\" is translated into French as \"le compte rendu de\". 3) Discrepancies in annotation guidelines -though \"moi\" should be semantically aligned to \"me\" in the English sentence and hence given the label \"o\", our internal annotation scheme for French consistently annotates \"moi\" as \"visual\" if it follows \"montre\". shows a stronger alignment along the diagonal, while this tendency to align along the diagonal is weaker in the plot to the right (FastLabel). Table 4 contains some examples where fast_align made a mistake in transferring the labels from the source sentence, but FastLabel was correct. How much annotated data is required for Fast-Label to improve upon fast_align? Figure 3 reports label transfer accuracy between English-German bitexts in MultiATIS++ using varying amounts of training data to construct the n-gram models. Using only 20% of all available training data to construct the n-gram models gives FastLabel a significant boost over fast_align, demonstrating the applicability of our approach in data-sparse regimes. With growing training data, n-grams become better annotators (to a point where the 3-gram model outperforms fast_align), but a performance gap with FastLabel persists. Although the focus of our work was on maximizing the label transfer accuracy, we also note that posterior regularization resulted in a more semantically accurate translation table (see Appendix B) compared to fast_align. Conclusion We illustrated how to augment existing algorithms (such as fast_align) with information about annotation guidelines, through posterior regularization. Lightweight, self-contained and data-efficient, our approach retains the benefits of statistical aligners while leading to higher quality alignments. It also mitigates semantic inconsistencies that can appear in the annotation guidelines of large scale industrial NLP systems. A natural extension of this work is to use more sophisticated models than n-grams to predict the label distributions. The task of matching the distribution of source labels onto some target through word alignments also bears some similarities with optimal transport. We leave such investigation to the future. C Hyperparameters Eflomal was run using the \"model3\" argument so that the final model makes use of IBM model 1, Hidden Markov Models, and also models fertility. Both the forward and reverse alignments (i.e they were not symmetrized) were used to make the priors. AWESoME was fine-tuned for 2 epochs in an unsupervised fashion independently on the training split of both MultiATIS++ and our internal data, with the following hyperparameters: D Compute FastLabel, eflomal and fast_align were run on cpu on a consumer-grade laptop. AWESoME was finetuned for 2 epochs on a single Nvidia Tesla V100 GPU. Our python re-write of fast_align trains at the rate of approximately 260 samples per second. With posterior regularization using trigrams, the training speed drops down to approximately 80 iterations per second. This translates to a training time of 15 seconds per iteration (MultiATIS++ dataset, 4300 training samples) with fast_align and almost 1 minute per training iteration for FastLabel (with trigrams). Though our rewrite of fast_align (and consequently FastLabel) is faster to train compared to recent models such as AWESoME, it is still slower than the original implementation of fast_align and eflomal (which are written in c) -this is currently a limitation of our work and we intend to address this in a future code release. Acknowledgements We would like to thank Fabian Triefenbach, Markus Boese and Yannick Versley for their feedback on an earlier version of this manuscript. A EM steps with posterior regularization The iterative algorithm closely mimics the classical EM coordinate ascent, with the addition of solving the Lagrange multipliers: 1. (Start) Random initialization of the IBM 2 model parameters \u03b8 0 . 2. Compute p F A as specified by the IBM 2 model, given \u03b8 t . 3. Find the optimal Lagrange multipliers \u03bb * c and compute the tilted distribution q * . 4. Find the optimal parameters \u03b8 t+1 using q * in place of p F A . 5. Iterate from step 2 until convergence. B Excerpt of the translation table for English-French bitexts In table 5, French words that are not semantic translations of the English source word are highlighted in red. The \"count\" represents the number of bitexts where the English and French words appeared in the source and target sentences respectively. We observed that posterior regularization using labels improved the quality of the translation table (and consequently, alignments) as well.",
    "abstract": "Unsupervised word alignments offer a lightweight and interpretable method to transfer labels from high-to low-resource languages, as long as semantically related words have the same label across languages. But such an assumption is often not true in industrial NLP pipelines, where multilingual annotation guidelines are complex and deviate from semantic consistency due to various factors (such as annotation difficulty, conflicting ontology, upcoming feature launches etc.); We address this difficulty by constraining the alignment model to remain consistent with both source and target annotation guidelines, leveraging posterior regularization and labeled examples. We illustrate the overall approach using IBM 2 (fast_align) as a base model, and report results on both internal and external annotated datasets. We measure consistent accuracy improvements on the MultiATIS++ dataset over AWESoME, a popular transformer-based alignment model, in the label projection task (+2.7% at word-level and +15% at sentence-level), and show how even a small amount of target language annotations helps substantially.",
    "countries": [
        "Italy"
    ],
    "languages": [
        "Italian",
        "English",
        "Hindi",
        "French",
        "Portuguese",
        "Chinese"
    ],
    "numcitedby": "0",
    "year": "2022",
    "month": "July",
    "title": "Constraining word alignments with posterior regularization for label transfer"
}