{
    "framing_question": "What information does the paper provide about the researchers\u2019 positionality, if any?\"",
    "response": "The paper does not provide any information about the researchers' positionality.",
    "article": "Les r\u00e9cents d\u00e9veloppements des approches d'apprentissage neuronal profond ont permis des avanc\u00e9es tr\u00e8s significatives dans le domaine de l'interrogation des syst\u00e8mes d'information en langage naturel. Cependant, pour le fran\u00e7ais, les ressources \u00e0 disposition ne permettent de consid\u00e9rer que les requ\u00eates sur des donn\u00e9es stock\u00e9es sous forme de texte. Or, aujourd'hui la majorit\u00e9 des donn\u00e9es utilis\u00e9es en entreprise sont stock\u00e9es sous forme tabulaire. Il est donc int\u00e9ressant d'\u00e9valuer si les ressources anglophones associ\u00e9es (jeux de donn\u00e9es tabulaires et mod\u00e8les) peuvent \u00eatre adapt\u00e9es au fran\u00e7ais tout en conservant de bons r\u00e9sultats. Introduction Ces derni\u00e8res ann\u00e9es les avanc\u00e9es en traitement automatique du langage permettent d'envisager des applications plus pouss\u00e9es dans des milieux professionnels, comme par exemple l'am\u00e9lioration du traitement des donn\u00e9es pour la gestion de la relation client (CRM). Ainsi le traitement des questions en langage naturel sur des donn\u00e9es peut \u00eatre tr\u00e8s prometteur. Le traitement des questions en langage naturel a connu un vif int\u00e9r\u00eat, \u00e0 l'image du jeu de donn\u00e9es SQuAD pr\u00e9sent\u00e9 par (Rajpurkar et al., 2018) , qui fait d\u00e9sormais partie du jeu de t\u00e2che du benchmark GLUE (Wang et al., 2019) . La t\u00e2che consiste \u00e0 extraire les portions de textes qui permettent de r\u00e9pondre \u00e0 la question pos\u00e9e. Or, la plupart des donn\u00e9es sont stock\u00e9es sous forme d'une base de donn\u00e9es tabulaire. Ainsi, dans le cadre de donn\u00e9es stock\u00e9es dans une base SQL, le contexte des questions serait une table de donn\u00e9es, et la r\u00e9ponse serait alors une traduction de cette question en SQL. Plusieurs jeux de donn\u00e9es ont \u00e9t\u00e9 r\u00e9alis\u00e9s afin de r\u00e9pondre \u00e0 cette t\u00e2che d'analyse de donn\u00e9es tabulaires, que ce soit en se focalisant sur des questions g\u00e9n\u00e9rales et complexes (Pasupat & Liang, 2015) , plusieurs questions simples (Iyyer et al., 2017) , ou en cherchant une traduction la plus fid\u00e8le qui soit d'un langage naturel vers le SQL (Zhong et al., 2017) . Si chacun de ces jeux de donn\u00e9es propose un mod\u00e8le associ\u00e9, on peut toutefois remarquer que le mod\u00e8le TAPAS propos\u00e9 par (Herzig et al., 2020) , utilise d'une mani\u00e8re originale l'architecture BERT (Devlin et al., 2019) , pour proposer un nouveau traitement de cette t\u00e2che ; il donne actuellement les meilleurs r\u00e9sultats. Cependant toutes ces ressources ne sont con\u00e7ues que pour un usage qui concerne la langue anglaise. Par suite, l'on peut se demander dans quelle mesure une nouvelle collecte de donn\u00e9es est n\u00e9cessaire pour obtenir un mod\u00e8le \u00e9quivalent \u00e0 TAPAS pour le fran\u00e7ais. C'est pourquoi nous proposons ici une traduction du jeu de donn\u00e9es propos\u00e9 par (Zhong et al., 2017) , ainsi que son \u00e9valuation sur une version r\u00e9-entra\u00een\u00e9e du mod\u00e8le TAPAS, afin de d\u00e9terminer si ce jeu de donn\u00e9es obtenu par traduction d'une ressource anglophone est suffisant pour obtenir un mod\u00e8le de traitement de questions en langage naturel sur des donn\u00e9es tabulaires en fran\u00e7ais. Plus pr\u00e9cis\u00e9ment, nous souhaitons \u00e9tablir dans quelle mesure ce mod\u00e8le r\u00e9-appris sur les donn\u00e9es traduites produit des r\u00e9sultats comparables \u00e0 ceux obtenus pour l'anglais sur une t\u00e2che \u00e9quivalente. Pr\u00e9sentation des jeux de donn\u00e9es Afin de r\u00e9aliser la t\u00e2che de traduction du langage naturel en une expression SQL, plusieurs jeux de donn\u00e9es peuvent \u00eatre exploit\u00e9s : -WIKITableQuestion (Pasupat & Liang, 2015) est un jeu de donn\u00e9es compos\u00e9 de questions sur des tables HTML issues de Wikipedia auxquelles sont associ\u00e9es des questions complexes r\u00e9alis\u00e9es par des humains \u00e0 qui il a \u00e9t\u00e9 demand\u00e9 de cr\u00e9er, suivant une table donn\u00e9e, des questions complexes dont la r\u00e9ponse n\u00e9cessite plusieurs op\u00e9rations sur la table (agr\u00e9gation, comparaisons, superlatifs, op\u00e9rations math\u00e9matiques). Au total il comprend 22 033 questions sur 2 108 tables. -SQA (Iyyer et al., 2017) : cet ensemble de donn\u00e9es a \u00e9t\u00e9 construit en demandant \u00e0 des humains de d\u00e9composer un sous-ensemble de questions hautement compositionnelles de WIKITQ, o\u00f9 chaque question d\u00e9compos\u00e9e r\u00e9sultante peut \u00eatre renseign\u00e9e par une ou plusieurs cellules d'une table SQL. L'ensemble final se compose de 6 066 s\u00e9quences de questions avec 2,9 questions par s\u00e9quence en moyenne. -WikiSQL (Zhong et al., 2017) : ce jeu de donn\u00e9es se concentre sur la traduction de texte en SQL. Il a \u00e9t\u00e9 construit en demandant \u00e0 des humains de paraphraser une question bas\u00e9e sur un mod\u00e8le en langage naturel, deux autres \u00e9tant invit\u00e9s \u00e0 v\u00e9rifier la qualit\u00e9 des paraphrases propos\u00e9es. Le r\u00e9sultat est un ensemble de 80 654 questions sur 24 241 tables issues de Wikip\u00e9dia. Entre ces trois jeux de donn\u00e9es, notre choix s'est port\u00e9 sur WikiSQL, car c'est le plus important d'un point de vue quantitatif, mais aussi parce qu'il fait office de benchmark pour cette t\u00e2che, \u00e9tant souvent cit\u00e9 en ce sens ( (Baik et al., 2019 ), (Lyu et al., 2020) ). De plus dans leur article pr\u00e9sentant le mod\u00e8le, (Herzig et al., 2020) ont pu tester l'apprentissage par transfert de WIKISQL vers un autre jeu de donn\u00e9es avec un certain succ\u00e8s. Notre exp\u00e9rience \u00e9tant fond\u00e9e sur cette application de l'apprentissage par transfert sur des donn\u00e9es traduites, le choix de ce jeu de donn\u00e9 semble justifi\u00e9. De la m\u00eame mani\u00e8re que (Kabbadj, 2018) ont propos\u00e9 une traduction du jeu de donn\u00e9es SQuAD en utilisant l'API de google traduction, nous proposons une version traduite du jeu de donn\u00e9es WikiSQL en utilisant cette m\u00eame API. Cette t\u00e2che de traduction comporte trois \u00e9tapes : -la traduction de la question en langage naturel de l'anglais vers le fran\u00e7ais -la traduction des ent\u00eates des colonnes de la Au lieu de cr\u00e9er un mod\u00e8le contraint \u00e0 une structure de table sp\u00e9cifique, Google a fait le choix d'une approche plus globale en cr\u00e9ant un r\u00e9seau de neurones adapt\u00e9 \u00e0 toute forme de jeu de donn\u00e9es tabulaires. Son mod\u00e8le TAPAS r\u00e9utilise l'architecture de l'encodeur BERT, en y ajoutant des plongements suppl\u00e9mentaires. L'ajout le plus notable au mod\u00e8le de base BERT est l'int\u00e9gration d'informations suppl\u00e9-mentaires pour l'encodage de l'entr\u00e9e textuelle. Tapas exploite les incorporations apprises pour les index de ligne et de colonne ainsi que pour un index de rang sp\u00e9cial qui repr\u00e9sente l'ordre des \u00e9l\u00e9ments dans les colonnes num\u00e9riques. L'architecture obtenue surpasse actuellement les autres mod\u00e8les pour l'interrogation en langage naturel de donn\u00e9es tabulaires. Le mod\u00e8le TAPAS est assez similaire \u00e0 BERT mais il en diff\u00e8re par l'ajout \u00e0 son tokenizer des plongements des positions relatives, ainsi que sept tokens mod\u00e9lisant les tables. TAPAS est pr\u00e9-appris sur une t\u00e2che de mod\u00e8le masqu\u00e9 1 , \u00e0 l'aide de millions de tables venant de la version anglaise de Wikipedia et les textes correspondants. Enfin, TAPAS est entra\u00een\u00e9 plus finement sur une t\u00e2che des r\u00e9ponses aux questions. Le mod\u00e8le cherche alors \u00e0 pr\u00e9dire deux choses : les cellules correctes associ\u00e9es \u00e0 la r\u00e9ponse et l'agr\u00e9gateur correspondant. Application et r\u00e9sultats 4.1 Apprentissage du mod\u00e8le Outre les ajouts et modifications apport\u00e9s au mod\u00e8le BERT originel d\u00e9crit pr\u00e9c\u00e9demment, TAPAS suit un protocole d'apprentissage en trois \u00e9tapes qui s'appuie sur plusieurs jeux de donn\u00e9es. La premi\u00e8re \u00e9tape consiste en un pr\u00e9-entra\u00eenement sur un jeu de donn\u00e9es de 6,2 millions de tables anglophones extraites de Wikipedia suivant le mod\u00e8le de masquage propos\u00e9 dans BERT (Devlin et al., 2019) . Le but ici est d'initialiser l'entra\u00eenement du mod\u00e8le \u00e0 partir du contexte constitu\u00e9 des \u00e9l\u00e9ments qui composent la table trait\u00e9e : la t\u00e2che consiste \u00e0 retrouver certains \u00e9l\u00e9ments masqu\u00e9s de ce contexte. Cette \u00e9tape de pr\u00e9-apprentissage est suivie d'une \u00e9tape d'ajustement fin (fine tuning) qui finalise 1. Masked language modeling (MLM) Dans leurs travaux les plus r\u00e9cents sur le mod\u00e8le (Eisenschlos et al., 2020) , les auteurs ont ajout\u00e9 une \u00e9tape interm\u00e9diaire d'apprentissage. Pour notre exp\u00e9rimentation, nous sommes partis de ce mod\u00e8le ayant b\u00e9n\u00e9fici\u00e9 de ce pr\u00e9-entra\u00eenement suppl\u00e9mentaire. Exp\u00e9rimentation sur les donn\u00e9es francophones Le but de l'exp\u00e9rimentation est de d\u00e9terminer dans quelle mesure ce nouveau jeu de donn\u00e9es francophones impacte les performances du mod\u00e8le TAPAS. Ainsi l'un des mod\u00e8les TAPAS entra\u00een\u00e9 sur WikiSQL pour la langue anglaise sert de mod\u00e8le t\u00e9moin. \u00c0 cela on compare un mod\u00e8le suivant la m\u00eame architecture et ayant re\u00e7u le m\u00eame pr\u00e9-entra\u00eenement, mais dont l'entra\u00eenement fin a \u00e9t\u00e9 r\u00e9alis\u00e9 sur le nouveau jeu de donn\u00e9es francophones. Les deux jeux de donn\u00e9es sont alors test\u00e9s sur leurs jeux de donn\u00e9es respectifs. Un sch\u00e9ma r\u00e9capitule ce processus en figure 3 , les indicateurs de sont les m\u00eames que ceux d\u00e9crits dans l'article originel de Tapas. Conclusion et travaux futurs Si les r\u00e9sultats propres de l'exp\u00e9rience ne permettent pas d'en d\u00e9duire pour l'instant une r\u00e9elle efficacit\u00e9 du mod\u00e8le en situation r\u00e9elle, ils permettent n\u00e9anmoins d'encourager cette approche de traduction de jeu de donn\u00e9es. En effet on peut esp\u00e9rer de meilleurs r\u00e9sultats avec un apprentissage plus long, ou un jeu de donn\u00e9es traduit et relu, ce qui all\u00e9gerait la t\u00e2che d'expertise humaine n\u00e9cessaire \u00e0 l'obtention d'un jeu de donn\u00e9es pour cette t\u00e2che de traitement de requ\u00eates en fran\u00e7ais sur des donn\u00e9es tabulaires. De plus ces r\u00e9sultats nous \u00e9clairent sur l'usage de l'apprentissage fin, qui permet d'une part d'adapter plus facilement de larges mod\u00e8les \u00e0 de nouvelles langues, et d'autre part d'\u00e9viter de travailler sur des mod\u00e8les complets souvent tr\u00e8s volumineux ; dans notre cas les donn\u00e9es de pr\u00e9-apprentissage forment un corpus de 6.2 millions de tables. Enfin, des r\u00e9sultats compl\u00e9mentaires permettront d'affiner les conclusions et perspectives de cette \u00e9tude, comme sur l'influence de la traduction sur les performances d'exactitude. On peut aussi imaginer un mod\u00e8le suivant la m\u00eame architecture mais prenant en compte des donn\u00e9es francophones sur chaque \u00e9tape de l'apprentissage. R\u00e9f\u00e9rences AIKEN M. ( 2019 ). An updated evaluation of google translate accuracy. Studies in Linguistics and Literature, 3, p253. DOI : 10.22158/sll.v3n3p253. 2. Tels que pr\u00e9sent\u00e9s dans l'article de (Eisenschlos et al., 2020) , apr\u00e8s entra\u00eenement sur TPU.",
    "funding": {
        "military": 0.0,
        "corporate": 0.0,
        "research agency": 0.0,
        "foundation": 3.128162811005808e-07,
        "none": 0.9999998063873687
    }
}