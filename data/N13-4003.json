{
    "article": "Outline Due to easy to use apps (Facebook, Twitter, etc.), higher Internet connectivity and always on facility allowed by smart phones, the key characteristics of raw data are changing. This new data can be characterized by 4V's -Volume, Velocity, Variety and Veracity. For example during a Football match, some people will Tweet about goals, penalties, etc., while others may write longer blogs and further there will be match reports filed in trusted online news media after the match. Although the sources may be varied, the data describes and provides multiple evidences for the same event. Such multiple evidences should be used to strengthen the belief in the underlying physical event as the individual data points may have inherent uncertainty. The uncertainty can arise from inconsistent, incomplete and ambiguous reports. The uncertainty is also because the trust levels of the different sources vary and affect the overall reliability. We will summarize various efforts to perform reliability aware entity integration. The other problem in text analysis in such setting is posed by presence of noise in the text. Since the text is produced in several informal settings such as email, blogs, tweet, SMS, chat and is inherently noisy and has several veracity issues. For example, missing punctuation and the use of non-standard words can often hinder standard natural language processing techniques such as part-of-speech tagging and parsing. Further downstream applications such as entity extraction, entity resolution and entity completion have to explicitly handle noise in order to return useful results. Often, depending on the application, noise can be modeled and it may be possible to develop specific strategies to immunize the system from the effects of noise and improve performance. Also the aspect of reliability is key as a lot of this data is ambiguous, incomplete, conflicting, untrustworthy and deceptive. The key goals of this tutorial are: 1. Draw the attention of researchers towards methods for doing entity analytics and integration on data with 4V characteristics. 2. Differentiate between noise and uncertainty in such data. 3. Provide an in-depth discussion on handling noise in NLP based methods. 4. Finally, handling uncertainty through information fusion and integration. This tutorial builds on two earlier tutorials: NAACL 2010 tutorial on Noisy Text and COMAD 2012 tutorial on Reliability Aware Data Fusion. In parallel the authors are also hosting a workshop on related topic \"Reliability Aware Data Fusion\" at SIAM Data Mining Conference, 2013. Outline 2.1 Data with 4V characteristics",
    "abstract": "",
    "countries": [
        "India"
    ],
    "languages": [
        ""
    ],
    "numcitedby": "1",
    "year": "2013",
    "month": "June",
    "title": "{NLP} for uncertain data at scale"
}