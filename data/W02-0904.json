{
    "article": "Many lexical semantic relations, such as the hyponymy relation, can be extracted from text as they occur in detectable syntactic constructions. This paper shows how a hypernym-hyponym based lexicon for Swedish can be created directly from a news paper corpus. An algorithm is presented for building partial hierarchical structures from non domain-specific texts. Introduction Automatic acquisition of information on semantic relations from text has become more and more popular during the last ten to fifteen years. The goal has been to build various types of semantic lexicons for use in natural language processing (NLP) systems, such as systems for information extraction/retrieval or dialog systems. The lexicons are used to introduce extended semantic knowledge into the different systems. Hand-built general-purpose lexicons, such as the WordNet (Fellbaum, 1998) , have often been used to bring semantic knowledge into NLP-systems. Two important problems concerning (semantic) lexicons are those of domain coverage and updates. Firstly, a general-purpose lexicon cannot be expected to cover all specific words used in different sub-domains. Therefore, the need for domain-specific lexicons has recently been brought to the surface. Secondly, any lexicon, general or specific, has to be updated from time to time, in order to keep up with new words and new uses of existing words. Our minimally supervised method for automatically building partial hierarchies presents one way to solve the update problem. The objective of this project is to automatically build a hierarchical hyponymy lexicon of noun phrases given large, part-of-speech tagged and lemmatized corpora that are not restricted to one specific domain or topic. The lexicon will thus, reflect partial hierarchical hyponymy structures that bring forward extended hypernym-hyponym relations. Section 2 describes previous work in the area of automatic acquisition of semantic lexicons, section 3 elaborates on the principles for this work, and the remaining sections describe the implementation as well as the evaluation of the algorithm for building a hierarchical hyponymy lexicon. Previous work One of the first studies on acquisition of hyponymy relations was made by Hearst (1992) . She found that certain lexico-syntactic constructions can be used as indicators of the hyponymy relation between words in text. Example 1 shows a relation of this kind and an example. The noun phrase ' \u00a2\u00a1 \u00a4\u00a3 ' is a hypernym and '\u00a5 \u00a6\u00a5 \u00a7\u00a1 \u00a9 \u00a4 \u00a2\u00a1 \u00a9 \"! $# % '& ( \u00a7\u00a1 0) ' is one or more (conjoined) noun phrases that are the hyponyms: 1 '2 43 5 \u00a2\u00a1 \u00a4\u00a3 76 1 \u00a5 \u00a6\u00a5 \u00a7\u00a1 \u00a98 9 \u00a9 \u00a7\u00a1 4 @ \"! $# % '& ( \u00a7\u00a1 0) (1) 'such cars as Volvo, Seat and Ford' Hearst proposed furthermore, that new syntactic patterns can be found in the following way: 1. Use the list of hypernyms-hyponyms found by the type of pattern described above to search for places in the corpus where the two expressions occur syntactically close to each other. Save the syntactic examples. 2. Examine all saved syntactic environments and find new useful syntactic patterns. 3. Use each new pattern to find more hypernymhyponym examples. Continue at 1. Caraballo (1999) uses a hierarchical clustering technique to build a hyponymy hierarchy of nouns. The internal nodes are labeled by the syntactic constructions from Hearst (1992) . Each internal node in the hierarchy can be represented by up to three nouns. Work by Riloff & Shepherd (1997) and Charniak & Roark (1998) aims to build semantic lexicons where the words included in each category or entry are related to, or are a member of the category. Sanderson & Croft (1999) build hierarchical structures of concepts on the basis of generality and specificity. They use material divided by different text categories and base the decision of subsumption on term co-occurrence in the different categories. A term x is said to subsume y if the documents in which y occurs are a subset of the documents in which x occurs. The relations between concepts in their subsumption hierarchy are of different kinds (among other the hyponymy relation), and are unlabeled. The work most similar to ours is that of Morin & Jacquemin (1999) . They produce partial hyponymy hierarchies guided by transitivity in the relation. But while they work on a domain-specific corpus, we will acquire hyponymy data from a corpus which is not restricted to one domain. Principles for building a hierarchical lexicon This section will describe the principles behind our method for building the hierarchical structures in a lexicon. As the objective is to build a nominal hyponymy lexicon with partial hierarchical structures, there are conditions that the hierarchical structures should meet. The structures can each be seen as separate hyponymy hierarchies, and for each hierarchy the following criteria should be fulfilled: 1. A hierarchy has to be strict, so that every child node in it can have one parent node only. 2. The words or phrases forming the nodes in a hierarchy should be disambiguated. 3. The organization in a hierarchy should be such that every child node is a hyponym (i.e. a type/kind) of its parent. Generally, principle 1-2 above are meant to prevent the hierarchies from containing ambiguity. The built-in ambiguity in the hyponymy hierarchy presented in (Caraballo, 1999) is primarily an effect of the fact that all information is composed into one tree. Part of the ambiguity could have been solved if the requirement of building one tree had been relaxed. Principle 2, regarding keeping the hierarchy ambiguity-free, is especially important, as we are working with acquisition from a corpus that is not domain restricted. We will have to constrain the way in which the hierarchy is growing in order to keep it unambiguous. Had we worked with domain-specific data (see e.g. Morin and Jaquemin (1999) ), it would have been possible to assume only one sense per word or phrase. The problem of building a hyponymy lexicon can be seen as a type of classification problem. In this specific classification task, the hypernym is the class, the hyponyms are the class-members, and classifying a word means connecting it to its correct hypernym. The algorithm for classification and for building hierarchies will be further described in section 6. Corpus and relevant terms This work has been implemented for Swedish, a Germanic language. Swedish has frequent and productive compounding, and morphology is richer compared to, for example, English. Compounding affects the building of any lexical resource in that the number of different word types in the language is larger, and thus, the problems of data sparseness become more noticeable. In order to, at least partly, overcome the data sparseness problem, lemmatization has been performed. However, no attempt has been made to make a deeper analysis of compounds. The corpus used for this research consists of 293,692 articles from the Swedish daily news paper 'Dagens Nyheter'. The corpus was tokenized, tagged and lemmatized. The tagger we used, implemented by Megyesi (2001) for Swedish, is the TnT-tagger (Brants, 2000) , trained on the SUC Corpus (Ejerhed et al., 1992) . After preprocessing, the corpus was labeled for base noun phrases (baseNP). A baseNP includes optional determiners and/or premodifiers, followed by nominal heads. Naturally, conceptually relevant terms, rather than noun phrases, should be placed in the lexicon and the hierarchies. For reasons of simplification, though, the choice was made as to treat nominal heads with premodifying nouns in genitive (within the limits of the baseNP described above) as the relevant terms to include in the hierarchies. However, premodifiers describing amounts, such as 'kilo', are never included in the relevant terms. Lexico-syntactic constructions Lexico-syntactic constructions are extracted from the corpus, in the fashion suggested by Hearst (1992) . Five different Swedish constructions has been chosen -constructions 2-6 below -as a basis for building the lexicon (an example with the English translation is given below for each construction) 1 : A B C! C \" @ \u00a2\u00a1 \u00a4\u00a3 A % 'D \u00a5 \u00a6\u00a5 \u00a7\u00a1 \u00a9 9 9 $ E \u00a7\u00a1 \u00a9F% G IH \u00a9# P RQ SQ SP T& ( \u00a2\u00a1 U) (2) 's\u00e5dana k\u00e4nslor som medk\u00e4nsla och barmh\u00e4rtighet' /lit. such feelings as sympathy and compassion/ \u00a7\u00a1 \u00a9\u00a3 \u00a5 A B V A % WD \u00a5 \u00a6\u00a5 \u00a7\u00a1 4 9 \u00a9 U \u00a7\u00a1 \u00a9F% G IH \u00a9# P RQ XQ YP T& 8 ( \u00a7\u00a1 U) (3) 'exotiska frukter som papaya, pepino och mango' /lit. exotic fruits such as papaya, pepino and mango/ \u00a7\u00a1 0) \u00a5 ` \u00a2\u00a1 \u00a9 a 4 b% G IH \u00a9# P RQ SQ SP T& c C F \" d \u00a2\u00a1 \u00a4\u00a3 (4) 'trafikinformation och annan information' /lit. information on traffic and other information/ \u00a7\u00a1 0) \u00a5 ` \u00a7\u00a1 \u00a9 V 4 e% G IH \u00a9# P TQ SQ YP I& fQ Xg ih ( \" C \"! CP \" \u00a7\u00a1 \u00a4\u00a3 (5) 1 Construction six requires a numerical expression (num.expr.) greater than one. 'riksdagen, stadsfullm\u00e4ktige och liknande f\u00f6rsamlingar' /lit. the Swedish Parliament, the town councilor and similar assemblies/ \u00a7\u00a1 U) \u00a5 ` \u00a2\u00a1 \u00a9 V 4 e% G IH \u00a9# P RQ XQ YP T& \u00a7\u00a1 \u00a4 \u00a4 Fp 9D bq rP Is t u& 'q v \u00a7\u00a1 \u00a4\u00a3 (6) ' \u00d6sterleden och V\u00e4sterleden, de tv\u00e5 motorv\u00e4gsprojekt' /lit. the East way and the West way, the two highway projects/ The basic assumption is that these constructions (henceforth called hh-constructions), yield pairs of terms between which the hyponymy relation holds. After a manual inspection of 20% of the total number of hh-constructions, it was estimated that 92% of the hh-constructions give us correct hyponymy relations. Erroneous hh-constructions are mainly due to problems with, for example, incorrect tagging, but also change in meaning due to PP-attachment. Building the hierarchical lexicon To give an accurate description of the algorithm for building the lexicon, the description here is divided into several parts. The first part describes how hypernyms/hyponyms are grouped into classes, building an unambiguous lexicon base. The second part describes how arrangement into hierarchical structures is performed from this unambiguous data. Last, we will describe how the lexicon is extended. Classification There are two straightforward methods that can be used to classify the data from the hh-constructions. The first would be to group all hypernyms of the same lemma into one class. The second would be to let each hypernym token (independently of their lemma) initially build their own class, and then try to group tokens according to their sense. The first method is suitable for building classes from the hhconstructions for a domain-specific corpus. However, when working with a news paper corpus, as in our case, this method would lead to possible ambiguity in the classes, as hypernyms of the same lemma can have more than one sense. Thus, we choose to take the second, more cumbersome approach in order to avoid all possible ambigu-'...fever, pain, and other symptoms...' Hypernym: symptom; Hyponyms: fever, pain w class: symptom 3 class feature: symptom; class members: fever, pain Table 1 : Example of how an initial class is created from a simple hh-construction. ity in the lexicon. Avoiding ambiguity is important as the result of classification will be used as a base for building a lexicon with hierarchical structures. Initially, the hypernym and hyponyms of the hhconstructions from the text are used to build a base for a class system. An example of how an initial class is created from a simple hh-construction is given in Table 1 . Each class X N has a class feature X which is the hypernym's lemma, where N is a unique number designating the unique class and where the class members are the hyponym lemmas. After this initial step, the unique classes are grouped into larger classes. Constraints are put on the grouping process in order to keep the classes unambiguous. 2 Two classes A and B can only be collapsed if they fulfill the following two prerequisites: 1. The class features of the classes have to be the same. 2. There has to be a non-empty intersection in class members between the classes. An example of a collapsing operation of this kind is given in Table 2 . As can be seen in the table, the method captures correct sense distinctions as well as incorrect ones (i.e. two classes are created when there should be only one). The effect of this will be further discussed in section 8. Note however, that some incorrect sense distinctions introduced here are corrected through the introduction of hierarchical structure, which will be discussed in the next section. Building hierarchical structure Hierarchical structure is introduced in the lexicon through a number of rules, which are directed by  the over all principle of transitivity in the hyponymy relation. That is, if X is a kind of Y, and Y is a kind of Z, then the two classes containing these pairs can only be composed if the hyponymy relation also holds between X and Z. In practice, the three hypernym-hyponym pairs X-Y, Y-Z and X-Z all have to be found in our corpus. 3  Next, we will turn to the outline of the implementation for building the hierarchical structures from the classes created through the method described in the previous section: 1. For each class k among all classes: a. find all sets of classes that can be used in building hierarchies with class k. b. choose one set of classes that should be used. 2. Compose all chosen sets of classes. 3. Build trees that reflect all the implemented compositions. A typical hierarchical structure of the kind that is built here can be seen in Figure 1 . The algorithm for building this hierarchical structure will now be described in more detail: Searching for a set of classes for composition is performed according to the transitivity principle described above. For each hypernym-hyponym pair f ) \u00a7 hg \") (see example below), search for two other classes (class 2 and 3) that contains the hypernym-hyponym pairs f \u00a8 ji ) and g \u00a8 ki 3For further discussion about transitivity in trees, see (Woods, 1997) . respectively: Class 1 l f ) U mq nq nq vg \") T Iq nq nq /symptom 2: A Rx D yt u d% WD \u00a8-FP I oP I& , g Q XD P T F p) , t 9 g / Class 2 l f q mq nq nq ri @) R Iq nq nq  In this way, several compositions might cowork to build trees, and the more compositions that are used, the deeper the tree will be. It is worth noting that, when any tree is built, end nodes (i.e. non-internal hyponyms) with the same lemma as other end nodes in the collapsed tree are moved downwards in the tree. The goal is to keep only one instance, i.e. the one that is placed lowest in the tree. Also, measures are taken all along in the building process in order to keep the tree acyclic. Extending the lexicon Obviously, apart from the hypernym-hyponym data that we get from the hh-constructions listed in section 5, more data can be found in text. In order to capture some of the data, we propose a similar but simpler algorithm to that of Hearst (1992) . The algorithm is simpler in that it does not search for new syntactic environments that reveals the hypernymhyponym relation. Instead, it relies on the general syntactic pattern in step 2 (below) for finding new lexical hypernym-hyponym data: 1. Look through the previously extracted hh-constructions and extract the pairs of hypernyms-hyponyms where the frequency of the pair is higher than 2. 2. Search in new data for patterns of the following kind: \u00a7\u00a1 \u00a4\u00a3 (funcword)+ \u00a2\u00a1 \u00a4\u00a8( \u00a7\u00a1 4 ,)* and # or \u00a7\u00a1 0) where \u00a7\u00a1 \u00a4\u00a3 is a baseNP, where (funcword)+ is one or more function words 5 and where the sequence '( \u00a2\u00a1 \u00a9 , (and # or))+ \u00a7\u00a1 0) ' is a conjoined noun phrase. Extract related hypernyms and hyponyms where: a. hypernym from step 1. is head in \u00a7\u00a1 \u00a9\u00a3 b. hyponym from step 1. is head in one of the noun phrases in the conjoined noun phrase. Results & Evaluation The number of extracted hh-constructions from the original corpus is 14,828. Statistics describing changes in the data throughout the implementation is presented in Table 3 . The table shows the change in number of top nodes as well as in the number of d-pairs. A d-pair is defined as an ordered pair of terms w ex \u00a6 \u00a6y {z in the hierarchy where t1 dominates t2, and where t1 u v t2. For example, from the hierarchy in Figure 1 we get eight d-pairs. The statistics in the last column in Table 3 presents the number of d-pairs per top node in the data. This is suggested as a measurement of how complex the partial hierarchies are on average. The three values in Table 3 -number of top nodes, number of d-pairs and d-pairs per top node -are given for the original data, the original with the extended data, the classified data and for the data when hierarchical structure is introduced. Values are also given for two possible extracted lexicons (see below). As can be seen in Table 3 , the number of d-pairs increased through the introduction of hierarchies by 2,071 d-pairs (from 22,832 to 24,903 pairs). The relatively low number of new hyponymy relations (that is d-pairs) is disappointing, but with improvements discussed later, the number could hopefully be increased. Evaluation of semantic hierarchies or lexicon always presents a challenge. Usually, human judges are used to evaluate the result, or the result is compared against a gold-standard resource. Lacking a suitable Swedish gold-standard, our method is evaluated with human judges. In building a usable lexicon from the data, we try to exclude hierarchies with few terms in them. Several options were tested and two of them are presented in Table 3 : one lexicon where all top nodes had at least seven descendants (lexicon-7) and one where all top nodes had at least ten descendants (lexicon-10). The latter, lexicon-10, was used in evaluation. That is, 1,000 of the d-pairs from lexicon-10 was randomly picked in order to evaluate the partial hierarchies and new hyponymy relations. Four human judges were to decide, for each pair, if they thought it was a correct pair or not. The result, presented in Table 4 , is in the range of 52.2% to 76.6% correct. Table 5 presents five ways to look at the result. The first gives the average result over the four judges. The second, at-least-one, gives the percentage of d-pairs where at least one of the judges deemed the pair as correct. The majority is the percentage of d-pairs where at least two deemed the pair as correct, and the consensus option refers to the percentage of d-pairs where all judges agreed. The at-least-one option, the least strict of the measures, give us 82.2% correct, while the most strict (the consensus) gives us 41.6% correct. The kappa value (Carletta, 1996) was used to evaluate the agreement among the judges and to estimate how difficult the evaluation task was. surprisingly, as evaluation of semantic information, in general, is hard to perform on purely objective grounds, the kappa value is rather low; that is, the value for four annotators on the 1,000 d-pairs is K=0.51. The low kappa value for the evaluation task reflects the great many problems of evaluations of semantic resources by humans. Some of these problems are discussed below: While lemmatization or stemming is necessary for performing this kind of task, it may also cause problems in cases where morphology is important for correct classification. For example, while the plural form of the word 'boy' (i.e. 'boys') is a valid hyponym of the hypernym 'group', the singular form would not be. As was also reported by Caraballo (1999) , the judges sometimes found proper nouns (as hyponyms) hard to evaluate. E.g. it might be hard to tell if 'Simon Le Bon' is a valid hyponym to the hypernym 'rock star' if his identity is unknown to the judge. One way to overcome this problem might be to give judges information about a sequence of higher ancestors, in order to make the judgement easier. It is difficult to compare these results with results from other studies such as that of Caraballo (1999) , as the data used is not the same. However, it seems that our figures are in the same range as those reported in previous studies. Charniak & Roark (1998) , evaluating the semantic lexicon against gold standard resources (the MUC-4 and the WSJ corpus), reports that the ratio of valid to total entries for their system lies between 20% and 40%. Caraballo (1999) let three judges evaluate ten internal nodes in the hyponymy hierarchy, that had at least twenty descendants. Cases where judges had problems with proper nouns as hyponyms, corresponding to these mentioned above, were corrected. When the best hypernym was evaluated, the result reported for a majority of the judges was 33%. Discussion and future work In this paper, we have mainly been concentrating on algorithm development for building the partial hierarchies and on evaluating the quality of the hyponymy relations in the hierarchies. In future work we will continue to put our efforts to include more of the extracted data into the hierarchies. In classification of hh-construction data (section 6.1), for example, there is a great many classes that are never collapsed where there should have been a collapse. That is, correct sense distinction is captured (through correct collapses), but incorrect sense distinction is also introduced due to lack of overlap in hyponyms. For example, if two classes with the hypernym 'animal' are found where there is no nonempty intersection in hyponyms, 'animal' will incorrectly be treated as having two senses. This is a side effect of the method we are using in order to get disambiguated data to build hierarchies from. In most cases, introduction of incorrect sense distinction is due to one of two situations: first, when the hypernym only has proper noun hyponyms (e.g. 'person' or 'artist'), the overlap in hyponyms tends to be small. Secondly, when the hypernym is a very general concept, for example 'part', 'question' or 'alternative', the hyponyms will rarely overlap. No assessment of the scope of these problems has been performed in this study. A more thorough investigation ought to be performed in order to know how to overcome the problem of incorrect sense distinctions. Also, the kind of general, underspecified hypernyms, such as 'question' mentioned above are rarely meaningful as concepts on their own. As discussed by Hearst (1992) , more information is needed to solve the underspecification, and the missing information is probably found in previous sentences. An improved algorithm has to deal with this problemeither in excluding this type of hypernyms, or in improving on the concepts by finding information that solves the underspecification. Modification in the algorithm to impose hierarchi-cal structure should be carried out in the future, so that more compositions are performed for each class (as discussed in section 6.2). This, together with a more elaborate extension algorithm (section 6.3) should give us further hierarchical links in the lexicon. Compound analysis and improvements on term extraction for Swedish will also be helpful in future work. Improvements would possibly lead to more collapses by the algorithm presented in section 6.1, which in turn would reduce the number of incorrect sense distinctions. The resulting hierarchies are not fully strict, e.g. descendants of the same lemma type can occasionally be found in different branches of the same tree. This has to be dealt with in future implementations, as well. Conclusions We have shown how an unambiguous hypernymhyponym lexicon with partial hierarchies can be built from data that is unrestricted by domain. The algorithm has been implemented for Swedish, but we can assume that the method easily can be applied to other languages as well. Even though the number of hierarchical structures imposed by the method is rather low, the quality of the hyponymy relations is good and we believe that improvements in the algorithm will increase the number of partial hierarchies. Acknowledgments Many thanks to Kjell Elenius for making the corpus of news texts available to me, to the human judges for their patience with the difficult evaluation task, to Rolf Carlson, Be\u00e1ta Megyesi and Sofia Gustafson-Capkov\u00e1 for helpful comments and discussions. Many thanks also for helpful suggestions for improvements from the anonymous reviewers. This research was supported by CTT's industrial partners, KHT, VINNOVA and the Swedish National Graduate School of Language Technology.",
    "abstract": "Many lexical semantic relations, such as the hyponymy relation, can be extracted from text as they occur in detectable syntactic constructions. This paper shows how a hypernym-hyponym based lexicon for Swedish can be created directly from a news paper corpus. An algorithm is presented for building partial hierarchical structures from non domain-specific texts.",
    "countries": [
        "Sweden"
    ],
    "languages": [
        "Swedish",
        "English"
    ],
    "numcitedby": "40",
    "year": "2002",
    "month": "July",
    "title": "Building a hyponymy lexicon with hierarchical structure"
}