{
    "article": "Logical reasoning is of vital importance to natural language understanding. Previous studies either employ graph-based models to incorporate prior knowledge about logical relations, or introduce symbolic logic into neural models through data augmentation. These methods, however, heavily depend on annotated training data, and thus suffer from overfitting and poor generalization problems due to the dataset sparsity. To address these two problems, in this paper, we propose MERIt, a MEta-path guided contrastive learning method for logical ReasonIng of text, to perform selfsupervised pre-training on abundant unlabeled text data. Two novel strategies serve as indispensable components of our method. In particular, a strategy based on meta-path is devised to discover the logical structure in natural texts, followed by a counterfactual data augmentation strategy to eliminate the information shortcut induced by pre-training. The experimental results on two challenging logical reasoning benchmarks, i.e., ReClor and LogiQA, demonstrate that our method outperforms the SOTA baselines with significant improvements. 1 Introduction Logical reasoning has long been recognized as one key critical thinking ability of human being. Until very recently, some pioneer researchers have crystallized this for the NLP community, and built several public challenging benchmarks, such as ReColor (Yu et al., 2020) and LogiQA (Liu et al., 2020) . Logical reasoning 2 requires to correctly infer the semantic relations with respect to the constituents among different sentences. A typical formulation of logical reasoning is illustrated * Corresponding author: Yangyang Guo and Liqiang Nie. 1 Our code and pre-trained models are available at https: //github.com/SparkJiao/MERIt. 2 We refer the term logical reasoning to the task itself in the remaining of this paper. in Figure 1 , namely, a real-world examination instance from ReClor. As can be seen, to find the correct answer for the given question, one needs to extract the logical structures residing in a pair of each option and the whole context, and justify its reasonableness. As a matter of fact, logical reasoning is still at its initial stage, thence, existing studies are somewhat rare in literature. Some efforts have been devoted to designing specific model architectures or integrating symbolic logic as the hints attached to the potential logical structure. For instance, Huang et al. (2021) and Ouyang et al. (2021) first constructed a graph of different constituents and then performed implicit reasoning with graph neural networks (GNNs). Wang et al. (2022) proposed LReasoner, a unified context extension and data augmentation framework based on the parsed logical expressions. These approaches have achieved some progress on benchmark datasets. However, though equipped with pre-trained language models, they still suffer from problems like overfitting and poor generalization. We attribute these drawbacks to the difficulty of building a model aware of the logical relations beneath natural language, which is revealed from two sides: 1) the high sparsity of the existing datasets, and 2) the goal of general pre-training, i.e., masked language modeling (Devlin et al., 2019) , which however, deviates largely from that of the logical reasoning. To tackle this issue, we aim to build a bridge between logical reasoning and self-supervised pre-training, and accordingly inherit the strong generalization power from pre-trained language models. Our proposed method is inspired by the recent progress of contrastive learning based pre-training. It mainly consists of two novel components: metapath guided data construction and counterfactual data augmentation. Both components are leveraged to perform automatic instance composition from unlabeled corpus (e.g., Wikipedia) for contrastive learning. Regarding the first component, we propose to employ the meta-path to define a symbolic form of logical structure. The intuition behind this is that the logical structure can be expressed as a reasoning path composed of a series of relation triplets, and a meta-path inherently offers such a means of consistency (Liu et al., 2021) . Specifically, given an arbitrary document and a pair of entities in it, we try to find a positive instance pair in the document according to the logical structure. And the negative ones can thus be generated by modifying the relations involved in the structure, which explicitly break the logical consistency. Nevertheless, the contrastive learning often fails when models easily locate trivial solutions (Lai et al., 2021) . In this context, the pre-trained language model may exclude the negative options through their conflicts with the world knowledge. To eliminate this information shortcut, in our second novel component, we devise a strong counterfactual data augmentation (Zeng et al., 2020b) strategy. By mixing counterfactual data during pre-training, of which the positive instance pair is also against the world knowledge, this component shows more ad-vantage in reasoning over logical relations. We integrate this method with both AL-BERT (Lan et al., 2020) and RoBERTa (Liu et al., 2019) 3 for further pre-training, and then fine-tune them on two downstream logical reasoning benchmarks, i.e., ReClor and LogiQA. The experimental results demonstrate that our method can outperform all the existing strong baselines, yet without any augmentation from the original training data. Besides, the ablation studies also show the effectiveness of the two essential strategies in our method. The contribution of this paper is summarized as follows: 1. We propose MERIt, a MEta-path guided contrastive learning method for logical Reason-Ing of text, to reduce the heavy reliance on annotated data. To the best of our knowledge, we are the first to explore self-supervised pretraining for logical reasoning. 2. We successfully employ the meta-path strategy to mine the potential logical structure in raw text. It is able to automatically generate negative candidates for contrastive learning via logical relation editing. 3. We propose a simple yet effective counterfactual data augmentation method to eliminate the information shortcut during pre-training. 4. We evaluate our method on two logical reasoning tasks, LogiQA and ReClor. The experimental results show that our method achieves the new state-of-the-art performance on two benchmark datasets. 2 Related Work Self-Supervised Pre-training With the success of language modeling based pretraining (Devlin et al., 2019; Brown et al., 2020) , designing self-supervised pretext tasks to facilitate specific downstream ones has been extensively studied thus far. For example, Guu et al. (2020) proposed to train the retriever jointly with the encoder via retrieval enhanced masked language modeling for open-domain question answering. Jiao et al. (2021) devised a retrieval-based pre-training approach to bridge the gap between language modeling and machine reading comprehension by enhancing the evidence extraction ability. Deng et al. (2021) proposed ReasonBERT to facilitate complex reasoning over multiple and hybrid contexts. The model is pre-trained on automatically constructed query-evidence pairs, which involve different types of corpora and long-range relations. In addition, contrastive learning (Hadsell et al., 2006) contributes to a strong toolkit to implement self-supervised pre-training. The key to contrastive learning is to build efficacious positive and negative counterparts. For example, Gao et al. (2021) leveraged Dropout (Srivastava et al., 2014) to build positive pairs from the same sentence while keeping the semantics untouched. Other sentences in the same mini-batch serve as negative candidates to obtain better sentence embeddings. ERICA (Qin et al., 2021) is a knowledge enhanced language model pre-trained through entity and relation discrimination, where the negative candidates are sampled from the pre-defined dictionaries. Nevertheless, directly employing these contrastive learning approaches to logical reasoning is arduous. One possible reason to this is the absence of distant labels or strong assumptions to group the naturally occurring text by its logical structure. Logical Reasoning Logical reasoning has attracted increasing research attention recently. Devising specific model architectures and integrating symbolic logic have been proved to be two effective solutions. For example, Huang et al. (2021) and Ouyang et al. (2021) proposed to extract the basic units for logical reasoning, e.g., the elementary discourse or fact units, and then employed GNNs to model possible relationships. The graph structure of constituents can be viewed as a form of prior knowledge pertaining to logical relations. Differently, Betz et al. (2021) and Clark et al. (2020) used synthetically generated datasets to prove that the Transformer (Vaswani et al., 2017) or pre-trained GPT-2 is able to perform complex reasoning, motivating following researchers to introduce symbolic rules into neural models. For example, Wang et al. (2022) developed a context extension and data augmentation framework, which is based on the extracted logical expressions. Superior performance over its contenders can be observed on the ReClor dataset. In this paper, we propose a self-supervised contrastive learning approach to enhance the logical reasoning ability of neural models. Orthogonal to existing methods, our approach is endowed with two intriguing merits: 1) it shows strong advan-tage in utilizing the unlabeled text data, and 2) the symbolic logic is seamlessly introduced into neural models via the guidance of meta-path for automatic data construction. Preliminary Contrastive Learning Contrastive Learning (CL) aims to learn recognizable representations by pulling the semantically similar examples close and pushing apart the dissimilar ones (Hadsell et al., 2006) . Given an instance x, a semantically similar example x + , and a set of dissimilar examples X \u2212 to x, the objective of CL can be formulated as: L CL = L(x, x + , X \u2212 ) = \u2212 log exp f (x, x + ) x \u2208X \u2212 \u222a{x + } exp f (x, x ) (1) where f is the model to be optimized. Symbolic Logical Reasoning As shown in Figure 1 , given a context containing a series of logical variables {v 1 , v 2 , \u2022 \u2022 \u2022 , v n }, and the relations between them, the logical reasoning objective is to judge whether a triplet v i , r i,j , v j in language, where r i,j is the relation between v i and v j , can be inferred from the context through a reasoning path: v i , r i,j , v j \u2190 (v i r i,i+1 \u2212\u2192 v i+1 \u2022 \u2022 \u2022 r j\u22121,j \u2212\u2192 v j ). ( 2 ) The equation is also referred to symbolic logic rules (Clark et al., 2020; Liu et al., 2021) . Meta-Path Given an entity-level knowledge graph, where the nodes refer to entities and edges are the relations among them, the meta-path connecting two target entities e i , e j can be given as, e i r i,i+1 \u2212\u2192 e i+1 r i+1,i+2 \u2212\u2192 \u2022 \u2022 \u2022 e j\u22121 r j\u22121,j \u2212\u2192 e j , (3) where r i,j denotes the relation between entities e i and e j . The meta-path in the entity-level knowledge graph are often employed as a particular data structure expressing the relation between two indirectly connected entities (Zeng et al., 2020a; Xu et al., 2021) . Method In this paper, we study the problem of logical reasoning on the task of multiple choice question answering (MCQA). Specifically, given a passage P , a question Q and a set of K options O = {O 1 , \u2022 \u2022 \u2022 , O K }, the goal is to select the cor- rect option O y , where y \u2208 [1, K]. Notably, to tackle this task, we devise a novel pre-training method equipped with contrastive learning, where the abundant knowledge contained in the largescale Wikipedia documents is explored. We then transfer the learned knowledge to the downstream logical reasoning task. From Logical Reasoning to Meta-Path In a sense, in MCQA for logical reasoning, both the given context (i.e., passage and question) and options express certain relations between different logical variables (Figure 1 ). Go a step further, following Equation 2 , the relation triplet contained in the correct option should be deduced from the given context through a reasoning path, while that in the wrong options should not. In other words, the context is logically consistent with the correct option only. In light of this, the training instances for our contrastive learning based pre-training should be in the form of a context-option pair, where the context consists of multiple sentences and expresses the relations between the included constituents, while the option should illustrate the potential relations between parts of the constituents. Nevertheless, it is non-trivial to derive such instance pairs from large-scale unlabeled corpus like Wikipedia due to the redundant constituents, e.g., nouns and predicates. In order to address it, we propose to take the entities contained in unlabeled text as logical variables, and Equation 2 can be transformed as: e i , r i,j , e j \u2190 (e i r i,i+1 \u2212\u2192 e i+1 \u2022 \u2022 \u2022 r j\u22121,j \u2212\u2192 e j ). (4) As can be seen, the right part above is indeed a meta-path connecting e i , e j as formulated in Equation 3, indicating an indirect relation between e i , e j through intermediary entities and relations. In order to aid the logical consistency conditioned on entities to be established, we posit an assumption that under the same context (in the same passage), the definite relation between a pair of en-tities can be inferred from the contextual indirect one, or at least not logically contradict to it. Taking the passage in Figure 2 as an example, it can be concluded from the sentences s 1 and s 5 that, the director McKean has cooperated with Stephanie Leonidas. Therefore, the logic is consistent between {s 1 , s 5 } and s 3 . This can be viewed as a weaker constraint than the original one in Equation 2 for logical consistency, yet it can be further enhanced by constructing negative candidates violating logics. Motivated by this, given an arbitrary document D = {s 1 , \u2022 \u2022 \u2022 , s m } , where s i is the i-th sentence, we can first build an entity-level graph, denoted as G = (V, E), where V is the set of entities contained in D and E denotes the set of relations between entities. Notably, to comprehensively capture the relations among entities, we take into account both the external relation from the knowledge graph and the intra-sentence relation. As illustrated in Figure 2 (a), there will be an intra-sentence relation between two entities if they are mentioned in a common sentence. Thereafter, we can derive the pre-training instance pairs according to the meta-paths extracted from the graph, which will be detailed in the following subsections. Meta-Path Guided Positive Instance Construction As defined in Equation 4 , in the positive instances, the answer should contain a relation triplet that is logically consistent with the given context. Since we take the intra-sentence relationship into consideration, given a pair of entities contained in the document, we first collect the sentences mentioning both of them as the set of answer candidates. Accordingly, we then try to find a meta-path connecting the entity pair and hence derive the corresponding logically consistent context. In particular, as shown in Figure 2 (b), given an entity pair e i , e j , we denote the collected answer candidates as A + , and then we use Depth-First Search (Tarjan, 1972) to find a meta-path linking them on G, following Equation 3. Thereafter, the context sentences S corresponding to the answer candidates in A + are derived by retrieving those sentences undertaking the intra-sentence relations during the search algorithm. Finally, for each answer candidate a \u2208 A + , the pair (S, a) is treated as a positive context-answer pair to facilitate our contrastive learning. The details of positive instance generation algorithm are described in Appendix A. Negative Instance Generation In order to obtain the negative instances (i.e., negative context-option pairs) where the option is not logically consistent with the context, the most straightforward way is to randomly sample the sentences from different documents. However, this approach could lead to trivial solutions by simply checking whether the entities involved in each option are the same as those in the given context. In the light of this, we resort to directly breaking the logical consistency of the positive instance pair by modifying the relation rather than the entities in the context or the option, to derive the negative instance pair. In particular, given a positive instance pair (S, a), we devise two negative instance generation methods: the context-oriented and the optionoriented method, focusing on generating negative pairs by modifying the relations involved in the context S and answer a of the positive pair, respectively. Considering that the relation is difficult to be extracted, especially the intra-sentence relation, we propose to implement this reversely via the entity replacement. In particular, for the optionoriented method, suppose that e i , e j is the target entity pair for retrieving the answer a, we first randomly sample a sentence z that contains at least one different entity pair e a , e b from e i , e j as the relation provider. We then obtain the negative option by replacing the entities e a and e b in z with e i and e j , respectively. The operation is equivalent to replacing the relation contained in a with that in z. Formally, we denote the operation as a \u2212 = Relation_Replace(z \u2192 a). Pertaining to the context-oriented negative instance generation method, we first randomly sample a sentence s i \u2208 S, and then conduct the modification process as follows, s \u2212 i = Relation_Replace(z \u2192 s i ), where the entity pair to be replaced in s i should be contained in the meta-path corresponding to the target entity pair e i , e j . Accordingly, the negative context can be written as 2022 ), the neural models are adept at finding a trivial solution through the illusory statistical information in datasets to make correct predictions, which often leads to inferior generalization. In fact, this issue can also occur in our scenario. In particular, since the correct answer is from a natural sentence and describes a real world fact, while the negative option is synthesized by entity replacement, which may conflict with the commonsense knowledge. As a result, the pretrained language model tends to identify the correct option directly by judging its factuality rather than the logical consistency with the given context. For example, as shown in Figure 2 (d) (left), the language model deems a as correct, simply due to that the other synthetic option a \u2212 conflicts with the world knowledge. S \u2212 = S \\ {s i } \u222a {s \u2212 i }. To overcome this problem, we develop a simple yet effective counterfactual data augmentation method to further improve the capability of logical reasoning (Zeng et al., 2020b) . Specifically, given the entities P that are involved in the metapath, we randomly select some entities from P and replace their occurrences in the context and the answer of the positive instance pair (S, a) with the entities extracted from other documents. In this manner, the positive instance also contradicts to the world knowledge. Notably, considering that the positive and negative instance pairs should keep the same set of entities, we also conduct the same replacement for a \u2212 or S \u2212 , if they mention the selected entities. As illustrated in Figure 2 Contrastive Learning based Pre-training As discussed in previous subsection, there are two contrastive learning schemes: option-oriented CL and context-oriented CL. Let A \u2212 be the set of all constructed negative options with respect to the correct option a. The option-oriented CL can be formulated as: L OCL = L(S, a, A \u2212 ). (5) In addition, given C \u2212 as the set of all generated negative contexts corresponding to S, the objective of context-oriented CL can be written as: L CCL = L(a, S, C \u2212 ). ( 6 ) To avoid the catastrophic forgetting problem, we also add the MLM objective during pre-training and the final loss is: L = L OCL + L CCL + L MLM . (7) Fine-tuning During the fine-tuning stage, to approach the task of MCQA, we adopt the following loss function: L QA = \u2212 log exp f (P, Q, O y ) i exp f (P, Q, O i ) , ( 8 ) where O y is the ground-truth option for the question Q, given the passage P . Figure 3 shows the overall training scheme of our method. f is the model to be optimized, \u03b8, \u03c9 0 , \u03c9 1 and \u03c6 are parameters of different modules. During pre-training, we use a 2-layer MLP as the output layer. The parameters of the output layer are denoted as \u03c9 0 , and \u03b8 represents the pre-trained Transformer parameters. As for the fine-tuning stage, we employ two schemes. For simple fine-tuning, we follow Devlin et al. (2019) to add another 2layer MLP with randomly initialized parameters \u03c9 1 on the top of the pre-trained Transformer. In addition, to fully take advantage the knowledge acquired during pre-training stage, we choose to directly fine-tune the pre-trained output layer with optimizing both \u03b8 and \u03c9 0 . In order to address the discrepancy that the question is absent during pretraining, the prompt-tuning technique (Lester et al., 2021) is employed. Specifically, some learnable embeddings with randomly initialized parameters \u03c6 are appended to the input to transform the question in downstream tasks into declarative constraint. Experiment Dataset and Baseline We evaluated our method on two challenging logical reasoning benchmarks, i.e., LogiQA and Re-Clor, with several strong baselines, including the pre-trained language models, DAGN (Huang et al., 2021) , Focal Reasoner (Ouyang et al., 2021) and LReasoner (Wang et al., 2022) . For more details, please refer to Appendix B. Implementation Detail We further pre-trained RoBERTa and ALBERT on Wikipedia for another 500 and 100 steps, respectively, and the batch size for pre-training is set to 4,096. All experiments conducted on downstream tasks are repeated for 5 times with different random seeds. The knowledge graph we used for constructing training data is provided by Qin et al. (2021) . More implementation details can be found in Appendix C. 6 Result and Analysis Overall Results The overall results on ReClor and LogiQA are shown in Table 1 . It can be observed that 1) MERIt outperforms all the strong baselines using the same backbone with significant improvements. Besides, our method achieves the new state-of-theart performance on both datasets. 2) Our method leads to drastic contribution to the original models without further pre-training, i.e., RoBERTa and ALBERT, and the prompt-tuning further enhances our model with a significant performance margin, which both demonstrate the potential of our pretraining method. 3) MERIt achieves better performance on the more difficult split of ReClor (Test-H), indicating that our pre-training method is less affected by the statistical shortcut (Yu et al., 2020) . 4) MERIt + Prompt does not benefit from the framework of LReasoner significantly. This is probably because the basic knowledge about logic rules has been covered in our method. 5) We also report the best result on the test set on LogiQA and ReClor for fair comparison with the published results of LReasoner. It can be observed that in terms of the best accuracy on the test set, our model still outperforms LReasoner consistently based on both RoBERTa and ALBERT. Ablation Study Table 2 shows the results of our ablation studies. To observe the impacts brought by the meta-path strategy, we built a baseline model without the metapath strategy by randomly selecting the sentences in a passage to form the context-answer pairs. From this table we can conclude that: 1) the model without counterfactual data augmentation (-DA) has a severe performance degradation. It suggests that the counterfactual data is essential for MERIt to conduct logical reasoning. As for the  ratio of original data to the counterfactual one, on test set, we found that 1:3 (+ DA 3 ) leads to better performance using prompt tuning while 1:2 (+ DA 2 ) obtains the best performance using simple fine-tuning. 2) The model without the guidance of meta-path (-Meta-Path) demonstrates a much worse performance than MERIt, indicating that the meta-path strategy plays an important role by discovering the potential logic structure. 3) Considering the results of models without the objectives of option-oriented CL and context-oriented CL, it can be seen that both contrastive learning schemes are beneficial for logical reasoning. In addition, the context-oriented CL is more effective than optionoriented CL. One possible reason to this is that the context-oriented CL is more diverse in format since each sentence can be disturbed while the optionoriented CL will make the model pay more attention to the option, leading to a worse generalization during fine-tuning.   achieves improvements. 2) MERIt + Prompt shows better performance under low resource, especially on test-H. Our method trained on 40% data has achieved comparable performance with RoBERTa. Performance with Limited Training Data In addition, on test-H, our method outperforms RoBERTa and LReasoner trained on full dataset using only 20% and 40% training data, respectively, evidently demonstrating the generalization capability of our method. 3) Further improvements to LReasoner become insignificant when consuming more training data. This suggests that the basic logic rules can be easily fitted. Effect of Pre-training Steps In order to explore the effects of pre-training steps, we fine-tuned the models pre-trained for different steps on ReClor and the results are shown in Figure 5 . From the histogram we can find that our method achieves the best performance on dev set at 500 steps. Besides, the model pre-trained with 100 steps (using only around 410k samples) has achieved comparable performance with the best one, indicating that our method is very competitive with few training iterations. Performance on DREAM We also evaluated our method on another benchmark requiring complex reasoning abilities, DREAM (Sun et al., 2019) , to verify its generalization ability to different tasks. As shown in Table 3 , our method can also make significant improvements compared with RoBERTa, demonstrating the generalization ability of our method. Results of DeBERTa Table 4 shows the results of DeBERTa-v2-xlarge and DeBERTa-v2-xxlarge on ReClor, which validate that our method can be scaled to stronger pre-trained language models with significant improvements. Conclusion and Future Work In this paper, we present MERIt, a meta-path guided contrastive learning method to facilitate logical reasoning via self-supervised pre-training. MERIt is built upon the meta-path strategy for automatic data construction and the counterfactual data augmentation to eliminate the information shortcut during pre-training. With the evaluation on two logical reasoning benchmarks, our method has obtained significant improvements over strong baselines relying on task-specific model architecture or augmentation of original dataset. Pertaining to the further work, we plan to strengthen our method from both data construction and model architecture design angles. More challenging instances are expected to be constructed if multiple meta-paths can be considered at the same time. Besides, leveraging GNNs may bring better interpretability and generalization since the graph structure can be integrated into both pre-training and fine-tuning stages. A DFS-based Algorithm for Meta-Path Extraction Algorithm 1 The DFS algorithm to obtain the meta-paths. Input: The graph G = (E, V); The sentences of the document D = {s 1 , \u2022 \u2022 \u2022 , s m }; The entity set of the i-th sentence V i ; Output: P, S, and A + ; 1: for each (e i , e j ) \u2208 V \u00d7 V and i = j do 2: A + = {s k |e i \u2208 V k , e j \u2208 V k }; 3: D = D \\ A + ; 4: cond, P, S \u2190 DFS(e i , {e i }, \u2205, e j , G, D ); 5: if cond is TRUE and A + is not \u2205 then 6: return A + , P, S; for each (e j , s k ) \u2208 V \u00d7 D and (e i , e j ) \u2208 E, e j \u2208 V k do 16: G = (E, V \\ {e j }); ReClor (Yu et al., 2020) is extracted from logical reasoning questions of standardized graduate admission examinations. The held-out test set is further divided into EASY and HARD subsets, denoted as test-E and test-H, respectively. The instances in test-E are biased and can be solved even without knowing contexts and questions by neu-ral models. A leaderboard 4 is also host for public evaluation. LogiQA (Liu et al., 2020) Besides, we also compare the performance with the directly fine-tuned large pre-trained language models, including RoBERTa and ALBERT. C Implementation Detail C.1 Data Construction During the data construction process, we have employed two tricks to improve the complexity of the pretext task: 1. For the sentence z as the relation provider for negative instance construction, the sentences from the document are primarily to be considered because they share the same entities with the context or describe the same topic. This can also be viewed as a trick to avoid trivial solution by checking whether the samples come from the same domain. Another problem is that if z comes from the same document, taking the option-oriented method as example, the replacement may not work if e i = e a and e j = e b . To address it, we will change the order of the entities to be replaced, i.e., swapping the mentions of e i and e j . 2. Similarly, for counterfactual data augmentation, supposing the extracted meth-path of a training instance connects an entity pair e i , e j , e i and e j are always considered to be replaced for generating counterfactual data. And thus the sets of answer candidates A + constructed from other documents, where the corresponding meta-paths also link e i , e j , can be employed as negative candidates directly. The motivation of the trick is to avoid modifications on the original texts as many as possible. C.2 Pre-training Setting We employed the model implementation of Transformer from Huggingface (Wolf et al., 2020) and pytorch 5 framework. The corpus for pre-training is generated from the dataset provided by Qin et al. (2021) 6 , which includes the pre-processed passages from Wikipedia and the recognized entities with their distantly annotated relations. The generated corpus contains one million samples and each sample has 3 negative options. During pre-training, we adopted the LAMB (You et al., 2020) optimizer, warming up the learning rate to the peak and then linearly decaying it. It takes 32 hours on 4 RTX 2080Ti GPUs for RoBERTa pre-training and 3 days on 2 TeslaT4 GPUs for ALBERT pre-training. Other hyperparameters for pre-training are reported in Table 5 . dates construction and counterfactual data generation play similar roles with the anonymization operation. Both of them aim at guiding the model focus on the logical/graph structure. The only assumption our approach built upon is that inferring the consistency defined in Equation 4 is in demand of logical reasoning, which has already been explored in many studies for document-level relation extraction (Zeng et al., 2021 (Zeng et al., , 2020a)) . ALBERT Acknowledgements We sincerely appreciate the valuable comments from all the reviewers to help us make the paper polished. We also greatly thank to Liqiang Jing and Harry Cheng for their kind suggestions. This work is supported by the National Natural Science Foundation of China, No.:U1936203; the Shandong Provincial Natural Science Foundation, No.:ZR2019JQ23; and Young creative team in universities of Shandong Province, No.:2020KJN012. C.3 Hyper-parameters for Fine-tuning The random seeds we utilized for repeated experiments are 42, 43, 44, 45 and 4321. The hyperparameters for fine-tuning are shown in Table 7 . D Case Study for Generated Examples E Results for Linear Probing Table 6 shows the results of linear probing on Re-Clor, where we used a single linear layer as the output layer and only fine-tuned its parameters. As shown in the table, MERIt (100 steps) and MERIt (ALBERT) outperform RoBERTa and AL-BERT on both dev and test set, respectively. F A Different View from Contrastive Graph Representation Learning To understand why the pre-training approach can promote logical reasoning, we provide a different view from the contrastive learning for graphs. Following Qiu et al. ( 2020 ), x and x + in Equation 1 are different sub-graphs extracted from the same graph through random walk with restart (Tong et al., 2006 ) while x \u2212 is sub-graph sampled from a different graph. To avoid the trivial solution by simply checking whether the node indices of two subgraphs match, they also developed an anonymization operation by relabeling the nodes of each subgraph. In fact, our proposed method can be taken as a special case of graph contrastive learning. Firstly, the context and answer based on the meta-path can be viewed as sub-graphs of G. In particular, the answer is the sub-graph with only two nodes (the two entities connected by the meta-path). Secondly, the entity replacement for negative candi-",
    "funding": {
        "defense": 0.0,
        "corporate": 0.0,
        "research agency": 1.0,
        "foundation": 0.0,
        "none": 1.9361263126072004e-07
    },
    "reasoning": "Reasoning: The acknowledgements section of the paper mentions support from the National Natural Science Foundation of China, the Shandong Provincial Natural Science Foundation, and the Young creative team in universities of Shandong Province. These are indicative of funding from research agencies. There is no mention of funding from defense, corporate entities, foundations, or an absence of funding."
}