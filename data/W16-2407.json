{
    "article": "We develop the concept of weighted aligned hypergraph bimorphism where the weights may, in particular, represent probabilities. Such a bimorphism consists of an R \u22650 -weighted regular tree grammar, two hypergraph algebras that interpret the generated trees, and a family of alignments between the two interpretations. Semantically, this yields a set of bihypergraphs each consisting of two hypergraphs and an explicit alignment between them; e.g., discontinuous phrase structures and nonprojective dependency structures are bihypergraphs. We present an EM-training algorithm which takes a corpus of bihypergraphs and an aligned hypergraph bimorphism as input and generates a sequence of weight assignments which converges to a local maximum or saddle point of the likelihood function of the corpus. Introduction In natural language processing alignments play an important role. For instance, in machine translation they show up as hidden information when training probabilities of dictionaries (Brown et al., 1993) or when considering pairs of input/output sentences derived by a synchronous grammar (Lewis and Stearns, 1968; Chiang, 2007; Shieber and Schabes, 1990; Nederhof and Vogler, 2012) . As another example, in language models for discontinuous phrase structures and non-projective dependency structures they can be used to capture the connection between the words in a natural language sentence and the corresponding nodes of the parse tree or dependency structure of that sentence. In (Nederhof and Vogler, 2014) the generation of discontinuous phrase structures has been for-malized by the new concept of hybrid grammar. Much as in the mentioned synchronous grammars, a hybrid grammar synchronizes the derivations of nonterminals of a string grammar, e.g., a linear context-free rewriting system (LCFRS) (Vijay-Shanker et al., 1987) , and of nonterminals of a tree grammar, e.g., regular tree grammar (Brainerd, 1969) or simple definite-clause programs (sDCP) (Deransart and Ma\u0142uszynski, 1985) . Additionally it synchronizes terminal symbols, thereby establishing an explicit alignment between the positions of the string and the nodes of the tree. We note that LCFRS/sDCP hybrid grammars can also generate non-projective dependency structures. In this paper we focus on the task of training an LCFRS/sDCP hybrid grammar, that is, assigning probabilities to its rules given a corpus of discontinuous phrase structures or non-projective dependency structures. Since the alignments are first class citizens, we develop our approach in the general framework of hypergraphs and hyperedge replacement (HR) (Habel, 1992) . We define the concepts of bihypergraph (for short: bigraph) and aligned HR bimorphism. A bigraph consists of hypergraphs H 1 , \u03bb, and H 2 , where \u03bb represents the alignment between H 1 and H 2 . A bimorphism B = (g, A 1 , \u039b, A 2 ) consists of a regular tree grammar g generating trees over some ranked alphabet \u03a3, two \u03a3-algebras A 1 and A 2 which interpret each symbol in \u03a3 as an HR operation (thus evaluating every tree to two hypergraphs), and a \u03a3-indexed family \u039b of alignments between the two interpretations of each \u03c3 \u2208 \u03a3. The semantics of B is a set of bigraphs. For instance, each discontinuous phrase structure or non-projective dependency structure can be represented as a bigraph (H 1 , \u03bb, H 2 ) where H 1 and H 2 correspond to the string component and the tree component, respectively. Fig. 1 shows an example of a bigraph representing a non-projective depen- (y (0) 1 ) out H 2 H 1 \u03bb Figure 1: (a) A sentence with non-projective dependencies is represented in (b) by a bigraph (H 1 , \u03bb, H 2 ). Both hypergraphs H 1 and H 2 contain a distinct hyperedge (box) for each word of the sentence. H 1 specifies the linear order on the words. H 2 describes parent-child relationships between the words, where children form a list to whose start and end the parent has a tentacle. The alignment \u03bb establishes a one-to-one correspondence between the (input vertices of the) hyperedges in H 1 and H 2 . dency structure. We present each LCFRS/sDCP hybrid grammar as a particular aligned HR bimorphism; this establishes an initial algebra semantics (Goguen et al., 1977) for hybrid grammars. The flexibility of aligned HR bimorphisms goes well beyond hybrid grammars as they generalize the synchronous HR grammars of (Jones et al., 2012) , making it possible to synchronously generate two graphs connected by explicit alignment structures. Thus, they can for instance model alignments involving directed acyclic graphs like Abstract Meaning Representations (Banarescu et al., 2013) or Millstream systems (Bensch et al., 2014) . Our training algorithm takes as input an aligned HR bimorphism B = (g, A 1 , \u039b, A 2 ) and a corpus c of bigraphs. It is based on the dynamic programming variant (Baker, 1979; Lari and Young, 1990; Prescher, 2001) of the EM-algorithm (Dempster et al., 1977) and thus approximates a local maximum or saddle point of the likelihood function of c. In order to calculate the significance of each rule of g for the generation of a single bigraph (H 1 , \u03bb, H 2 ) occurring in c, we proceed as usual, constructing the reduct B \u00a3 (H 1 , \u03bb, H 2 ) which generates the singleton (H 1 , \u03bb, H 2 ) via the same derivation trees as B and preserves the probabil-ities. We show that the complexity of constructing the reduct is polynomial in the size of g and (H 1 , \u03bb, H 2 ) if B is an LCFRS/sDCP hybrid grammar. However, as the algorithm itself is not limited to this situation, we expect it to be useful in other cases as well. Preliminaries Basic mathematical notation We denote the set of natural numbers (including 0) by N and the set N \\ {0} by N . For n \u2208 N, we denote {1, . . . , n} by [n] . An alphabet A is a finite set of symbols. We denote the set of all strings over A by A * , the empty string by \u03b5, and A * \\ {\u03b5} by A + . We denote the length of s \u2208 A * by |s| and, for each i \u2208 [|s|], the ith item in s by s(i), i.e., s is identified with the function s : [|s|] \u2192 A such that s = s(1) \u2022 \u2022 \u2022 s(|s|). We denote the range {s(1), . /\u223c = [s(1)] \u223c \u2022 \u2022 \u2022 [s(|s|)] \u223c . Terms, regular tree grammars, and algebras A ranked alphabet is a pair (\u03a3, rk) where \u03a3 is an alphabet and rk : \u03a3 \u2192 N is a mapping associating a rank with each symbol of \u03a3. Often we just write \u03a3 instead of (\u03a3, rk). We abbreviate rk \u22121 (k) by \u03a3 k . In the following let \u03a3 be a ranked alphabet. Let A be an arbitrary set. We let \u03a3(A) denote the set of strings {\u03c3(a 1 , . . . , a k ) | k \u2208 N, \u03c3 \u2208 \u03a3 k , a 1 , . . . , a k \u2208 A} (where the parentheses and commas are special symbols not in \u03a3). The set of well-formed terms over \u03a3 indexed by A, denoted by T \u03a3 (A), is defined to be the smallest set T such that A \u2286 T and \u03a3(T ) \u2286 T . We abbreviate T \u03a3 (\u2205) by T \u03a3 and write \u03c3 instead of \u03c3() for \u03c3 \u2208 \u03a3 0 . A regular tree grammar (RTG) 1 (G\u00e9cseg and Steinby, 1984) is a tuple g = (\u039e, \u03a3, \u03be 0 , R) where \u039e is an alphabet (nonterminals), \u039e \u2229 \u03a3 = \u2205, el- ements in \u03a3 are called terminals, \u03be 0 \u2208 \u039e (initial nonterminal), R is a ranked alphabet (rules); each rule in R k has the form \u03be \u2192 \u03c3(\u03be 1 , . . . , \u03be k ) where \u03be, \u03be 1 , . . . , \u03be k \u2208 \u039e, \u03c3 \u2208 \u03a3 k . We denote the set of all rules with left-hand side \u03be by R \u03be for each \u03be \u2208 \u039e. Since RTGs are particular context-free grammars, the concepts of derivation relation and generated language are inherited. The language of the RTG g is the set of all well-formed terms in T \u03a3 generated by g; this language is denoted by L(g). We define the \u039e-indexed family (D \u03be g | \u03be \u2208 \u039e) of mappings D \u03be g : T \u03a3 \u2192 P(T R ); for each term t \u2208 T \u03a3 , D \u03be g (t) is the set of t's derivation trees in T R which start with \u03be and yield t. Formally, for each \u03be \u2208 \u039e and \u03c3 (t 1 , . . . , t k ) \u2208 T \u03a3 , the set D \u03be g (\u03c3(t 1 , . . . , t k )) contains each term (d 1 , . . . , d k ) where = (\u03be \u2192 \u03c3(\u03be 1 , . . . , \u03be k )) is in R and d i \u2208 D \u03be i g (t i ) for each i \u2208 [k]. We define D g (t) = \u03be\u2208\u039e D \u03be g (t) and D \u03be g (T \u03a3 ) = t\u2208T \u03a3 D \u03be g (t). Finally, D \u03be 0 g (T \u03a3 , \u03be) is the set of all \u03b6 \u2208 T R ({\u03be}) such that there is a \u03b6 \u2208 D \u03be 0 g (T \u03a3 ) which has a subtree whose root is in R \u03be , and \u03b6 is obtained from \u03b6 by replacing exactly one of these subtrees by \u03be. Example 2.1. Let \u03a3 = \u03a3 0 \u222a \u03a3 2 where \u03a3 0 = {\u03c3 2 , \u03c3 4 , \u03c3 5 } and \u03a3 2 = {\u03c3 1 , \u03c3 3 }. Let g be an RTG 1 in this context we use \"tree\" and \"term\" as synonyms with initial nonterminal S and the following rules: S \u2192 \u03c3 1 (A, B) A\u2192 \u03c3 2 B \u2192 \u03c3 3 (C, D) C\u2192 \u03c3 4 D \u2192 \u03c3 5 We observe that S \u21d2 * g \u03c3 1 (\u03c3 2 , \u03c3 3 (\u03c3 4 , \u03c3 5 )). Let \u03b7, \u03b6, and \u03b6 be the following trees (in order): B \u2192 \u03c3 3 (C, D) C \u2192 \u03c3 4 D \u2192 \u03c3 5 S \u2192 \u03c3 1 (A, B) A \u2192 \u03c3 2 B S \u2192 \u03c3 1 (A, B) A \u2192 \u03c3 2 \u03b7 Then \u03b6 \u2208 D S g (T \u03a3 , B) because \u03b6 \u2208 D S g (T \u03a3 ) and the left-hand side of the root of \u03b7 is B. A \u03a3-algebra is a pair A = (A, (\u03c3 A | \u03c3 \u2208 \u03a3)) where A is a set and \u03c3 A is a k-ary operation on A for every k \u2208 N and \u03c3 \u2208 \u03a3 k . As usual, we will sometimes use A to refer to its carrier set A or, conversely, denote A by A (and thus \u03c3 A by \u03c3 A ) if there is no risk of confusion. The \u03a3-term algebra is the \u03a3-algebra T \u03a3 with \u03c3 T \u03a3 (t 1 , . . . , t k ) = \u03c3(t 1 , . . . , t k ) for every k \u2208 N, \u03c3 \u2208 \u03a3 k , and t 1 , . . . , t k \u2208 T \u03a3 . For each \u03a3-algebra A there is exactly one \u03a3-homomorphism, denoted by [[.]] A , from the \u03a3-term algebra to A (Wechler, 1992) . Hypergraphs and hyperedge replacement In the following let \u0393 be a finite set of labels. A \u0393hypergraph is a tuple H = (V, E, att, lab, ports), where V is a finite set of vertices, E is a finite set of hyperedges, att : E \u2192 V * \\ {\u03b5} is the attachment of hyperedges to vertices, lab : E \u2192 \u0393 is the labeling of hyperedges, and ports \u2208 V * is a sequence of (not necessarily distinct) ports. The set of all \u0393-hypergraphs is denoted by H \u0393 . The vertices in V \\ [ports] are also called internal vertices and denoted by int(H). For the sake of brevity, we shall in the following simply call \u0393-hypergraphs and hyperedges graphs and edges, respectively. We illustrate a graph in figures as follows (cf., e.g., graph((\u03c3 2 ) A ) in Fig. 2a ). A vertex v is illustrated by a circle, which is filled and labeled by i in case that ports(i) = v. An edge e with label \u03b3 and att(e) = v 1 . . . v n is depicted as a \u03b3-labeled rectangle with n tentacles, lines pointing to v 1 , . . . , v n which are annotated by 1, . . . , n. (We sometimes drop these annotations.) If we are not interested in the particular set of labels \u0393, then we also call a \u0393-graph simply graph and write H instead of H \u0393 . In the following, we will refer to the components of a graph H by indexing them with H unless they are explicitly named. Let H and H be graphs. H and graph((\u03c3 5 ) A ) H are disjoint if V H \u2229 V H = \u2205 and E H \u2229 E H = \u2205. (b) [[\u03c3 1 (\u03c3 2 , \u03c3 3 (\u03c3 4 , \u03c3 5 ))]] A = 1 is . 2 [[\u03c3 2 ]] A [[\u03c3 3 (\u03c3 4 , \u03c3 5 )]] A 3 4 3 4 3 4 1 2 1 2 2 4 1 3 1 2 = 1 is . 2 hearing [[\u03c3 3 (\u03c3 4 , \u03c3 5 )]] A A 3 4 3 4 3 4 1 2 3 4 1 2 1 2 3 4 1 2 1 2 = 1 is . 2 hearing [[\u03c3 4 ]] A A [[\u03c3 5 ]] A 3 4 3 4 3 4 1 2 3 4 1 2 1 2 1 2 1 2 1 2 = 1 is . 2 hearing scheduled A on today 1 2 1 2 1 2 \u2022 \u2022 \u2022 3 4 3 4 3 4 3 4 3 4 3 4 3 4 1 2 1 2 1 2 1 2 Figure 2 : (a) The (\u03a3, \u0393)-HR algebra A and (b) the evaluation of the term \u03c3 1 (\u03c3 2 , \u03c3 3 (\u03c3 4 , \u03c3 5 )) in A. Let E = E H \u2229 E H . If att H | E = att H | E and lab H | E = lab H | E , then the union of the graphs H and H is the graph H \u222a H = (V H \u222a V H , E H \u222a E H , att H \u222aatt H , lab H \u222alab H , ports H ports H ). For every We assume that each variable e i is labeled by a distinguished symbol \u22a5 \u2208 \u03a3 and depict e i by e i instead of \u22a5 . Throughout this paper, we will not distinguish between isomorphic graphs, i.e., graphs that are identical up to a bijective renaming of vertices and edges. However, since hyperedge replacement is defined on concrete graphs and requires that H, H 1 , . . . , H k are pairwise disjoint, we may choose isomorphic copies of the involved graphs, i.e., rename edges or vertices. To avoid the cumbersome conversion between abstract and concrete graphs, we assume that this renaming is opaque. F \u2286 E H let H \\ F = (V H , E, att H | E , lab H | E , ports H ) where E = E H \\ F . Let k \u2208 N In this sense, we may define an HR operation as a total function from H k to H as follows. Let H be a graph. For pairwise distinct edges e 1 , . . . , e k \u2208 E H , the HR operation H e 1 ...e k : H k \u2192 H is given by H e 1 ...e k (H 1 , . . . , H k ) = H[e 1 /H 1 , . . . , e k /H k ] for all graphs H 1 , . . . , H k \u2208 H. A (\u03a3, \u0393)-HR algebra (Courcelle, 1991 ) is a \u03a3algebra A = (H \u0393 , (\u03c3 A ) \u03c3\u2208\u03a3 ) where, for every k \u2208 N and \u03c3 \u2208 \u03a3 k , we have \u03c3 A = H e 1 ...e k for some H \u2208 H \u0393 and pairwise distinct e 1 , . . . , e k \u2208 E H . Then we denote H by graph(\u03c3 A ). An HR algebra is a (\u03a3, \u0393)-HR algebra for some \u03a3 and \u0393. An example of a (\u03a3, \u0393)-HR algebra A and the application of [[.] ] A to a term are given in Fig. 2 . Bigraphs and Aligned HR Bimorphisms Now we formally introduce our central notions of bigraph and aligned HR bimorphism. A case study with examples follows in the next section. Throughout this section let \u2206 and \u2126 be alphabets. V \u03bb = V H 1 \u222a V H 2 , E \u03bb \u2229 E H 1 = E \u03bb \u2229 E H 2 = \u2205, att(e) \u2208 (V H 1 ) + \u2022 (V H 2 ) + for each e \u2208 E \u03bb , and ports \u03bb = \u03b5. . . . y (1) m1 x (1) 1 . . . x (1) n1 e 1 y (k) 1 . . . y (k) mk x (k) 1 . . . x (k) nk e k \u2022 \u2022 \u2022 e (0) 1 e (0) n0 e (1) 1 e (1) m1 e (n) 1 e (n) mk (b) \u03c3 1 (y (0) 1 ) inp is . (y (0) 1 ) out y (1) 1 x (1) 1 e 1 x (2) 1 x (2) 2 e 2 (c) inp is . out x (1) 1 x (2) 1 x (2) 2 (d) inp x (2) 2 out x (1) 1 x (2) 1 Figure 3: The graphs (a) H \u03c3 IO , (b) H \u03c3 1 , (c) s (0) 1 , and (d) s (1) 1 . The large circles and the dotted lines in (a) and (b) visualize the underlying term structure; e.g., in (b) \u03c3 1 has two children because \u03c3 1 \u2208 \u03a3 2 . Definition 3.2. An aligned HR bimorphism of type (\u03a3, \u2206, \u2126) is a tuple B = (g, A 1 , \u039b, A 2 ) , where g is an RTG over \u03a3 and A 1 , A 2 are a (\u03a3, \u2206)-HR algebra and a (\u03a3, \u2126)-HR algebra, resp., such that graph(\u03c3 A 1 ) and graph(\u03c3 A 2 ) are disjoint for each \u03c3 \u2208 \u03a3. Further, \u039b is a \u03a3-indexed family (\u039b \u03c3 | \u03c3 \u2208 \u03a3), each \u039b \u03c3 being an alignment of graph(\u03c3 A 1 ) and graph(\u03c3 A 2 ). In the following, for each term t \u2208 T \u03a3 , we assume (w.l.o.g.) that [[t]] A 1 and [[t]] A 2 are disjoint. Definition 3.3. Let B = (g, A 1 , \u039b, A 2 ) be an aligned HR bimorphism. The semantics of B, denoted by L(B), is the set of bigraphs defined as follows. First, let the B-alignment be the T \u03a3 -indexed family \u039b B = (\u039b B (t) | t \u2208 T \u03a3 ) where \u039b B (t) is the alignment of [[t]] A 1 and [[t]] A 2 defined induc- tively on t as follows. Let t = \u03c3(t 1 , . . . , t k ) \u2208 T \u03a3 . For j \u2208 [2], suppose that \u223c j is the equivalence relation involved in the hyperedge replacement that yields graph(\u03c3 A j )[e 1 /[[t 1 ]] A j , . . . , e k /[[t k ]] A j ]. We assume that \u039b \u03c3 , \u039b B (t 1 ), . . . , \u039b B (t k ) have pairwise disjoint sets of edges. Then we define the B-alignment of [[t]] A 1 and [[t]] A 2 to be the graph \u039b B (t) = (\u039b \u03c3 \u222a\u039b B (t 1 )\u222a\u2022 \u2022 \u2022\u222a\u039b B (t k ))/(\u223c 1 \u222a\u223c 2 ) and we let [[t]] B = ([[t]] A 1 , \u039b B (t), [[t]] A 2 ). Finally, we define L(B) = {[[t]] B | t \u2208 L(g)}. Case Study: Hybrid Grammars We show how an LCFRS/sDCP hybrid grammar (Nederhof and Vogler, 2014) can be represented as an aligned HR bimorphism. These grammars deal with sequence terms; hence, we first recall their definition and show how to view sequence terms as particular graphs. A Graph View on Sequence Terms Let \u0393 be a ranked alphabet and Y be a set disjoint from \u0393. The sets of terms and sequence-terms (sterms) over \u0393 indexed by Y (Seki and Kato, 2008) are denoted by T \u0393 (Y ) and T * \u0393 (Y ), respectively, and defined inductively as follows: 1 . Y \u2286 T \u0393 (Y ), 2. if k \u2208 N, \u03b3 \u2208 \u0393 k and s i \u2208 T * \u0393 (Y ) for each i \u2208 [k], then \u03b3(s 1 , . . . , s k ) \u2208 T \u0393 (Y ), and 3. if n \u2208 N and t i \u2208 T \u0393 (Y ) for each i \u2208 [n], then t 1 , . . . , t n \u2208 T * \u0393 (Y ). Let s \u2208 T * \u0393 (Y ) . We say that s is linear if every y \u2208 Y occurs at most once in s. In the following we only consider linear s-terms. We note that, if \u0393 = \u0393 0 , then s is essentially a string over \u0393 0 and Y . If \u0393 = \u0393 1 , then s corresponds to a sequence of ordinary (unranked) terms over \u0393 1 indexed by Y . Every linear s-term s can be represented as a graph s : it has two distinct ports inp and out, representing the start and end of s, resp. For each variable y \u2208 Y , s has two distinct ports y inp and y out . For each occurrence of a symbol \u03b3 \u2208 \u0393 k in s, there is a \u03b3-labeled edge with 2k + 2 tentacles in s . The (2i \u2212 1)-th and 2i-th tentacle (i \u2208 [k]) point to the start and end vertex, respectively, of the i-th child sequence of \u03b3. The last two tentacles point towards the predecessor and the successor of \u03b3, respectively: this may be a vertex separating two symbols, the start or end vertex of a (sub-)sequence, or the port realizing y inp or y out for some y \u2208 Y . For instance, the s-term s (0) 1 = is( x (1) 1 , x (2) 1 ), . ( ) in T * \u0393 ({x (1) 1 , x (2) 1 , x (2) 2 }) is represented by s LCFRS, sDCP, and LCFRS/sDCP Hybrid Grammars Here we formalize LCFRS/sDCP hybrid grammars as particular aligned HR bimorphisms, where the algebras A 1 and A 2 are an LCFRS algebra and an sDCP algebra, resp. Since both LCFRS and sDCP can be viewed as particular types of attribute grammars (AG), we first define the concept of AG algebra and, in a second step, instantiate it to LCFRS algebra and sDCP algebra. For each \u03c3 \u2208 \u03a3 k , let syn \u03c3 A = (n 0 , . . . , n k ) \u2208 N k+1 and inh \u03c3 A = (m 0 , . . . , m k ) \u2208 N k+1 be tuples defining the sets I = {y (0) j | j \u2208 [n 0 ]}\u222a{y (i) j | i \u2208 [k], j \u2208 [m i ]} and O = {x (0) r | r \u2208 [m 0 ]} \u222a {x ( ) r | \u2208 [k], r \u2208 [n ] } of inside and outside attributes, resp. (The abbreviations stem from the AG notions synthesized attributes and inherited attributes.) The definition of an AG algebra A follows the two-phase approach in (Engelfriet and Heyker, 1992) . In the first phase, for each symbol \u03c3 in \u03a3 k , we define a graph H \u03c3 IO of type syn \u03c3 A , inh \u03c3 A as shown in Fig. 3a : there is a pair of vertices for each inside attribute y In the second phase, we choose an I-indexed family of s-terms (s (i) j \u2208 T * \u0393 (O) | y (i) j \u2208 I) such that each x ( ) r in O occurs exactly once in all s (i) j together (single syntactic use restriction). Then we replace each edge e (i) j by the graph s (i) j ; this specifies a particular information flow. Formally, we set \u03c3 A = H \u03c3 e 1 ...e k where H \u03c3 = H \u03c3 IO [e (i) j / s (i) j | y (i) j \u2208 I] . For instance, for \u03c3 1 \u2208 \u03a3 2 we have syn \u03c3 1 A = (1, 1, 2) and inh \u03c3 1 A = (0, 1, 0), and so we construct H \u03c3 1 IO accordingly. Next, we choose s (0) 1 and s (1) 1 as depicted in Fig. 3c and 3d , respec-tively. Then H \u03c3 1 = H \u03c3 1 IO [e (0) 1 / s (0) 1 , e (1) 1 / s (1) 1 ] is the graph in Fig. 3b where dashed lines indicate the identification of vertices. Note that H \u03c3 1 equals graph((\u03c3 1 ) A ) in Fig. 2a . A (\u03a3, \u0393)-HR algebra A is a (\u03a3, \u0393)-attribute grammar algebra ((\u03a3, \u0393)-AG algebra), if each symbol \u03c3 in \u03a3 is interpreted as described above. For instance, A of Fig. 2a is a (\u03a3, \u0393)-AG algebra. We observe that (\u03a3, \u0393)-AG algebras have the following property: for every edge e \u2208 E H \u03c3 , if lab H \u03c3 (e) \u2208 \u0393 k then e has 2k + 2 tentacles. We call the vertex att H\u03c3 (e)(k + 1) the input vertex of e and denote it by inp(e). Note that no two terminal edges in H \u03c3 have the same input vertex. This single-input property will be crucial for an efficient representation of subgraphs during the reduct construction (cf. Sec. 5.2). Next we instantiate the concept of AG-algebra to LCFRS algebras and to sDCP algebras. An LCFRS does not have inherited attributes: Definition 4.1. Let \u2206 = \u2206 0 be a ranked alphabet. A (\u03a3, \u2206)-AG algebra A is a (\u03a3, \u2206)-LCFRS algebra, if inh \u03c3 A = (0, . . . , 0) for all \u03c3 \u2208 \u03a3. Definition 4.2. Let \u2126 = \u2126 1 be a ranked alphabet and let A be a (\u03a3, \u2126)-AG algebra. We say that A is a (\u03a3, \u2126)-sDCP algebra. Then the graph view on an LCFRS/sDCP hybrid grammar is an HR bimorphism B = (g, A 1 , \u039b, A 2 ), where \u2022 g = (\u039e, \u03a3, \u03be 0 , R) is an RTG, \u2022 A 1 is a (\u03a3, \u2206)-LCFRS algebra, \u2022 A 2 is a (\u03a3, \u2126)-sDCP algebra, \u2206 = \u2126 (regard- ing \u2206 and \u2126 as sets of symbols), and \u2022 there are functions fan : \u039e \u2192 N , inh : \u039e \u2192 N, and syn : \u039e \u2192 N such that fan(\u03be 0 ) = 1, inh(\u03be 0 ) = 0, syn(\u03be 0 ) = 1, and for every (\u03be \u2192 \u03c3(\u03be 1 , . . . , \u03be k )) \u2208 R, it holds that -(fan(\u03be), fan(\u03be 1 ), . . . , fan(\u03be k )) = syn \u03c3 A 1 and -(inh(\u03be), inh(\u03be 1 ), . . . , inh(\u03be k )) = inh \u03c3 A 2 and (syn(\u03be), syn(\u03be 1 ), . . . , syn(\u03be k )) = syn \u03c3 A 2 . Moreover, we require the following: Let \u03c3 \u2208 \u03a3 and H j = graph(\u03c3 A j ) for j \u2208 [2]. For each e \u2208 E \u039b\u03c3 we have att \u039b\u03c3 (e) = inp(e 1 ) inp(e 2 ) where e 1 \u2208 E H 1 , e 2 \u2208 E H 2 , and lab H 1 (e 1 ) = lab H 2 (e 2 ). Example 4.3. Let g be as in Ex. 2.1 and consider the LCFRS/sDCP hybrid grammar B = (g, A 1 , \u039b, A 2 ), where A 1 , \u039b, and A 2 are as specified in Fig. 4 . Then the bigraph in Fig. 1b equals [[\u03c3 1 (\u03c3 2 , \u03c3 3 (\u03c3 4 , \u03c3 5 ))]] B and is thus in L(B). EM Training Algorithm In the first step of our training algorithm, a corpus c : R \u2192 R \u22650 is computed as follows. After initialization (line 3), each bigraph B occurring in c is considered (line 4), the reduct (B, p i ) \u00a3 B is built (line 5), the inside/outside weights of the new WRTG (g , p ) are calculated (line 6), and according to these weights and the current weight assignment p i the count c ( ) of each rule is incremented (lines 8-9). In the second step, the corpus c is normalized (lines 10-14) and the result is the next probability assignment p i+1 (line 15). Algorithm 5.1 EM-training algorithms for weighted aligned HR bimorphisms. Input: weighted aligned HR bimorphism (B, p 0 ) = ((g, A 1 , \u039b, A 2 ), p 0 ) with g = (\u039e, \u03a3, \u03be 0 , R), and a finite, non-empty corpus c of bigraphs. Output: sequence p 1 , p 2 , p 3 , . . . of improved probability assignments for R. 1: i \u2190 0 2: while true do output p i+1 and i \u2190 i + 1 Acknowledgment We thank the referees for their careful reading of the manuscript. (y (0) 1 ) inp is . (y  2 ) out (y 2 ) out , (y Figure 4 : The interpretation of \u03c3 1 , . . . , \u03c3 5 in A 1 , \u039b, and A 2 . EM Training We present a training algorithm which takes as input a weighted aligned HR bimorphism and a finite, non-empty corpus c of bigraphs. It is essentially the same as the training algorithm for probabilistic context-free grammars (PCFG) (Baker, 1979; Lari and Young, 1990; Nederhof and Satta, 2008) . As shown in (Prescher, 2001) , this algorithm is a dynamic programming variant of the EM-algorithm (Dempster et al., 1977) . Thus, our algorithm generates a sequence of probability assignments which converges to a probability assignment p; the likelihood of c under p is a local maximum or saddle point of the likelihood function of c. Weighted Aligned HR Bimorphisms We define weighted RTG in a similar way as PCFG was defined in (Nederhof and Satta, 2006) . A weighted regular tree grammar (WRTG) is a pair (g, p) where g = (\u039e, \u03a3, \u03be 0 , R) is an RTG and p : R \u2192 R \u22650 is the weight assignment. A weight assignment p is a probability assignment if \u03c1\u2208R \u03be p(\u03c1) = 1 for each \u03be \u2208 \u039e. We extend p to the mapping p : D g (T \u03a3 ) \u2192 R \u22650 on derivations as follows: for each where p : D \u03be 0 g (T \u03a3 , \u03be) \u2192 R \u22650 is defined in the same way as p , with the addition that p (\u03be) = 1. As usual, we will drop the primes from p , p , and p . ) is an aligned HR bimorphism and (g, p) is a WRTG. Reduct Construction Given a weighted aligned HR bimorphism (B, p) = ((g, A 1 , \u039b, A 2 ), p) and a bigraph (H 1 , \u03bb, H 2 ), we restrict g to an RTG g such that only trees t \u2208 L(g) satisfying [[t]] B = (H 1 , \u03bb, H 2 ) are in L(g ). Also, we show that if B is an LCFRS/sDCP hybrid grammar, then g can be constructed in time polynomial in the size of B and (H 1 , \u03bb, H 2 ). for some e \u2208 E H , then e \u2208 E H . The set of all m-subgraphs of H is denoted by H m S (H). For instance, graph((\u03c3 4 ) A ) in Fig. 2a is a 2subgraph of the last graph in Fig. 2b . If a graph H is the result of applying an HR operation to graphs H 1 , . . . , H k , then each H i is a |ports H i |-subgraph of H. (For this, the mapping \u03d5 in Definition 5.2 is needed, because some of the ports of H i may be identified with each other in H.) Hence, for the reduct we consider only m-subgraphs of H, where m is the maximal port length of HR operations in A 1 or A 2 . We observe that H m S (H) is finite because we identify isomorphic graphs. Definition 5.3. Let (B, p) = ((g, A 1 , \u039b, A 2 ), p) be a weighted aligned HR bimorphism with g = (\u039e, \u03a3, \u03be 0 , R) and let (H 1 , \u03bb, H 2 ) be a bigraph. We define (B, p) \u00a3 (H 1 , \u03bb, H 2 ), the reduct of (B, p) with respect to (H 1 , \u03bb, H 2 ), to be the weighted aligned HR bimorphism ((g , A 1 , \u039b, A 2 ), p ) where g and p are defined as follows. If \u03be 0 , \u2205) and p = \u2205. Otherwise, let m \u2208 N be the maximum of all |ports graph(\u03c3 A 1 ) | and |ports graph(\u03c3 A 2 ) | where \u03c3 \u2208 \u03a3. Now, we construct g = (\u039e , \u03a3, \u03be 0 , R ) where we abbreviate We define p ( ) = p( ). Theorem 5.4. In Def. 5.3 the following hold: 2. There is a deterministic tree relabeling \u03c6 from D g to D g such that for all t \u2208 L(g ) and d \u2208 D g (t), \u03c6| D g (t) is a bijection between D g (t) and D g (t), and p (d ) = p(\u03c6(d )). \u2205 by construction, and thus, both statements of the theorem hold. Otherwise, the first statement follows from the following claim. Claim (*) For every n \u2208 N, \u03be \u2208 \u039e, t \u2208 T \u03a3 , and For the proof of the second statement we define \u03c6((\u03be, s, \u03b7, r)) = \u03be for each (\u03be, s, \u03b7, r) \u2208 \u039e , and extend \u03c6 in the canonical way to derivation trees. Then the statement is an immediate consequence of the constructions of R and \u03c6 and Claim (*). Complexity We determine the complexity of the reduct construction for the special case of LCFRS/sDCP hybrid grammars. We assume that the maximal length m of ports in the HR operations is fixed and not part of the input. In preparation, we determine an upper bound on |\u039e |. Let H \u2208 H be such that from each vertex there is an (undirected) path to a port. Given H each A is uniquely determined by its boundary representation (Lautemann, 1990; Chiang et al., 2013; Groschwitz et al., 2015) , which consists of (a) the pair (ports , where f * = max \u03be\u2208\u039e f (\u03be) for f \u2208 {fan, syn, inh}. Constructing \u039e and R simultaneously with a deductive parsing algorithm (Shieber et al., 1995) has",
    "abstract": "We develop the concept of weighted aligned hypergraph bimorphism where the weights may, in particular, represent probabilities. Such a bimorphism consists of an R \u22650 -weighted regular tree grammar, two hypergraph algebras that interpret the generated trees, and a family of alignments between the two interpretations. Semantically, this yields a set of bihypergraphs each consisting of two hypergraphs and an explicit alignment between them; e.g., discontinuous phrase structures and nonprojective dependency structures are bihypergraphs. We present an EM-training algorithm which takes a corpus of bihypergraphs and an aligned hypergraph bimorphism as input and generates a sequence of weight assignments which converges to a local maximum or saddle point of the likelihood function of the corpus.",
    "countries": [
        "Sweden",
        "Germany"
    ],
    "languages": [],
    "numcitedby": "3",
    "year": "2016",
    "month": "August",
    "title": "{EM}-Training for Weighted Aligned Hypergraph Bimorphisms"
}