{
    "article": "We present a method for compositionally translating Japanese NN compounds into English, using a wordlevel transfer dictionary and target language monolingual corpus. The method interpolates over fullyspecified and partial translation data, based on corpus evidence. In evaluation, we demonstrate that interpolation over the two data types is superior to using either one, and show that our method performs at an F-score of 0.68 over translation-aligned inputs and 0.66 over a random sample of 500 NN compounds. Introduction This paper addresses the task of the machine translation (MT) of Japanese noun-noun (NN) compounds into English. NN compounds are defined to take the form of a concatenated noun pair, the elements of which we will refer to as N \u00a1 and N \u00a2 (in linear order of occurrence). Examples of Japanese NN compounds are \u00a3 \u00a5\u00a4 \u00a7\u00a6 \u00a9\u00a5 kikai \u00a6 hoNyaku \"machine translation\", \u00a5 \u00a6 \u00a9 \u00a5 miNkaN \u00a6 kigyou \"private company\" and \u00a6 \u00a5 kaNkei \u00a6 kaizeN \"improvement in relations\". 1  Our interest in NN compounds stems from the realisation that they are highly frequent and highly productive in Japanese, and translate into a variety of English constructions. We estimate that the token occurrence of Japanese NN compounds in the 1996 Mainichi Shimbun Corpus (32m word tokens, Mainichi Newspaper Co. (1996) ) is roughly 10%, underlining their high frequency. The average token frequency per NN compound type is around 7, and slightly more than half of the NN compounds occur only once in the corpus (mirroring the results of Lapata and Lascarides (2003) for English). Additionally, new NN compounds are constantly evolving (Nagata et al., 2001) , all of which motivate a robust translation method which is able to handle novel NN compounds. In terms of MT, Japanese-English NN compound translation is made difficult because of: (a) constructional variability in the English translations (evidenced in the English translations for the example Japanese NN compounds above); (b) lexical idisoyncracies in Japanese and English (e.g. \" $# \u00a6 % \u00a5& haifu \u00a6 keikaku \"distribution schedule\" vs. ' \u00a5( \u00a6 % \u00a5& keizai \u00a6 keikaku \"economic plan/programme\" vs. ) 10 \u00a6 % \u00a5& shuyou \u00a6 keikaku \"major project\"); and (c) non-compositional NN compounds (e.g. 2 43 $5 \u00a6 6 \u00a57 idobata \u00a6 kaigi \"(lit.) well-side meeting\", which translates most naturally into English as \"idle gossip\"). We use the Japanese-English NN compound MT task as a test case for a compositional translation method which makes use of a word-level translation lexicon and monolingual corpus data. Much work on the similar task of terminology translation has relied on parallel or comparable corpora (Fung and McKeown, 1997; Rapp, 1999; Tanaka and Matsuo, 1999; Lee and Kim, 2002; Tanaka, 2002) . We attempt to use only target language corpus evidence in the translation process, to reduce data sparseness and make the method as portable to novel domains as possible. We suggest that the method proposed in this research can be used as a specialist NN compound translation module in a full-scale MT system. This is supported by the finding of Koehn and Knight (2003) that, in the context of statistical MT, over-all translation performance improves when noun phrases are translated independently of the sentential context. The remainder of this paper is structured as follows. Section 2 describes the proposed method, and Section 3 outlines the resources used in this research. Section 4 provides detailed evaluation of the proposed method. Section 5 contextualises this research with respect to previous work, and Section 6 concludes the paper. Proposed method We translate NN compounds through the composition of word-level translations and a constructional translation template. In order to translate \u00a6 4 kaNkei \u00a6 kaizeN \"improvement in relations\", for example, we make use of the three independent pieces of evidence: the translations of relations and improvement for and , respectively, and the (English ) translation template [N \u00a1 \u00a2 in N \u00a1 \u00a1 ] (where N \u00a1 \u00a2 indicates that the word 2 is a noun (N) in En- glish ( \u00a3 ) and corresponds to the \u00a4 th-occurring noun in the original Japanese). This method has the obvious advantage that it can generally generate a translation for a given NN compound input assuming that there are word-level translations for each of the component nouns; that is it has high coverage. It is based on the assumption that Japanese NN compounds translate compositionality into English, which Tanaka and Baldwin (2003) found to be the case 43.1% of the time in a Japanese-English NN compound translation task. In this paper, we focus primarily on selecting the correct translation for those NN compounds which can be translated compositionally, but also investigate what happens when non-compositional NN compounds are translated using a compositional method. Our method can be broken down into two basic stages: generation and selection (similarly to Cao and Li (2002) and Langkilde and Knight (1998) ). Generation consists of taking the cross-product of all word-level translations for each of the two Japanese nouns, and slotting each such pairing into the various translation templates. Each word translation and template slot is annotated for part of speech (POS), and we constrain the generation process to 2 Strictly speaking, word-level translations are \"listemes\" not words, as they can be made up of multiple English words. We always treat the word-level translation in the manner of a word, however, i.e. as a single unit with unique part of speech. output only those candidates where each slot and filler in the translation template agree in POS; e.g., no translation would be generated from the combination of the adjectival relational and template [N \u00a1 \u00a2 in N \u00a1 \u00a1 ] (with relational corresponding to either N \u00a1 or N \u00a2 in the original Japanese). In selection, we take the generated translation candidates and score each, returning the highestscoring translation candidate as our final translation. Ignoring the effects of POS constraints for the moment, the number of generated translations is \u00a5 \u00a7\u00a6 \u00a9 where \u00a8and are the fertility of Japanese nouns N \u00a1 and N \u00a2 , respectively, and is the number of translation templates. As a result, there is often a large number of translation candidates to select between, and the selection method crucially determines the efficacy of the method. Our scoring method rates the corpus-based translation quality ( ) of a given translation candidate according to both corpus evidence for the fully-specified translation and its parts in the context of the translation template in question. This is calculated as: \u00a6 \"! \u00a1 \u00a1 $# ! \u00a1 \u00a2 # % '& )( \u00a70 1\u00a6 \"! \u00a1 \u00a1 $# ! \u00a1 \u00a2 # % '2 (1) 3 40 5\u00a6 \"! \u00a1 \u00a1 # % 60 5\u00a6 \u00a9! \u00a1 \u00a2 # 2 87 90 5\u00a6 \"! \u00a1 \u00a1 @0 5\u00a6 \"! \u00a1 \u00a2 @0 5\u00a6 \u00a9 where ! \u00a1 \u00a1 and ! \u00a1 \u00a2 are the word-level translations of the Japanese N \u00a1 and N \u00a2 , respectively, and is the translation template. 3 Each probability is calculated according to a maximum likelihood estimate based on relative corpus occurrence. The formulation of is based on linear interpolation, by which we use weights to combine the probabilities of the fully-specified translation candidates with those of the translation parts first conditioned on translation templates and second independently. The weights take the form of ( , 3 and 7 , where A CB ( # 3 # 7 B ED and ( F2 G3 H2 I7 P& D . Our use of linear interpolation constitutes a basic form of smoothing, in that we would like to have some means of selecting the most likely translation in the absence of evidence for the fully-specified translation candidate. The basic intuition behind decomposing the translation candidate into its two parts within the context of the translation template ( 0 5\u00a6 \u00a9! \u00a1 \u00a1 $# % and 0 5\u00a6 \"! \u00a1 \u00a2 # % \u00a1 \u00a2 to N \u00a1 \u00a1 ] than [N \u00a1 \u00a2 on N \u00a1 \u00a1 ]. The third term in equation 1 ( 0 5\u00a6 \"! \u00a1 \u00a1 @0 5\u00a6 \"! \u00a1 \u00a2 @0 5\u00a6 \u00a9 ) represents a second level of backing-off and treats ! \u00a1 \u00a1 , ! \u00a1 \u00a2 and as independent items. Resources The proposed method makes use of a number of resources, namely: (a) pre-processed target language corpus data; (b) a word-level translation dictionary; (c) test data over which to evaluate the method; and (d) an inventory of translation templates. Corpus data The corpus data was taken from the 80m word written component of the British National Corpus (BNC, Burnard (2000) ). The British National Corpus was chosen because of its size and domain-inspecificity. Corpus size will affect the relative coverage of fullyspecified translations, and the fact that the BNC covers a broad range of domains helps us to accurately capture the subcategorisation properties of a given word (in the form of 0 5\u00a6 \"! \u00a1 \u00a2 # % , as described in Section 2). We dependency-parsed the BNC using RASP (Briscoe and Carroll, 2002) , a tag sequence grammar-based stochastic parser. RASP captures noun-noun dependencies using the ncmod relation between a head noun and its noun dependent, optionally linked via a preposition or genitive construction. The noun-noun dependency structure of the NP the Jubjub bird's relation to the frumious Bandersnatch, for example, would be captured by three ncmod relations: ncmod( ,bird,Jubjub) ncmod(POSS,relation,bird) ncmod (to,relation,Bandersnatch) which represent the NN, genitive and to-PP construction, respectively. Note that the head of the dependency relation occupies the second position in the tuple, and the dependent the third position. All ncmod tuples are normalised for number and case using morph (Minnen et al., 2001) , meaning that it is possible to sum up the token count of each ncmod triple type, and convert it directly into a maximum likelihood-based probability. Translation dictionary The word-level translation dictionary used in this research is the ALTDIC dictionary. ALTDIC was compiled from the ALT-J/E MT system (Ikehara et al., 1991) , and has approximately 400,000 entries including more than 200,000 proper nouns. In order to make ALTDIC directly compatible with the BNC-derived RASP tuples, we: (a) converted any American spellings to British spellings, and (b) lemmatised the spelling-normalised words using morph and the POS tags supplied in ALTDIC. Spelling normalisation was based on simple lookup in the VARCON table of American-British spelling variants. 4 Test data The primary test data used in this research comprises 500 Japanese NN compounds extracted from the 1996 Mainichi Shimbun Corpus (Mainichi Newspaper Co., 1996), as described in Tanaka and Baldwin (2003) . We first segmented and tagged the corpus using ALTJAWS 5 and then extracted out all NN bigrams adjoined by non-nouns. We next filtered off all NN compounds with a token occurrence of less than 10. As our test data, we took the 250 most frequent NN compounds, and a random selection of 250 NN compounds from the remainder of the extracted data. 6  In order to evaluate translation accuracy over the test data, we generated a unique gold-standard translation for each Japanese NN compound to represent its optimally-general English translation. This was done with reference to the ALTDIC dictionary and the public domain EDICT dictionary (Breen, 1995) , although a significant number of novel translations were generated due to: (a) NN compounds not occurring in either dictionary, and (b) the dictionary translations being inappropriate. We next normalised all English translations by: (a) converting any American spellings to British For the aligned NN compound subset, we constructed a second set of source languagerecoverable translations (incorporating the origi-nal gold-standard translation). This was done in order to give the method credit for \"near-miss\" translations, that is translations which are syntactically unmarked, capture the basic semantics of the source language expression and from which the source language expression is recoverable with reasonable confidence. Examples include issue of blame and responsibility issue as alternative translations for 1 32 54 76 sekiniN \u00a6 moNdai \"liability issue\". In this, we set ourselves apart from the highly subjective method of manual translation evaluation where bilingual annotators are presented with the source language expression and system output, and asked to rate the output for \"plausibility\" or \"usability\" (Tanaka and Matsuo, 1999; Cao and Li, 2002) . By pre-generating our source language-recoverable translations (or L1-coverable translations) we remove the annotator from direct contact with our method and hence hope to make evaluation as objective as possible. Given that we are only ever required to evaluate translations generated by our method, we only consider those translation candidates our method can generate for a given source language expression using ALTDIC. To reduce the annotation overhead, we break the task down into two steps: (1) identify appropriate word-level translations for each member of the NN compound as conditioned by the context of that compound, and (2) generate all translation candidates using only those word-level translations from step 1, and select from among them. In this way, we reduce the number of translation candidates per input the annotator must look at by around two-thirds as compared to a one-pass method of sifting through all translation candidates we are able to generate. Below, we refer to this set of aligned NN compounds with source language-recoverable translations as ALIGN RECOV . Template Example [N \u00a1 \u00a1 N \u00a1 \u00a2 ] \u00a2\u00a1 \u00a6 ' \u00a5( shijou \u00a6 keizai \"market economy\" [J \u00a1 \u00a1 N \u00a1 \u00a2 ] \u00a3 \u00a5\u00a4 \u00a6 \u00a9\u00a3 iryou \u00a6 kikaN \"medical institution\" [N \u00a1 \u00a2 of N \u00a1 \u00a1 ] \u00a6 \u00a2 \u00a7 \u00a6 \u00a9 ishiN \u00a6 teika \"loss of dignity\" [N \u00a1 \u00a2 N \u00a1 \u00a1 ] \u00a2 \u00a6 \u00a9 \u00a2 saNsei \u00a6 tasuu \"majority agreement\" [N \u00a1 \u00a1 VG \u00a1 \u00a2 ] \u00a2 \u00a6 \u00a9 \u00a2 jouhou \u00a6 shuushuu \"information gathering\" [J \u00a1 \u00a1 VG \u00a1 \u00a2 ] \u00a2! \u00a6 \u00a2\" chousa \u00a6 houdou \"investigative reporting\" We use another two datasets in secondary evaluation. The first consists of frequently-occurring compounds found in the Nikkei 1996 corpus (Nikkei Publishing Co., 1996) . Each NN compound was translated by a professional translator, guided by 2 sentences from the Nikkei 1996 corpus containing that compound. The translator was asked to provide suitable translations for each NN compound, with no stipulation on the number or linguistic form of the translations. Out of the translated NN compound data, we selected those which were: (a) not found in the 500 NN compounds from above, and (b) compositionally translatable (i.e. both component Japanese nouns were contained in the word-level translation dictionary). This resulted in 401 items, which we refer to as NIKKEI below. The second dataset used in secondary evaluation originates from a Japanese-English terminological dictionary. We extracted out all Japanese NN compounds which satisfied the two conditions outlined above for the NIKKEI dataset. This resulted in 2,245 items, which we refer to as TERMDICT below. Translation templates A total of 28 translation templates were used in this research, a sample of which are shown in Table 1. They were determined by combining all POSconditioned alignment mappings between Japanese NN compounds and their English translations found in ALIGN GOLD . One noteworthy translation template is [N \u00a1 \u00a2 N \u00a1 \u00a1 ], where the English translation takes the form of an NN compound but the order of the nouns is reversed. That is, in the example \u00a6 saNsei \u00a6 tasuu \"majority agreement\" from Table 1 , tasuu translates as majority and 3 saNsei as agreement, the order of which is then reversed in the English translation. 7 Evaluation In this section, we evaluate the translation candidate scoring method over the ALIGN GOLD , ALIGN RECOV , NIKKEI and TERMDICT datasets according to translation F-score relative to the model translations (see below). We test the effect of varying the values of ( and 7 in equation 1 (with the value of 3 being determined by D \u00a1 ( \u00a1 7 ), and also run the method over UNALIGN GOLD to test its robustness over data for which translation compositionality does not hold. We evaluate translation performance according to the standard measures of precision, recall and Fscore. Precision is the relative proportion of inputs for which we generate a correct translation (as determined by the translation data set we are evaluating against), recall is the relative proportion of inputs for which we are able to generate a translation, and F-score is the harmonic mean of the two. We evaluate our method against two baselines derived from . The first baseline (Baseline-1) takes the most probable fully-specified translation candidate (i.e. is equivalent to setting ( & D , 3 & A and 7 & A in equation 1). The second (Baseline-2) scores translation candidates according to template-specified partial translation probabilities (i.e. is equivalent to setting ( & A , 3 & D and 7 & A in equation 1). Baseline-1 is prone to low recall as a result of there being no fully-specified translation candidate attested in the corpus. Baseline-2 is prone to low precision as it does not consider the lexical affinity between the word-level translations. An outline of baseline F-scores for each of the datasets, along with the total number of items, the average number of gold-standard transaltions per item and the average number of translation candidates generated per item, is given in Table 2 . We also indicate the best F-score obtained for each dataset, obtained from Figures 1-3 . The results for ALIGN GOLD and ALIGN RECOV are given in Figure 1 , and those for NIKKEI and TER-MDICT are given in Figure 2 and Figure 3 , respectively. In each case, ( is plotted on a logarithmic scale on the \u00a2 axis, and separate curves are given for 7 values of 0.00, 0.01, 0.10 and 0.20. Note that a given combination of ( and 7 values will uniquely determine the 3 value. For each curve, a peak is seen for an ( value of around 0.8 and 7 value of around 0.1, above both baselines. Baseline-1 is superior to Baseline-2 in all cases. This suggests that fully-specified translation data (i.e. 0 5\u00a6 \u00a9! \u00a1 \u00a1 # ! \u00a1 \u00a2 # % ) is vital in translation selection, but that some degree of smoothing is required via partially-specified translation data (i.e. 0 5\u00a6 \u00a9! \u00a1 \u00a1 # @0 5\u00a6 \u00a9! \u00a1 \u00a2 # % ) and fully- indepedent data (i.e. 0 5\u00a6 \u00a9! \u00a1 \u00a1 @0 5\u00a6 \u00a9! \u00a1 \u00a2 60 5\u00a6 \u00a9 ). The L1-recoverable translation F-score of around 0.68 for ALIGN RECOV can be interpreted as reflecting the performance of the method in a real-world MT application, where understandability often takes precedence over prescriptive correctness. Next, we look to the unaligned NN compound data. While we are unable to compositionally generate the gold-standard translation for these inputs, we wish to know how far off the mark the translations we output are. To evaluate the quality of the translation output, we employ the 6-way classification of translation output quality detailed in Table 3 The results over the UNALIGN GOLD dataset are given in Table 3 . The Basic column presents the proposed method applied as described herein, for which over 40% of outputs are either L1-recoverable or basic sense-recoverable. Over one-third of inputs cannot be translated, and only about 20% receive misleading or nonsensical translations. 2 MBMT couples the proposed method with memory-based MT (MBMT) in the form of a listing of translation data for Japanese NN compounds as found in the combined ALTDIC and EDICT dictionaries. MBMT is applied as a pre-processor in outputting the dictionary-derived translation directly if the NN compound is found to exist in the dictionaries, falling back to the proposed method only if this fails. This \"cascaded\" method was shown by Tanaka and Baldwin (2003) to be an effective way of combining the high-precision of MBMT with the high-recall of compositional translation. For the UNALIGN GOLD dataset, the cascaded translation methodology results in nearly 50% of outputs being assigned classes 1-3, and enhances translation coverage slightly. The combined L1-recoverable Fscore over the full 500-element set (in combination with MBMT, based on classes 1-2 in the case of UN-ALIGN GOLD ) is 0.66. One significant area in which our method falls down is that it treats all translations contained in the transfer dictionary as being equally likely, where in fact there is considerable variability in general applicability. One example of this is the simplex \u00a2\u00a1 kiji which is translated as either article or item (in the sense of a newspaper) in ALTDIC, but the former is clearly the more general translation. Lacking knowledge of this conditional probability, the method considers the two translations to be equally probable, giving rise to the preferred translation of related item for \u00a4\u00a3 \u00a6 \u00a5\u00a1 kaNreN \u00a6 kiji \"related article\" due to the markedly greater corpus occurrence of related item over related article. There are two immediate sources of such conditional probabilities: dictionary alignment data and parallel/comparable corpora. Given that we are committed to using a monolingual corpus, the former method is preferred. Related work One piece of research relatively closely related to our method is that of Cao and Li (2002) , who use bilingual web data and various combinations of the EM algorithm, a naive Bayes classifier and TF-IDF to translate Chinese NN compounds into English. They report an impressive F-score of 0.73 over a dataset of 1000 instances, although they also cite a prior-based F-score (equivalent to our Baseline-1) of 0.70 for the task, such that the particular data set they are dealing with would appear to be less complex than that which we have targeted. Lee and Kim (2002) use definitions from a bilingual dictionary and target language corpora, and treat translation selection as disambiguation of a source word sense and selection of a target word. They report the accuracy of their method for nouns to be 0.55, although in the case of compound nouns it seems to be overkill to rely on such rich semantic resources to achieve relatively modest precision. Fung and McKeown (1997) extract terminology translations based on the assumption of crosslin-gual distributional similarity, as defined by seed and previously-extracted translation pairs across comparable corpora. Their results show the usefulness of comparable corpora, but also underline the dependence of the method on closely-correlated crosslingual corpora, which can sometimes be an unreasonable expectation. Rackow et al. (1992) look at a German-English compound noun MT task over a range of translation templates. They propose the use of \"default constructions\" for single words in a manner similar to that described in this research, but base determination of such defaults on English translations within a parallel corpus. Specifically, they take the Hansards corpus and observe which of ecology and ecological, e.g., occurs more often as a noun premodifier and use this information in generating ecological movement rather than ecology movement as a translation for the German Umweltbewegung. Unfortunately, no attempt is made to evaluate the method. Grefenstette (1999) uses web data to select English translations for compositional German and Spanish noun compounds, and achieves an impressive accuracy of 0.86-0.87. The translation task Grefenstette targets is intrinsically simpler than that described in this paper, however, in that he filters out the effects of translation template selection by considering only those compounds which translate into NN compounds in English. It is also possible that the historical relatedness of languages has an effect on the difficulty of the translation task, although further research would be required to confirm this prediction. Having said this, the successful use of web data by a variety of researchers suggests an avenue for future research in comparing our results with those obtained using web data. Conclusion We have proposed a method for translating NN compounds and applied it to a Japanese-English MT task. The method interpolates over translation probabilities of different levels of specification, and returns the highest-scoring translation from amongst them. In evaluation, we showed our method to perform at an F-score of 0.68 over aligned data and 0.66 over a random sample of 500 NN compounds. Acknowledgements This material is based upon work supported by the National Science Foundation under Grant No. BCS-0094638 and also the Research Collaboration between NTT Communication Science Laboratories, Nippon Telegraph and Telephone Corporation and CSLI, Stanford University. We would like to thank Emily Bender, Francis Bond, Dan Flickinger, Stephan Oepen, Ivan Sag and the two anonymous reviewers for their valuable input on this research.",
    "abstract": "We present a method for compositionally translating Japanese NN compounds into English, using a wordlevel transfer dictionary and target language monolingual corpus. The method interpolates over fullyspecified and partial translation data, based on corpus evidence. In evaluation, we demonstrate that interpolation over the two data types is superior to using either one, and show that our method performs at an F-score of 0.68 over translation-aligned inputs and 0.66 over a random sample of 500 NN compounds.",
    "countries": [
        "Japan",
        "United States"
    ],
    "languages": [
        "Japanese",
        "English",
        "Chinese"
    ],
    "numcitedby": "13",
    "year": "2003",
    "month": "September 23-27",
    "title": "Translation selection for {J}apanese-{E}nglish noun-noun compounds"
}