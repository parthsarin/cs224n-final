{
    "article": "Previous work on Korean language processing has proposed different basic segmentation units. This paper explores different possible dependency representations for Korean using different levels of segmentation granularity -that is, different schemes for morphological segmentation of tokens into syntactic words. We provide a new Universal Dependencies (UD)-like corpus based on different levels of segmentation granularity for Korean. The corpus contains 67K words in 5,000 sentences which are split into training, development and evaluation data sets. We report parsing results using the new dependency corpus for Korean and compare them with the previous Korean UD corpus. Dependency Parsing and the Korean Language Language processing including morphological analysis for Korean has traditionally been based on the eojeol, which is a basic segmentation unit delimited by a blank in the sentence. Let us consider the sentence in (1), which contains ten eojoels (the corresponding morphological analysis is found in Figure 1 ). The number of eojoels is entirely based on the blank space character and the tenth eojeol in (1) also includes the punctuation mark. Almost all natural-language processing systems that have been previously developed for Korean have used the eojeol as a fundamental unit of analysis. As Korean is an agglutinative language, joining content and functional morphemes is very productive and they can be combined exponentially. For example, yeoghal ('role') is a content morpheme (a common noun) and -eul, a case marker ('ACC', accusative), is a functional morpheme. 1 They form together a single eojeol yeoghal-eul ('role + ACC'). A predicate gangjoha-ass-da ('focused') also consists of the content morpheme gangjo-ha ('focus') and its functional morphemes, -ass ('PAST', past tense) andda ('IND', indicative), respectively. In this paper, we analyze different levels of segmentation granularity in dependency representations for syntactic annotation ( \u00a72). We then propose a scheme to build a new Universal Dependencies (UD)-like corpus for Korean based on segmentation granularity ( \u00a73). UD has been developed cross-linguistically using a consistent treebank annotation scheme for many languages. 2 We provide 5,000 sentences based on each of the segmentation granularity possibilities described in this paper. We also present its UD parsing results, compare them with previously proposed UD for Korean ( \u00a74), and discuss future perspectives of dependency annotation and parsing for Korean ( \u00a75). Segmentation Granularity for Korean We define the following four different levels of segmentation granularity for Korean. These granularity levels have been independently proposed in previous work on Korean language processing as different basic segmentation units. Eojeols Most language processing systems and corpora developed for Korean have used the eojeol as a fundamental unit of analysis (Figure 2 ). For example, the Sejong corpus, the most widely-used corpus for Korean, uses the eojeol as the basic unit of analysis as presented in (1). Separating words and punctuation As eojeols have been used as a basic analysis unit in Korean corpora, the tokenization task is often ignored for Korean. However, there are corpora which use an English-like tokenization (Figure 3 ). Words in these corpora are already preprocessed: for example, the Penn Korean treebank (Han et al., 2002) , in which punctuation marks are separated from words. Note that among existing corpora for Korean, only the Sejong treebank separates quotation marks from the word. Other Sejong corpora including the morphologically analyzed corpus do not separate the quotation marks. While the Korean Penn treebank separates all punctuation marks, quotation marks are the only symbols that are separated from words in the Sejong treebank. Chung and Gildea (2009) used this granular-ity of separating words and symbols for a baseline tokenization system for a machine translation system. Park et al. (2014) also used this granularity to develop Korean FrameNet lexicon units. Separating case markers The Sejong corpus has been criticized for the scope of the case marker, in which only a final noun (usually the lexical anchor) in the noun phrase is a modifier of the case marker (Collins, 1997; Bikel, 2004) , and NPs in the Korean Penn treebank will have a similar NP structure in the Sejong corpus (Chung et al., 2010) . To fix the problem in the previous treebank annotation scheme, there are other annotation schemes proposed in the corpus and lexicalized parsing grammars for the purpose to correctly express the scope of the case marker (Figure 4 ). Park (2006) considered case markers (or postpositions) as independent elements in Tree adjoining grammars (Joshi et al., 1975) . Therefore, he defined case markers as an auxiliary tree to be ad-  joined to a noun phrase. For example, the single token jagga-deul-do becomes two tokens, jaggadeul ('author') and -do ('also'). However, verbal endings on the inflected forms of predicates are still in the eojoel and they are represented as initial trees for Korean TAG grammars. The lemma of the predicate and its verbal endings are dealt with as inflected forms instead of separate functional morphemes. Separating verbal endings Government and binding (GB) theory for Korean often proposed a syntactic analysis, in which the entire sentence depends on verbal endings. For example, gangjo-ha-ass-da becomes gangjoha ('emphasize'), -ass ('PAST'), and -da ('IND') as described in Figure 5 . The Kaist treebank (Choi et al., 1994) , the first treebank created for Korean adapted this type of analysis (Figure 6 ). While the Kaist treebank separates case markers and verbal endings with their lexical morphemes, punctuation marks are not separated and they are still a part of the preceding token. Therefore, strictly speaking, this granularity level is not exactly same as in the Kaist treebank. Discussion The different levels of segmentation granularity described in this section have been proposed mainly because of different syntactic analysis in several previously proposed Korean treebank (Choi et al., 1994) , Sejong 3 , and Penn (Han et al., 2002) treebanks. Even for the segmentation granularity which we deal with, syntactic theory is implicitly presented in the corpus for Korean words. Granularity described in \u00a72.1 and \u00a72.3 is based on the Sejong treebank. Granularity described in \u00a72.2 and \u00a72.4 is based on the Korean Penn treebank and the Kaist treebank, respectively. Many applications for Korean language processing are based on another level of segmentation granularity, in which all morphemes are separated: phrase-structure parsing (Choi et al., 2012; Park et al., 2016) and statistical machine translation (SMT) (Park et al., 2016) , etc. Such morpheme-3 https://www.sejong.or.kr based analysis for the word can be generated by a morphological analysis system, and most POS tagging systems such as Hong (2009) and Park et al. (2011) can produce all morpheme-based analysis. For example, jagga-deul-do ('authors-ALSO') is separated into jagga ('author'), deul ('PLUR'), and do ('ALSO'). However, we do not deal with this granularity to represent dependencies. It shows rather how words are formed, and it should include the fine-grained relationships between morphemes. This type of representation of words does not conform with the current dependency schemes for other languages and especially, neither with UD best practices. UD for Korean Since Universal Dependencies (UD) has been released (Nivre et al., 2016) , several studies have been published, both theoretical (Schuster and Manning, 2016) and practical (Zeman et al., 2017) . As for other morphologically rich languages, specific Universal Dependencies for Japanese were introduced relatively recently to meet the requirement of UD's cross-linguistically consistent treebank annotation (Tanaka et al., 2016) . In the current UD, other morphologically rich languages such as Kazakh (Tyers and Washington, 2015) and Turkish (Sulubacak et al., 2016) are also available. In this section, we describe how to build UDs for Korean based on the different levels of segmentation granularity. 6 : CoNLL-U format that separates verbal endings, which requires a dependency relationship between the verbal head and the verbal ending (aux), for example a verb gangjoha ('focus'), and two verbal endings ass ('PAST') and da ('IND') for tense and mood. Universal POS Using the eojeol and morpheme level mapping tables to Universal POS tags for the Sejong tagset proposed in Petrov et al. (2012) and Park et al. (2016) , we can convert the single tags (morphemes) and the sequences of tags (eojeols and tokens) in the Sejong corpus into Universal POS tags. We also use additional mapping rules by using the approach to find Universal POS tags described in Oh et al. (2011) in which they predict phrase tags for the eojeol. In addition, the Sejong tags (morphemes) and the sequence of tags (tokens and eojeols) represented as immediate nonterminal nodes in the eventual parse tree can be used as a language-specific part-of-speech tag in the CoNLL-U format. Figure 7 shows example mapping rules for each segmentation granularity level. Tagsets in the Sejong corpus are mapped to the Universal POS tag sets either individually (NNP \u2192 PROPN) or by a sequence of the POS tags (NNP+JKS \u2192 PROPN). Figure 8 represents the 1-to-1 mapping from the POS tags in the Sejong corpus to Universal POS tags described in Park et al. (2016) . These 1-to-1 mapping rules are used throughout segmentation granularity schemes described \u00a72.1 to \u00a72.4 if the eojeol is composed only by a single morpheme. Universal features Park ( 2006 ) detailed an approach to extract features from the Sejong treebank. Syntactic tags and morphological analysis allow us to extract syntactic features automatically and to develop universal features. For example, NP-SBJ syntactic tag is changed into NP and a syntactic feature Case=Nom is added. Syntactic tags which end with -sbj (subject), -obj (object) and -CMP (attribute), we extract Case features which describe argument structures in the sentence. Alongside Case features, we also extract Mood and Tense from the morphological analyses in the Sejong treebank. Since however morphological analyses for verbal and adjectival endings in the Sejong treebank are simply divided into ep (nonfinal endings), ef (final endings) and ec (conjunctive endings), Mode and Tense features can not be extracted directly. Park (2006) such as -si. Universal dependency representations We use basic dependencies (core, non-core, noun dependents) for eojeols for segmentation granularity in \u00a72.1. We add punct between word and punctuation marks ( \u00a72.2), and case between noun phrase and case markers ( \u00a72.3). We also employ fixed for verbal endings ( \u00a72.4). Initial dependency labels are based on phrase information in the Sejong treebank such as np-sub, np-obj, etc. We create conversion rules to conform to Universal Dependency relations. nsubj (nominal subject) and csubj (clausal subject) can be assigned in which np-sbj occurs and nouns ended with either jks (nominative marker) or jx (topic marker). We distinguish nsubj and csubj as follows: \u2022 if a subject noun is a derivational noun from the verb or the adjective, which are usually ended with etn+jks or etn+jx (where etn is a derivational morpheme for the noun), then csubj. \u2022 otherwise, nsubj. (2) a. While the previous UD for Korean uses nsubj:pass for the passive construction in Korean, we do not use it for the following two reasons: First, passive and causative verbs are often in the same form if they use passive or causative derivational morphemes such as -i, -hi, etc. and they are very ambiguous. Second, intransitive verbs are also allowed in the passive construction unlike in English. obj (direct object) can be assigned in which np-obj occurs and nouns ended with jko (accusative marker). There are several cases where nouns can be ended with jx (topic marker). There are also some cases where nouns can be ended with jx (topic marker) for obj. iobj (second core dependent) can be assigned when np-alt (NP adjunct) occurs and nouns ended with jkb (auxiliary marker) such as -ege, -e, -gge (dative markers). (3) ... sagoa-leul unggaro-ege ju-eoss-da acl (adnominal clause) and amod (adjectival modifier) for Korean, in which vp-mod occurs, are defined as follows: \u2022 if a verb ends with etm (verbal/adjectival ending for the relative clause) and it modifies a noun, we assign acl. \u2022 if a adj ends with etm and it modifies a noun, we assign amod. UD for Korean annotates acl:rel instead of acl to specify a relative clause for the verb ended with etm. ajt (adjunct) or nmod (nominal dependents) can be assigned where np-ajt or np occurs, respectively. det:poss is assigned for noun ended with jkg (genitive marker). Other UD relations such as advmod, det, etc can be assigned as a 1-to-1 mapping table by using Sejong POS labels as described in Table 1 . Experiments and Results We collected sentences from news articles in one of Korean News websites published during 2016. 4  We select the length of sentences in which there We perform initial automatic preprocessing tasks using existing tools for Korean such as POS tagging (Hong, 2009) , assigning Universal POS labels (Petrov et al., 2012; Park et al., 2016) , and MaltParser-based dependency parsing (Park et al., 2016) . We manually correct the initial preprocessing tasks especially focused on dependency relation as described in \u00a73.3. 6 First, we build a corpus as described in \u00a72. tation schemes based on segmentation granularity for Korean. Table 3 shows results produced by UDPipe (Straka et al., 2016) . Upper granularity (towards granularity described in \u00a72.4) generally gives better results than lower granularity (towards \u00a72.1) because lexical items with functional morphemes in lower granularity can yield data sparseness. Bengoetxea and Gojenola (2010) presents a system that also changes segmentation granularity. They converted back the result of parsing to the original granularity to decide whether the new representation is effective for parsing. Additionally, the usual attachment score metrics used to evaluate dependency parsers are biased as described in Nivre and Fang (2017) for the cross-lingual setting. This bias can be equally applied to different segmentation granularity for Korean. We leave the evaluation as future work. The current Universal Dependencies treebank for Korean used for the CoNLL 2017 UD Shared Task (Zeman et al., 2017) 7 uses the same segmentation granularity as described in \u00a72.2. We obtain 59.64% (UAS) and 51.05% (LAS) using the current version of UD for Korean (Nivre et al., 2017) . While the current UD for Korean has a more sentences in the training data (4400 sentences vs. 3000), its results are comparable with the results by our corpus of \u00a72.2 where we obtain 65.72% (UAS) and 48.44% (LAS). Conclusion The different levels of segmentation granularity described in this paper are mainly due to different representations of syntactic structure in the various Korean treebank datasets. They have used different word segmentation depending on their linguistic and computational requirements. While a certain segmentation granularity may be well suited for some linguistic phenomena or applications, it does not mean that this granularity is a better representation than the other in general. We need to find the most adequate segmentation granularity to adapt to our requirements for Korean language processing. The UDs corpus for Korean based on different levels of segmentation granularity will be publicly available. Acknowledgement We thank Francis Morton Tyers, Lo\u00efc Dugast, and the anonymous reviewers for their helpful comments and suggestions.",
    "abstract": "Previous work on Korean language processing has proposed different basic segmentation units. This paper explores different possible dependency representations for Korean using different levels of segmentation granularity -that is, different schemes for morphological segmentation of tokens into syntactic words. We provide a new Universal Dependencies (UD)-like corpus based on different levels of segmentation granularity for Korean. The corpus contains 67K words in 5,000 sentences which are split into training, development and evaluation data sets. We report parsing results using the new dependency corpus for Korean and compare them with the previous Korean UD corpus.",
    "countries": [
        "United States"
    ],
    "languages": [
        "Korean"
    ],
    "numcitedby": "4",
    "year": "2017",
    "month": "September",
    "title": "Segmentation Granularity in Dependency Representations for {K}orean"
}