{
    "article": "This paper presents an overview of Task 4 at SemEval-2022, which was focused on detecting Patronizing and Condescending Language (PCL) towards vulnerable communities. Two sub-tasks were considered: a binary classification task, where participants needed to classify a given paragraph as containing PCL or not, and a multi-label classification task, where participants needed to identify which types of PCL are present (if any). The task attracted 77 teams. We provide an overview of how the task was organized, discuss the techniques that were employed by the different participants, and summarize the main resulting insights about PCL detection and categorization. Introduction The study of unfair, misleading or offensive language has attracted the interest of many scholars from the NLP research community. Most relevant tasks in this context focus on explicit, aggressive and flagrant phenomena, such as fake news detection or fact-checking (Conroy et al., 2015; Nakov et al., 2018; Atanasova et al., 2019; Barr\u00f3n-Cedeno et al., 2020) ; detecting propaganda techniques (Da San Martino et al., 2020) ; modeling offensive language (Zampieri et al., 2019 (Zampieri et al., , 2020) ) identifying hate speech (Basile et al., 2019) ; and rumour propagation (Derczynski et al., 2017) . However, there also exist subtler but equally harmful types of language, which have received less attention by the NLP community, and which, due to their subtle nature, we can expect to be more difficult to detect. This is the case, among others, for Patronizing and Condescending Language (PCL), which was the focus of Task 4 at SemEval-2022. An entity engages in patronizing or condescending communication when its use of language reveals a superior attitude towards others. These attitudes, when normalized, routinize discrimination and make it less visible (Ng, 2007) . Furthermore, the use of PCL is often unconscious and well-intended, especially when referring to vulnerable communities (Wilson and Gutierrez, 1985; Merskin, 2011) . This good will can make PCL especially harmful, as the audience receives this discriminatory language with low defense and is often unaware of its effects. Research in sociolinguistics presents PCL as a subtle, often unconscious but harmful and discriminative kind of language (Mendelsohn et al., 2020) . It creates and feeds stereotypes (Fiske, 1993) , which result in greater exclusion, rumour spreading and misinformation (Nolan and Mikami, 2013) . PCL also tends to strengthen power-knowledge relationships (Foucault, 1980) , calling for charitable action instead of cooperation and presenting those who can help as saviours of those in a less privileged position (Bell, 2013; Straubhaar, 2015) . Furthermore, PCL tends to conceal who is responsible for very deep-rooted societal problems, sometimes by implicitly or explicitly blaming the underprivileged communities or individuals for their situation, and often involves ephemeral and simple solutions. (Chouliaraki, 2010) . The use of PCL by privileged communities has also been related to the so-called pornography of poverty (Nathanson, 2013) , a communication style that depicts vulnerable situations with a pity discourse to move a target audience to charitable action and/or compassionate attitudes. While the negative impact of PCL, both in social interactions and in corporate and political discourse, has been extensively studied in the social sciences, it still remains an under-explored phenomenon in NLP. Nonetheless, we believe that PCL detection offers a number of important challenges for NLP research, which warrant more work in this area, especially given the societal benefits that would result. For instance, given its subtle and subjective nature, we can expect PCL detection to be harder than tasks that are focused on more flagrant phenomena. Moreover, PCL detection often involves the need for an implied understanding of human values and ethics, which requires a form of commonsense reasoning that NLP models are likely to struggle with. In this context, we have organized SemEval 2022 Task 4: Patronizing and Condescending Language (PCL) Detection. This task has attracted more than 300 participants, organized in 77 teams, during the official competition. The competition remains open on CodaLab to encourage further research on this topic 1 . Related Work As already mentioned in the introduction, PCL has been extensively studied within the context of sociolinguistics (Margi\u0107, 2017; Giles et al., 1993; Huckin, 2002; Chouliaraki, 2006) . Within NLP, however, modelling of patronizing discourse has only received limited attention. As a notable exception, Wang and Potts (2019) compiled a corpus of Reddit comments, which were annotated as using a condescending tone or not. Note that in contrast to our SemEval task, their work did not specifically focus on vulnerable communities. In our previous work (Perez-Almendros et al., 2020) , we introduced Don't Patronize Me!, which is, to the best of our knowledge, the first annotated corpus of PCL towards vulnerable communities. This corpus was used as the training data for the SemEval task. Some other works have studied types of discourse that are highly related to condescension, including Sap et al. (2020) , who studied how certain uses of language indicate power relations, Mendelsohn et al. (2020) , who discussed the dehumanization of minorities through language and Zhou and Jurgens (2020), who investigated how some expressions of condolences and empathy interplay with authoritative voices in online communities. Dataset The seed material for this task is Don't Patronize Me! (DPM), an annotated dataset with Patronizing and Condescending Language towards vulnerable communities, which was introduced in our previous work (Perez-Almendros et al., 2020) . This dataset contains 10,469 paragraphs, which were used as the training set for the SemEval task. To create the test set for this task, we annotated 3,898 additional paragraphs, following the same process. All paragraphs were extracted from news stories from media in 20 English speaking countries, origi-nally provided by the News on Web (NoW) corpus 2 (Davies, 2013) . We used a keyword-based strategy to collect paragraphs, focusing on texts in which vulnerable communities are mentioned (e.g., refugees or homeless). The data was annotated by three annotators, with backgrounds in communication, media and data science. For the main dataset, two annotators annotated the instances with the following labels: 0 (not PCL), 1 (borderline), and 2 (PCL), achieving an inter-annotator agreement (IAA) of 41% for the raw annotations and 61% when removing borderline cases. For all the total disagreements (paragraphs labeled 0 by one annotator and 2 by the other), the third annotator acted as a referee, providing a final label. The final dataset uses a scale from 0 to 4, indicating the level of agreement between the annotators. Labels 0 and 4 correspond to clearly not condescending and clearly condescending (i.e. both annotators assigned 0 or both assigned 2), label 2 means that both annotators marked that paragraph as a borderline case (1-1), and labels 1 and 3 correspond to cases where either one of the annotators assigned the borderline label (0-1 or 1-2), or there was a disagreement that was resolved by the third annotator. Each positive example from the dataset is furthermore labelled with one or more PCL categories. We briefly recall the meaning of these categories. Unbalanced power relations (UNB): the author entitles themselves as being in a privileged situation, considering themselves as saviours of those in need (Bell, 2013; Straubhaar, 2015) . Shallow solution (SHAL): a charitable, superficial and short-term action is presented as life changing. Presupposition (PRES): stereotypes and clich\u00e9s are used to describe a community, relying on assumptions without having all the information. Authority voice (AUTH): the author stands as spokesperson and defendant of the community or individual and/or allows themselves to give expert advice about how to overcome underprivileged situations. Metaphor (MET): the author describes a difficult situation in a more poetic way through Cat. Examples UNB They deserve another opportunity or You can make a difference in their lives. SHAL Raise money to combat homelessness by curling up in sleeping bags for one night. PRES Elderly or disabled people who are simply unable to evacuate due to physical limitations. AUTH Accepting their situation is the first step to having a normal life. MET Poor children might find more obstacles in their race to a worthy future. COMP [...] discarded in the streets of Europe [...] MERR Her mom is disabled and living with her gives her strength to face everyday's life or Refugees are wonderful people. Table 1 : Examples of the different PCL categories. figures-of-speech such as metaphors and euphemisms. Compassion (COMP): the message uses flowery wording to reflect on the vulnerability or toughness of the situation, raising a feeling of pity among the audience. The poorer, the merrier (MERR): the author praises the vulnerability, granting positive values to all members of a vulnerable community and showing their admiration. Task Description The aim of the proposed task is to identify the presence of PCL (Subtask 1), and to identify the categories of PCL that are present in a given paragraph (Subtask 2). Training data The 10,469 annotated paragraphs from the DPM corpus were provided as training data. To frame Subtask 1 as a binary classification problem, paragraphs with labels 0 and 1 were considered as negative examples, while paragraphs 3 See Perez-Almendros et al. ( 2020 ) for further details. with labels 3 and 4 were considered as positive examples of PCL. The original labels on the scale from 0 to 4 were also made available. The 993 positive examples in the training data are labelled with the corresponding PCL categories. Span annotations for these categories were also provided. Test data A total of 3,898 paragraphs were released as test set, with the same format and metainformation as the training set, but without labels and span annotations. Paragraphs initially labelled as 2 were excluded from the test data, as these correspond to borderline cases. External resources We welcomed the use of external resources in this task. Participants were encouraged to explore transfer learning or data augmentation techniques with a variety of source corpora and language resources. Evaluation System submissions were ranked in the two subtasks as follows: Subtask 1: F1 score for the positive class. Subtask 2: Macro-averaged F1 over all categories. Participation Framework The task was hosted on CodaLab 4 , with participants needing to register and submit their results through the platform. The competition involved the following three phases: \u2022 Practice phase: The 10,469 paragraphs from the training data were split into 8,376 training paragraphs and 2,095 validation paragraphs. This was done to allow participants to compare their systems on a public leader board. The training-validation split respected the natural distribution of labels in the data. \u2022 Evaluation phase: This was the official evaluation phase for the SemEval competition. The test data was released and the leader board for this phase remained hidden to prevent participants from fine-tuning their systems on the test data. Each participant was allowed two different submissions for each subtask. \u2022 Post-evaluation phase: The learderboard for the evaluation phase and the official ranking for each subtask were published, as the Sem-Eval competition ended. Participation in the SemEval task is no longer possible, but the competition remains open on CodaLab to allow participants to re-test and further improve their systems. Results and Discussion A total of 77 different teams participated in the evaluation phase of our task, with 145 valid submissions for Task 1 and 84 for Task 2. For the competition, we allowed a maximum of 2 submissions per team. A total of 42 out of 77 teams outperformed the baseline for Subtask 1, while 37 out of 48 outperformed the baseline for Subtask 2. Tables 2 and 3 present the rankings for Subtask 1 and 2, respectively, where we have only listed the best performing system for each team. For Subtask 1, the best-performing systems used the following strategies: Team PALI-NLP used an ensemble of pre-trained RoBERTa models (Liu et al., 2019) . While training, they applied grouped Layer-Wise Learning Rate Decay, a variant of LLRD (Howard and Ruder, 2018) , based on the idea that different layers capture different types of information (Yosinski et al., 2014) . By optimizing the learning rate in different layers, the model captures more diverse and fine-grained linguistic features of PCL. To tackle the class imbalance in the dataset, they use weighted random samples (Hashemi and Karimi, 2018) to emphasize the positive instances. Team STCE created adversarial examples to train an ensemble model of RoBERTa and De-BERTa (He et al., 2020) . They also used weighted samples to address the class imbalance and explored different loss functions, establishing Cross Entropy and the contrastive loss algorithm NT-Xent introduced by Chen et al. ( 2020 ) as first and second loss function, respectively. For Subtask 2, the best-performing systems used the following strategies: Team BEIKE NLP participated with a system based on prompt learning (Petroni et al., 2019; Brown et al., 2020) . They first reformulate PCL detection as a cloze prompt task and then fine-tune a pre-trained DeBERTa model. For both sub-tasks, unsurprisingly, most systems rely on pre-trained language models, although a few teams have used CNN, LSTM, SVM or Logistic Regression based systems (XU, PC1, I2C, Ryan Wang, McRock, Amrita_CEN, SATLab and Team Lego, among others), or an ensemble of some of the above together with language models (UTSA_NLP, Taygete). Although the use of language models usually outperformed other systems in this task, some LSTM models, such as the one submitted by team Xu, achieved competitive results. The ensembling of different models has also been a popular technique. Other strategies that proved successful include adversarial training, data augmentation and multitask learning. In the following, we summarize how these techniques have been used by the different systems. Ensemble learning Ensembling different models has previously been found useful for text classification (Nozza et al., 2016; Kanakaraj and Guddeti, 2015; Fattahi and Mejri, 2021) . Accordingly, ensembling was one of the most common strategies for improving on baseline PCL detection methods. Most of the teams combined different language models (e.g. PALI-NLP, STCE, PINGAN Omini-Sinitic,PAI_Team, LRL_NC, SSN_NLP_MLRG, ASRtrans, amsqr, UMass PCL). Considering the choice of language models, the most successful systems either used RoBERTa, DeBERTa or an ensemble which included the former ones and other models. For instance, these models were used by the best performing teams for both subtasks, i.e. PALI-NLP and STCE for Subtask 1 and BEIKE NLP and PINGAN Omini-Sintic for Subtask 2. To fine-tune the language models effectively, incorporating a contrastive loss function, in addition to the standard cross-entropy loss, has also proved useful. Finally, it should be noted that the combination of language models with different types of neural networks (Taygete, UTSA_NLP) has also proven useful. Balancing class distribution The class imbalance in the dataset has been addressed by participating teams in different ways. Some teams opted for downsampling the number of negative examples (Ryan Wang, LastResort, MS@IW), while others tried a cost-sensitive learning approach to address this issue (Amrita_CEN). However, the most popular approach to balance the class distribution has been through data augmentation (amsqr, Xu, Utrech Uni, UMass PCL, among others). To create new positive examples, participants have used strategies such as the use of large generative models like GPT3 (Brown et al., 2020) or T5 (Raffel et al., 2020) (MS@IW, PINGAN Omini-Sinitic and Tesla); back-translation (Taygete); the addition of synonymous sentences to the original data (I2C), or the application of the so-called Easy Data Augmentation methods, a set of simple but effective techniques such as synonym replacement, random insertion, random swap, and random deletion (AliEdalat) (Wei and Zou, 2019; Rastogi et al., 2020) . External resources Various types of external resources have been used. For example, lexical databases such as WordNet (Miller, 1995) have been used to augment, enrich and improve the training data (Ali Edalat). Datasets from related tasks, including TalkDown (Wang and Potts, 2019) , and two metaphor detection datasets, namely MOH (Mohammad et al., 2016) (Hu et al., 2020) , have also been used to improve several systems (Ali Edalat, ASRtrans, Tesla, MaChAmp). Other related NLP challenges have served as auxiliary tasks for pre-training PCL models (AliEdalat, UMass PCL), although such strategies have not always been successful (ULFRI). The MaChAmp team used 7 SemEval-2022 tasks, including ours, for training a model based on multi-task learning. The DH-FBK team also opted for multi-task learning, but they only used the data from the Don't Patronize Me dataset itself to create auxiliary tasks. For instance, they trained their model to predict the uncertainty of a label in Subtask 1, using the finegrained set of labels (0-4); the agreement of the annotators in Subtask 2; the spans where the cate-gories were present; or the country of origin of the news outlets. AliEdalat similarly used the metainformation from the Don't Patronize Me dataset as additional features for training their model. Prompt learning",
    "funding": {
        "defense": 0.0,
        "corporate": 0.0,
        "research agency": 1.9361263126072004e-07,
        "foundation": 0.0,
        "none": 0.9999499805090164
    },
    "reasoning": "Reasoning: The provided text does not mention any specific funding sources for the research or the development of the SemEval-2022 Task 4. Without explicit mention of funding from defense, corporate entities, research agencies, foundations, or an indication of no funding, it is not possible to accurately determine the funding sources based on the provided information.",
    "abstract": "This paper presents an overview of Task 4 at SemEval-2022, which was focused on detecting Patronizing and Condescending Language (PCL) towards vulnerable communities. Two sub-tasks were considered: a binary classification task, where participants needed to classify a given paragraph as containing PCL or not, and a multi-label classification task, where participants needed to identify which types of PCL are present (if any). The task attracted 77 teams. We provide an overview of how the task was organized, discuss the techniques that were employed by the different participants, and summarize the main resulting insights about PCL detection and categorization.",
    "countries": [
        "United Kingdom"
    ],
    "languages": [
        "English"
    ],
    "numcitedby": 33,
    "year": 2022,
    "month": "July",
    "title": "{S}em{E}val-2022 Task 4: Patronizing and Condescending Language Detection"
}