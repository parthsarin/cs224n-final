{
    "article": "In this paper, we propose a system that automatically generates templates for detecting Chinese character errors. We first collect the confusion sets for each high-frequency Chinese character. Error types include pronunciation-related errors and radical-related errors. With the help of the confusion sets, our system generates possible error patterns in context, which will be used as detection templates. Combined with a word segmentation module, our system generates more accurate templates. The experimental results show the precision of performance approaches 95%. Such a system should not only help teachers grade and check student essays, but also effectively help students learn how to write. Introduction In essays written in Chinese by students, incorrect Chinese characters are quite common. Since incorrect characters are a negative factor in essay scoring, students should avoid such errors in their essays. Our research goal is to build a computer tool that can detect incorrect Chinese characters in student essays and correct them, so that teachers and students can learn faster with help from the computer system. Compared with the detection of spelling errors in English, the detection of incorrect Chinese characters is much more difficult. In English, a word consists of a series of letters while a meaningful Chinese word usually consists of 2 to 4 Chinese characters. The difficulty lies partly in the fact that there are more than 5,000 high-frequency characters. In previous works on Chinese character error detection systems (Zhang, Huang, Zhou, & Since the cost of manual compilation is high, Chen et al. proposed an automatic method that can collect these common errors from a corpus (Chen, Wu, Lu, & Ku, 2009) . The idea is similar to template generation, which builds a question-answer system (Ravichandran & Hovy, 2001) (Sung, Lee, Yen, & Hsu, 2008) . The template generation method investigates a large corpus and mines possible question-answer pairs. Templates for Chinese character error detection can be generated and tested by the chi-square test on the basis of a large corpus. In this paper, we will further improve the methods for building confusion sets and automatically generating a template. According to recent studies (Liu, Tien, Lai, Chuang, & Wu, 2009a; 2009b) , character errors in student essays are of four major types: errors in which characters have similar shapes (30.7%), errors in which characters have similar pronunciation (79.9%), errors in which the two previous types are combined (20.9%), and other errors (2.4%). Therefore, an ideal system should be able to deal with these errors, especially those resulting from similar pronunciation and similar character shapes. The confusion set for similar pronunciation is relatively easy to build, whereas the confusion set for similar shapes is more difficult. In addition to the Wubi input method, the Cangjie input method is also used to compile confusion sets (Liu & Lin, 2008) . The paper is organized as follows. In Section 2, we introduce the system design and related works. In Section 3, we describe a new process of template generation. Section 4 describes the experimental procedure and the data. Finally, in Section 5, we give the conclusion and propose our future research. Improving the Template Generation for 129 Chinese Character Error Detection with Confusion Sets System Design Chinese Character Error Detection and Correction System The system that can detect and correct Chinese character errors works as follows. First, it needs a student to input an essay. The system then reports the errors in the essay and gives suggestions on correction, as shown in Figure 1 . Such a system uses templates that can detect whether common errors have occurred. A template consists of a pair of words, a correct one and an error one, such as \"\u8faf\uf941\u6703\"-\"\u8fa8\uf941\u6703\". For example, if the error template \"\u8fa8\uf941\u6703\" is matched in an essay, our system can conclude that there is an error and make a suggestion on correction to \"\u8faf\uf941\u6703\". Figure 1. System function of Chinese character error detection in an essay In previous works, these templates were compiled manually (Liu, Tien, Lai, Chuang, & Wu, 2009b) . The quality of the manually-edited templates is high. Nevertheless, the method is time-consuming and costs too much manpower. Therefore, an automatic template generation method based on the context of errors was proposed in 2009 (Chen, Wu, Lu, & Ku, 2009) , several examples of automatically generated tri-gram and four-gram templates are shown in Figure 2 . The automatic template generation method is less costly; however, it does not accommodate conventional vocabulary. The template generation method has a serious drawback. In Figure 2 , we find that several templates contain unrecognizable words, such as \"\u8faf\u8b77\uf9d8,\" \"\u8996\u8faf\uf941,\" and \"\u96fb\u8996\u8faf,\" which are trigrams of Chinese characters that do not have any meaning. These templates can be used to detect character errors, but are not suitable for suggesting corrections. In the following subsections, we will propose a new method to avoid this drawback. Confusion Set The first step in template generation is to replace one character in a word with a character in the corresponding confusion set. For example, by replacing one character in the correct word \"\u82ad\u8549,\" we get a wrong word \"\u7b06\u8549\". Such a correct-wrong word pair is used as the template for error detection and correction suggestion. According to Liu et al. (Liu, Tien, Lai, Chuang, & Wu, 2009a; 2009b) , the most common error types are characters with similar shapes and characters with similar pronunciation. The percentage of these two types of errors combined is 89.7% of all errors. Therefore, the confusion set should deal with characters with similar pronunciation and shapes. We first compile all of the characters that have the same pronunciation from a dictionary and make them the elements of a confusion set. For example, \"\u516b(ba1)\" and \"\u5df4(ba1)\" have the same pronunciation. Therefore, they belong to the same confusion set. To reduce the size of the confusion set, we treat characters with different tones as belonging to different sets, even though they sound similar. For example, \"\u7f77(ba4)\" is not in the confusion set of \"\u516b (ba1)\". We formed 1,351 sets with a total of 15,160 characters, as shown in Figure 3 . In this paper, we use a simple rule to compile characters with similar shapes. In the first book on Chinese characters, known as Shuowen Jiezi (\uf96f\u6587\u89e3\u5b57) (Xu, 2009) , in the second Chinese Character Error Detection with Confusion Sets century, radicals (\u90e8\u9996) were used to categorize characters. We use the key component of a character, its radical, as the basic shape of the character to find the characters with the same radicals. There are 214 radicals in Chinese, according to the Kangxi Dictionary (\u5eb7\u7199\u5b57\u5178) (Zhang, 1999) . Therefore, we compile 214 confusion sets with a total of 9,752 different characters. Figure 4 shows some examples. After constructing the confusion sets, our system can find characters with the same pronunciation and characters with similar shapes for any character that is input. For example, given a character \"\u5147,\" the system can find characters with the same pronunciation \"\u51f6\u5144\u5308\u6d36 \u605f\u80f8,\" and characters with similar shapes \"\u5144\u5149\u5146\u5148\u514c\u514b\u514d,\" as shown in Figure 5 . This is a crucial step of our new template generation. Zhuyin Pinyin Characters \u3105\u311a ba1 \u8686\u6252\u516b\u5df4\u4ec8\u53ed\u6733\u82ad\u75a4\u634c\u7b06\u7c91\u8c5d\u9200\u5427 \u3105\u311a\u02ca ba2 \u9238\u8307\u62d4\u80c8\u8dcb\u83dd\u8a59\u8ef7\u9b43\u9f25\u72ae \u3105\u311a\u02c7 ba3 \u9200\u628a\u9776 \u3105\u311a\u02cb ba4 \u4f2f\u7f77\u9738\u7308\u5f1d\u7238\u58e9\u705e\u628a\u8019 \u3105\u311b bo1 \u525d\u5697\u6ce2\u889a\u73bb\u67ed\u7835\u7f3d\u5575\u83e0\u7886\u64a5\u5d93\u8e73\u9c4d\u5ca5\u64ad\u894f \u3105\u311b\u02ca bo2 \u7206\u4f2f\u72ae\u894f\u6300\u8514\u67cf\u74dd\u8584\u6cca\u8b08\u6ffc\u92cd\u5e1b\u52c3\u80c9\u632c\u6d61 \u3105\u311b\u02c7 bo3 \u7c38\u8ddb\u86be \u3105\u311b\u02cb bo4 \u64ad\u6a97\u8617\u4eb3\u64d8\u8b52\uf963\u6300\u859c\u7c38\u7e74 Figure 3. Examples of characters in confusion sets Radicals Characters \u4e00 \u4e00\u4e02\u4e01\u4e03\u4e09\u4e0b\u4e08\u4e0a\u4e07\u4e0c\u4e11\u4e10\uf967\u4e0f\u4e19\u4e16\u4e15\u4e14 \u4e36 \u4e38\u51e1\uf95e\u4e3b \u4e3f \u4e42\u4e43\u4e45\u4e48\u4e4b\u5c39\u4e4d\u4e4f\u4e4e\u4e52\u4e53\u4e51\u4e56\u4e58 \u4e59 \u4e59\u4e5d\u4e5c\u4e5f\u4e5e\u4e63\u4e69\u4e73\u4e7e\uf91b \u4e85 \uf9ba\u4e88\u4e8b \u4e8c \u4e8c\u4e8e\u4e91\u4e95\u4e92\u4e94\u4e93\u4e99\u4e9b\u4e9e\u4e9f \u4ea0 \u4ea1\u4ea2\u4ea4\u4ea6\u4ea5\u4ea8\u4eab\u4eac\u4ead\uf977\u4eb3\u4eb6\u4eb9 \u4eba \u4eba\u4ec1\uf9fd\u4ec3\u4ec6\u4ec7\u4ecd\u4eca\u4ecb\u4ec4\u4ec2\u4ec9\u4ee5\u4ed8\u4ed4\u4ed5\u4ed6\u4ed7 \u513f \u5140\u5143\u5141\u5145\u5144\u5149\u5147\u5146\u5148\u514c\u514b\u514d\u5155\u5154\u5152\u5157\u515a\u515c \u5165 \u5165\u5167\u5168\uf978 Automatic Template Generation Figure 6 shows the flowchart of our automatic template generation process. The basic assumption is that the corpus might contain more correct words than wrong ones. Therefore, our system first replaces one character in the correct words to form the corresponding wrong words. Then, our system checks the frequency of the words in the corpus. If the replacement creates a word with a relatively high frequency, we do not treat it as a wrong word. Figure 6. The flowchart of the automatic template generation process As we mentioned in Section 2.1, the automatically-generated templates might not be suitable for suggesting corrections. To overcome this drawback, we use existing vocabulary, instead of n-gram character sequences, as the candidate for a template. There are 145,608 words in the MOE dictionary (Ministry of Education, 2007) . We treat them as the seeds of the templates. In our experiment, we focus on 4,998 high-frequency characters that were compiled on the basis of a 1998 survey (National Languages Committee, 1998). Our system generates templates by checking each high-frequency character and finding all of the words that contain the character. Then, the system replaces the character in each Chinese Character Error Detection with Confusion Sets word with a character in the corresponding confusion set. The correct-wrong word pair undergoes a simple statistical test. If it passes the test, it will be kept as a template; otherwise, it will be discarded. The statistical test is based on the frequency of each word in the pairs appearing in a large corpus. To prevent the process from generating controversial templates, our system also conducts a close test. The close test checks whether the new template will cause a false alarm on our old test data. The template that generates conflicting templates will also be discarded. The close test threshold is set to 0, which means any template that might cause a false alarm will not be used. A template generation example is shown in Figure 7 . The statistical test in our system is not a rigid test. We tune the threshold of relatively high frequency based on two formulae. One is adopted from the chi-square test, and the other one is from our observation. The first test is a simplified (n=1) chi-square test used in a previous work (Hung & Wu, 2008) : 2 2 ( ) O E X E \u2212 = , ( 1 ) where E is the frequency of a correct word and O is the frequency of a wrong word. To avoid further disputation, we assume that E>O in our study. The chi-square test provides a threshold mechanism to decide whether a correct-wrong pair is a proper template or not. In this study, we suggest the test should be like Equations ( 2 ) and (3). , Cfreq Wfreq Cfreq AverageFreq > > (2) 1 ( ) n i Cvocabulary i Threshold n = = \u2211 , ( 3 ) where Cfeq is the frequency of the correct word, Wfeq is the frequency of the wrong word, and AverageFreq is the average of the frequencies of all correct words. If the frequency of the correct word is higher than the threshold and if the square root of the frequency of the correct word is higher than the frequency of the wrong word, then the pair passes the test. We have found that the templates that do not pass the test are also the ones that will cause false alarms; for example, the pairs \"\u672a\uf92d\"-\"\u70ba\uf92d,\" \"\u5df2\u7d93\"-\"\u4ee5\u7d93,\" and \"\u4f46\u662f\"-\"\u4f46\u4e8b\". When the context is different, these templates do not always give correct detection results and cause false alarms. Word Segmentation As in the examples above, short templates with only two characters could cause false alarms. The reason is that, when we treat words as bi-gram character sequences, many word boundaries may be unclear. For example, as shown in Figure 8 , the template \"\u64c1\u6709\"-\"\u96cd\u6709\" can be used to detect and correct the first sentence, \"\u4e00\u500b\u4eba\u53ef\u96cd\u6709\u5f88\u591a\u5feb\uf914\", in which one of the word pair appears, but the template \"\u64c1\u6709\"-\"\u4ee5\u6709\" cause a false alarm in the second sentence, \"\u4e00\u500b\u4eba\u53ef\u4ee5\u6709\u5f88\u591a\u5feb\uf914\". We find that this failure can be avoided by using correct word segmentation. The character \"\u4ee5\" should be a part of the previous word \"\u53ef\u4ee5\". If we have enough confidence in the word segmentation, then the characters in a segmented word should not be candidates for character error detection. Figure 8. A false alarm in the second sentence for a short template \"\u64c1\u6709\"-\"\u96cd\u6709\" and \"\u64c1\u6709\"-\"\u4ee5\u6709\" We assume that a word segmentation tool can give the correct results for normal input sentences and does not segment sentences with wrong character sequences into words. Figure 9 shows the segmentation results of the two sentences shown in Figure 8 . In our experiment, we used the segmentation tool provided by CKIP, Academia Sinica 1 . With the help of this segmentation tool, our system can compile more accurate short templates. Some short templates are shown in Figure 10 . Chinese Character Error Detection with Confusion Sets Figure 9. Segmentation tool can help prevent false alarms Experimental Settings, Results and Analysis Training Corpus and Student Essays Our method requires a large corpus to compile templates. Therefore, we used the largest available news corpus as our training set. The corpus is described in Table 1 . Student essays were collected from one junior high school in Taipei. We used some of the essays for the close test and the rest as the open test, keeping them unseen to the system. The students were 7 th or 8 th graders. The essays were reviewed by their teachers, and the character errors were highlighted. These 3264 essays were written by hand and were digitized later. See Figure 11 for an example. This is part of our experimental setting that tries to avoid the influence of different input methods. We deleted some symbols and characters that could not be represented by Unicode. Figure 11. The file format of our test corpus Table 2 shows the analysis of the student essays. Most of the characters (94%) in use fell into the frequent characters set. Character errors were not very serious for most of the students, with less than 2 character errors per essay. Table 3 shows our analysis of the character error types. We find that even in written essays, students tend to write characters having the same pronunciation (66~70%). There is also a high percentage of wrong written characters with the same radical (13~16%). Table 4 Improving the Template Generation for 137 Chinese Character Error Detection with Confusion Sets shows the templates most used for the student essays. These templates are quite common and are too simple for teachers to teach at the 7 th and 8 th grade levels. A system that can correct these errors may reduce the work of teachers. System Evaluation In this study, we compare the quality of characters manually compiled from books and students with that of automatically generated ones. Since the frequencies of 2-character words, 3-character words, and 4-character words are very different, our system uses different thresholds -2300, 500, and 100 for 2-character words, 3-character words, and 4-character words, respectively, in the experiment. The precision and recall are defined as follows: dr ( ) r Macro Recall N \u2211 = (4) dr ( ) sd Macro Precision N \u2211 = (5) (dr) Micro Recall (r) \u2211 = \u2211 (6) (dr) Micro Precision (sd) \u2211 = \u2211 (7) where dr is the number of correct characters, r is the number of character errors, sd is the number of character errors that our system detects, and N is the number of all of the essays. Macro Precision and Macro Recall are focused on the performance of correction per essay. This is what real world students might encounter with the system. As Micro Recall and Micro Precision treat the whole data set as one essay, they are suitable for evaluating the average performance of the system. We prefer high precision while maintaining a relatively high recall because we do not want the users to see too many false alarms. Experimental Results We conducted a series of experiments to determine how to improve our system. First, we used confusion sets and the chi-square test to generate templates and compared the performance with the previous work, which did not use confusion sets. Second, we tested whether the square root test is more suitable for our system than the chi-square test. Third, we tested the influence of the segmentation added to our system. We report the best performance of the experimental results by combining the automatically generated templates with the manually edited templates. The Comparison of Eexperimental Results of Four Automatic Template Generation Settings Figure 12 shows the experimental results of using the chi-square test in template generation. Setting A used the automatically generated 19,402 templates in the previous work. Setting B used the confusion sets during the process of automatic template generation. The total number of generated templates was 54,253. The performance of the method proposed in this paper is better than the previous work for both precision and recall. Setting C was the automatically generated templates using the confusion set and the square root test. The total number of templates was 50,467. This new setting results in much higher precision. The Macro Precision value is even better than the manually edited Macro Precision value. This result shows that, when we reduce the automatically generated templates with the square root test, we also reduce noise. For Setting D, our system used confusion sets and a word segmentation tool before the square root test, which generated 9,013 templates. We find that the number of templates is reduced while the performance is improved in terms of both Macro Precision and Micro Precision. The trade off is the performance of recall. Improving the Combining Automatically Generated Templates with Manually Edited Templates Figure 13 shows the comparison of the performance of our system combing automatically generated templates with manually edited templates. Setting E used the 6,701 manually edited templates. Setting F used the combination of Setting E and Setting C, which had a total of 57,167 templates. Setting G used the combination of Setting E and Setting D, totaling 15,713 templates. The performance of the combinations declines a little bit in terms of both Macro Precision and Micro Precision. Nevertheless, there is an increase in both Macro Recall and Micro Recall. Compared with the results in the previous experiment, the combination helps the overall performance. This means that our system can incorporate more templates and attain better performance in the future. Figure 13. A comparison of experimental results of combining manually edited with automatically generated templates Based on the analysis of the confusion sets, our system should have a 70% to 80% recall rate because we compile all of the characters with the same pronunciation and some similar characters in the confusion sets. Nevertheless, the recall remains low, even though we are able to control the high-precision performance. Therefore, we will need to conduct further analysis of our system. Analysis of the Mistakes in the Experiment In this subsection, we discuss the 90,135 templates in Setting I of the third experiment, which were generated by using confusion sets, word segmentation, and the square root test. This setting was designed to maintain high precision and to increase recall. Regarding the Precision Theoretically, our system can get 100% precision using templates. In practice, however, there are still many exceptions. In Table 5 , we list some false alarms in the open tests. According to an online dictionary (Ministry of Education, 2007) , some templates that we compiled are interchangeable, such as: \"\u5783\u573e\u6876\"-\"\u5783\u573e\u7b52,\" \"\u5947\u8e5f\" -\"\u5947\u8de1,\" \"\u96fb\u7dda\u687f\" -\"\u96fb\u7dda\u6746,\" and \"\u92b7\u8072\uf9eb\u8de1\" -\"\u6d88\u8072\uf9eb\u8de1\". This is not consistent with the judgment of some teachers. Some templates are just too short and cannot include the necessary context in order for a correct decision to be made, such as \"\u4e00\u518d\"-\"\u4e00\u5728\". The necessary context should include more semantic rather than surface syntax. There were some bad templates that our system should have not generated, such as \"\u653e\u8072\u5927\u54ed\"-\"\u653e\u8072\u5927\u53eb,\" \"\uf967\u7528\uf96f\"-\"\uf967\u7528\u8b1b,\" and \"\uf95a\u66f8\u4eba\"-\"\uf95a \u66f8\u505a,\" which can be attributed to the size of the corpus. Nevertheless, no corpus is large enough to be perfect for all applications. We find that these are the major causes of false alarms. Regarding the Recall We treated the errors that the teachers provided from the student essays as templates and compared them to the automatically generated templates, as shown in Table 6 . The first column shows the percentage of \"not in the automatically generated template\". The second column shows the percentage of an error occurring in a word that is not in the dictionary. The third column shows the percentage of an error occurring in a word that is not in the corpus. The last column shows the percentage of an error occurring in a word that is neither in the dictionary nor in the corpus. We find that most student errors were not mined from the news corpus, although our system has mined many useful error templates. From the union set of those not in a dictionary and not in a corpus, we find that 53.17% of the necessary templates in the close test set cannot be generated by our system, while 32.97% of the necessary templates in the open test cannot be generated by our system. This is a mismatch of the corpus and student essays. The assumption of our system is that the corpus contains the correct and wrong usages. Nevertheless, since news reporters and junior high school students make character errors for different words, we need to have a more suitable corpus to improve our system. If we have a more contemporary dictionary that includes the words in Table 7, our system can perform better. Conclusion and future works Based on the confusion sets of Chinese characters, word segmentation, and the square root test, our system can generate a large number of templates from a corpus. These templates can detect and correct Chinese character errors in essays. The templates are more readable and have better performance in both precision and recall performance compared to that of previous system. To improve the system, we will work in two areas. In the knowledge part, we will enlarge the confusion sets to include more seeds for template generation. We will compile a more suitable corpus for detection and correction of errors in student essays. For the dictionary, we will collect more contemporary terms via the Internet, such as from Wikipedia and Wikitionary. For the language model part, we will use the student essays that we collected in this study to generate an error model, and use that error model to help determine character errors. Acknowledgement This study was conducted under the \"Project Digital Convergence Service Open Platform\" of the Institute for Information Industry, which is subsidized by the Ministry of Economic Affairs of the Republic of China.",
    "abstract": "In this paper, we propose a system that automatically generates templates for detecting Chinese character errors. We first collect the confusion sets for each high-frequency Chinese character. Error types include pronunciation-related errors and radical-related errors. With the help of the confusion sets, our system generates possible error patterns in context, which will be used as detection templates. Combined with a word segmentation module, our system generates more accurate templates. The experimental results show the precision of performance approaches 95%. Such a system should not only help teachers grade and check student essays, but also effectively help students learn how to write.",
    "countries": [
        "Mauritius"
    ],
    "languages": [
        "English",
        "Chinese"
    ],
    "numcitedby": "1",
    "year": "2010",
    "month": "June",
    "title": "Improving the Template Generation for {C}hinese Character Error Detection with Confusion Sets"
}