{
    "article": "The goal of the AMETRA project is to make a computer-assisted translation tool from the Spanish language to the Basque language under the memory-based translation framework. The system is based on a large collection of bilingual word-segments. These segments are obtained using linguistic or statistical techniques from a Spanish-Basque bilingual corpus consisting of sentences extracted from the Basque Country's of\u00a3cial government record. One of the tasks within the global information document of the AMETRA project is to study the combination of well-known statistical techniques for the translation of short sequences and techniques for memory-based translation. In this paper, we address the problem of constructing a statistical module to deal with the task of translating segments. The task undertaken in the AMETRA project is compared with other existing translation tasks, This study includes the results of some preliminary experiments we have carried out using well-known statistical machine translation tools and techniques. Introduction Over the last few years has became more and more popular the integration of different techniques in the development of machine translation systems. Currently, most of the existing commercial systems make use of the best parts of different approaches to obtain better results and \u00a3nally better products. The aim of the AMETRA project is to include some statistical translation techniques, which have been successfully applied in speci\u00a3c domain tasks to improve the results of a Spanish-Basque computerassisted translation system, which uses a memorybased approach. The success of a statistical machine translation system relies on the availability of a large bilingual corpus to be used to train different translation and language models. Thus, is specially important the quality of such a corpus in terms of complexity. Ideally, the corpus should be perfectly split into sentences, be free of noise and errors and be free as possible of incorrect translations. In practice, this is not the usually the case. New corpora usually require substantial preprocessing as is the case with our corpus. We show how the statistical techniques can be succesfully applied and how the statistical and the translation memory approaches can be combined to a translation of Spanish to Basque. Statistical Machine Translation (review) The goal of the translation process in statistical machine translation (SMT) can be formulated as follows: A source language string f J 1 = f 1 . . . f J is to be translated into a target language string e I 1 = e 1 . . . e I . In the experiments reported in this paper, the source language is Spanish and the target language is Basque. Every target string is considered as a possible translation for the input. If we assign a probability P r(e I 1 |f J 1 ) to each pair of strings (e I 1 , f J 1 ), then according to Bayes' decision rule, we have to choose the target string that maximizes the product of the target language model P r(e I 1 ) and the string translation model P r(f J 1 |e I 1 ). Many existing systems for statistical machine translation make use of a special way of structuring the string translation model as proposed by (Brown et al., 1993) : The correspondence between the words in the source and the target string is described by alignments that assign one target word position to each source word position. The lexicon probability p(f |e) of a certain target word e occurring in the target string is assumed to depend basically only on the source. These alignment models are similar to the concept of Hidden Markov models (HMM) in speech recognition. The alignment mapping is j \u2192 i = a j from source position j to target position i = a j . The alignment a J 1 may contain alignments a j = 0 with the 'empty' word e 0 to account for source words that are not aligned to any target word. In (statistical) alignment models P r(f J 1 , a J 1 |e I 1 ), the alignment a J 1 is introduced as a hidden variable. Typically, the search is performed using the socalled maximum approximation: \u00eaI 1 = arg max e I 1 P r(e I 1 ) \u2022 a J 1 P r(f J 1 , a J 1 |e I 1 ) \u2248 arg max e I 1 P r(e I 1 ) \u2022 max a J 1 P r(f J 1 , a J 1 |e I 1 ) The search space consists of the set of all possible target language strings e I 1 and all possible alignments a J 1 . In this work, we used IBM Model 1 and IBM Model 4 (Brown et al., 1993) as translation models. With respect to the language models, we used a trigram language performed using the Good-Turing estimate and smoothed by the Katz technique. Finally, as a decoding algorithm we used a stack-based decoder which is outlined in more detail in the next section. Stack-based decoding The stack decoding algorithm, also called A * algorithm, was introduced by F. Jelinek in (Jelinek, 1969) the \u00a3rst time. The stack decoding algorithm attempts to generate partial solutions, called hypotheses, until a complete sentence is found; these hypotheses are stored in a stack and ordered by their score. In our case, this measure is a probability value given by both the translation and the language models. The decoder follows a sequence of steps for achieving an optimal hypothesis: 1. Initialize the stack with an empty hypothesis. The search is started from a null string and obtains new hypotheses after an expansion process (step 2c) which is executed at each iteration. The expansion process consists of the application of a set of operators over the best hypothesis in the stack. Thus, the design of stack decoding algorithms involves de\u00a3ning a set of operators to be applied over every hypothesis as well as the way in which they are combined in the expansion process. Both the operators and the expansion algorithm depend on the translation model that we use. In our case, we used IBM Model 3 and IBM Model 4. Iterate The operators used in the implementation are those de\u00a3ned in (Berger et al., 1996) and (Germann et al., 2001) for the IBM Model 3 and IBM Model 4. The expansion we used in each iteration is strongly inspired on the expansion given in (Berger et al., 1996) for the IBM Model 3, and was presented in (Ortiz et al., 2003) . This algorithm had been previously adapted for the IBM Model 4, and additionaly has been adapted in this work for the IBM Model 1. The AMETRA corpus The AMETRA corpus is a bilingual corpus from the Spanish language to Basque language. This corpus was extracted from the Basque Country's of\u00a3cial government record, which was segmented into sentences during a previous project. The application of statistical machine translation algorithms over this corpus raises several important dif\u00a3culties: \u2022 The corpus has several segmentation errors. \u2022 The corpus is often inconsistent. Concretely, the inconsistences are due to the machine transcription process of the corpus itself. For example, the same word appears sometimes with all its symbols in upper case, and sometimes in lower case; or for the Spanish language, the same word is sometimes accentuated and other times not, etcetera. \u2022 The corpus presents a high degree of nonmonotonicity. In addition, a lot of names, numbers and dates appear, enormously increasing the size of the vocabularies. These problems can be partially solved by carrying out a corpus preprocessing. So far, the preprocessing consisted of \u00a3ltering out punctuation marks. Both vocabularies are too big in relation to the number of available sentences (even after a preprocessing step). The Basque vocabulary is particularly enormous in this sense. Table 1 shows statistics of the unpreprocessed corpus (the vocabulary size of not preprocessed corpus is shown in parenthesis). The sentences with sixty or more words were not taken into account because we considered them to be paragraphs. Table 1 also shows the differences between the mean length of the sentences for both languages, this shows the \"agglutinative character\" of the Basque language in relation to the to the Spanish language. Table 1 also shows the relation between the number of available sentences inf the corpus and the size of the Basque vocabulary. Figure 1 shows a histogram of the Basque sentence length for the preprocessed corpus. A more extensive study shows that whole paragraphs appeared frequently in a single line. Comparison with other well known tasks Before describing the process of splitting sentences into segments, and presenting the results produced by the stack-based decoder, it might be interesting  to \u00a3nd out how complex is the AMETRA corpus. A good way to do this is to compare it with other widely studied tasks such as HANSARDS, VERB-MOBIL or EUTRANS-I. First of all, the corpus must be prepared to make a translation experiment. For AMETRA corpus, such an experiment requires a a previous shuf\u00a4ing of the corpus because strong relations exist between consecutive sentences, due to its alphabetical ordering. After the shuf\u00a4ing, the last 1000 sentences were used for test purposes and all the previous for training. Table 2 shows the statistics of the AMETRA whole sentence preprocessed corpus. Once the corpus was trained, those sentences whose length were twelve or below were extracted, due to the high complexity of the search process using stackbased decoding algorithms (see (Ortiz et al., 2003) ). We obtained twelve subsets of the test corpus, labeled with the symbol t followed by the sentence length, to which the stack-based decoders were applied. Table 3 shows the measures WER 1 (Word Error Rate) and PER 2 (Position independent Error Rate) of translation quality for the subsets, as well as the search error rate 3 and the number of translated segments for every subset. The PER and WER measures in Table 3 , show the high complexity of the AMETRA corpus. However, the search error rate is reasonably low and seems to be related to the number of translations of every source word (also referred as the W parameter within the stack-based decoder, see (Ortiz et al., 2003) ). We can state that the search process was carried out correctly, but over a very complex and even badly estimated model due to the negative characteristics of the corpus. Let's see the big difference between the WER and PER's values, which is typical in tasks like VERB-MOBIL (see (Wahlster, 2000) ). VERBMOBIL is related to the tourist domain, and the translation is made from German to English (see Table 4 for some statistics). Since the PER measure does not take word order into account, is appropriate for those tasks where the word ordering between the source and target languages is very different. AMETRA is one of those tasks. We can also show the statistics of the HANSARDS task, HANSARDS task consists of debates in the Canadian Parliament, where French and English are the of\u00a3cial languages. It is a well known task and is also very dif\u00a3cult for machine translation, see Table 5 . Translation results were obtained for the HAN-SARDS task in (Ortiz et al., 2003) with stack-based decoders and the WER measure was never lower than 51 points. However AMETRA is even more complex than HANSARDS due to the small number of training sentences in relation to the large vocabularies of the languages. Also note the high perplexity of the AMETRA task (see Table 2 ) in relation to HANSARDS. Perhaps it would be interesting to ask ourselves when machine translation can be successfully applied. The EUTRANS-I task, commonly known as the Traveler task, is a nice example of a suf\u00a3ciently simple task that can be translated by a machine, in contrast with AMETRA and HANSARDS. The EUTRANS-I task consists of a semi-automatically generated Spanish-English corpus. The domain of the corpus consists of a human-to-human communication situation at a reception desk of a hotel. The statistics of such a corpus are shown in Table 6 . A mean WER measure that is lower than 10 points can be achieved without too much computational cost and with no preprocessing step. Table 7 contains additional data about the obtained language models for the tasks AMETRA, HAN-SARDS, VERBMOBIL and EUTRANS-I. The table shows the bigrams and trigrams that appear only once in the training corpus (in percentages). It also shows the number of unseen bigrams and trigrams in the Another way of placing AMETRA in the machine translation framework is to compare it with the task in (Al-Onaizan et al., 1999) , this task is a Czech-English corpus that was trained and translated. There is a certain paragraph of the document describing the Czech language which says: \"In the corpus there are 72 000 word forms in the Czech part versus 31 000 forms in English\", due to the multiplicity of cases, numbers, genders, etc that the Czech language has. This situation is similar to the AME-TRA corpus. And the similarities go further because the above mentioned task does not have a great number of training sentences (only 51 000). Corpus segmentation and translation results The AMETRA project deals with memory-based computed-assisted translation. The database of the systems consists in a large collection of short, bilingual word sequences (segments). Statistical techniques can help the process of extracting the bilingual segments from the AMETRA corpus: Features of the segmented training and test corpus We have performed the following sequence of steps over the whole corpus in order to obtain the training and test subcorpus of segments, which will be used to carry out the translation experiments for the segments: 1. A training of the whole partially-preprocessed corpus, using the GIZA++ tool was carried out. IBM Model 5 was obtained. 2. The best word-alignments in the training set were computed using the GIZA++ tool and the trained IBM Model 5. The training corpus was segmented according to the following criterion: A bilingual segment is composed by the shortest sequence of source words and the shortest sequence of target words in such a way that no source words can be aligned with target words that are not in the associated sequence of target words and no target words can be aligned with source words that are not in the associated sequence of source words. From the set of bilingual segments, the last 2714 segments were selected for testing purposes and all the previous sentences for training a new translation model. Once again the tool GIZA++ was used to carry out the training, using the same set of parameters as in step 1. The training of a trigram language model was done by using the SRILM toolkit. Table 8 shows the statistics of the segmented AME-TRA corpus, yet divided for training and test purposes. The language model perplexity is also given, and its comparison with the perplexity of other tasks is interesting (see the next subsection). The shuf\u00a4ing of the corpus divides the language model perplexity by two units approximately. Figure 2 shows how the segmentation has affected the sentence length in the new segmented corpus. Translation segment results Table 9 shows the translation results for the AME-TRA segments. It's very important to point out that the WER and PER measures are only valuable if reliable reference sentences are given. In our case the corpus already presented a high level of noise, and is underwent a complex transformation process (it was divided into segments) introducing additional noise. Therefore an increase in the number of incorrect reference sentences is expected. We observed high values for the WER and PER measures and an increase in the search error rate. The use of only one sentence as translation reference might be related with these values, since the references are not always trustworthy. Table 10 shows some examples of wrong reference translations. All of them were due to these segmentations errors. We also observed moderate mean values for the WER and PER and for the search error rate. However, this is mainly due to the great number of segments having a length equal to one, because we calculated weighted means. These considerations oblige us to consider the results that appear in the table with a certain amount caution. Training and translation with IBM model 1 Due to the problems that the AMETRA corpus has (see section 4), we tried to use the IBM Model 1 in a new translation experiment. IBM Model 1 is the simplest IBM Model, and we supposed that it would perform better in a high noise situation, which is the case of the AMETRA corpus. The results in Table 11 were obtained using the same segmented corpus as the one presented in Ta- Table 10 : Some examples of wrong translation references extracted from the AMETRA corpus. ble 9 but using the IBM Model 1 as the translation model 5 . The use of the IBM Model 1 introduces a slight improvement in relation to the results obtained with IBM Model 4. We attribute it to the noise of the corpus that we have mentioned above. The IBM Model 1 does not care about the correct ordering of the target words; however, when we increased the length of the segments, the WER was not greater than the one we obtained for the experiments with the IBM Model 4. We are inclined to think that the language model is better estimated than the distortion model of IBM Model 4. These results cannot be considered as de\u00a3nitive ones. There is still a technical problem of how to make the search process with the IBM Model 1 using stack-based decoders, that we have not already solved. Speci\u00a3cally, the IBM Model 1 does not provide any information about the most likely zero fertility words that the stack-based decoder needs for to perform the translation (provisionally, we have 5 Search error rate is not given because this feature is not already incorporated to the translator taken this information from the IBM model 3 fertility model). Conclusions and future works In our study of the AMETRA task we have discussed the high complexity of the AMETRA task, identifying the main problems that must be dealt with. Obviously, a lot of work must be done if we want to use statistical methods within the memory-translations framework. Further efforts have to be made about preprocessing, which seems to be the most important dif\u00a3cult here. Training with the tool GIZA++ of a segmented corpus obtained from a previous training with the same tool does not seem to be appropriate, because the alignments from which the segments were obtained already had a certain number of errors. For the same reason the translation quality evaluation with automatic measures like WER and PER were not free of errors either. We plan to investigate groups of words-based translation models in order to eliminate the need of segmenting the corpus. In (Al-Onaizan et al., 1999) , a study about how to perform the training of a task similar to the AME-TRA task is introduced. It might be interesting to follow the guidelines proposed there. Among them, we highlight the use of three toolkits for the Czech language: a lemmatizer, a morphological analyzer and a POS tagger. Lemmatized corpora will be also used In the AMETRA project. In relation to the POS tagger, we propose the use of a categorized language model in order to reduce the huge perplexity that the current trigram language model has. In order to deal with the task complexity, we are considering the adaptation of stack-based decoders for their use as translation assistants where the prediction of short partial hypotheses is made instead of whole sentence translations. Acknowledgements This work has been partially supported by the IN-TEK project under grant TEC-154-02 and by the Spanish CICYT project under grant TIC 2000-1599-C02-01 .",
    "abstract": "The goal of the AMETRA project is to make a computer-assisted translation tool from the Spanish language to the Basque language under the memory-based translation framework. The system is based on a large collection of bilingual word-segments. These segments are obtained using linguistic or statistical techniques from a Spanish-Basque bilingual corpus consisting of sentences extracted from the Basque Country's of\u00a3cial government record. One of the tasks within the global information document of the AMETRA project is to study the combination of well-known statistical techniques for the translation of short sequences and techniques for memory-based translation. In this paper, we address the problem of constructing a statistical module to deal with the task of translating segments. The task undertaken in the AMETRA project is compared with other existing translation tasks, This study includes the results of some preliminary experiments we have carried out using well-known statistical machine translation tools and techniques.",
    "countries": [
        "Spain"
    ],
    "languages": [
        "English",
        "French",
        "Spanish",
        "Basque"
    ],
    "numcitedby": "4",
    "year": "2003",
    "month": "September 23-27",
    "title": "On the use of statistical machine-translation techniques within a memory-based translation system ({AMETRA})"
}