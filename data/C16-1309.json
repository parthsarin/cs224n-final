{
    "article": "Retrospective event detection is an important task for discovering previously unidentified events in a text stream. In this paper, we propose two fast centroid-aware event detection models based on a novel text stream representation -Burst Information Networks (BINets) for addressing the challenge, following the D2N2K (Data-to-Network-to-Knowledge) paradigm. The BINets are time-aware, efficient and can be easily analyzed for identifying key information (centroids). These advantages allow the BINet-based approaches to achieve the state-of-the-art performance on multiple datasets, demonstrating the efficacy of BINets for the task of event detection. Introduction Retrospective Event Detection (RED) (sometimes called topic detection) is a core task for text stream analysis, which aims to detect events that are previously unknown to the system (Wayne, 1998; Rajaraman and Tan, 2001) and is useful for many applications such as text stream summarization and evolutionary analysis of events in both news and social streams. docid time text d 1 Jan 12, 2010 A 7.0 magnitude quake hits the impoverished Caribbean nation of Haiti, killing more than 200,000 people, injuring an estimated 300,000. d 2 Feb 27, 2010 A huge magnitude 8.8 earthquake strikes near the coast of south-central Chile, shaking buildings, causing blackouts and killing at least 147 people. d 3 Apr 14, 2010 A 7.1-magnitude earthquake struck Tibetan Autonomous Prefecture of Yushu in southern Qinghai Province on April 14, 2010, killing at least 400 people and injuring more than 10,000. Table 1 : Documents discussing different earthquake events. Most previous event detection approaches tend to use document-or keyword-based clustering models. Another solution proposed in recent years is to build a keyword graph to model the co-occurrence of keywords for detecting keyword communities as events (Sayyadi and Raschid, 2013) . Even though these methods can achieve fair performance in small datasets, they have either of the following limitations: \u2022 No time-awareness: many event detection models do not take into account time information. As a result, it is very likely that the documents that talk about different events (as Table 1 shows) are grouped into one cluster just because their lexical similarity is high. \u2022 Inefficient: clustering-based methods tend to be time-consuming. For example, the time complexity of GAC (group average clustering) -the most commonly used clustering method in event detection -is O(n 2 log n). The computational challenge makes them difficult to work on a large dataset. \u2022 Deviation of cluster centroids: it is likely that the clusters obtained by the methods are not eventcentric, which has an adverse effect on the result, as illustrated in Figure 1 . Figure 1 : Deviation of cluster centroids: If clusters are not constructed around the centroid of the events (e.g., the dashline cluster is constructed around non-centroids such as people, kill and injure instead of earthquake or bombing), the performance will be adversely affected. To offer a better solution to event detection without the above limitations, we propose to use a novel text stream representation: Burst Information Networks (BINets) (Ge et al., 2016a; Ge et al., 2016b) . In contrast to the keyword graph which is based on word co-occurrence, a BINet is constructed based on burst co-occurrence. In a BINet (Fig. 2 ), a node is a burst of one word, which can be represented by the word with one of its burst periods, and an edge between two nodes indicates how strongly they are related (i.e., how frequently they co-occur). Since the nodes in a BINet contains temporal information (e.g., burst period), a BINet is time-aware in which nodes in a community are both topically and temporally coherent. Hence, we can say each community in a BINet corresponds to an event. Based on the BINet representation, we propose two fast centroid-aware event detection models. We show that the BINetbased models are efficient, allowing it to work on a large dataset, and the clusters obtained by the models center around the key information of events. Experiments on multiple datasets show that the BINet-based approaches achieve the state-of-the-art performance in terms of both accuracy and efficiency. The contributions of this paper are: \u2022 We propose to use BINets -a novel text stream representation for event detection, which is timeaware, can be efficiently built and support event-centric clustering, addressing the typical limitations of previous models. \u2022 We propose two fast centroid-aware algorithms for event detection based on the BINet representation, which not only solve the centroid deviation problem but also are more efficient than traditional approaches. \u2022 We construct and release a dataset for evaluating event detection models on a large text stream during a long time span. 2 Burst Information Networks Burst Detection A word's burst refers to a sharp increase of word frequency during a period. It usually indicates key information, important events or trending topics in a text stream as Figure 3 shows and is useful for many applications. In this paper, we detect a word's burst using the method of Zhao et al. (2012) which is a variant of (Kleinberg, 2003) and models burst detection as a burst state sequence decoding problem where a word w's burst state s t (w) at time t could be 1 or 0 to indicate if the word bursts or not at t. Specially, if a word w bursts at every time epoch during a period, we call this period a burst period of w and w has a burst during this period. In Figure 3 , earthquake has 2 burst periods (i.e., Jan 12 -Jan 31, and Feb 27 -Mar 7), which correspond to two famous earthquake events (i.e., 2010 Haiti earthquake and 2010 Chile earthquake). There are two burst periods (red) for earthquake during the period, corresponding to two strong earthquake events happening in Haiti and Chile respectively. Formally, we define P i (w) as the ith burst period of the word w. It is a time interval, during which the word w bursts at every time epoch: P i (w) = [t s i (w) , t e i (w)] \u2200t \u2208 P i (w) s t (w) = 1 where t s i (w) and t e i (w) denotes the starting and ending time of the ith burst period of w, and s t (w) denotes the burst state of w at time t. Burst Information Network Construction A BINet represents associations between key facts in a text stream, which has been proven to be effective in multiple knowledge mining tasks (Ge et al., 2016a; Ge et al., 2016b) . The basic component of a BINet is burst elements which are nodes of the information network: A Burst Element is a burst of a word. It can be represented by a tuple: w, P i (w) where w denotes the word and P i (w) denotes one burst period of w. Though a word may have multiple burst periods, a burst element has only one burst period. A word during its different burst periods will be regarded as different burst elements. There are two main advantages using burst elements as nodes to build the information network: \u2022 A burst element not only includes semantic information but also incorporates the temporal dimension. Nodes in a community are topically and temporally coherent while nodes that are topically or temporally distant cannot be adjacent, which makes it reasonable to consider a community in a BINet corresponds to an event. \u2022 Since a burst element denotes a burst word during one of its burst period, its sense is likely to be consistent. Multiple bursts of a word will be considered as different burst elements. Therefore, nodes in a BINet tends to be less ambiguous. Formally, a BINet is defined as G = V, E . Each node v \u2208 V is a burst element and each edge e \u2208 E denotes the association between burst elements. Intuitively, if two burst elements frequently co-occur, then they should be highly weighted. We define \u03c9 i,j as the weight of an edge between v i and v j , which is equal to the number of documents where v i and v j co-occur. 3 Event detection based on the BINet Motivation The goal of event detection is to organize a text stream into multiple document sets, in each of which the documents coherently discuss the same event. The traditional clustering methods are usually inefficient and not time-aware. Moreover, they tend to suffer from the problem of deviation of cluster centroids, as illustrated in Figure 1 . In Figure 1 , earthquake and bombing are centroids (i.e., key information) of an earthquake event and a bombing event respectively. If clusters are constructed around the centroids (e.g., solid line clusters), the performance will be good; while if clusters center around non-centroid nodes (e.g., the dashline cluster centers around kill and people), the results will be poor. To address the limitations above, we propose to model event detection problem as community detection on the BINet in which each community is both topically and temporally coherent, corresponding to one event. Instead of using popular community detection algorithms in social network analysis whose time complexity is high, we propose two fast centroid-aware event detection model: node-based detection model (NDM) and area-based detection model (ADM). Both of the approaches first identify the key nodes (or key areas) on the BINet, which indicate the centroid (i.e., key information) of events in the text stream, and then construct clusters that center around the key nodes (or key areas). The difference of the models is that NDM attempts to detect a bunch of node communities as clusters while ADM detects the overlapping document areas to form document clusters, as Figure 4 and Figure 5 depict. In some sense, NDM and ADM correspond to the keyword-and document-based clustering model respectively. In the following sections, we will present the details of NDM and ADM. Community The Table 2 : Example of the communities detected by our approach. Each community corresponds to one event and nodes with the top PageRank values tend to be keywords that are the most situable to describe the events. 3.2 Centroid-aware event detection models Node-based detection model The goal of node-based detection model (NDM) is to detect node communities on the BINet each of which corresponds to one event. To guarantee that detected communities center around the key nodes that correspond to key information (i.e,. centroid) of events in the text stream, we first identify the key nodes on the BINet. Owing to the BINet representation, it is easy to identify the key nodes through the analysis of the network. Among a variety of ways to identify the influential nodes in a network, we simply adopt the Pagerank algorithm (Page et al., 1997) . For a node v, its PageRank value pr(v) is computed as follows: pr(v) = d v \u2208N (v) \u03c9v,v \u00d7 pr(v ) + 1 \u2212 d |V | where |V | is the number of nodes in the BINet, N (v) denotes the set of nodes adjacent to v, d is the damping factor and is set to 0.85, \u03c9v,v = \u03c9 v,v \u03c9 v , * , which is the normalized weight of the edge between v and v . Intuitively, a node with a high PageRank value is usually important and likely to be the key node that indicates the key information of an event. Therefore, we rank nodes in the BINet by their PageRank value and choose the node which has the highest PageRank value and does not belong to any community as a key node to construct a community E around it with its closely related nodes: E = {v} \u222a {u|\u03c9 v,u > \u03c3 N } where v is the node with the highest PageRank value and does not belong to any community, \u03c9v,u is the normalized weight of the edge between v and u, and \u03c3 N is the threshold for selecting closely related nodes. By repeating the process, we can detect multiple communities on the BINet efficiently, each of which centers around a key node. Table 2 shows some communities detected by this approach from 1995-2010 Xinhua news in English Gigaword. One can observe that each community corresponds to one event and nodes with the top PageRank values in a community tend to be key information of the events. We summarize the algorithm in Algorithm 1. For NDM, we need to infer a document's event after community detection. For a document d, we infer the probability that d discusses the event e k as follows: P (e k |d) = v k \u2208V k (d) pr(v k ) v\u2208V (d) pr(v) (1 C = [E 1 , E 2 , ..., E k ] 3: while L > 0 do 4: v \u2190 L[0] (the first element in L) 5: E \u2190 {v} \u222a {u|\u03c9 v,u > \u03c3 N } 6: L \u2190 L \u2212 E 7: C.append(E) 8: end while Area-based Detection Model A document area is the area (i.e., a set of nodes) on the BINet a document corresponds to. For example, A3 in Figure 5 is the area that the document written during the Haiti earthquake about Haiti, government and police corresponds to on the BINet. The idea of area-based detection model (ADM) is discovering the document areas that massively overlap on the BINet to construct clusters so that the documents whose areas are in the same cluster are about the same event. In contrast to NDM in which each item in a cluster is a node, the items in a cluster obtained by ADM is document areas on the BINet. To guarantee that the clusters center around the centroids of events, we first identify key nodes on the BINet, as NDM does. In ADM, however, we treat a key area as the centroid of an event, which is different from NDM that treats a key node as an event centroid. To identify the key areas on the BINet, we first define the PageRank score of an area A as the normalized sum of the PageRank value of the nodes in it: pr(A) = v\u2208A pr(v) |A| Then, we repeatedly choose the area which has the highest PageRank score and does not belong to any cluster as a key area to construct a cluster with the areas that massively overlap it: E = {A} \u222a {A |f (A, A ) > \u03c3 A } (2) where \u03c3 A is the threshold to construct cluster, f (A, A ) is a score to indicate how much A overlaps A and it is computed as follows: f (A, A ) = |A \u2229 A | |A \u222a A | (3) We summarize the algorithm of ADM in Algorithm 2. As NDM, ADM detects events in a greedy manner; hence, the detection process is fast. However, in contrast to NDM, ADM allows one area to belong to multiple communities, which means that one document could belong to multiple events. Algorithm 2 Area-based detection model 1: Input: Ranked list of documents areas: L, BINet: G = V, E ; 2: Output: A list of event communities: C = [E 1 , E 2 , ..., E k ] 3: while L > 0 do 4: A \u2190 L[0] (the first element in L) 5: E \u2190 {A} \u222a {A |f (A, A ) > \u03c3 A } 6: L \u2190 L \u2212 E 7: C.append(E) 8: end while Experiments and Evaluation We conduct experiments to evaluate the performance of our approach. We first evaluate our approach on the TDT4 dataset to compare other event detection approaches. Then, we apply our approach on a larger corpus (2009 -2010 news corpus) to test its scalability and performance. For preprocessing, we remove stopwords and conduct lemmatization and name tagging using Stanford CoreNLP toolkit (Manning et al., 2014) before the construction of a BINet. Evaluation on TDT4 The TDT4 collection is a well known dataset for comparing methods for event detection. The English part of the dataset includes approximately 29,000 news documents from news agencies such as CNN and BBC from October 2000 to Janurary 2001 (spanning 4 months), while only 1,884 documents 1 are annotated to be related to 71 human identified events (topics). As the setting adopted by previous work (Li et al., 2005; Sayyadi and Raschid, 2013) , we use the annotated subset as gold standard for evaluating the performance of our models. As most of the previous work (Yang et al., 1998; Li et al., 2005) addressing the event detection challenge, we use Micro-Precision, Micro-Recall, Micro-F1 as well as Macro-F1 to evaluate the performance. We compare our approach to the following models whose effectiveness on the TDT4 corpus has been verified by previous work: (Allan et al., 1998) : A popular online event detection model, which is often used as a baseline to compare event detection models. \u2022 GAC (Yang et al., 1998) : A classical but effective approach for event detection using group average clustering. \u2022 KeyGraph (Sayyadi and Raschid, 2013) : Betweenness score based community detection approach on KeyGraph. It is notable that the evaluation measures used in Sayyadi and Raschid (2013) are somewhat different from those in this paper and other work -they used Macro-precision, Macrorecall 3 and Macro-F1. We only report its Macro-F1 in Table 3 . \u2022 Probabilistic model (Li et al., 2005) : A time-aware probabilistic graphical model for event detection. \u2022 Allan 2 It is the state-of-the-art approach on TDT4 dataset. Table 3 shows the results 4 on the TDT4 dataset. The BINet approaches perform well on the dataset: Both NDM and ADM outperform the classical baselines (i.e., Allan, GAC and Keygraph) . The ADM performs better than NDM and even achieves the comparable performance to the state-of-the-art approach by (Li et al., 2005) because the centroid in ADM is a key area that contains more information than a key node in NDM. The reasons for the good performance are two-fold: First, the BINet-based approach is time-aware, which avoid many unnecessary mistakes made by the baseline models that only take into account text content; Second, the BINet-based models are centroid-aware, which guarantee that 4 : Performance and running time of various event detection models on the 2-year news stream. We do not report the precision, recall and f-score for the models that cannot get results within 2 hours. Models Model Micro-P Micro-R Micro-F1 Macro-F1 Running time GAC - - - - >2 hours KeyGraph - - - - >2 hours Probabilistic model - - - - >2 hours B-GAC 0. The number in the round bracket is the running time of the model when it is run in 8-way parallel. The running time is measured on a workstation with Intel Xeon 3.5 GHz CPU and 64GB RAM. the generated clusters center around centroids of events and avoid the problem of deviation of cluster centroids. Evaluation on a 2-year news stream Even though TDT4 is a widely used dataset for event detection, it has several limitations: First, the period of TDT4 dataset is short (only 4 months) as Li et al. (2005) claimed. In TDT4 dataset, hardly can we see multiple events of the same type in the TDT4 dataset (e.g., there is only one flood event in TDT4 dataset). Therefore, even if we just use content-based clustering methods regardless of time information, the performance is not bad. Second, the data size of the TDT4 corpus is so small compared with a real text stream that many stream-based features such as burst cannot function as well as in a real stream. To test the performance of our detection models on a real text stream, we construct a dataset using 2009 -2010 news from English Gigaword (APW and XIN sections) as a text stream where there are 584,414 news articles in total. We construct a BINet on this dataset, which contains 46,254 nodes and 514,682 edges. For evaluation, we select 83 events that happened during 2009 -2010 and annotate their relevant documents in the text stream. The selected events are all important events and have their corresponding Wikipedia pages. The annotation process is similar to (Li et al., 2005) : we use the Wikipedia title of the events to search the candidate documents using Lucene and then manually identify if the returned documents are actually relevant to the events. Since this annotation process does not guarantee finding all the relevant documents to an event, we call the annotations silver standard 5 . In total, there are 2,584 documents that are annotated as relevant to those 83 events. Table 4 shows the results of various approaches on the 2-year news stream. Due to the size of the dataset, most traditional event models cannot finish the detection task within two hours since their time complexity is too high. The B-GAC model proposed by (Zhao et al., 2012) is the only one that can finish the task within 2 hours because it adopts the split-merge-clustering strategy that splits 6 the data into multiple small pieces by time for clustering and then merges the clusters. Though such a strategy can alleviate the issue of the scalability, the split of data will affect the global overview of the text stream and have an adverse effect on finding the centroids of events. In contrast, our BINet-based approaches can finish detecting events within 1 hour without splitting the stream and achieve the best result owing to their awareness of both time 7 and event centroids. We compare the time complexity of our centroid-aware event detection models to other commonly used event detection approaches, as shown in Table 5 where n is the number of documents, K is the event number (K in our BINet-based approaches depends on the selection of \u03c3 N and \u03c3 A ), |W | is the size of vocabulary, and |V | and |E| are the number of nodes and edges on the BINet respectively. The running time of NDM and ADM consist of four parts: burst detection, BINet construction, PageRank analysis, Models Time complexity GAC O(n 2 log n) B-GAC O(n 2 log n) Keygraph O(nK + |W | 3 ) NDM O(nK + |V | log |V | + |E| + |W |T ) ADM O(n(log n + L) + |V | + |E| + |W |T ) Related Work Event detection is one of the most popular research topics in recent years and has been extensively studied for the decades (Yang et al., 1998; Swan and Allan, 2000; Allan, 2002; Fung et al., 2005; He et al., 2007; Sayyadi et al., 2009; Zhao et al., 2012; Sayyadi and Raschid, 2013; Ge et al., 2015) . They are based on either document-or keyword-based clustering, which usually suffer from either unawareness of time, high expensive computation cost or deviation of cluster centroids. In contrast, our approach is time-aware, centroid-aware and so efficient that it can be run on a large text stream. In addition, there is much work (Sakaki et al., 2010; Lee et al., 2011; Diao et al., 2012; Aggarwal and Subbian, 2012; Wang et al., 2013; Dong et al., 2015) studying event detection problem in social media. They usually use more or less social media features such as spatio-temporal information, which are not in the same setting with our task. Conclusion and Future Work This paper proposes to use a novel text stream representation -Burst Information Networks to address the retrospective event detection challenge. Based on the BINet, we propose two fast centroid-aware event detection models that can effectively overcome the limitations of the previous event detection models and achieve the state-of-the-art performance on both TDT4 and a long-span text stream. In the future, we plan to study events in a text stream more deeply based on the BINet representation. Since a BINet can offer a global overview of events in the stream level, we plan to use the BINets to derive an event's type, extract its schema and even fill its slots after we detect its corresponding regions on the BINet. Hopefully, this framework could work for endless event knowledge mining if it could be used for monitoring the massive text streams. Acknowledgments We thank the anonymous reviewers for their valuable comments. This work is supported by the National Key Basic Research Program of China (No.2014CB340504), the Research Fund for the Doctoral Program of Higher Education (20130001110027) and the National Natural Science Foundation of China (No. 61375074, 61273318). The contact author is Zhifang Sui.",
    "abstract": "Retrospective event detection is an important task for discovering previously unidentified events in a text stream. In this paper, we propose two fast centroid-aware event detection models based on a novel text stream representation -Burst Information Networks (BINets) for addressing the challenge, following the D2N2K (Data-to-Network-to-Knowledge) paradigm. The BINets are time-aware, efficient and can be easily analyzed for identifying key information (centroids). These advantages allow the BINet-based approaches to achieve the state-of-the-art performance on multiple datasets, demonstrating the efficacy of BINets for the task of event detection.",
    "countries": [
        "China"
    ],
    "languages": [
        "English"
    ],
    "numcitedby": "18",
    "year": "2016",
    "month": "December",
    "title": "Event Detection with Burst Information Networks"
}