{
    "framing_question": "What motivation does this paper state for the work, if any?",
    "response": "The paper states that the motivation for the work is to reduce human effort in designing prior knowledge for spoken dialog systems, such as the agenda graph. Manually designing the agenda graph can be labor intensive and time consuming, especially for various applications. The paper proposes a clustering and linking method to automatically construct an agenda graph from human-human dialogs, which can help to reduce the human effort required to build the agenda graph.",
    "article": "Various knowledge sources are used for spoken dialog systems such as task model, domain model, and agenda. An agenda graph is one of the knowledge sources for a dialog management to reflect a discourse structure. This paper proposes a clustering and linking method to automatically construct an agenda graph from human-human dialogs. Preliminary evaluation shows our approach would be helpful to reduce human efforts in designing prior knowledge. Introduction Data-driven approaches have been long applied for spoken language technologies. Although a data-driven approach requires time-consuming data annotation, the training is done automatically and requires little human supervision. These advantages have motivated the development of data-driven dialog modelings (Williams and Young, 2007, Lee et al., 2009) . In general, the datadriven approaches are more robust and portable than traditional knowledge-based approaches. However, various knowledge sources are still used in many spoken dialog systems that have been developed recently. These knowledge sources contain task model, domain model, and agenda which are powerful representation to reflect the hierarchy of natural dialog control. In the spoken dialog systems, these are manually designed for various purposes including dialog modeling (Bohus and Rudnicky, 2003, Lee et al., 2008) , search space reduction (Young et al., 2007) , domain knowledge (Roy and Subramaniam, 2006) , and user simulation (Schatzmann et al., 2007) . We have proposed an example-based dialog modeling (EBDM) framework using an agenda graph as prior knowledge (Lee et al., 2008) . This is one of the datadriven dialog modeling techniques and the next system action is determined by selecting the most similar dialog examples in dialog example database. In the EBDM framework for task-oriented dialogs, agenda graph is manually designed to address two aspects of a dialog management: (1) Keeping track of the dialog state with a view to ensuring steady progress towards task completion, and (2) Supporting n-best recognition hypotheses to improve the robustness of dialog manager. However, manually building such graphs for various applications may be labor intensive and time consuming. Thus, we have tried to investigate how to build this graph automatically. Consequently, we sought to solve the problem by automatically building the agenda graph using clustering method from an annotated dialog corpus. Related Work Clustering techniques have been widely used to build prior knowledge for spoken dialog systems. One of them is automatic construction of domain model (or topic structure) which is one of the important resources to handle user's queries in call centers. Traditional approach to building domain models is that the analysts manually generate a domain model through inspection of the call records. However, it has recently been proposed to use an unsupervised technique to generate domain models automatically from call transcriptions (Roy and Subramaniam, 2006) . In addition, there has been research on how to automatically learn models of taskoriented discourse structure using dialog act and task information (Bangalore et al., 2006) . Discourse structure is necessary for dialog state-specific speech recognition and language understanding to improve the performance by predicting the next possible dialog states. In addition, the discourse structure is essential to determine whether the current utterance in the dialog is part of the current subtask or starts a new task. More recently, it has been proposed stochastic dialog management such as the framework of a partially observable Markov decision process (POMDP). This framework is statistically data-driven and theoretically principled dialog modeling. However, detailed dialog states in the master space should be clustered into general dialog states in summary space to scale up POMDP-based dialog management for practical applications (Williams and Young, 2007) . To address this problem, an unsupervised automatic clustering of dialog states has been introduced and investigated in POMDPbased dialog manager (Lefevre and Mori, 2007) . In this paper, we are also interested in exploring methods that would automatically construct the agenda graph as prior knowledge for the EBDM framework. Agenda Graph In this section, we begin with a brief overview of EBDM framework and agenda graph. The basic idea of the EBDM is that the next system action is predicted by finding semantically similar user utterance in the dialog state space. The agenda graph was adapted to take into account the robustness problem for practical applications. Agenda graph G is a simply a way of encoding the domain-specific dialog control to complete the task. G is represented by a directed acyclic graph (DAG) (Figure 1 ). An agenda is one of the subtask flows, which is a possible path from root node to terminal node. G is composed of nodes (v) which correspond to possible intermediate steps in the process of completing the specified task, and edges (e) which connect nodes. In other words, v corresponds to dialog state to achieve domainspecific subtask in its expected agenda. Each node includes three different components: (1) A precondition that must be true before the subtask is executed; (2) A description of the node that includes its label and identifier; and (3) Links to nodes that will be executed at the subsequent turn. In this system, this graph is used to rescore n-best ASR hypotheses and to interpret the discourse state such as new task, next task, and new subtask based on topological position on the graph. In the agenda graph G, each node holds a set of relevant dialog examples which may appear in the corresponding dialog states when a precondition of the node is true. To determine the next system action, the dialog manager first generates possible candidate nodes with n-best hypotheses by using a discourse interpretation algorithm based on the agenda graph, and then selects the focus node which is the most likely dialog state given the previous dialog state. Finally the best example in the focus node is selected to determine appropriate system action. Human efforts are required to manually design the agenda graph to integrate it into the EBDM framework. However, it is difficult to define all possible precondition rules and to assign the transition probabilities to each link based only on the discretion of the system developer. To solve these problems, we tried to construct the agenda graph from the annotated dialog corpus using clustering technique. Clustering and Linking Node Clustering Each precondition has been manually defined to map relevant dialog examples into each node. To avoid this, the dialog examples are automatically grouped into the closest cluster (or node) by a node clustering. In this section, we explain a feature extraction and clustering method for constructing the agenda graph. Feature Extraction Each dialog example should be converted into a feature vector for a node clustering. To represent the feature vectors, we first extract all n-grams which occur more frequently than a threshold and do not contain any stop word as word-level features. We also extract utterancelevel and discourse-level features from the annotated dialog corpus to reflect semantic and contextual information because a dialog state can be characterized using semantic and contextual information derivable from the annotations. The utterance is thus characterized by the set of various features as shown in Table 1 .  For a set of N dialog examples X={x i |i=1,..,N}, the binary feature vectors are represented by using a set of features from the dialog corpus. To calculate the distance of two feature vectors, we used a cosine measure as a binary vector distance measure: j i j i j i x x x x x x d \uf0d7 \uf0d7 \uf02d \uf03d ) ( 1 ) , ( where x i and x j denoted two feature vectors. However, each feature vector contains small number of non-zero terms (<20 features) compared to the feature space (>2000 features). Therefore, most pairs of utterances share no common feature, and their distance is close to 1.0. To address this sparseness problem, the distance between two utterances can be computed by checking only the non-zero terms of corresponding feature vectors (Liu, 2005) . Clustering After extracting feature vectors from the dialog corpus, we used K-means clustering algorithm which is the simplest and most commonly used algorithm employing a squared error criterion. At the initialization step, one cluster mean is randomly selected in the data set and k-1 means are iteratively assigned by selecting the farthest point from pre-selected centers as the following equation: \uf028 \uf029\uf0f7 \uf0f8 \uf0f6 \uf0e7 \uf0e8 \uf0e6 \uf03d \uf0e5 \uf02d \uf03d \uf0ce 1 1 , max arg k i i X x k u x d u where each cluster c k is represented as a mean vector u k . At the assignment step, each example is assigned to the nearest cluster t c \u02c6by minimizing the distance of cluster mean u k and dialog example x t . \uf028 \uf029 \uf028 \uf029 t k K k t x u d c , min arg \u02c61 \uf0a3 \uf0a3 \uf03d The responsibilities r kt of each cluster c k are calculated for each example x t as the following rule: \uf028 \uf029 \uf07b \uf07d \uf028 \uf029 \uf07b \uf07d \uf0e5 \uf0d7 \uf02d \uf0d7 \uf02d \uf03d l t l t k kt x u d x u d r , exp , exp \uf062 \uf062 where \u03b2 is the stiffness and usually assigned to 1. During the update step, the means are recomputed using the current cluster membership by reflecting their responsibilities: \uf0e5 \uf0e5 \uf03d t kt t t kt k r x r u Node Linking From the node clustering step, node v k for cluster c k is obtained from the dialog corpus and each node contains similar dialog examples by the node clustering algorithm. Next, at the node linking step, each node should be connected with an appropriate transition probability to build the agenda graph which is a DAG (Figure 2 ). This linking information can come from the dialog corpus because the task-oriented dialogs consist of sequential utterances to complete the tasks. Using sequences of dialog examples obtained with the dialog corpus, relative frequencies of all outgoing edges are calculated to weight directed edges: ) ( ) ( ) , ( i j i j i v x n v v x n v v f \uf0ce \uf0ae \uf0ce \uf03d where \uf028 \uf029 i v x n \uf0ce represents the number of dialog examples in v i and \uf028 \uf029 j i v v x n \uf0ae \uf0ce denotes the number of dialog examples having directed edge from v i to v j . Next some edges are pruned when the weight falls below a pre-defined threshold \u03b4, and the cycle paths are removed by deleting minimal edge in cycle paths through a depth-first traversal. Finally the transition probability can be estimated by normalizing relative frequencies with the remained edges. \uf0e5 \uf03d l l i j i i j v v f v v f v v p ) , ( ) , ( ) | ( Experiment & Result A spoken dialog system for intelligent robot was developed to provide information about building (e.g., room number, room name, room type) and people (e.g., name, phone number, e-mail address). If the user selects a specific room to visit, then the robot takes the user to the desired room. For this system, we collect a humanhuman dialog corpus of about 880 user utterances from 214 dialogs which were based on a set of pre-defined 10 subjects relating to building guidance task. Then, we designed an agenda graph and integrated it into the EBDM framework. In addition, a simulated environment with a user simulator and an ASR channel (Jung et al., 2008) was developed to evaluate our approach by simulating a realistic scenario. First we measured the clustering performance to verify our approach for constructing the agenda graph. We used the manually clustered examples by a set of precondition rules as the reference clusters. Table 2 shows error rates when different feature sets are used for Kmeans clustering in which K is equal to 10 because a hand-crafted graph included 10 nodes. The error rate was significantly reduced when using all feature sets. We also evaluated the dialog system performance with the agenda graphs which are manually (HC-AG) or automatically designed (AC-AG). We also used 10-best recognition hypotheses with 20% word error rate (WER) for a dialog management and 1000 simulated dialogs for an automatic evaluation. In this result, although the system with HC-AG slightly outperforms the system with AC-AG, we believe that AC-AG can be helpful to manage task-oriented dialogs with less human costs for designing the hand-crafted agenda graph. Conclusion & Discussion In this paper, we address the problem of automatic knowledge acquisition of agenda graph to structure task-oriented dialogs. We view this problem as a first step in clustering the dialog states, and then in linking between each cluster based on the dialog corpus. The experiment results show that our approach can be applicable to easily build the agenda graph for prior knowledge. There are several possible subjects for further research on our approach. We can improve the clustering performance by using a distance metric learning algorithm to consider the correlation between features. We can also discover hidden links in the graph by exploring new dialog flows with random walks. Acknowledgement This research was supported by the MKE (Ministry of Knowledge Economy), Korea, under the ITRC (Information Technology Research Center) support program supervised by the IITA (Institute for Information Technology Advancement) (IITA-2009-C1090-0902-0045). System TCR (%)",
    "funding": {
        "military": 0.0,
        "corporate": 0.0,
        "research agency": 0.5234211060889296,
        "foundation": 1.0280378716087668e-06,
        "none": 0.9525735663029693
    }
}