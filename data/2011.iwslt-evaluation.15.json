{
    "article": "The Quaero program is an international project promoting research and industrial innovation on technologies for automatic analysis and classification of multimedia and multilingual documents. Within the program framework, research organizations and industrial partners collaborate to develop prototypes of innovating applications and services for access and usage of multimedia data. One of the topics addressed is the translation of spoken language. Each year, a project-internal evaluation is conducted by DGA to monitor the technological advances. This work describes the design and results of the 2011 evaluation campaign. The participating partners were RWTH, KIT, LIMSI and SYSTRAN. Their approaches are compared on both ASR output and reference transcripts of speech data for the translation between French and German. The results show that the developed techniques further the state of the art and improve translation quality. Introduction Quaero 1 is a research and development program with the goal of developing multimedia and multilingual indexing and management tools for professional and general public applications. German and French public and private organizations collaborate on research and the realisation of advanced demonstrators and prototypes of innovative applications and services for access and usage of multimedia information, such as spoken language, images, video and music. The program facilitates strong synergies between the participating industrial partners and research organisations. Regular evaluations are conducted to evaluate the market readiness and technological maturity of the research and development results. One of the topics tackled in the Quaero program is spoken language translation (SLT). In this work, the 2011 project-internal evaluation campaign on SLT is described. The campaign focuses on the language pair German-French in both directions, and both human and automatic transcripts of the spoken text are considered as input data. The automatic transcripts were produced by the Rover combination of single-best output of the best submission from each of the three sites participating in the internal 2010 automatic speech recognition (ASR) evaluation, which is described in an accompanying paper [1] . The campaign was designed and conducted by DGA and compares the different approaches taken by the four participating partners RWTH, KIT, LIMSI and SYSTRAN. In addition to publicly available data, monolingual and bilingual corpora collected in the Quaero program were used for training and evaluating the systems. The approaches to machine translation taken by the partners differ substantially. KIT, LIMSI and RWTH apply statistical techniques to perform the task, whereas SYSTRAN uses their commercial rule-based translation engine. KIT makes use of a phrase-based decoder augmented with partof-speech (POS) information and bilingual language models. LIMSI applies the n-gram-based approach and rescores the output with a neuronal language model. RWTH performs system combination on several systems, making use of both the phrase-based and the hierarchical paradigm. All partners adapt the speech data within their preprocessing step, in order to be able to apply their usual text translation techniques. To visualize the improvements over time, previous year's systems are evaluated as well. The results show that the novel techniques developed by the partners within the scope of the program improve the state of the art and lead to better quality of the automatic translations. The paper is structured as follows. The evaluation framework is specified in Section 2. In Section 3 we describe each participant's translation system. The results of the campaign are discussed in Section 4 and we conclude in Section 5. Quaero Evaluation Framework Description of the Task Translation of speech is the process of translating the transcription of spoken language in a text document from one natural language to another. Different kinds of text data inputs can be considered according to their closeness to the initial speech: manual transcriptions, automatic transcriptions and final text editions [2] . In our case, both automatic and manual transcriptions has have been used as sources for the translation. The main objective of this evaluation is to measure the performance of the technology and its readiness for integration in innovative projects. This performance has been measured on both directions between the languages French and German. The systems have been evaluated on a mixture of broadcast news and broadcast conversations transcriptions. For each translation direction, two different conditions were considered. They differ on the type of input material. The evaluated conditions were the following: manual transcriptions segmented with a sentence-based segmentation and output of an ASR system with a segmentation generated automatically. Data Description For the statistical systems, two training data sources were available. The partners were allowed to use the well-known data from the ACL 2010 Joint Fifth Workshop On Statistical Machine Translation 2 and data, which was collected within the Quaero program. The domain of the collected data is politics-news and UN documents. Both bilingual and monolingual data were provided for the languages German and French. Table 1 shows the statistics for the amount of data released for training. The data was collected from the following individual sources: \u2022 admin.ch \u2022 project-syndicate.org \u2022 bookshop.europa.eu \u2022 presseurop.eu \u2022 arte.tv The corpora used to evaluate this task have been built from French and German (manual) transcriptions extracted from the test set used in the previous year's Quaero evaluation campaign of ASR [1] . These transcriptions come from recordings of broadcast shows. The transcriptions were resegmented manually by the human translators into sentences. Indeed the time-based segmentation, traditionally used for ASR purposes, induced translation issues in the previous evaluation. These issues result from the fact that the timebased segments are independent of the semantic units (e.g. units can be split when breathing) and from the difference of syntax between French and German. ASR outputs have also been automatically segmented and aligned with the human generated transcriptions to make possible the use of the same references with the two kinds of sources. The reference transcriptions were translated twice by human translators and their translations have been used as references for both evaluation conditions: translation of manual transcriptions and translation of ASR output. In the first case, only the MT performances are evaluated as the input is a reference transcription, whereas in the second one, the complete processing chain is evaluated as the translation system has to deal with the errors of the speech recognition system. Table 2 summarizes the statistics of the evaluation corpora. Over the years a development set of around 50K words per translation direction has been built from the test sets of the previous years. Metrics and Scoring The BLEU-4 score [3] and the Translation Edit Rate (TER) [4] were chosen as the evaluation metrics for machine translation in Quaero program. BLEU measures the closeness of a candidate translation to one or several reference translations by counting the number of n-grams in the system output that also occur in the reference translation. TER is an error measure for machine translation that measures the number of edits required to change a system output into one of the references. TER is defined as the minimum number of edits needed to change a hypothesis so that it matches one of the references, normalized by the average length of the references. The possible edits are the insertion, deletion and substitution of single words and the shifts of word sequences. In this evaluation two references were used to compute BLEU and TER scores. Both references were produced independently by professional human translators. Scores were calculated in case and punctuation sensitive fashion. System Descriptions KIT The KIT system for the German to French and French to German SLT translation tasks in the Quaero 2011 evaluation campaign is designed as follows. To adapt our models to the speech translation tasks, we try to match the text-based training data to the text produced by a speech recognizer. After generating the word alignment, we removed all punctuation marks from the source side of the training corpus and mapped the alignment to the new corpus. Then we continued with building the translation models and reordering models on this corpus with the standard techniques for text translation. For the test data, we applied additional smart-casing for all words. That means on encountering an unknown word we check the phrase table for occurrences of that word in a different casing variant and change the case as required to be able to translate it. Some of the available data contains a lot of noise. The Giga corpus, for example, includes a large amount of noise such as non-standardized HTML characters. Also, the Bookshop and Presseurop corpora contain truncated lines, which do not match its aligned translation sentence. These noisy pairs potentially degrade the quality of the translation model. The special filtering was applied to the Giga corpus and some of the Quaero data. We used a Support Vector Machines classifier to filter the corpus, inspired by the work of [5] on comparable data. To generate the translation model, we used the MGIZA++ Toolkit to calculate the word alignment for the training corpus. Afterwards, the alignments were combined using the grow-diag-final-and heuristic. Word reordering is addressed using the POS-based reordering model as described in [6] to account for the different word orders in the languages. To cover long-range reorderings, we apply a modified reordering model with non-continuous rules [7] . The part-of-speech tags for the reordering model are obtained using the TreeTagger [8] . The phrase table and the phrases were built with the Moses Toolkit [9] and scored by our inhouse parallel phrase scorer [10] . We used 4-gram language models with Kneser-Ney smoothing, which are generated by using the SRILM toolkit [11] . The system applied a bilingual language model as described in [12] to extend the context of source language words available for translation. Tuning is performed using minimum error rate training against the BLEU score as described in [13] . Translations are generated using our in-house phrase-based decoder [14] . German-French For German to French we applied longrange POS-based reordering rules and lattice phrase extraction. We added a bilingual language model and a POSbased bilingual language model. The part-of-speeches for this model were generated by using the RF tagger for German [15] and the LIA Tagger for French 3 . These taggers produce more fine-grained linguistic information than the TreeTagger, whose output is used for POS-based reordering. French-German For French to German we also used long-range POS based reordering rules and lattice phrase extraction. Using the POS-based language model led to a big improvement. LIMSI LIMSI's participation in Quaero 2011 evaluation campaign was focused on the translation of German from and into French. The adaptation of our text translation system to speech inputs is mostly performed in preprocessing, aimed at removing dysfluencies, partially recognized or repeated words, etc. The rest of the pipeline is unchanged as compared to text translations. For translations between German and French we used N-code 4 , our in-house statistical machine translation system based on bilingual n-grams. N-code overview N-code's translation model implements a stochastic finite-state transducer (FST) trained using an n-gram model (source,target) pairs. The training requires source-side sentence reorderings to match the target word order, also performed by a stochastic FST reordering model, which uses POS information to generalize reordering patterns beyond lexical regularities. Complementary to the translation model, ten more features are used in a linear scoring function: a target-language model; four lexicon models; two lexicalized reordering models [16] to predict the orientation of the next translation unit; a weak distancebased distortion model; and finally a word-bonus model and a tuple-bonus model which compensate for the system preference for short translations. The four lexicon models are similar to the standard ones in phrase-based systems: two scores correspond to the relative frequencies of the tuples and two lexical weights, estimated from the automatically generated word alignments. The weights associated to features are found using the minimum error rate training procedure [17] on the development set. The decoding is beam-search-based on top of a dynamic programming algorithm. Reordering hypotheses are computed in a preprocessing step, making use of reordering rules built from the word reorderings introduced in the tuple extraction process. The resulting reordering hypotheses are passed to the decoder as word lattices [18] . German-French Part-of-speech information for German is computed using in-house CRF-based tagger [19] . All the available data has been preprocessed and word aligned using MGIZA++; these alignments were then used in a standard Ncode pipeline. As development set we used the WMT 2010 newstest set; internal tests were conducted on the test data of 2009 and 2011. LIMSI used the best available text translation system and the preprocessing with tools initially developed and used for our German to English systems [20] . These tools have also been augmented so as to perform a restricted form of longrange reorderings, notably to move separable particles closer to the verbs they depend on [21] . For the reordering models we selected the monotone-swap-discontinuous (MSD) model. Language models Large 4-gram language models were trained on all the available data as described in [22] . Additionally, SOUL, a neuronal language model was used to rescore the n-best hypotheses. These models were trained following the methodology of [23] and used for rescoring n-best lists. We used 10-gram history size (differences with 6-gram were insignificant). Using the neural language model led to (small but consistent) improvements in all tasks. RWTH This Section describes the RWTH system for the participation in the Quaero 2011 SLT evaluation campaign on both the German to English and English to German task. The adaptation of our text translation system to speech inputs was mostly performed in preprocessing. We deleted all punctuation from the source language of our training and development data. To give the translation system more stability, we inserted on each source sentence one punctuation mark at the end of the sentence. The rest of the pipeline was unchanged as compared to text translations. For the Quaero 2011 evaluation RWTH utilized state-ofthe-art phrase-based and hierarchical translation systems as well as our in-house system combination framework. GIZA [24] was employed to train word alignments, all language models were created with the SRILM toolkit [11] and are standard 4-gram language models with interpolated modified Kneser-Ney smoothing. The phrase-based statistical machine translation system (pbt) used in this work is an inhouse implementation of the state-of-the-art machine translation decoder described in [25] . For our hierarchical setups, we employed the open source translation toolkit Jane [26] , which has been developed at RWTH and is freely available for non-commercial use. The basic concept of RWTH's approach to machine translation system combination is described in [27, 28] . With both decoders, we did several setups with different amounts of models. Optional additional models are discriminative word lexicon (dwl) models, triplet lexicon models [29] and additionally binary count features. Unless stated otherwise, we optimized the model weights with standard minimum error rate training [17] on 100-best lists on BLEU. With the help of system combination, we combined the hypotheses of all our different setups. German-French For German to French we did a system combination of the following five systems: \u2022 Jane with standard features \u2022 Jane with additional 26 binary count features \u2022 pbt with standard features \u2022 pbt with additional model dwl \u2022 pbt with additional model triplets French-German For French to German we did a system combination of the following seven systems: \u2022 Jane with standard features \u2022 Jane with additional 26 binary count features \u2022 Jane with standard features with BLEU \u2212TER as optimization criterion \u2022 Jane with additional model triplets \u2022 pbt with standard features \u2022 pbt with additional models dwl and triplets \u2022 pbt with additional model triplets With the system combination of all different systems, we got an improvement in BLEU and in TER compared to the best single system of both tasks. SYSTRAN The German and French data submitted by SYSTRAN were obtained by the SYSTRAN baseline engine, being traditionally classified as a rule-based system. However, over the decades, its development has always been driven by pragmatic considerations, progressively integrating many of the most efficient MT approaches and techniques. Some of the analysing modules, like the part-of-speech-tagger for example, make use of decision-tree techniques combining linguistic rules with corpus-extracted knowledge. For this reason, it is difficult to categorize the SYSTRAN engine as simply rule-or statistics-based. An essential component of the SYSTRAN engine are the manually developed linguistic resources, ranging from 100K to 800K entries for each language pair. The dictionaries contain single-and multiword entries as well as complex, customized disambiguation rules. Translation is basically performed in four steps: 1. Preprocessing: Normalisation, segmentation, lookup from idiom, stem and compound dictionaries 2. Analysis: part-of-speech analysis, homograph resolution, syntactic dependency parsing A central guiding principle at SYSTRAN for the development of the translation engine is that the output be deterministic and transparent; it ought to be possible to explain the translation results and -if necessary -to modify the rules involved. Results The results for all four evaluated conditions are summarized in the Tables 3 through 6 . On each condition, the results of all four partners are given in BLEU and TER. The best scores according to each metric are in bold face. From the results it is clear that, especially for the French target language, the statistical systems have advantages over the rule-based engine employed by SYSTRAN when measured with BLEU and TER. This can be expected, as statistical systems are optimized specifically to perform well on these scores. However, rule-based engines are known to often outperform the statistical approach when it comes to acceptance among human evaluators. For the German-French translation of manual transcripts (cf. Table 3 ), KIT clearly outperforms the other partners in both measures. For the corresponding French-German task (cf. Table 4 ) LIMSI has a strong advantage over their competitors. When translating the automatic transcripts, the differences between the three statistical systems are much smaller. For both German-French (cf. Table 5 ) and French-German (cf. Table 6 ), KIT reaches the best BLEU score, while RWTH has the best TER. In Table 6 , we also included scores from the respective eval- In TER, the improvement between the respective best systems is 2.0%. The results also illustrate the difficulty of translating ASR output as opposed to clean, human generated text. For German-French, the KIT system degrades by 11.2% BLEU and 16.5% TER when moving from reference to automatic transcription as input. On French-German, the difference is 9.8% BLEU and 10.6% TER for the LIMSI system, which performed best on the manual transcripts. Conclusions In this work, we described the spoken language translation evaluation 2011 of the Quaero research program. It focuses on the German and French languages. As input for the translation engines, both automatic and human generated transcriptions of the speech data was considered. The four partners KIT, LIMSI, RWTH and SYSTRAN make use of substantially different techniques to perform the task, which were compared and evaluated in this campaign conducted by DGA. Both rule-based and statistical approaches are applied. The basic statistical translation engines make use of three different paradigms: phrase-based, hierarchical and ngram-based. Additionally, each site incorporated specialized techniques developed within the scope of Quaero, that can improve translation quality. The results show the higher difficulty of the task of translating automatic transcripts rather than clean text. The improvement over time achieved by the research conducted within the Quaero program is shown on the French-German translation of automatic transcripts. The best system of the 2009 evaluation could be improved by 2.5% BLEU. Acknowledgements This work was achieved as part of the Quaero program, funded by OSEO, French State agency for innovation.",
    "abstract": "The Quaero program is an international project promoting research and industrial innovation on technologies for automatic analysis and classification of multimedia and multilingual documents. Within the program framework, research organizations and industrial partners collaborate to develop prototypes of innovating applications and services for access and usage of multimedia data. One of the topics addressed is the translation of spoken language. Each year, a project-internal evaluation is conducted by DGA to monitor the technological advances. This work describes the design and results of the 2011 evaluation campaign. The participating partners were RWTH, KIT, LIMSI and SYSTRAN. Their approaches are compared on both ASR output and reference transcripts of speech data for the translation between French and German. The results show that the developed techniques further the state of the art and improve translation quality.",
    "countries": [
        "Germany",
        "France"
    ],
    "languages": [
        "French",
        "German"
    ],
    "numcitedby": "3",
    "year": "2011",
    "month": "December 8-9",
    "title": "Advances on spoken language translation in the Quaero program"
}