{
    "article": "The increased demand for structured scientific knowledge has attracted considerable attention in extracting scientific relation from the ever growing scientific publications. Distant supervision is widely applied approach to automatically generate large amounts of labelled data for Relation Extraction (RE). However, distant supervision inevitably accompanies the wrong labelling problem, which will negatively affect the RE performance. To address this issue, (Han et al., 2018) proposes a novel framework for jointly training RE model and Knowledge Graph Completion (KGC) model to extract structured knowledge from nonscientific dataset. In this work, we firstly investigate the feasibility of this framework on scientific dataset, specifically on biomedical dataset. Secondly, to achieve better performance on the biomedical dataset, we extend the framework with other competitive KGC models. Moreover, we proposed a new endto-end KGC model to extend the framework. Experimental results not only show the feasibility of the framework on the biomedical dataset, but also indicate the effectiveness of our extensions, because our extended model achieves significant and consistent improvements on distantly supervised RE as compared with baselines. Introduction Scientific Knowledge Graph (KG), such as Unified Medical Language System (UMLS) 1 , is extremely crucial for many scientific Natural Language Processing (NLP) tasks such as Question Answering (QA), Information Retrieval (IR), Relation Extraction (RE), etc. Scientific KG provides large collections of relations between entities, typically stored as (h, r, t) triplets, where h = head entity, r = relation and t = tail entity, e.g., (acetaminophen, may treat, pain) . However, as with general KGs such as Freebase (Bollacker et al., 2008) and DBpedia (Lehmann et al., 2015) , scientific KGs are far from complete and this would impede their usefulness in real-world applications. Scientific KGs, on the one hand, face the data sparsity problem. On the other hand, scientific publications have become the largest repository ever for scientific KGs and continue to increase at an unprecedented rate (Munroe, 2013) . Therefore, it is an essential and fundamental task to turn the unstructured scientific publications into well organized KG, and it belongs to the task of RE. In RE, one obstacle that is encountered when building a RE system is the generation of training instances. For coping with this difficulty, (Mintz et al., 2009) proposes distant supervision to automatically generate training samples via leveraging the alignment between KGs and texts. They assumes that if two entities are connected by a relation in a KG, then all sentences that contain these entity pairs will express the relation. For instance, (aspirin, may treat, pain) is a fact triplet in UMLS. Distant supervision will automatically label all sentences, such as Example 1, Example 2 and Example 3, as positive instances for the relation may treat. Although distant supervision could provide a large amount of training data at low cost, it always suffers from wrong labelling problem. For instance, comparing to Example 1, Example 2 and Example 3 should not be seen as the evidences to support the may treat relationship between aspirin and pain, but will still be annotated as positive instances by the distant supervision. (1) The clinical manifestations are generally typical nocturnal pain that prevents sleep and that is alleviated with aspirin. (2) The tumor was remarkably large in size , and pain unrelieved by aspirin. (3) The level of pain did not change significantly with either aspirin or pentoxifylline , but the walking distance was farther with the pentoxifylline group . To automatically alleviate the wrong labelling problem, (Riedel et al., 2010; Hoffmann et al., 2011) apply multi-instance learning. In order to avoid the handcrafted features and errors propagated from NLP tools, (Zeng et al., 2015) proposes a Convolutional Neural Network (CNN), which incorporate mutli-instance learning with neural network model, and achieves significant improvement in distantly supervised RE. Despite the impressive achievement in RE, this model still has the limitation that it only selects the most informative sentence and ignores the rest, thereby loses the rich information stored in those neglected sentences, For instance, among Example 1, Example 2 and Example 3, Example 1 is undoubtedly the most informative one for detecting relation may treat, but it unnecessarily means other sentences such as Example 3 could not contribute to the relation detection. In Example 3, entity aspirin and entity pentoxifylline have alternative relation, and the latter is a drug to treat muscle pain, therefore the former is also likely to be a pain-killing drug. To address this issue, recently, attention mechanism is applied to extract features from all collected sentences. (Lin et al., 2016) proposes a relation vector based attention mechanism for distantly supervised RE. (Han et al., 2018) proposes a novel joint model that leverages the KG-based attention mechanism and achieves better performance than (Lin et al., 2016) on distantly supervised RE from New York Times (NYT) corpus. The success that the joint model (Han et al., 2018) has attained in the newswire domain (or non-scientific domain) inspires us to choose the strong model as our base model and assess its feasibility on biomedical domain. Specifically, the first question of this research is how the joint model behaves when the system is trained on biomedical KG (e.g., UMLS) and biomeical corpus (e.g., Medline corpus). (Han et al., 2018) indicates that the performance of the base model could be affected the representation ability of KGC model. The representation ability of a KGC model also varies with dataset (Wang et al., 2017) . Therefore, given a new dataset (e.g., a biomedical dataset), it is necessary to extend the base model with other competitive KGC models, and choose the best fit for the given dataset. However, the base model only implements two KGC models, which are based on TransE (Bordes et al., 2013) and TransD (Ji et al., 2015) respectively. Thus, the second question of this work is how other competitive KGC models such as ComplEx (Trouillon et al., 2016) and SimplE (Kazemi and Poole, 2018) influence the performance of the base model on biomedical dataset. At last but not least, in biomedical KG, a relation is scientifically restricted by entity type (ET). For instance, in the relation (h, may treat, t), the ET of t should be Disease or Syndrome. Therefore, ET information is an important feature for biomedical RE and KGC. For leveraging the ET information, which the base model lacks, in this work, we propose an end-to-end KGC model to enhance the base model. The proposed KGC model is capable of identifying ET via the word embedding of target entity and incorporating the predicted ET into a state-of-to-art KGC model to evaluate the plausibility of potential fact triplets. We conduct evaluation on biomedical datasets in which KG is collected from UMLS and textual data is extracted from Medline corpus. The experimental results not only show the feasibility of the base model on the biomedical domain, but also prove the effectiveness of our proposed extensions for the base model. Related Work RE is a fundamental task in the NLP community. In recent years, Neural Network (NN)-based models have been the dominant approaches for non-scientific RE, which include Convolutional Neural Network (CNN)-based frameworks (Zeng et al., 2014; Xu et al., 2015; Santos et al., 2015) Recurrent Neural Network (RNN)-based frameworks (Zhang and Wang, 2015; Miwa and Bansal, 2016; Zhou et al., 2016) . NN-based approaches are also used in scientific RE. For instance, (Gu et al., 2017) utilizes a CNN-based model for identifying chemical-disease relations from Medline corpus. (Hahn-Powell et al., 2016) proposes an LSTM-based model for identifying causal precedence relationship between two event mentions in biomedical papers. (Ammar et al., 2017) applies (Miwa and Bansal, 2016) 's model for scientific RE. Although remarkably good performances are achieved by the models mentioned above, they still train and extract relations on sentence-level and thus need a large amount of annotation data, which is expensive and time-consuming. To address this issue, distant supervision is proposed by (Mintz et al., 2009) . To alleviate the noisy data from the distant supervision, many studies model distant supervision for RE as a Multiple Instance Learning (MIL) problem (Riedel et al., 2010; Hoffmann et al., 2011; Zeng et al., 2015) , in which all sentences containing a target entity pair (e.g.,aspirin and pain) are seen as a bag to be classified. To make full use of all the sentences in the bag, rather than just the most informative one, (Lin et al., 2016) proposes a relation vector based attention mechanism to extract feature from the entire bag and outperforms the prior approaches. (Han et al., 2018) proposes a joint model that adopts a KG-based attention mechanism and achieves better performance than (Lin et al., 2016) on distantly supervised RE from NYT corpus. In this work, we are primarily interested in applying distant supervision techniques to extract biomedical fact triplets from scientific publications. To validate and enhance the efficacy of the previous techniques in biomedical domain, we choose the strong joint model proposed by (Han et al., 2018) as the base model and make some necessary extension for our scientific RE task. Since from the two main groups of KGC models (Wang et al., 2017) : translational distance models and semantic matching models, the base model only implements the translational distance models, TransE (Bordes et al., 2013) and TransD (Ji et al., 2015) , we thus extend the base model with the semantic matching models, Com-plEx (Trouillon et al., 2016) and SimplE (Kazemi and Poole, 2018), for selecting the best fit for our task. In addition, the base model has not incorporated the ET information, which we assume is crucial for scientific RE. Therefore, we propose an end-to-end KGC model to enhance the base model. Different from the work (Xie et al., 2016) , which utilizes an ET look-up dictionary to obtain ET, the end-to-end KGC is capable of identifying ET via the word embedding of a target entity and thus is free of the attachment to an incomplete ET look-up dictionary. Base Model The architecture of the base model is illustrated in Figure 1 . In this section, we will introduce the base model proposed by (Han et al., 2018) in two main parts: KGC part, RE part. KGC Part Suppose we have a KG containing a set of fact triplets O = {(e 1 , r, e 2 )}, where each fact triplet consists of two entities e 1 , e 2 \u2208 E and their relation r \u2208 R. Here E and R stand for the set of entities and relations respectively. KGC model then encodes e 1 , e 2 \u2208 E and their relation r \u2208 R into low-dimensional vectors h, t \u2208 R d and r \u2208 R d respectively, where d is the dimensionality of the embedding space. As mentioned above, the base model adopts two representative translational distance models Prob-TransE and Prob-TransD, which are based on TransE (Bordes et al., 2013) and TransD (Ji et al., 2015) repectively, to score a fact triplet. Specifically, given an entity pair (e 1 , e 2 ), Prob-TransE defines its latent relation embedding r ht via the Equation 1 . r ht = t \u2212 h (1) Prob-TransD is an extension of Prob-TransE and introduces additional mapping vectors h p , t p \u2208 R d and r p \u2208 R d for e 1 , e 2 and r respectively. Prob-TransD encodes the latent relation embedding via the Equation 2 , where M rh and M rt are projection matrices for mapping entity embeddings into relation spaces. r ht = t r \u2212 h r , (2) h r = M rh h, t r = M rt t, M rh = r p h p + I d\u00d7d , M rt = r p t p + I d\u00d7d The conditional probability can be formalized over all fact triplets O via the Equations 3 and 4, where f r (e 1 , e 2 ) is the KG scoring function, which is used to evaluate the plausibility of a given fact triplet. For instance, the score for (aspirin, may treat, pain) would be higher than the one for (aspirin, has ingredient, pain), because the former is more plausible than the latter. \u03b8 E and \u03b8 R are parameters for entities and relations respectively, b is a bias constant. P (r|(e 1 , e 2 ), \u03b8 E , \u03b8 R ) = exp(f r (e 1 , e 2 )) r \u2208R exp(f r (e 1 , e 2 )) (3) f r (e 1 , e 2 ) = b \u2212 r ht \u2212 r (4) RE Part Sentence Representation Learning. Given a sentence s with n words s = {w 1 , ..., w n } including a target entity pair (e 1 , e 2 ), CNN is used to generate a distributed representation s for the sentence. Specifically, vector representation v t for each word w t is calculated via Equation 5 , where W w emb is a word embedding projection matrix (Mikolov et al., 2013) , W wp emb is a word position embedding projection matrix, x w t is a one-hot word representation and x wp t is a one-hot word position representation. The word position describes the relative distance between the current word and the target entity pair (Zeng et al., 2014) . For instance, in the sentence \"Patients recorded pain e 2 and aspirin e 1 consumption in a daily diary\", the relative distance of the word \"and\" is [1, -1]. v t = [v w t ; v wp1 t ; v wp2 t ], (5) v w t = W w emb x w t , v wp1 t = W wp emb x wp1 t , v wp2 t = W wp emb x wp2 t The distributed representation s is formulated via the Equation 6 , where, [s] i and [h t ] i are the i-th value of s and h t , M is the dimensionality of s, W is the convolution kernal, b is a bias vector, and k is the convolutional window size. [s] i = max t {[h t ] i }, \u2200i = 1, ..., M (6) h t = tanh(Wz t + b), z t = [v t\u2212(k\u22121)/2 ; ...; v t+(k\u22121)/2 ] KG-based Attention. Suppose for each fact triplet (e 1 , r, e 2 ), there might be multiple sentences S r = {s 1 , ..., s m } in which each sentence contains the entity pair (e 1 , e 2 ) and is assumed to imply the relation r, m is the size of S r . As discussed before, the distant supervision inevitably collect noisy sentences, the base model adopts a KG-based attention mechanism to discriminate the informative sentences from the noisy ones. Specifically, the base model use the latent relation embedding r ht from Equation 1 (or Equation 2 ) as the attention over S r to generate its final representation s f inal . s f inal is calculated via Equation 7 , where W s is the weight matrix, b s is the bias vector, a i is the weight for s i , which is the distributed representation for the i-th sentence in S r . s f inal = m i=1 a i s i , (7) a i = exp( r ht , x i ) m k=1 exp( r ht , x k ) , x i = tanh(W s s i + b s ) Finally, the conditional probability P (r|S r , \u03b8) is formulated via Equation 8 and Equation 9 , where, \u03b8 is the parameters for RE, which includes {W w emb , W wp emb , W, b, W s , b s , M, d}, M is the representation matrix of relations, d is a bias vector, o is the output vector containing the prediction probabilities of all target relations for the input sentences set S r , and n r is the total number of relations. P (r|S r , \u03b8) = exp(o r ) nr c=1 exp(o c ) (8) o = Ms f inal + d (9) 4 Extensions The base model opens the possibility to jointly train RE models with KGC models for distantly supervised RE. The empirical results of the base model on NYT corpus indicate that the performance of distantly supervised RE varies with KGC models (Han et al., 2018) . In addition, the performance of KGC models depends on a given dataset (Wang et al., 2017) . Therefore, we assume that it is necessary to attempt multiple competitive KGC models for the joint framework so as to find the optimal combination for our biomedical dataset. However, the base model only implements translational distance models: TransE and TransD, but not the semantic matching models, and this, we assume, might hinder its performance in the new dataset. To address this, we select two representative semantic matching models: Com-plEx (Trouillon et al., 2016) and SimplE (Kazemi and Poole, 2018) as the alternative KGC part. As discussed in Section 1, in scientific KGs, a fact triplet is severely restricted by ET information (e.g., ET of e 2 should be Disease or Syndrome in the fact triplet (e 1 , may treat, e 2 )). Therefore, for leveraging ET information, which the base model lacks, we also propose an end-to-end KGC model to extend the base model. Since the proposed KGC model is build on SimplE and is capable of Named Entity Recognition (NER), we call it SimplE NER. ComplEx based Attention Given a fact triplet (e 1 , r, e 2 ), ComplEx then encodes entities e 1 , e 2 and relation r into a complexvalued vector e 1 \u2208 C d , e 2 \u2208 C d and r \u2208 C d respectively, where d is the dimensionality of the embedding space. Since entities and relations are represented as complex-valued vector, each x \u2208 C d consists of a real vector component Re(x) and imaginary vector component Im(x), namely x = Re(x)+iIm(x). The KG scoring function of ComplEx for a fact triplet (e 1 , r, e 2 ) is calculated via Equation 10 , where \u01132 is the conjugate of e 2 ; Re(\u2022) (or Im(\u2022)) means taking the real (or imaginary) part of a complex value. u, v, w is defined via Equation 11 , where [\u2022] n is the n-th entry of a vector. f r (e 1 , e 2 ) = Re( e 1 , r, \u01132 ) = Re(r), Re(e 1 ), Re(e 2 ) + Re(r), Im(e 1 ), Im(e 2 ) + Im(r), Re(e 1 ), Im(e 2 ) \u2212 Im(r), Im(e 1 ), Re(e 2 ) (10) u, v, w = d n=1 [u] n [v] n [w] n (11) Since the asymmetry of this scoring function, namely f r (e 1 , e 2 ) = f r (e 2 , e 1 ), ComplEx can effectively encode asymmetric relations (Trouillon et al., 2016) . For calculating the attention, the r ht in Equation 7 is defined via Equation 12 , where represents the element-wise multiplication. r ht = Re(e 1 ) Re(e 2 )+Im(e 1 ) Im(e 2 ) (12) SimplE based Attention Given a fact triplet (e 1 , r, e 2 ), SimplE then encodes each entity e \u2208 E into two vectors h e , t e \u2208 R d and each relation r \u2208 R into two vectors v r , v r \u22121 \u2208 R d respectively, where d is the dimensionality of the embedding space. h e captures the entity e's behaviour as the head entity of a fact triplet and t e captures e's behaviour as the tail entity. v r represents r in a fact triplet (e 1 , r, e 2 ), while v r \u22121 represents its inverse relation r \u22121 in the triplet (e 2 , r \u22121 , e 1 ). The KG scoring function of SimplE for a fact triplet (e 1 , r, e 2 ) is defined via Equation 13 . f r (e 1 , e 2 ) = 1 2 ( h e 1 , v r , t e 2 + h e 2 , v r \u22121 , t e 1 ) (13 ) Similar to the attention from ComplEx, the r ht in Equation 7 is defined via Equation 14 . r ht = 1 2 (h e 1 h e 2 + t e 1 t e 2 ) (14) SimplE NER based Attention The h w = tanh(W w emb x w ), h 1 = sigmoid(W 1 h w + b 1 ), h 2 = sigmoid(W 2 h 1 + b 2 ), y = sigmoid(W ET h 2 + b ET ) (15) where W w emb is a word embedding projection matrix, which is initialized by the pre-trained word + h e 2 , v r \u22121 , t e 1 + h ET 1 , v r , t ET 2 + h ET 2 , v r \u22121 , t ET 1 ) (16) Experiments Our experiments aim to demonstrate that, (1) the base model proposed by (Han et al., 2018) Data The biomedical datasets used for evaluation consist of biomedical knowledge graph and biomedical textual data, which will be detailed as follows. Knowledge Graph. We choose the UMLS as the KG. UMLS is a large biomedical knowledge base developed at the U.S. National Library of Medicine. UMLS contains millions of biomedical concepts and relations between them. We follow (Wang et al., 2014) , and only collect the fact triplet with RO relation category (RO stands for \"has Relationship Other than synonymous, narrower, or broader\"), which covers the interesting relations like may treat, my prevent, etc. From the UMLS 2018 release, we extract about 60 thousand such RO fact triplets (i.e., (e 1 , r, e 2 )) under the restriction that their entity pairs (i.e., e 1 and e 2 ) should coexist within a sentence in Medline corpus. They are then randomly divided into training and testing sets for KGC. Following (Weston et al., 2013) , we keep high entity overlap between training and testing set, but zero fact triplet overlap. The statistics of the extracted KG is shown in Table 1 . For training the ET Classification Part in Section 4.3, we also collect about 35 thousand entity-ET pairs (e.g., heart rates-Clinical Attribute) from the UMLS 2018 release. Textual Data. Medline corpus is a collection of bimedical abstracts maintained by the National Library of Medicine. From the Medline corpus, by applying a string matching model 2 , we extract 732, 771 sentences that contain the entity pairs (i.e., e 1 and e 2 ) in the KG mentioned above as our textual data, in which 592, 605 sentences are for training and 140, 166 sentences for testing. For identifying the NA relation, besides the \"related\" sentences, we also extract the \"unrelated\" sentences based on a closed world assumption: pairs of entities not listed in the KG are regarded to have NA relation and sentences containing them considered to be the \"unrelated\" sentences. By this way, we extract 1, 738, 801 \"unrelated\" sentences for the training data, and 431, 212 \"unrelated\" sentences for the testing data. sample sentences in the training data. Parameter Settings We base our work on (Han et al., 2018) and extend their implementation available at https:// github.com/thunlp/JointNRE, and thus adopt identical optimization process. We use the default settings of parameters 3 provided by the base model. Since we address the distantly supervised RE in biomedical domain, we use the Medline corpus to train the domain specific word embedding projection matrix W w emb . Result and Discussion ( Han et al., 2018) evaluates the base model on nonscientific dataset. In this work, we firstly plan to assess its feasibility on scientific dataset, and secondly, to investigate the effectiveness of our extensions, which is discussed in Section 4, with respect to enhancing the distantly supervised RE from scientific dataset. Relation Extraction We follow (Mintz et al., 2009; Weston et al., 2013; Lin et al., 2016; Han et al., 2018) and conduct the held-out evaluation, in which the model for distantly supervised RE is evaluated by comparing the fact triplets identified from textual data (i.e., the bag of sentences containing the target entity pairs) with those in The precision-recall curves are shown in Figure 3 , where \"JointD+KATT\" and \"JointE+KATT\" represent the RE model with the KG-based attention obtained from Prob-TransD and Prob-TransE respectively, which are our base models and trained on both KG and textual data. Similarly, \"JointComplEx+KATT\", \"JointSim-plE+KATT\" and \"JointSimplE NER+KATT\" represent the RE model with the KG-based attention obtained from ComplEx, SimplE and SimplE NER respectively, which are our extensions. \"CNN+AVE\" and \"CNN+ATT\" represent the RE model with average attention and relation vector based attention (Lin et al., 2016) respectively, which are not joint models and only trained on textual data. The results show that: (1) All RE models with KG-based attention, such as \"JointE+KATT\", outperform those models without it, such as \"CNN+ATT\". This observation is in line with (Han et al., 2018) . This demonstrates that not just for non-scientific dataset , jointly training a KGC model with a RE model is also an effective approach to improve the performance of distantly supervised RE for biomedical dataset. In other words, the outperformance proves the feasibility of the base model proposed by (Han et al., 2018) on biomedical dataset. The comparison between (Han et al., 2018) 's results on non-scientific dataset and ours on scientific dataset also indicates that the performance of base model could differ according to the dataset. Specifically, on scientific dataset, \"JointE+KATT\" performs better than \"JointD+KATT\" but in non-scientific dataset the latter outperforms the former. (2) Our extended models, \"JointCom-plEx+KATT\", \"JointSimplE+KATT\" and \"JointSimplE NER+KATT\", achieve better precision than the base model over the major range of recall. It could be attributed to their better capability of modeling asymmetric relations (e.g., may treat and may prevent), because their KG scoring functions are asymmetry (i.e., f r (e 1 , e 2 ) = f r (e 2 , e 1 )). The superior performance indicates the necessity of our extensions on the base model. Specifically, given the frequently used biomedical dataset, UMLS and Medline corpus, it would be an effective method to switch the translational distance models, such as TransE and TransD, with the semantic matching models, s 1 : M wortmannin resulted in 80% and 20% decreases of glucose uptake stimulated by insulin e1 and TPA e2 , respectively. s 2 : The effects of insulin e1 , IGF1 and TPA e2 were also observed in the presence of cycloheximide. s 3 : ... such as ComplEx and SimplE, for increasing the performance of distantly supervised RE. The effect of different KGC models on the distantly supervised RE will be discussed later. (3) The model enhanced by our proposed KGC model, \"JointSimplE NER+KATT\", achieves the highest precision over almost entire range of recall compared with the models that apply the existing KGC models. This proves the effectiveness of our proposed KGC model for the distantly supervised RE. Additionally, different from the exiting KGC models, the proposed end-to-end KGC model is capable of identifying ET information from word embedding of target entity. This indicates that the incorporation of semantic information of entity, such as ET, is a promising approach for enhancing the base model. Effect of KGC on RE. (Han et al., 2018) indicates that KGC models could affect the performance of distantly supervised RE. For investigating the influence of KGC models on our specific RE task, we compare their link prediction results on our KG with their corresponding Precision@N (P@N) results on our RE task. Link prediction is the task that predicts tail entity t given both head entity h and relation r, e.g., (h, r, * ), or predict head entity h given ( * , r, t). We report the mean reciprocal rank (MRR) and mean Hit@N scores for evaluating the KGC models. MRR is defined as: M RR = 1 2 * |tt| (h,r,t)\u2208tt ( 1 rank h + 1 rankt ), where tt represents the test triplets. Hit@N is the proportion of the correctly predicted entities (h or t) in top N ranked entities. Table 3 and Table 4 represent the RE precision@N and link prediction results respectively. This comparison indicates that given a biomedical dataset, the performance of a KGC model on the link prediction task could predict its effectiveness on its corresponding distantly supervised RE task. This observation also instruct us how to select the best KGC model for the base model. In addition, Table 3 and Table 4 indicate that ET is not only effective for distantly supervised RE task, but also for KGC task, and this observation will inspire us to explore other useful semantic feature of entity, such as the definition of entity, for our task. Model P@2k P@4k P@6k Mean JointE+KATT 0.876 0.786 0.698 0.786 JointD+KATT 0.848 0.725 0.528 0.700 JointComplEx+KATT 0.892 0.819 0.741 0.817 JointSimplE+KATT 0.900 0.808 0.721 0.809 JointSimplE NER+KATT 0.913 0.829 0.753 0.831 Conclusion and Future Work In this work, we tackle the task of distantly supervised RE from biomedical publications. To this end, we apply the strong joint framework proposed by (Han et al., 2018) as the base model. For enhancing its performance on our specific task, we extend the base model with other competitive KGC models. What is more, we also propose a new end-to-end KGC model, which incorporates word embedding based entity type information into a sate-of-the-art KGC model. Experimental results not only show the feasibility of the base model on the biomedical domain, but also indicate the effectiveness of our extensions. Our extended model achieves significant and consistent improvements on the biomedical dataset as compared with baselines. Since the semantic information of target entity, such as ET information, is effective for our task, in the future, we will explore other useful semantic features, such as the definition of target entity and fact triplet chain between entities (e.g., cancer\u2192disease has associated gene\u2192 Ku86\u2192gene plays role in process\u2192NHEJ), for our task. Acknowledgement This work was supported by JST CREST Grant Number JPMJCR1513, Japan and KAKENHI Grant Number 16H06614.",
    "abstract": "The increased demand for structured scientific knowledge has attracted considerable attention in extracting scientific relation from the ever growing scientific publications. Distant supervision is widely applied approach to automatically generate large amounts of labelled data for Relation Extraction (RE). However, distant supervision inevitably accompanies the wrong labelling problem, which will negatively affect the RE performance. To address this issue, (Han et al., 2018) proposes a novel framework for jointly training RE model and Knowledge Graph Completion (KGC) model to extract structured knowledge from nonscientific dataset. In this work, we firstly investigate the feasibility of this framework on scientific dataset, specifically on biomedical dataset. Secondly, to achieve better performance on the biomedical dataset, we extend the framework with other competitive KGC models. Moreover, we proposed a new endto-end KGC model to extend the framework. Experimental results not only show the feasibility of the framework on the biomedical dataset, but also indicate the effectiveness of our extensions, because our extended model achieves significant and consistent improvements on distantly supervised RE as compared with baselines.",
    "countries": [
        "Japan"
    ],
    "languages": [
        ""
    ],
    "numcitedby": "8",
    "year": "2019",
    "month": "June",
    "title": "Distantly Supervised Biomedical Knowledge Acquisition via Knowledge Graph Based Attention"
}