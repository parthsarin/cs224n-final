{
    "article": "This paper describes a system for generating text abstracts which relies on a general, purely statistical principle, i.e., on the notion of \"relevance\", as it is defined in terms of the combination of tf*idf weights of words in a sentence. The system generates abstracts from newspaper articles by selecting the \"most relevant\" sentences and combining them in text order. Since neither domain knowledge nor text-sort-specific heuristics are involved, this system provides maximal generality and flexibility. Also, it is fast and can be efficiently ilnplemented for both on-line and off-line purposes. An experiment shows that recall and precision for the extracted sentences (taking the sentences extracted by human subjects as a baseline) is within the same range as recall/precision when the human subjects are coinpared amongst each other: this means in fact that tile performance of the system is indistinguishable from the performance of a human abstractor. Finally, the system yields significantly better results than a default \"lead\" algorithm does which chooses just some initial sentences from the text. Introduction With increasing amounts of machine readable information being available, one of the major problems for users is to find those texts that are most relevant to their interests and needs in as short an amount of time as possible. The traditional IR approach is that the user inputs a boolean query (possibly in a natural language-like formulation) and the system responds by presenting to the user the texts that are a \"best match\" to his query. In corpora where abstracts are not already provided it might facilitate the retrieval process a lot if text abstracts could be generated automatically either off-line to be stored together with tile texts (e.g., as ranked sentence numbers), or on-line, in accordance with the user's query. So far, there have been two main approaches in this field (for overviews on abstracting and summarizing see, e.g., (?) or (?)). One is oriented more towards information extraction, working with a knowledge base in a limited domain (\"top down\", see e.g., (?; ?; ?)), tile other type relies mainly on various heuristics (\"bottom up\", see e.g., (?; ?)) which are less dependent on the domain but are still at least; tuned to the text sort and thus have to be adapted whenever the system would have to be applied outside its original environment. Combinations of these methods have also been attempted recently (see e.g. (?)). The focus of this paper will be the description and evaluation of an abstracting system which avoids the disadvantages coming along with most of these traditional approaches, while still being able to achieve a performance which matches closely the results of an identical abstracting task performed by human subjects in a comparative study. The results indicate that it is indeed possible to build a system relying on a simple and efficient algorithm, using standard tf*idf weights only, while still achieving a satisfying output} 2 A System for Generating Text Abstracts Kupiec et al. (?) present the results of a study where 80% of the sentences in man-made abstracts were \"close sentence matches\", i.e., they were \"either extracted verbatim from the original or with minor modifications\" (p.70). Therefore, we argue that it is not only an easy way but indeed an appropriate one for an automatic system to choose a number of the most relevant sentences and present 1By \"satisfying\" we mean at least indicative for the content of ~he respective text, if not also informative about it. these as a \"text; abstract;\" to the user. ~ We further argue that; coherence, although certainly desirable, is imi)ossible without a large scale knowledge based 1;ext mldersl;an(ling syst;em which would not only slow down dm l)erformance signiticantly but necessarily could not be domain inde,1)endent. Our design goal was to use as simple and efflcleat an algorithm as t)ossibh',, avoiding \"hem(stics\" and \"fe, al;ures\" emph)yed by other systems (e.g., (?)) wlfich may be hell)tiff in a specific text domain but would have to be redesigned whenever it were ported to a new domain, a In this respect, our system can be compared with the approach of (?) wit() also t)resent an abstracting system for general domain texts. However, whereas their focus is on the evaluation of abstracl; readability (as stand-alone texts), ours is rather on abstract relevance. A flirther difference is the (non-standard) method of tf*idfweight ('ah:ulation timy are using for their system. Our sysl;em was deveh)ped in C+.t-, using libraries for dealing with texts marke(l ut) in SGML format. The algorithm performs the following sl;et)s: 4 1. Take an arl;Me fl'om the corl)uS 5 and lmild a word weight; matrix for all contellt words across all sentences (l;f*idf (:omputal;ion, where the idf-vahms ttte r(> trieved fl'om a preconqmted file). (; Iligit fre-(tuency closed class words (like A, THE, ON etc.) are excluded via a stop list file. 2. Determine the sentence weights for all senten(:es in tim arl;Me: Compltt;e the sum over 2Clem'ly, there will be less (:oherence than in a manmade abstract, but, the extracted passages can t)e presented in a way which indicates their relative position in tim text, thus avoiding a possil)ly wrong inti)ression of adjacency. aln fact,, it t,urned out that fact,ors which couhl 1)e thought of as %l)ecitic for newspaper articles\", su(:h as increased weights for title words or sentences in the beginning, did not have a sign(titan( eriect (m the all tf*idf-values of the (:on(eat words 7 for each sentence, s 3. Sort the sentences according to l;heir weights and extract the N highest weighted sentences in text order to yield (,he abstract of the doc-llHleltt. To r(~thtce the size of the vocabulary, our system (;()nv(',rts every word to Ul)I)er (:ase and (runt:ales words after the sixth character. This is also rout:it faster than a word stemming algorithm which has to perh)rm a inorphological analysis. For our experiment;s, the, amount of new ambiguities thereby introduced did not cause specific problems for tim system. For the test set, we (:host', 6 articles fl'om the corires whi(:h are (:los(; t;o tim gh)bal cortms a,verage of ] 7 senl;en(:es per ardcl(;; these artich',s (:ontain approx. 550 words alt(l 22 sentences on the, average (range: 19 23). All these artMes are at)out a single topic, i)robably becmme of our choi(:e al)out a ret)resenl;ative text, lengdL We (lo not address ttm issue of multi-topicality here; however, it is well-known that texts with more (hall olle tel)it are. hm'd to deal wit;it for all kinds of Ill. systeltlS. E.g., the ANES system, described i)y ('?), tries to i(lenl;iily l;hese texts beforehand to 1)e ex(:luded fl'om abstracl;ing. The system's rllll-til[te ()It a SUN St)arc workstal;ion (UNIX, SUN OS 4.1.3) is appro\u00d7. 3 seconds for an article of th(; test, set. Experiment: Abstracts as Extracts Generated by Human Subjects In order to bc able to ewfluate the quality of tim abstracts t)rodueed by our system, we, conducted an experiment where we asked 13 human subjects to choose the \"most relevant 5-7 sentences\" from the six articles Dom the test set. 9 ]b t;~cilitate their (;ask, the subjects should first give each of the sentences in an artMe a \"relewmce score\" from l (\"barely relewmt\")to 5 (\"highly relevant;\") and finally choose tit(', trust scored sentences for th(;ir abstracts. The subjects were all native speakers of English (since we used an Englistl cortms) and were. paid for their task. Compared l;o about 3 set:ends for the machine system, the hmnans nee(h;d rThis provides a bias towards longer sentences. Experiment,s with methods that normalized for sentence length yiehled worse results, so dtis bias appears to be apI)roI)riate. SWords in the title and/or appearing in t,ln! first,/last few sent,enees (:all be given Inore weight by tneans of an editable parame.l;e.r tilt;. It turns out,, however, that, these weights do not, lead to an improvement, of the syst,em's performance. 9This number corresponds in fact, well to the observation of (Y) that, the opt,ilnal smnmary length is bet;ween 20% and 30% of the original document length. about 8 minutes (two orders of magnitude more time) for determining the most relevant sentences for an article. Results and Discussion Automatically created abstracts Table 1 shows the precision/recall values for the tf*idf-method described in section ?? and for a default method that selects just the first N senfences fi'om the beginning of each artMe (\"lead\"method). Whereas tile lead method most likely provides a higher readability (see Brandow et al. (?) ), tile data clearly indicates that the tf*idf method is superior to this default approach in terms of relevance, l\u00b0 The computation of these precision/recall values is based on the sentences which were chosen by the human subjects from the experiinent, i.e., an average was built over the precision/recall between the machine system and each individual subject. Abstracts produced by human subjects The global analysis shows a surprisingly good correlation across the hunmn subjects for the sentence scores of all six articles (see table ??): in the Pearson-r correlation matrix, 71 coefticients are significant at the 0.01 level (***), 5 at the 0.05 level (*), and only 2 are non significant (n.s.). This result indicates that there is a good inter-subject agreement about the relative \"relevance\" of sentences in these texts. Comparison of machine-made and hurnan-Inade abstracts We computed precision/recall for (;very human subject, compared to all the other 12 subjects (taking the average precision/recall). From these individual recall/precision values, the average was computed to yield a global measure for interhuinan precision/recall. Depending oil the article, these values range from 0.43/0.43 to 0.58/0.58, the mean being 0.49/0.49. As we can see, these results are in the same range as the results for the machine system discussed previously (0.46/0.55, for abstracts with 6' sentences). This means that if we compare the output of the automatic system to the output of an average human subject in the experiment, there is no noticeable ditference in terms of precision/recall the machine l)erforlns as well as human subjects do, given the task of selecting the most relevant sentences from a text. 1\u00b0The tf*idf nmtho<t proved itself better than all the other methods of weight computation which we tested (see (?)); in particular, those using a combination of w~rious other heuristics, as proposed, e.g., in (?). Suggestions for further work Dealing with multi-topical texts It can be argued that so far we have only dealt with short texts about a single topic. It is not clear how well the system would be able to handh; texts where multiple threads of contents occur; possibly, one couhl employ the method of texttiling here (see e.g., (?)), which helps determining coherent sections within a text and thus could \"guide\" the abstracting system ill that it would be able to track a sequence of multit)le topics in a text,. On-line abstracting While our system currently produces abstracts offline, it is feasible to extend it in a way where it uses the user's query in an IR environment to determine tile relevant sentences of the retrieved documents, tIere, instead of producing a \"general abstract\", the resulting on-line abstract would reflect more of the \"user's perspective\" on the respective text. However, it would have to be investigated, how nmch weight-increase the words from the user's query should get in order not to bias tile resulting output in too strong a way. Further issues concerning the human-inaehine interface are: \u2022 highlighting passages containing the query words \u2022 listing of top ranked keywords in tile retrieved text(s) \u2022 indicating the relative position of the extracted sentences in the text \u2022 allowing for scrolling in the main text, starting at an arbitrary position within the abstract Conclusions Ill this paper, we have shown that it is possible to implement a system for generating text abstracts which purely operates with word frequency statistics, without using either domain specific knowledge or text, sort specific heuristics. It was demonstrated that the resulting abstracts have the same quality in terms of precision/recall as the abstracts created by human subjects ill an experiment. While a simple lead-method is more likely to produce higher readability judgments, the advantage of the tf*idf-method for abstracting is its, superiority in terms of capturing content relevance. Acknowledgments Tile major part of this work has been drawn froln the author's dissertation at the Centre for Cognitive Science, University of Edinburgh, UK. I wish to thank lily supervisors Steve Finch and Richard",
    "abstract": "This paper describes a system for generating text abstracts which relies on a general, purely statistical principle, i.e., on the notion of \"relevance\", as it is defined in terms of the combination of tf*idf weights of words in a sentence. The system generates abstracts from newspaper articles by selecting the \"most relevant\" sentences and combining them in text order. Since neither domain knowledge nor text-sort-specific heuristics are involved, this system provides maximal generality and flexibility. Also, it is fast and can be efficiently ilnplemented for both on-line and off-line purposes. An experiment shows that recall and precision for the extracted sentences (taking the sentences extracted by human subjects as a baseline) is within the same range as recall/precision when the human subjects are coinpared amongst each other: this means in fact that tile performance of the system is indistinguishable from the performance of a human abstractor. Finally, the system yields significantly better results than a default \"lead\" algorithm does which chooses just some initial sentences from the text.",
    "countries": [
        "United States"
    ],
    "languages": [
        "English"
    ],
    "numcitedby": "121",
    "year": "1996",
    "month": "",
    "title": "Fast Generation of Abstracts from General Domain Text Corpora by Extracting Relevant Sentences"
}