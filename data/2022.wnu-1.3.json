{
    "article": "Internet forums such as Reddit offer people a platform to ask for advice when they encounter various issues at work, school or in relationships. Telling helpful comments apart from unhelpful comments to these advice-seeking posts can help people and dialogue agents to become more helpful in offering advice. We propose a dataset that contains both helpful and unhelpful comments in response to such requests. We then relate helpfulness to the closely related construct of empathy. Finally, we analyze the language features that are associated with helpful and unhelpful comments. Introduction When people encounter issues in their lives (such as problems with family and friends, difficulties at school/work as well as troubles in pursuing one's interests and hobbies), many seek for advice in order to solve these problems. Some ask for such advice on internet forums, such as the r/Advice subreddit 1 . Other users can then comment on these posts to attempt to help the post authors. While many users can actively offer help, not all of them will be seen as helpful by the user asking for advice. Examples of a helpful and an unhelpful comment are presented in Figure 1 to show their contrast. In order to support people and dialogue agents to be more effective in offering helpful comments, a critical first step is to understand what makes these comments helpful. We make use of a feedback system on r/Advice that labels comments based on whether the original post author finds comments to be helpful. Based on this feedback system, we introduce a new dataset of comments, labelled with their binary helpfulness. Helpfulness has been extensively studied based on exchanges in online support communities (Chuang and Yang, 2012; Schotanus-Dijkstra et al., 2014; Paulus and Varga, 2015; Subramani and O'Connor, 2018; McKiernan et al., 2018; Green et al., 2020) . These studies found that helpfulness is associated with various characteristics such as emotional warmth, relevant knowledge, willingness to understand, empowering choice, active listening as well as sharing of similar experiences. However, these studies are solely based on qualitative interpretations and have thus far not sought to associate language features with helpfulness. To overcome this limitation, we seek to identify words that are most positively and negatively associated with helpfulness, and relate these words to characteristics of helpfulness from prior literature. Helpfulness is closely related to empathy, as they share many characteristics such as being emotionally warm and compassionate; accepting others' frame of reference, and practising active listening (Davis, 1983; Baron-Cohen and Wheelwright, 2004; Zhou et al., 2003) . We show that people's average helpfulness across all of their comments correlates with their measured empathy score. We also relate our study to literature on the language features that are associated with empathy (Sharma et al., 2020; Xiao et al., 2015; Gibson et al., 2015) and show that there is a great overlap among their language features. Our key contributions are: 1. We introduce and plan to openly release a novel dataset containing helpful and unhelpful comments in response to posts seeking for advice on life issues. 2. We relate helpfulness in comments that respond to posts seeking for advice on life issues to empathy. 3. We analyze the language features that are associated with helpful and unhelpful comments. Related Work Helpfulness on Online Support Communities Helpfulness has been studied in online support communities where peers can offer help and support to one another. These communities often center around a shared life situation such as chronic health conditions (Subramani and O'Connor, 2018; Green et al., 2020) and family bereavement (Schotanus-Dijkstra et al., 2014; Paulus and Varga, 2015) . Several factors were emphasized in common: Peers were found more helpful when they are emotionally warm and compassionate, give others choice on a solution, willing to accept others' perspectives and experiences, practice active listeningby paraphrasing, asking questions and reflecting feelings, give pertinent advice/insights to help others to solve their problem, as well as share similar experiences (Chuang and Yang, 2012; Schotanus-Dijkstra et al., 2014; Paulus and Varga, 2015; Subramani and O'Connor, 2018; McKiernan et al., 2018; Green et al., 2020) . While there has been significant work on what people find helpful, existing studies are based on qualitative themes and to the best of our knowledge, no work has been done on the language features that characterizes helpful support messages. Language Features for Empathy Empathy is closely related to helpfulness, as many factors contributing to helpfulness (being emotionally warm and compassionate; accepting others' perspectives; practising active listening) are also associated with empathy (Davis, 1983; Baron-Cohen and Wheelwright, 2004; Zhou et al., 2003) . There has been significant work on language features that characterize empathy. Sharma et al. (2020) identified that empathy is expressed in language use relating to expressing warm and compassionate emotions, communicating an understanding of others' experience, and asking more about the person's experiences. Xiao et al. (2015) and Gibson et al. (2015) found that language use relating to asking for others' perspective (e.g. it sounds like; do you think) are positively associated with empathy while language use that orders other around (e.g. you need to; please answer the) are negatively associated with empathy. Language features for empathy overlap with the features that characterize helpfulness, reinforcing the strong connection between empathy and helpfulness. Dataset Our English dataset is obtained from r/Advice, which allows post authors to mark out comment(s) that they have found helpful 2 . Comments to posts with at least one helpful comment, but were not themselves labeled as helpful are labelled as unhelpful. This inclusion criterion minimizes the mislabelling of comments to posts whose authors did not actively participate in labelling comments. Text from Reddit was downloaded through the Pushshift Application Programming Interface 3 . Suitable posts and all associated comments from the Advice subreddit were downloaded within 300 days (Apr 2019 -Feb 2020). Comments by the post authors and automated bots were excluded. Across the 24964 posts that were downloaded, there were 92477 associated comments (41146 helpful). On average, each comment has 95.8 words (SD=134.5). Training/validation/test split was 80-10-10. How does Helpfulness Relate to Empathy? To determine how helpfulness relates to empathy, we calculate an aggregated metric for each user based on the proportion of their comments found to be helpful. We then correlate average user helpfulness against an established psychological measure of empathy. Empathy Quotient Questionnaire The short form of Empathy Quotient (EQ) questionnaire (Wakabayashi et al., 2006) was used to measure empathy (details are in appendix A). Higher scores on the EQ represent higher empathy. The EQ questionnaire has high internal consistency (Cronbach's \u03b1 = 0.90) and test-retest reliability after 12 months (r = 0.97, p < .001). Participants Only users with more than 20 comments were included to minimize the likelihood that their average helpfulness was biased due to limited observations. 508 Reddit users were sent an online questionnaire through Reddit and 91 responded. Gender and age were optional to report. 86 participants reported gender (53 male and 33 female) and 83 reported age (M=33.7, SD=13.8). The mean user helpfulness is 0.5440 (SD=0.1956). Using a two-sample t-test, the distribution of EQ scores (M=24.45, SD=8.822, N=91) in this study is found to be not significantly different (t(1850) = 0.0169, p = 0.9866) from the sample (M=23.8, SD=8.75, N=1761) in Wakabayashi et al. (2006) , demonstrating the representativeness of our sample. Results As illustrated in Figure 2 , there is a moderate correlation effect between EQ and User helpfulness (r(91) = 0.359, p < 0.001). We also explored correlating User helpfulness with various subscales of the EQ, namely cognitive empathy, affective empathy and social skills based on Zhou et al. (2020) . Helpfulness correlates most strongly with cognitive empathy (r(91) = 0.355, p < 0.001), followed by affective empathy (r(91) = 0.261, p = 0.012) and finally social skills (r(91) = 0.203, p = 0.054). This suggests that helpful commenters more often are better able to understand how the post authors think compared to how they feel or communicating it across in a social deft manner (which has a boundary p value). Predicting for Helpful Comments To explore the potential for the dataset to be useful in training models to distinguish between help- ful and unhelpful comments, we trained several baseline models and report their micro-average F1 scores. The performance of baseline models on this task is relatively low but similar to the performance on empathy datasets (Gibson et al., 2015; Khanpour et al., 2017; Sharma et al., 2020) . The relatively low performance of baseline models on this task suggests that while recognizing helpfulness in language is trivial for typically-developing humans, they remain challenging for machines. Techniques such as commonsense reasoning (Sap et al., 2019; Bosselut et al., 2019) can be explored in the future to better capture the highly complex relationship between language and helpfulness. Significant Predictors of Helpfulness To characterize helpfulness in our dataset, significant predictors of helpfulness (p < 0.05) based on the Logistic Regression model were extracted and analysed. 4 Thematic categories that were inductively generated from these predictors are shown in Table 4 while word clouds are available in Appendix D. The first overarching theme is positive and friendly words. Helpfulness is positively predicted by polite, friendly-sounding and optimisticsounding words but negatively predicted by words that indicate negative emotions. This relates to the literature findings on how uplifting and friendly online support peers are found to be more helpful. (Paulson et al., 1999; Subramani and O'Connor, 2018) Affect-related words (such as sad and tears) were previously found to be significant predictors of empathy (Gibson et al., 2015) . A second overarching theme is words relating to attempts to understand the perspective of others. Helpful commenters do so by addressing post authors directly, instead of patronizing the difficulties that they face. This is also in agreement with literature on how helpfulness is associated with peers' attempt to accept others' frame of references and experiences. (Subramani and O'Connor, 2018; Green et al., 2020) Furthermore, terms indicating an inclination to find out more about the perspective of others (e.g. \"do you think\", \"it sounds like\" and \"you think about\") were also predictors in empathy datasets (Gibson et al., 2015; Xiao et al., 2015) . Overall, the overarching themes that are predictive of helpfulness in our dataset are supported by literature on helpfulness and language features associated with empathy. Human-Annotated Features for Comment Helpfulness To better understand the capabilities and limitations of language features in capturing comment helpfulness, two graduate students manually annotated a selection of helpful comments. Annotations were done on 5 comments each from 91 authors who responded to our empathy quotient questionnaire. Comments were sampled using a stratified approach that results in a sampled average helpfulness to be closest possible to the author's average helpfulness score (P earson s r = 0.937, p < 0.001). Then we labelled each comment with one or more of the 10 possible labels based on helpfulness literature (see Section 2). They are 1. Highly directive, short advice 2. Dismissing concern 3. Negative terms 4. Tangential or unspecific comment 5. Share similar experience 6. Ask clarifying questions 7. Relevant knowledge 8. Emotional support 9. Recognizing difficulty 10. Tentative language. Average Cohen's \u03ba is 0.690 (\u03c3=0.107). Definitions and Cohen's \u03ba for each label are in Appendix 5. Using a logistic regression, we found that only the use of negative terms and tangential or unspecific comment are negatively associated with helpfulness (p < 0.05) while providing relevant knowledge is positively associated (p < 0.05). The use of negative terms was also captured by the logistic regression based on language use while the other two factors were not. An inspection of examples revealed that negative terms only comprises of a small set of words while those two factors require contextual semantic understanding of what is relevant knowledge to a situation and what is tangential. Future work can make use of knowledge-enhanced models (Peters et al., 2019; Clark et al., 2021) to better capture such contextual understanding. Conclusion We introduce and plan to openly release a novel dataset containing helpful and unhelpful comments in response to posts seeking for advice on life issues. We show that the helpfulness of such comments is related to the commenters' empathy and pioneer an analysis into language features predictive of helpful and unhelpful comments on online support communities. Our work can contribute towards supporting people and automated dialogue agents to offer more helpful comments to others. Ethics and Broader Impact This project has been approved by University of Cambridge Faculty of Education Institutional Review Board. The use of Reddit data in this project is in alignment with the Reddit End User License Agreement and the Terms of Use for Developers. Because part of the project requires participants to respond to questionnaires, we made sure that the items were phrased sensitively so that no unintended harm would be caused. No payment was made to voluntary participants, as the survey could be done within a few minutes. We also guided participants to make informed decisions about their participation, giving them the opportunity to withdraw any time, during and after the completion of the questionnaire. The collected information, which does not include personally identifiable information, was stored securely with access restricted to the research team. We also manually inspected a small selection of Reddit data to ensure that they do not contain names, personally identifying information or offensive content. We anticipate that this project can accelerate the development of models that can better detect and express helpfulness in social settings, between humans and with social dialogue agents. A Empathy Quotient Questionnaire Items originate from the long form of Empathy Quotient questionnaire (Baron-Cohen and Wheelwright, 2004) , which is well-cited (>3500 citations) and demonstrates good validity in large (>500,000) and culturally-diverse samples (Kosonogov, 2014; Groen et al., 2015; Greenberg et al., 2018) . The short form was chosen to reduce the time taken to answer the questionnaire and thereby increase the response rate. The short form is a 22-item forced-choice self-report questionnaire that can be answered on a four-point Likert Scale (Strongly Agree, Agree, Disagree, Strongly Disagree). Questions include \"I often find it difficult to judge if something is rude or polite\", \"I can pick up quickly if someone says one thing but means another\", and \"I am good at predicting how someone will feel\". Each response can give 0, 1 or 2 points, leading to a maximum total EQ score of 44. B Baseline Models D Word Clouds of Significant Predictors of Helpfulness Size of words are directly proportional to their significance of correlation.   Acknowledging that it's a very bad situation for the author to be in 0.419* (I'm sorry that this is a really bad situation) Tentative language Phrasing advice as tentative suggestions -such as using 0.739 \"you might want to try . . . \" or \" I am no expert on this but . . . \" Table 5: Labels, descriptions and Cohen's \u03ba for manual annotation of helpfulness in comments. * Cohen's \u03ba for \"Recognizing difficulty\" is low due to the very low number of positive labels (<5%)",
    "abstract": "Internet forums such as Reddit offer people a platform to ask for advice when they encounter various issues at work, school or in relationships. Telling helpful comments apart from unhelpful comments to these advice-seeking posts can help people and dialogue agents to become more helpful in offering advice. We propose a dataset that contains both helpful and unhelpful comments in response to such requests. We then relate helpfulness to the closely related construct of empathy. Finally, we analyze the language features that are associated with helpful and unhelpful comments.",
    "countries": [
        "United Kingdom"
    ],
    "languages": [
        "English"
    ],
    "numcitedby": "0",
    "year": "2022",
    "month": "July",
    "title": "How to be Helpful on Online Support Forums?"
}