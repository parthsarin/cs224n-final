{
    "article": "This paper deals with Discourse Argument Identification (DAI) from both intra-sentence and inter-sentence perspectives. For intra-sentence cases, we approach it via a simplified shallow semantic parsing framework, which recasts the discourse connective as the predicate and its scope into several constituents as the argument of the predicate. Different from state-of-the-art chunking approaches, our parsing approach extends DAI from the chunking level to the parse tree level, where rich syntactic information is available, and focuses on determining whether a constituent, rather than a token, is an argument or not. For inter-sentence cases, we present a lightweight heuristic rule-based solution. Evaluation using Penn Discourse Treebank (PDTB) shows that the current research's parsing approach significantly outperforms the state-of-the-art chunking alternatives. Introduction Discourse parsing is considered one of the most challenging Natural Language Processing (NLP) tasks. It is essential in many downstream NLP applications, such as statistical machine translation (Meyer, 2011) , information retrieval (Huttunen et al., 2011) , opinion mining (Somasundaran et al., 2009) and so on. Generally, Discourse Argument Identification (DAI) involves two sub-tasks: Discourse Connective Identification (DCI) and Argument Scope Identification (ASI). ASI is much more complex than DCI, which has been comprehensively reported in literature with, for example, Fmeasure of 94.19% on the Penn Discourse Treebank (PDTB) Prasad et al. (2008) . Compared with DCI, the performance of ASI is much lower. For example, Ghosh et al. (2012) only got Fmeasure of 59.39% on exact Arg1 identification, on golden tree structures. Most previous studies on DAI focus on token level, such as Ghosh et al. (2012) (2011a) (2011b) and Lin et al. (2010) and suffer from the limitation of focusing on determining whether a token in a discourse simply either belongs to the argument of a connective or not. However, such a strong independence assumption among the tokens may result in poor performance. The tokens should not be independent and sometimes they combine together and play the specific role for the discourse connective. Accordingly, this paper focuses on PDTB-style exact argument identification, from both intrasentence and inter-sentence perspectives. For intra-sentence cases, we approach it via a simplified shallow semantic parsing framework, which recasts the discourse connective as the predicate and its scope into several constituents as the argument of the predicate. Different from state-of-the-art chunking approaches, our parsing approach extends DAI from the chunking level to the parse tree level, where rich syntactic information is available, and focuses on determining whether a constituent, rather than a token, is an argument or not. For inter-sentence cases, we present a lightweight heuristic rule-based solution. Evaluation on the PDTB shows that our parsing approach significantly outperforms the afore-mentioned chunking alternatives. The rest of this paper is organized as follows. Section 2 reviews related work on discourse parsing and on shallow semantic parsing. In Section 3 the PDTB corpus is briefly introduced. Section 4 describes the methodology used for exact argument identification. In Section 5 the results of the research experiment are presented. Finally, some conclusions are drawn. Related Work Related work on PDTB-style discourse parsing and shallow semantic parsing is presented in this section. PDTB-style discourse parsing consists of two major sub-tasks: Discourse Argument Identification (DAI) and Discourse Relation Identification (DRI). Related work for PDTB-style DAI can be mainly classified into three categories: rule-based approach, Dinesh et al. (2005) ; Prasad et al., (2010) , classification-based method, Wellner et al. (2007) ; Elwell et al. (2008) ; Lin et al. (2010) and chunking-based approach, Ghosh et al. (2011a Ghosh et al. ( ) (2011b Ghosh et al. ( ) (2012)) . To be more specific, Dinesh et al. (2005) proposed a tree subtraction method for restricted subordinating connectives. Prasad et al. (2010) provided a set of scope-based filters for argument identification. Wellner et al. (2007) and Elwell et al. (2008) investigated the matching of head-words located in the argument. However, a potential issue of their work is that no golden head-words were annotated in the PDTB. Lin et al. (2010) proposed a token-level argument node identifier, which determined whether each internal node was an Arg1, Arg2 or Non-argument, and then conducted a tree subtraction algorithm to extract the argument of connectives. Ghosh et al. (2012) which integrated the n-best result of the previous token-level approach (Ghosh et al, 2011a) For Arg1 position identification, Lin et al. (2010) showed that contextual features for connective C were useful when identifying Arg1's position. In addition, we can observe that the first and second next words (next 1 and next 2 ) of C also give a strong insight into Arg1's position. For example, the pronoun 'that', as contained within 'and ensure that', after the connective 'and', sometimes denotes abstract objects located in the previous sentence. Based on this observation, we add 8 new features: next 1 , next 1 POS, next 1 +C, next 1 POS+C POS, next 2 , next 2 POS, next 2 +C, next 2 POS+C POS. It is hard to decide which feature-set is more effective for Arg1 position identification, even if we use the Hill-climbing (greedy) feature selection technique, Caruana and Freitag (1994) , due to the combination of a large number of different features. Therefore, we adopt the Information Gain (IG), which is widely used in text classification, Li et al. (2009) , to calculate the efficacy of features and select an approximate optimal feature-set. After Arg1's position is identified, we handle the DAI according to intra-sentence and intersentence cases methodologies, as follows. Formulating Intra-sentence DAI as a Simplified Semantic Parsing Problem Given a parse tree and a predicate, shallow semantic parsing detects and classifies each of the constituents in the sentence into either their corresponding semantic argument (role) for the predicate, or as a non-argument. Similarly, the discourse connective can be taken as the predicate, while its scope can be mapped into several constituents dominated by the connective and thus can be regarded as the argument of the connective. Take this sentence as an example 'Shorter maturities are considered a sign of rising rates because portfolio managers can capture higher rates sooner.'. The connective 'because' has the Arg1 'Shorter maturities are considered a sign of rising rates' and 'portfolio managers can capture higher rates sooner' the Arg2. As shown in Figure 2 below, the node \"IN 9,9 \" represents the connective \"because\" while its Arg1 includes four constituents {NP-SBJ-9 0,1 ,VBP 2,2 ,VBN 3,3 ,S 4,8 }, and its Arg2 includes only one constituent {S 10,16 } . Similar to common shallow semantic parsing, our DAI consist of two pipeline phases: argument pruning and argument identification. Currently, we leave post-processing phase as one of our future works. (2004) , which is widely used in common shallow semantic parsing, is detailed as follows. (1) Designate the connective as the current node and collect its siblings. (2) Reset the current node to its parent and repeat Step (1) until it reaches a threshold Level (tree level distance between the current node and the connective). Argument identification: We divide the argument identification into the following two phases. Firstly, a binary classifier is applied to determine whether or not, after pruning, the argument candidates constitute valid arguments. Secondly, a multiclass classifier is adopted to assign a valid argument candidate with a label, e.g. Arg1 or Arg2 or Null. Most features listed in Table 1 are commonly used in shallow semantic parsing, and most of them are semantic driven(We adopt the head-finding rules described in Collins (1999) and the function type of connection listed in appendix A of Knott (1996) .). We categorize the features into three groups as lexical, syntactic and connective-driven features, as shown in Table 1 . For the connective-driven features, for example, statistics of connective positions in PDTB tells us that the connective positions are suitable as start, before and back of middle. Therefore, we separate these 3 situations into either lesser or greater than middle, F14, as shown in Table 1 . Features Remarks Feature value Lexical features F1 Connective itself because F2 Part-of-speech of the connective IN F3 The headword and its POS of constituent candidate sign, NN F4 The left and right word of the connective rates, portfolio F5 The left and right word of the constituent candidate considered, because Syntactic features F6 The syntactic category of the constituent candidate. S F7 The syntactic path from the constituent candidate to the connective. S<VP>SBAR-PRP>IN F8 The subcategory of the connective. SBAR-PRP:IN+S F9 The phrase type of the connective's parent node. SBAR-PRP F10 The subcategory of the constituent candidate. VP:VBN+S+SBAR-PRP F11 The phrase type of the constituent candidate's parent node. VP F12 The phrase type of the constituent candidate's left and right sibling. VBN,SBAR-PRP Connective-driven features F13 The position of the constituent candidate with the connective. \"left\" or \"right\" left F14 The position of the connective in sentence. \"lesser than middle\" or \"greater than middle\" greater than middle F15 The function type of the connective. \"subordinator\" or \"Coordinator\" or \"Conj-adverb\" subordinator TABLE 1 -Features and their instantiations for argument identification within DAI, with \"because\" as the connective, and S 4,8, as shown in Figure 2 , as the focus constituent. We don't use features provided by AddDiscourse tool because it was designed for discourse connective and relation identification. In this paper, we formulate the DAI as a shallow semantic parsing problem, and our main goal is to verify the effectiveness of shallow semantic parsing driven features in DAI. The relationship between the constituents and arguments can be embodied within the shallow semantic parsing framework if we regard connective as predicate. Rule-based Inter-sentence DAI According to Prasad et al. (2008) 's statistics, Arg1 in previous, adjacent sentence account for 30.1% in the whole PDTB corpus. Based on this observation, a lightweight heuristic rule-based solution is adopted. Therefore, we assign the preceding adjacent sentence as Arg1, which has already given F1-measures of 76.90% overall in the PDTB, as mentioned in Lin et al. (2010) . In addition, we assign the entire sentence excluding the connective as Arg2. Experiment In this section, we describe the experiment settings, together with the experiment results. Experiment Settings Similar to Lin et al.( 2010 )'s evaluation settings, we evaluate our system with GS_noEP(Gold Standard parsers without Error Propagation), GS_EP and Auto(Automatic parsers)_EP settings. All the results use the Johansson and Moschitti (2010)'s exact matching scoring of argument. For the intra-sentence cases, we remove parenthesis and keep subordinate clause for spans to comply with minimality principle on the PDTB, normalize all spans by removing leading or trailing punctuation, and evaluate the system on three main tasks: (1) argument detection, (2)independently classifying phase of known to be discourse arguments into the specific categories, Arg1 and Arg2, and (3) the combined task of detection of the discourse argument and then assigning respective labels (Arg1, Arg2, Null) to them. The Maximum Entropy software package Mallet (http://mallet.cs.umass.edu/) is selected as our classifier, and Berkley parser (http://code.google.com/p/berkeleyparser/downloads/list) is used to generate the automatic parser tree. For feature selection, we set IG_rate (a threshold value for IG) at a value of 0.5 which is widely used in the common text classification task. Experiment Results For the Arg1 position classification phase, we get F-measure of 97.55% using our new added features and feature selection process trained on Section 02-22 and tested on Section 23-24 under GS_noEP setting. A paired t-test shows that the improvement is significantly superior to Lin's 96.45% with p<0.01. The output of final feature sets after using our feature selection are {C; C's position; C POS; prev 1 ; prev 1 +C; prev 1 POS+C POS; prev 2 ; prev 2 POS; next 2 ; next 2 POS; next 2 + C; next 2 POS+C POS}. They show that the new added features along with the feature selection process are useful for determining Arg1's position and they can mitigate the effect of cascaded error propagation. Experiments on development sets (Section 00-01) show the proper value of Level for intrasentence cases, resulting in an average value of Level equal to 3.73. Therefore, we set Level=3 and Level=4 to check their influence on the parameter Level for the argument identification phase. We get F-measure of 86.70% for argument detection when Level equals to 4 trained on Section 02-22 and tested on Section 23-24 under GS_noEP setting, improvements of 1.10% over the Level equals to 3. For the heuristic rules in argument pruning, we also tried the pruning strategy (no Level consideration) as adopted in Xue et al.(2004) . However, its performance was about 2.0% lower than our extended pruning strategy. Due to space limitation, we do not give the detail comparison. The result also verifies our assumption that the argument of a connective consists of a constituent in the parser tree, which is always located at a specific level, near the connective. For the independently classifying phase of Arg1, Arg2 and Both (exact match of both Arg1 and Arg2 simultaneously) for intra-sentence cases, we get Accuracy of 94.15%, 88.72% and 83.28% for Arg1, Arg2 and Both, respectively. With the performance of Level equals to 4 is greater than Level equals to 3, therefore, we conduct the following experiments using a parameter Level equals to 4. Table 2 , below, compares the performance for the combined task, between our system and Ghosh's system. As is shown, the performance of Arg1 exact matching of our system significantly outperforms Ghosh's system, and the performance of Arg2 with our system slightly outperforms or comparable with theirs. In addition, the performance on automatic syntactic parsing is lower than on the golden parser tree. As expected, some nodes in the automatic parser tree cannot be mapped into corresponding nodes in the golden parser tree, which result in error propagation within the argument pruning and identification phases. Generally, the Precision of Ghosh's system is higher than our system, while the Recall of their system is lower than ours, which is maybe caused by the features listed in the Table 1 are fine-grained, most of them can capture the relationship between constituent and discourse connective, while features adopted in Ghosh's system are coarse-grained. Thus, the total F-measure of our system is higher than theirs. Our system Ghosh's system Arg1 Arg2 Both Arg1 Arg2 Both GS_noEP (Ghosh et Performance that is significantly superior to Ghosh's system (p<0.01,using paired t-test for significance) is denoted by *. Table 3 illustrates the performance comparison, for combined task, between our system and Lin's system. As is shown, the performance of Arg1 and Both of our system significantly outperforms Lin's system under GS_noEP setting. Furthermore, the performance of Arg1 and Both of our system slightly outperforms Lin's system under GS_EP setting. The performance of Arg2 of our system is lower than Lin's system, which may be caused by the following two reasons: firstly, Lin et al. (2010) significantly improved the connective identification performance by incorporating their own features and further processing; secondly, the data distribution of intrasentence and inter-sentence in Section 23 is not coincident with that in Section 23-24. In addition, we can observe that the performance of Arg1 and Both of our system significantly outperforms Lin's system under Auto_EP setting. This also verifies our framework is robust when facing parser tree error. For example, if the S 10,16 (Arg2) of the connective in Figure 2 is incorrectly expanded by the rule S 10,16 ->NP-SBJ 10,11 +MD 12,12 +VP 13,16 , the scope of Arg2 of the connective \"because\" can still be correctly detected. Our system Lin's system (Lin et al., Performance that is significantly superior to Lin's system (p<0.01,using paired t-test for significance) is denoted by *. Conclusions and Future Work In this paper, we have presented a new approach to PDTB-style discourse argument identification from intra-sentence and inter-sentence perspectives. For the intra-sentence cases, we formulate it as a simplified shallow semantic parsing problem. In particular, we regard the discourse connective as the predicate and map its scope into several constituents, which are deemed as argument of the predicate. For the inter-sentence cases, we present a lightweight heuristic rulebased solution. Evaluation on the PDTB shows the appropriateness of our approach. It also shows that our approach significantly outperforms the state-of-the-art chunking alternatives. Our future work will be to improve the performance further, through exploring tree kernel-based method, together with more feature engineering. Acknowledgments",
    "abstract": "This paper deals with Discourse Argument Identification (DAI) from both intra-sentence and inter-sentence perspectives. For intra-sentence cases, we approach it via a simplified shallow semantic parsing framework, which recasts the discourse connective as the predicate and its scope into several constituents as the argument of the predicate. Different from state-of-the-art chunking approaches, our parsing approach extends DAI from the chunking level to the parse tree level, where rich syntactic information is available, and focuses on determining whether a constituent, rather than a token, is an argument or not. For inter-sentence cases, we present a lightweight heuristic rule-based solution. Evaluation using Penn Discourse Treebank (PDTB) shows that the current research's parsing approach significantly outperforms the state-of-the-art chunking alternatives.",
    "countries": [
        "China"
    ],
    "languages": [
        ""
    ],
    "numcitedby": "8",
    "year": "2012",
    "month": "December",
    "title": "A Unified Framework for Discourse Argument Identification via Shallow Semantic Parsing"
}