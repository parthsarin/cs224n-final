{
    "article": "Named-Entity Recognition (NER) is still a challenging task for languages with low digital resources. The main difficulties arise from the scarcity of annotated corpora and the consequent problematic training of an effective NER pipeline. To abridge this gap, in this paper we target the Persian language that is spoken by a population of over a hundred million people world-wide. We first present and provide ArmanPerosNERCorpus, the first manually-annotated Persian NER corpus. Then, we introduce PersoNER, an NER pipeline for Persian that leverages a word embedding and a sequential max-margin classifier. The experimental results show that the proposed approach is capable of achieving interesting MUC7 and CoNNL scores while outperforming two alternatives based on a CRF and a recurrent neural network. Introduction Named-Entity Recognition (NER), introduced in the sixth Message Understanding Conference (MUC-6) (Grishman and Sundheim, 1996) , concerns the recognition of Named Entities (NE) and numeric expressions in unstructured text. Since 1996, great effort has been devoted to NER as a foundational task for higher-level natural language processing tasks such as summarization, question answering and machine translation. Shortage of gold standards has initially limited NER investigation to high-resource languages such as English, German and Spanish (Tjong Kim Sang and De Meulder, 2003) . Gradually, publicly available encyclopediae have enabled combinations of semi-supervised and distant supervision approaches for other languages (Althobaiti et al., 2015) . However, low-resource languages still face a significant scarcity of public repositories. For instance, only 8.8% of Wikipedia articles in Hindi are identified as entitybased articles in Freebase (Al-Rfou et al., 2015) . In this work, we aim to enable supervised NER for a low-resource language, namely Persian, by providing the first manually-annotated Persian NE dataset. The Persian language, despite accounting for more than a hundred million speakers around the globe, has been rarely studied for NER (Khormuji and Bazrafkan, 2014) and even text processing (Shamsfard, 2011) . In addition, we present PersoNER, a Persian NER pipeline consisting of a word embedding module and a sequential classifier based on the structural support vector machine (Tsochantaridis et al., 2005) . The proposed pipeline achieves interesting MUC7 and CoNNL scores and outperforms two alternatives based on a CRF and a recurrent neural network. statistical models for NER from data (Nadeau and Sekine, 2007) . Moreover, replacement of manuallyannotated gold standards with very large \"silver standard\" corpora mollifies the scarcity of supervised data. Silver standards are NE annotated corpora derived from processing Wikipedia's text and metainformation alongside entity databases such as Freebase (Nothman et al., 2013; Al-Rfou et al., 2015) . Existing NER approaches mainly divide over two categories: in the first, the task is decoupled into an initial step of word embedding, where words are mapped to feature vectors, followed by a step of word/sentence-level classification. The feature vector can be as simple as a binary vector of text features like 'word is all uppercased' or a more complex, real-valued vector capturing semantic and syntactic aspects of the word. Word2vec (Mikolov et al., 2013) , GloVe (Pennington et al., 2014) and Hellinger-PCA (Lebret and Collobert, 2014) are well-known examples of unsupervised word embeddings applied successfully to the NER task. For classification, sequential classifiers such as HMMs (Zhou and Su, 2002) , CRFs (Lafferty et al., 2001; Finkel et al., 2005) and deep neural networks (Al-Rfou et al., 2015) have been amongst the most popular choices. The second category, proposed by (Collobert et al., 2011) and recently followed by many including (Mesnil et al., 2013; Mesnil et al., 2015) and others, leverages recurrent neural networks (RNNs) to deliver end-to-end systems for NER. With this approach, an implicit word embedding is automatically extracted in the network's early layers by initializing the training with random values or a preliminary embedding. In this paper, we apply and compare approaches from both categories. The Proposed Approach The workflow of PersoNER is illustrated in Figure 1 . The steps include data collection, text normalization, word embedding and entity classification. In this section, we focus on the two technical modules, word embedding and classification, while data collection and text normalization are described in Section 4. Word Embedding Term-frequency (tf), term-frequency inverse-document-frequency (tf-idf), bag of words (bow) and word co-occurrence are general statistics intended to characterize words in a collection of documents. Out of them, word co-occurrence statistics have the ability to represent a word by the frequencies of its surrounding words which well aligns with the requirements of NER. Recently, Lebret and Collobert (2014) have shown that a simple spectral method analogous to PCA can produce word embeddings as useful as those of neural learning algorithms such as word2vec. Given an unsupervised training corpus and a vocabulary, V , the co-occurrence matrix, C |V |\u00d7|D| , in (Lebret and Collobert, 2014) is computed as: C(v i , d j ) = p(d j |v i ) = n(v i , d j ) d n(v i , d) (1) where v i \u2208 V ; i = 1 . . . |V | and d j \u2208 D \u2286 V ; j = 1 . . . |D|. n(v i , d j ) is the count of occurrences of context word d j in the neighborhood of reference word v i . Thus, C(v i , :) represents discrete probability distribution p(d|v i ) and is used to characterize v i . Since words are represented as discrete distributions, Lebret and Collobert (2014) argue that it is more appropriate to measure their distances in a Hellinger space. Accordingly, H(C) is the transformation of C into Hellinger space where the distance between any two discrete probability distributions, P and Q, is given by: dist(P, Q) = 1 \u221a 2 || \u221a P \u2212 Q|| 2 . (2) Eventually, PCA is applied to reduce the dimensionality of H(C) \u2208 R |V |\u00d7|D| to h(C) \u2208 R |V |\u00d7m , where m |D|. Classification In this subsection, we first briefly introduce sequential labeling as a formal problem and then describe the sequential classifier based on the structural support vector machine. Sequential Labeling Sequential labeling predicts a sequence of class labels, y = {y 1 , . . . y t , . . . y T }, based on a corresponding sequence of measurements, x = {x 1 , . . . x t , . . . x T }. It is a very common task in NLP for applications such as chunking, POS tagging, slot-filling and NER. A widespread model for sequential labeling is the hidden Markov model (HMM) that factorizes the joint probability of the measurements and the labels, p(x, y), by arranging the latter in a Markov chain (of order one or above) and conditioning the measurement at frame t on only the corresponding label. For an HMM of order one, p(x, y) is expressed as: p(x, y) = p(y 1 ) T t=2 p(y t |y t\u22121 ) T t=1 p(x t |y t ) (3) where p(y 1 ) is the probability of the initial class, terms p(y t |y t\u22121 ) are the transition probabilities and terms p(x t |y t ) are the emission, or measurement, probabilities. By restricting the emission probabilities to the exponential family, i.e., p(x t |y t ) \u221d exp(w T f (x t , y t )), the logarithm of probability p(x, y) can be expressed as the score of a generalized linear model: ln p(x, y) \u221d w T \u03c6(x, y) = w in f (y 1 ) + T t=2 w T tr f (y t , y t\u22121 ) + T t=1 w T em f (x t , y t ) (4) where w in , w tr and w em are the linear models for assigning a score to the initial classes, transitions and emissions, respectively. Functions f (y 1 ), f (y t , y t\u22121 ) and f (x t , y t ) are arbitrary, fixed \"feature\" functions of the measurements and the labels. The generalized linear model in ( 4 ) is more suitable for discriminative training than the generative probabilistic model in (3). Notable discriminative approaches are conditional random fields (CRFs) (Lafferty et al., 2001) and structural SVM (Tsochantaridis et al., 2005) . In particular, structural SVM has built a very strong reputation for experimental accuracy in NLP tasks (Joachims et al., 2009; Tang et al., 2013; Qu et al., 2014) and for this reason we exploit it in our NER pipeline. Eventually, given a measurement sequence x in input, inference of the optimal label sequence can be obtained as: \u0233 = argmax y p(x, y) = argmax y (w T \u03c6(x, y)) (5) This problem can be efficiently solved in O(T ) time by the Viterbi algorithm working in either the linear or logarithmic scale (Rabiner, 1989) . Structural SVM From a supervised training set of sequences, {X, Y } = {x i , y i }, i = 1 . . . N , structural SVM finds the model's parameters, w, by minimizing the usual SVM trade-off between the hinge loss and an L2 regularizer (Tsochantaridis et al., 2005) . Its learning objective can be expressed as: argmin w,\u03be 1 2 w 2 + C N i=1 \u03be i s.t. w T \u03c6(x i , y i ) \u2212 w T \u03c6(x i , y) \u2265 \u2206(y i , y) \u2212 \u03be i , i = 1 . . . N, \u2200y \u2208 Y (6) In the objective function, the first term is the regularizer while the second term, N i=1 \u03be i , is the hinge loss, i.e. a convex upper bound over the total loss on the training set. Hyperparameter C is an arbitrary, positive coefficient that balances these two terms. In the constraints, w T \u03c6(x, y) computes the generalized linear score for a (x, y) pair. In the case of sequential labeling, such a score is given by Eq. ( 4 ). Eventually, \u2206(y i , y) is the loss function chosen to assess the loss over the training set. For an NER task with M entity classes, each sequence of length T adds (M + 1) T constraints to (6). Due to their exponential number, exhaustive satisfaction of all constraints is infeasible. However, (Tsochantaridis et al., 2005) has shown that it is possible to find -correct solutions with a subset of the constraints of polynomial size consisting of only the \"most violated\" constraint for each sequence, i.e. the labeling with the highest sum of score and loss: \u03be i = max y (\u2212w T \u03c6(x i , y i ) + w T \u03c6(x i , y) + \u2206(y i , y)) \u2192 \u0233i = argmax y (w T \u03c6(x i , y) + \u2206(y i , y)) (7) This problem is commonly referred to as \"loss-augmented inference\" given its resemblance with the common inference of Eq. ( 5 ) and is the core of structural SVM. In the case of scores and losses that can be computed frame by frame (such as the 0-1 loss or the Hamming loss), the Viterbi algorithm with appropriate weights can still be used to compute the loss-augmented inference in O(T ) time. Data Collection In this section, we describe the collection and preprocessing of the Persian corpora. The datasets consist of 1) an unsupervised corpus, called PersoSentencesCorpus, that we use for the word embedding module and 2) a manually named-entity annotated data set of Persian sentences, called ArmanPersoNERCorpus, that we use for supervised classification. Alongside this publication, we release ArmanPersoNERCorpus 1 as the first ever publicly-available Persian NER dataset. PersoSentencesCorpus A very large corpus of documents covering a variety of contexts is required to populate an effective cooccurrence matrix. We fulfill this requirement by accumulating the following three datasets of Persian sentences: \u2022 The Leipzig corpora 2 with 1,000,000 sentences from news crawling and 300,000 from Wikipedia. \u2022 The VOA 3 news dataset with 277,000 sentences. \u2022 The Persian Dependency Treebank 4 with 29,982 sentences (Rasooli et al., 2013) . The aggregated corpus, called PersoSentencesCorpus, holds more than 1.6 million sentences and seems of adequate size to train the co-occurrence matrix. ArmanPersoNERCorpus To create an NE dataset, in collaboration with ArmanSoft 5 , we have decided to manually annotate NEs in a subset of the BijanKhan 6 (Bijankhan et al., 2011) corpus which is the most-established tagged Persian corpus, yet lacking entity annotation. We selected the subset from news sentences since they are the most entity-rich. Before the annotation, a comprehensive manual was designed based on the definition of Sekine's extended named entities (Sekine, 2007) adapted to the Persian Language. The annotation task was led by an experienced lead annotator who instructed the front-end annotators (two native post-graduate students) and revised their annotations. The guidelines were very clear and we expected minimal subjectivity. We have verified this hypothesis in two ways: by a sample of 500 already annotated NEs chosen randomly, and by another sample of 500 already annotated NEs from the two most semantically-close classes (location and organization). Both samples were revised by three other, independent native annotators and the percentages of corrections have been only 1.8% and 1.9%, respectively. All NEs have been annotated in IOB format. The annotated dataset, ArmanPersoNERCorpus, contains 250,015 tokens and 7,682 sentences (considering the full-stop as the sentence terminator). It can be used to train NER systems in future research on Persian NER, but it also offers an ideal test set for evaluation of NER systems trained on silver standards. The NEs are categorized into six classes: person, organization (such as banks, ministries, embassies, teams, nationalities, networks and publishers), location (such as cities, villages, rivers, seas, golfs, deserts and mountains), facility (such as schools, universities, research centers, airports, railways, bridges, roads, harbors, stations, hospitals, parks, zoos and cinemas), product (such as books, newspapers, TV shows, movies, airplanes, ships, cars, theories, laws, agreements and religion), and event (such as wars, earthquakes, national holidays, festivals and conferences); other are the remaining tokens. It is worth noting that annotation was not trivial since individual tokens have been categorized according to the context. For instance, \"Tokyo\" is a different type of entity in sentence \"Tokyo loc is a beautiful city\" versus sentence \"London org and Tokyo org sign flight agreement\". Table 1 summarizes the number of tokens for each entity class in ArmanPersoNERCorpus. Figure 2 shows a snapshot of the dataset together with an English transliteration of the tokens. Each line contains five tab-separated columns. In order from left to right, they are ez\u0101fe, POS-tag, inflexion, token and NER-tag. The first three columns are inherited from the BijanKhan corpus. Ez\u0101fe 7 is a grammatical particle in the Persian language that connects words of a phrase, usually noun-phrase, together. It is pronounced as an unstressed i vowel between the linked words, but generally not indicated in writing. Text Normalization As the preprocessing phase, the PersoSentencesCorpus has been normalized and tokenized following the approach proposed in (Feely et al., 2014) that suggests applying a pipeline of useful tools to deal with written Persian. The pipeline starts with PrePer (Seraji, 2013) which maps Arabic specific characters to their Persian Unicode equivalent. In addition, it replaces the full space between a word and its affix with a zero-width-non-joiner character. Then, a Farsi text normalizer (Feely, 2013) omits Arabic and Persian diacritics and unifies variant forms of some Persian characters to a single Unicode representation. Finally,  tokenization is performed by using three tokenizers in a cascade: the Farsi verb tokenizer of (Manshadi, 2013) , SetPer (Seraji et al., 2012) and tok-tok (Dehdari, 2015) . Experiments In this section, we report NER results based on the PersoSentencesCorpus and ArmanPersoNERCorpus datasets. The classification task is challenging given the much lower frequencies of the entity classes versus the non-entity class (other), as shown in Table 1 . For this task, we have not used any of the additional linguistic information that is available from the dataset (such as POS tag, inflexion etc). To calculate the co-occurrence matrix, C, we have used a context window of radius 5. The size of the dictionary, V , from the PersoSentencesCorpus is |V | = 49, 902 and that of subset D is D = 7, 099, obtained by selecting only the words with count greater than 15. The word embedding matrix h(C) has been computed by heuristically setting m = 300. For classification, each word has been encoded as a 3-gram that includes the previous and following feature vectors. All the models used for classification share the same word embeddings. For classification, we have compared the proposed SVM-HMM with a CRF and a deep learning approach based on the Jordan-RNN (Mesnil et al., 2013) . For the SVM-HMM we have used structural SVM from (Joachims, 2008) with a Markov chain of order 3 and learning constant C = 0.5. The CRF is from the HCRF library (Morency et al., 2010) and is trained with an L2 regularizer of weight 100. The Jordan-RNN is a recurrent neural network from (Mesnil et al., 2013) trained with 100 hidden states and initialized using the same features vectors. All parameters were chosen by 3-fold cross-validation over a reasonable range of values. The indices for the three folds are available in the dataset to allow for future result comparison. We have also tried continuous bag of words (Mikolov et al., 2013) , skip-grams (Mikolov et al., 2013) and GloVe (Pennington et al., 2014) as embeddings, and the Elman-RNN (Mesnil et al., 2013) as classifier, but results have proved generally less accurate. Table 2 shows the comparison of the average MUC7 and CoNLL scores from the 3-fold crossvalidation for the three classifiers. The MUC7 and CoNLL scores are F 1 values adapted to the NER task, with the CoNLL score generally stricter than MUC7 (Nadeau and Sekine, 2007) . As shown in Table 2 , the scores achieved by the SVM-HMM are higher overall and for all classes but one, with the Jordan-RNN as the second best. To verify statistical significance, we have also run a paired t-test over the results from the six individual classes and confirmed statistical significance of the differences even at p = 0.02. The relative ranking between SVM-HMM and the CRF is supported by similar results in the literature, including (Nguyen and Guo, 2007; Tang et al., 2013; Lei et al., 2014) , showing that regularized minimum-risk classifiers tend to outperform equivalent models trained under maximum conditional likelihood. The relative ranking between SVM-HMM and the RNN is instead somehow in contrast with the recent results in the literature, and a possible explanation for it is the relatively small size of the dataset compared to the number of free parameters in the models. We plan future comparative experiments with larger corpora to further probe this assumption. Conclusion In this paper, we have presented and released ArmanPersoNERCorpus, the first manually-annotated Persian NE dataset, and proposed an NER pipeline for the Persian language. The main components of the pipeline are word embedding by Hellinger PCA and classification by a structural SVM-HMM classifier. Experiments conducted over the ArmanPersoNERCorpus dataset have achieved interesting overall F 1 scores of 72.59 (MUC7) and 65.13 (CoNNL), higher than those of a CRF and a Jordan-RNN. The released dataset can be used for further development of Persian NER systems and for evaluation of systems trained on silver-standard corpora, and the achieved accuracy will provide a baseline for future comparisons.",
    "abstract": "Named-Entity Recognition (NER) is still a challenging task for languages with low digital resources. The main difficulties arise from the scarcity of annotated corpora and the consequent problematic training of an effective NER pipeline. To abridge this gap, in this paper we target the Persian language that is spoken by a population of over a hundred million people world-wide. We first present and provide ArmanPerosNERCorpus, the first manually-annotated Persian NER corpus. Then, we introduce PersoNER, an NER pipeline for Persian that leverages a word embedding and a sequential max-margin classifier. The experimental results show that the proposed approach is capable of achieving interesting MUC7 and CoNNL scores while outperforming two alternatives based on a CRF and a recurrent neural network.",
    "countries": [
        "Australia"
    ],
    "languages": [
        "Persian"
    ],
    "numcitedby": "19",
    "year": "2016",
    "month": "December",
    "title": "{P}erso{NER}: {P}ersian Named-Entity Recognition"
}