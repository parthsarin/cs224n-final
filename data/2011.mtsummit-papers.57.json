{
    "article": "Topic modeling is a popular framework to analyze large text collections. In the previous work, employing topic modeling into statistic machine translation mainly depends on one major topic of the test document. Different from the previous work, the proposed approaches will coverage not only major topic but also sub-topics. The basic idea of this paper is assumed that better translation quality, closer similarity of \"topic-document\" distributions between the target-side and the sourceside documents. We first give some initial experimental results to support this assumption. Then we transfer generating such a target document into selecting target-side sentences by an effective algorithm. A preliminary study showed that enforcing \"topic-document\" distributions to be consistent between target-side and source-side in SMT can potentially improve translation quality. Introduction Topic modeling is a popular framework to analyze large text collections, which softly cluster documents and terms into a fixed number of topics. There are a few studies on employing topic modeling into Statistical Machine Translation (SMT). Zhao et al. (2006) assumed that the training corpus are composed of documents, and proposed a model called \"BiTAM\" to improve the performance of word alignment, which consists of topicdependent translation lexicons modeling p(c|e, k), where c, e and k denote the source word, target word and the topic index respectively. Tam et al. (2007) first built the source-side and target-side topic models respectively, ie. p(c|k), p(e|k). Then, they proposed a bilingual-LSA model to automatically build the one-to-one correspondence between the source and target topic models. Foster et al.( 2007 ) described a mixture-model approach to implement a statistical machine translation system for new domains. Such approaches normally first partition the training data into different specific domains, then train a sub-model on each specific domain and finally combine a specific domain translation model with a general domain translation model depending on various text distances, one of which is using Latent Semantic Analysis (LSA, one of topic modeling methods). In the previous work, they dynamically choose translation model or language model according to the major topic of the test document, in some sense, they regarded \"topic\" as \"domain\". However, our proposed approaches will simultaneously coverage multiple topics of a test document, including not only the major topic but also some sub-topics. Due to use parallel document pairs, we follow the following assumption: better translation quality, closer similarity of \"topic-document\" distributions between the target-side and the source-side documents. First, some initial experimental results are given to support this assumption. For each sourceside sentence, we obtain a ranked N-best list of candidate translations in the target language based on a baseline system. It notes these sentences all belong to one document. After that, an effective algorithm for selecting target sentences to compose a target document with the minimal deviation to the \"topic-document\" distributions passed from the source-side. The rest of this paper is as follows. Section 2 gives initial experimental results. Section 3 describes our document-level system framework and introduces a baseline system. Section 4 presents an effective algorithm for target sentences selection. Section 5 presents experimental results. Finally, Section 6 draws a conclusion. Initial Experiment Corpus In this paper, we use FBIS as the training data, the 2003 NIST MT evaluation test data as the development data, and the 2005 NIST MT test data as the test data. Table 1 shows the statistics of these data sets (all these data with document boundaries annotation). Monolingual Topic Modeling Among various topic models, Latent Dirichlet Allocation (LDA, Blei et al., 2003) has drawn most attention recently in the NLP community and has been applied successfully in topic detection. In principle, LDA is a generative three-level hierarchical Bayesian probabilistic model for analyzing the content of documents and the meaning of words. Similar to other topic models, such as LSA, PLSA and PLSI, LDA assumes that documents are mixtures of topics and a topic can be represented as a probability distribution over words. In this paper, we use LDA to capture the topics in a document. We first use a LDA tool 1 to train topic models for the source-side(Chinese) and targetside(English) documents respectively in our training parallel corpus, FBIS, with a fixed number K( tuned to 15) topics. Using LDA, for each word w, we can obtain the \"topic-word\" distribution p(w|z i ) (topic z i K), and the \"topic-document\" distribution P(z i |d) for each document d. Moreover, using the obtained LDA models, we can infer the topic distributions of a new test document, namely p(z i |d new ) for each topic z i K. Initial Experiments Results In this section, we test the assumption that better translation quality, closer similarity of \"topicdocument\" distributions between the target-side and the source-side documents. In our test corpus, there are 100 documents (showed in table 1) and each source-side document has four reference texts (target-side documents) according to different system ID, we inference \"topic-document\" distributions for each reference documents (the 1-4 part of Figure 1 ) . We also inference \"topic-document\" distributions for 100 source-side documents based on trained sourceside LDA modeling (the 5 part of Figure 1 ). At the first sight, there is no obvious relation between 1 (or 2, 3, 4) and 5. But if re-arrange the topic sequence according to the \"correspondence\" (described in the next section 2.4) between the source-side and target-side topic modeling, we can observe that there are very close similarity distributions between source-side and target-side(the 6 part of Figure 1 ). From the above experimental results, we can slightly testify the correctness of our assumption in an empirical way. Now, we should address the problem on how to build the \"correspondence\" between the source-side and target-side topic modeling. Correspondence for monolingual topic modeling As described in Section 2.2, we trained monolingual LDA models for source-side language and target-side language respectively in advance. In order to supervise decoder to generate final targetside translation text according to the inferred topic distributions from the source-side document, we need a bridge, which is similar to Tam's work (Tam et al.,2007 ) by enforcing a one-to-one topic correspondence between the source and the target LDA-style models. However, we found the rigorous \"one-to-one\" topic correspondence cannot be obtained in our experiment. The phenomenon of mismatch exists in our experiment, for example, there are two topics in the source-side which can't match any topic in the target side, and in the same time, there are two topics in the source-side can be matched with one target-side topic twice. The reasons for why we cannot build the rigorous \"one-to-one\" correspondence maybe have two aspects: (1) the scale of corpus is not enough large; (2) the effect of \"polysemy\" and \"synonymy\" between different languages is different. So here we propose a simpler approach for small number topics like this: 1) Using GIZA++ (Och and Ney,2000) in two directions to perform word alignment on parallel corpus, and augmented to improve recall using the grow-diagonal-final heuristic. 2) Choose the top-n (n is fine-tuned to 200 in this paper) word-topic distribution of each topic in both languages. 3) With the help of lexical mapping (obtained from Step 1), pairwise comparison is performed based on Step 2. We count the mapping words between two topics in both languages and determine the mapping relation according to the maximum numbers of mapping. 3 Document-level SMT (1) where P(e|f) is a translation model and P lm is a language model. For each sentence in the source language(f), we can obtain a ranked n-best list of candidate translations in the target language based on a baseline system. Usually, we say the top 1 of the N-best translations is a best translation. Our system adopted Moses (a state-of-art phrase-based SMT system) as a baseline, which follows Koehn et al. (2003) . ). Obviously, the fourth step is a key step. Given the target document, it will be easy to gain the \"topic-document\" distributions based on previous trained target-side topic model. However, such target document does not exist because our decoder needs to translate sentence by sentence until to the last sentence. For a test document, with M source-side sentences, and each source-side sentence corresponds to N-best list of candidate translations, there will be N M target documents waiting for determining. With the growth of N and M, the computational complexity is too high. The workflow of document-level SMT Generate target-side document In this section, we propose to transfer the task of generating optimum target document into selecting better sentences. Transfer generating optimum target document into selecting sentences Assumed H represents the faithful target document's probability distributions over topics, i.e. )) | ( , ... ), | ( ), | ( ( 2 1 i k i i D T P D T P D T P H = , P(T j |D i ) stands for the probability of being topic T j given document D i . Due to the parallel corpus, we also think the target-side \"document-topic\" distributions are similar to the source-side ones (the initial experiment results showed in Section 2.3). So we assume H is constant here. Q represents one target document probability distribution over topics, i.e. )) | ( , ... ), | ( ), | ( ( 2 1 x k x x D T P D T P D T P Q = , where P(T j |D x ) stands for the probability of topic T j given one target document D x . Now we mainly manage how to construct Q. Using the Bayes rule, we have (2) where P(D x |T j ) stands for the probability that topic T j generates document D x . P(T j ) stands for the probability of Topic T j . P(D x ) stands for the probability of document D x . Let's assume that a sentence S r of a document D x represents a topic T j if the topic T j generates all the words of the sentence S r with some probability and that the document D x generates Topic T j . Under this assumption, we have: ) ( ) ( * ) | ( ) | ( \u2211 \u2208 = Dx Sr j x Tj Sr P Dx T D P ) | ( || || 1 ) | ( (3) where ||D x || stands for the number of sentence in document D x . For the same reason, we extend one sentence into some words by the Equation (4): \u2211 \u2208 = Sr Wi Tj Wi P Sr Tj Sr P ) | ( || || 1 ) | ( (4) where ||S r || stands for the number of words in sentence S r . It notes that P(W i |T j ) stands for the probability that topic T j generates word W i , which has been obtained by the previous trained target-side topic models. Furthermore, by applying Equation 3 and 4 to Equation 2, we can get: \u2211 \u2211 \u2208 \u2208 = Dx Sr S W j i x j x j r i T W P Sr Dx D P T P D T P ) | ( || || * || || 1 * ) ( ) ( ) | ( (5) where P(T j ) and P(D x ) are constant. In our case, for the sake of simplicity, we set P(T j ) /P(D x ) as 1. In this paper, we mainly investigate Kullback-Leibler (KL) divergence (Kullback & Leibler, 1951) to measure the distance between two probability distributions as follows: \u2211 = i KL i Q i H i H Q H D ) ( ) ( log ) ( ) || ( (6) Algorithm We implement our system by the Algorithm 1 based on the above transformation. The basic idea of Algorithm 1 is: assume the \"topic-document\" distributions are constant, update them with the distributions of continuous sentences, if the candidate leads to the minimal change among these distributions, we will choose it. It need to point out the score(h) should be constrained(we set \u03be=1), or it is possible to choose the translation candidate which contains plenty of topic words however the fluency of the whole sentence is very poor. The value of score(h) is an absolute value using the score of language model of original top 1 translation candidate in the N-best lists to minus the corresponding score of current candidate. For the two topics in the source-side which can't match any topic in the target side (showed in Section 2.4), we will set its corresponding P(W i |T j ) as P(W si |T sj1 ) and P(W si |T sj1 ), W si is a source-side word ;T sj1 and T sj2 is the two mismatched sourceside topics. For the topic in the source-side matched with multiple target-side topics, we determine it by looking through the top 1 distribution of \"word-topic\" for each topic. The highest value will be adopted. Input: The inferred latent \"topic-document\" distributions H from source-side; The 5 Experimentation and Discussion Experimental Setting Here, we use SRI language modeling toolkit to train a trigram general language model on English newswire text, mostly from the Xinhua portion of the Gigaword corpus ( 2007 ) and performed word alignment on the training parallel corpus using GIZA++ (Och and Ney,2000) in two directions. For evaluation, the NIST BLEU script (version 13) with the default setting is used to calculate the Bleu score (Papineni et al. 2002) , which measures case-insensitive matching of n-grams with n up to 4. Experimental Results The column of \"BLEU_W\" in Discussion There are 1082 sentences in our test data in sum (Table 1 showed in Section 2.1), and only 407 sentences selection make a difference, which only refers to 31 documents. For each sentence pair, we determined whether our additional processing improved or degraded performance compared to Moses output. Among the sentence pairs, 82 sentences do not change in fact, 304 sentences obtain positive change (examples showed in Table 3 ) and others 21 sentences degrades the performance. We performed some manual analysis of the output. We observe that such phenomenon can broadly be attributed to two reasons: 1) The performance of baseline; 2) The negotiation between the score of language model and topic model; Our proposed method based on the N-best list which produced by the baseline. If there is no good candidate waiting for choice, our method will not work effectively. The 82 sentences without change majorly belong to the reason 1 because there is no real change between the candidates in the N-best list. In the future work, we should integrate sourceside \"topic-document\" distributions into our decoder. For the reason 2, we did intervention by considering the deviation of language model score (see score(h) described in 4.2), however, it is not easy to set the reasonable threshold value(\u03be) . Maybe some re-rank algorithm can be introduced here. Conclusion Based on the assumption that better translation quality, closer similarity of \"topic-document\" distributions between the target-side and the sourceside documents, we obtained some small improvement results for statistical machine translation system. In this paper, we only implemented this assumption during the post-edit procedure. So if the quality of N-best translation is poor, our proposed method will lose effectiveness. In our feature work, we will implement this during decoding and design the corresponding MERT algorithm. Acknowledgments This research was supported by Projects 90920004, 60873150, and 61003155 under the National Natural Science Foundation of China, Project 20093201110006 under the Specialized Research Fund for the Doctoral Program of Higher Education of China. , , Moses: they said that the euro zone 's biggest country 's economic output figures will show every month , ... Ours:they said that the euro zone 's biggest country 's economic output data will continue to demonstrate every month ,... 1 Reference: They said economic output data from the largest Eurozone countries would continue to indicate great volatility each month , \u2026 Moses: ukraine crisis triggered tension will be a topic that . Ours: ukraine crisis triggering tension will be a topic of the things . 2 Reference:Triggering Tensions between East and West , Crisis in Ukraine Will Become an OSCE Topic . , , Moses: russia has repeatedly accused of meddling in west europe affairs , the political crisis that ukraine will become the focus of attention ,\u2026 Ours: russia has repeatedly accused western intervention in eastern europe affairs , the political crisis that ukraine will become the focus of attention ,...",
    "abstract": "Topic modeling is a popular framework to analyze large text collections. In the previous work, employing topic modeling into statistic machine translation mainly depends on one major topic of the test document. Different from the previous work, the proposed approaches will coverage not only major topic but also sub-topics. The basic idea of this paper is assumed that better translation quality, closer similarity of \"topic-document\" distributions between the target-side and the sourceside documents. We first give some initial experimental results to support this assumption. Then we transfer generating such a target document into selecting target-side sentences by an effective algorithm. A preliminary study showed that enforcing \"topic-document\" distributions to be consistent between target-side and source-side in SMT can potentially improve translation quality.",
    "countries": [
        "China"
    ],
    "languages": [
        "English",
        "Chinese"
    ],
    "numcitedby": "9",
    "year": "2011",
    "month": "September 19-23",
    "title": "Improve {SMT} with Source-Side {``}Topic-Document{''} Distributions"
}