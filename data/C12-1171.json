{
    "article": "Recognizing semantic relations between sentences, such as entailment and contradiction, is a challenging task that requires detailed analysis of the interaction between diverse linguistic phenomena. In this paper, we propose a latent discriminative model that unifies a statistical framework and a theory of Natural Logic to capture complex interactions between linguistic phenomena. The proposed approach jointly models alignments, their local semantic relations, and a sentence-level semantic relation, and has hidden variables including alignment edits between sentences and their semantic relations, only requires sentences pairs annotated with sentence-level semantic relations as training data to learn appropriate alignments. In evaluation on a dataset including diverse linguistic phenomena, our proposed method achieved a competitive results on alignment prediction, and significant improvements on a sentence-level semantic relation recognition task compared to an alignment supervised model. Our analysis did not provide evidence that directly learning alignments and their labels using gold standard alignments contributed to semantic relation recognition performance and instead suggests that they can be detrimental to performance if used in a manner that prevents the learning of globally optimal alignments. Introduction Recognizing Textual Entailment (RTE) (Dagan et al., 2005) is the task of recognizing entailment relations between a given text pair, Text T and Hypothesis H. RTE is useful for many information access tasks that depend on natural language processing technologies, and a breakthrough would lead to significant progress in information retrieval, document summarization, and question answering, among other tasks. The majority of approaches proposed in previous work recognize entailment relations between a pair of texts by capturing lexical or structural correspondences. Methods include simple word overlap-based measures (Jijkoun and de Rijke, 2005) as well as alignment of syntactic and semantic dependencies (Sammons et al., 2009; Wang and Zhang, 2009) . However, sentencelevel semantic relations are affected by various linguistic phenomena: not only lexical semantic relations (synonyms, antonyms) but also monotonicity (e.g. downward-monotone caused by scope of negation), implicative/factive expressions, quantifiers, etc. Thus similarity measures are insufficient to capture these phenomena and their interactions. Transformation-based approaches are one way to capture the affects of diverse linguistic phenomena and their interactions, where a set of linguistic phenomena are decomposed into units. By doing so it becomes possible to consider their effects on entailment independently. A number of previous works explores transformation-based entailment relation recognition. The approach of Stern et al. (2011) recognizes a sentence-level semantic relation through a proof which represents a sequence of edits from T to H produced by applying various entailment rules and the operations such as insertion, deletion, moving subtrees, etc. In addition, Heilman and Smith (2010) proposed a tree edit model which selects a sequence of edits using Tree Kernels, and Wang and Manning (2010) proposed a latent variable model which consider possible alignments as hidden structures. However, these model do not sufficiently represent interactions between linguistic phenomena such as factuality reversals caused by negation and flipping of entailment direction under downward-monotone contexts. In order to realize precise entailment relation recognition, we need to appropriately deal with semantic relations resulting from the interaction between linguistic phenomena. One of the most promising approaches to RTE is Natural Logic-based recognition (MacCartney and Manning, 2008; MacCartney, 2009) . This approach represents transformations from T to H with a set of three types of alignment edits (substitution, insertion and deletion), and assigns one of a set-theoretically defined semantic relations to each alignment edit. This approach is based on the principle of compositionality, i.e. the sentence-level semantic relation is derived by combining semantic relations of edits using pre-defined composition rules. By doing so, this approach makes progress toward precise sentence-level entailment relation recognition that considers linguistic phenomena and their interactions when assigning semantic relations. However, several issues remain unexplored. While it is common for alignment inference methods to require data annotated with alignments, it is a challenge to manually annotate alignments in a consistent manner. Annotation of alignments with semantic relations from Natural Logic is a greater challenge due to the complex nature of the semantic relations. In addition, even alignments can be annotated consistently, there is no guarantee of their global optimality; that is to say the alignments identified as correct by annotators may not necessarily contribute to identifying the correct semantic relation between a pair of sentences. Identifying alignments considering the full context of a sentence pair is a much more difficult annotation task. However, even without manual alignment annotations, it may be possible to infer consistent and plausible alignments by learning models that promote alignments which agree with annotations of correct semantic relations between sentences. A unified model of alignment and semantic relation recognition between sentences is needed that learns the alignments which will generate the correct semantic relation by considering the interaction between diverse linguistic phenomena. In this paper, we propose a novel latent discriminative model that jointly handles predicting alignment edits, classification of their semantic relations and entailment relation recognition by providing a joint distribution of variables including alignment edits, their local semantic relations and sentence-level semantic relations. Inspired by the Natural Logic-based approach of (MacCartney et al., 2008) , we incorporate the set of semantic relations and their composition rules from Natural Logic into our proposed model. In addition, our model can be trained from only sentence-level semantic relations to predict alignments and semantic relations that are consistent with Natural Logic composition. To the best of our knowledge, our study is the first work to propose a latent model for training a Natural Logic-based semantic relation recognition system that does not require alignment annotations and that jointly predicts plausible alignments and semantic relations between sentences, modeling a variety of linguistic phenomena and their interactions in a compositional manner. Natural Logic The concept of Natural Logic, a logic over natural language, is originally proposed by Lakoff (1970 ), and then van Benthem (1988 , 1991) and Valencia (1991) explored monotonicity calculus 1 to explain entailment relations using Natural Logic. While they considered only containment relations, MacCartney and Manning (2008) introduced an exclusion relation to deal with entailment relations which involve different objects or concepts (e.g. Stimpy is a cat |= Stimpy is not a poodle). In this section, we describe the theory of Natural Logic proposed by (MacCartney and Manning, 2008; MacCartney, 2009) . The basic idea of MacCartney et al's theory is that the semantic relation between sentences can be derived from the semantic relations of edits (substitution, deletion and insertion) from T to H. The fundamental assumption of the theory is compositionality: (some of) the entailments of a compound expression are a function of the entailments of its parts. They defined the seven types of semantic relations for edits: equivalence (a \u2261 b if a = b), forward-entailment (a \u228f b if a \u2282 b), backward-entailment (a \u2290 b if b \u2283 a), negation (a \u2227 b if a \u2229 b = \u03c6 \u2227 a \u222a b = U) 2 , alternation (a | b if a \u2229 b = \u03c6 \u2227 a \u222a b = U), cover (a \u222a b = \u03c6 \u2227 a \u222a b = U), and independence (a # b otherwise). Semantic relations provided by edits are projected onto other relations depending on their contexts using projection rules. For example, in a scope of negation, forward-entailment is projected onto backward-entailment (e.g soccer \u228f sports, I didn't play soccer. \u2290 I didn't play sports.). Other linguistic expressions such as logical connectives and quantifiers also projects semantic relations. A semantic relation between sentences is derived by combining the projected semantic relations of edits using composition rules. The rules are defined as tuples of semantic relations. Let the seven types of relations be , r i \u2208 , r j \u2208 , then a compositional rule is represented by r i r j \u21d2 r \u2286 . Some compositional rule derive a single relations (e.g. \u2261 \u228f \u21d2 \u228f), and others derive more than one semantic relations (e.g. | | \u21d2 {\u2261, \u228f, \u2290, |, #}). As semantic relation composition proceeded, semantic relations tend to move toward # 3 . A Latent Discriminative Model for Compositional Entailment Relation Recognition Given a text T and a hypothesis H, the task of RTE is to infer the correct semantic relation between T and H. However, we attempt to learn not only the correct semantic relation between T and H but also the characteristics of the alignments most likely to support that relation. We assume that sentence-level semantic relations can be derived compositionally. Following the framework of Natural Logic proposed by (MacCartney and Manning, 2008; MacCartney, 2009) , our proposed model assigns local semantic relations to edits which represent a transformation from T to H. A valid set of edits represents an alignment between T and H. Each edit is categorized as one of three types: substitution, deletion or insertion, and is given one of the seven semantic relations defined in Natural Logic described in \u00a72. A semantic relation between T and H is derived from a set of semantic relations of alignment edits by using the projection rules and the composition rules. The proposed model learns appropriate alignments which are consistent with compositional rules of Natural Logic from only sentence-level semantic relations, where appropriate alignments, their semantic relations and their projections are represented using hidden variables. We use a log-linear discriminative model with hidden variables to provide conditional joint probabilities of alignments, their associated semantic relations, and their projections and a sentence-level semantic relation. Model Our proposed model provides a conditional joint distribution of alignment edits, their semantic relations, their projected relations and the final semantic relation between T and H as follows. p(e, r e , r P e , r C |x ; Since r e i is derived without considering its context, r e i can be seen as the semantic relation between t i and h i . The variables r P e represents a set of projected semantic relations derived from r e , taking into account their contexts. If an edit is under the scope of negation, a quantifier or a conditional, then r e i is mapped to an appropriate semantic relation r P e i based on that context. Therefore r P e i can be seen as the sentence-level semantic relation between T and the sentence which can be obtained by applying the edit e i to T . The variables r C denotes a set of semantic relations derived by combining r P e , where each r C \u2208 r C corresponds to the result of composition of two semantic relations. Hereafter, we use r C T as the sentence-level semantic relation. Note that r C T \u2208 r C . Each variable r in r e , r P e and r C can have seven types of semantic relations described previously. \u03a8 k in equation ( 1 ) is a factor which scores the plausibility of alignment edits, their semantic relations, etc. \u03bb) = 1 Z(x ) exp k \u03a8 k (e, Our proposed model uses the following four types of factors to score the plausible alignment edits, their semantic relations and a sentence-level semantic relation. Alignment Factor \u03a8 A (e, x ) is used to deal with (unlabeled) phrase alignment for entailment relation recognition and is defined as \u03a8 A (e, x ) = \u03bb\u2022 f A (e, x ). In order to provide good alignments, it is necessary to capture the lexical similarity between words. The features used in this factor are mainly (i) surface-based similarity between alignment units, (ii) semantic relatedness of alignment units, which can be extracted from diverse lexical knowledge databases, and (iii) the contextual information for an edit. Alignment Semantic Relation Factor \u03a8 S (e, r e , x ) is introduced to provide plausibility of a semantic relation r e \u2208 r e for an alignment edit e \u2208 e and is defined as \u03a8 S = \u03bb \u2022 f S (e, r e , x ). Each variable r e has a distribution over the seven types of semantic relations defined in Natural Logic. In order to classify semantic relations, not only surface-based similarities, but also lexical semantic relations play an important role. In the NatLog system developed by (MacCartney, 2009) , an implementation of an RTE system of Natural Logic, lexical resource-derived features (e.g. WordNet, NomBank, etc.), string similarity features, and lexical category features are used. For this factor, we exploit diverse lexical resources to provide informative features for classifying semantic relations of edits. Projection Factor \u03a8 P (r e , r P e , x ) provides an appropriate projection from r e to r P e by considering the context of e, and is defined by \u03a8 P (r e , r P e , x ) = \u03bb \u2022 f P (r e , r P e , x ). This factor captures the effects of monotonicity (e.g. upward, downward). Given r e and its contexts, the semantic relation of the projected variable r P e is uniquely determined using the monotonicity rules of (MacCartney, 2009) . Composition Factor \u03a8 C (r C i\u22121 , r P e , r C i , x ) scores tuples of semantic relations, and is defined by \u03a8 C i (r C i\u22121 , r P e , r C i , x ) = \u03bb \u2022 f (r C i\u22121 , r P e , r C i , x ). In this factor, we use the composition rules used in (MacCartney, 2009) with some modification. We set the derived semantic relations to independence (#) for the rules which derive more than one semantic relations. Therefore, as with \u03a8 P , given two semantic relations r C i\u22121 and r P e , the joined relation of the variable r C i is uniquely determined. An overview of the proposed model is shown in Figure 1 . In this figure, we show the factor graph constructed by our proposed model for a pair of sentences in Japanese. Our model is divided by three layers: the alignment layer, the projection layer and the composition layer. First, in the alignment layer, our proposed model scores possible alignments using \u03a8 A and \u03a8 S . For alignment units, we use bunsetsu which is a reasonable unit for Japanese linguistic analysis. A bunsetsu is a chunk-like unit that consists of one or more content words and zero or more functional words. A set of possible alignments are obtained using an extended MANLI algorithm (MacCartney et al., 2008) . Next, for each alignment obtained by the alignment algorithm, we construct a factor graph as shown in Figure 1 . The factor graph has variables for alignments, projected relations, joined relations, and the factors defined previously. In the projection layer, semantic relations of alignments are projected by \u03a8 P , and finally a sentence-level semantic relation is obtained in the composition layer using the projected relations and composition rules encoded in \u03a8 C . In inference, since variables related to \u03a8 P and \u03a8 C are uniquely determined if r e is given, the model derives the best alignments, their semantic relations, and a sentence-level semantic relation simultaneously. In training, the parameters of the model are updated so as to derive alignments and their semantic relations which derive the correct sentence-level semantic relation based on the composition rules of Natural Logic. Features The features used in the proposed model are listed in Table 3 .2. Because RTE datasets are small, it is difficult to incorporate lexical features directly into our model as they may cause overfitting. Instead, we incorporate similarity metrics to model lexicality. On the other hand, because function words are closed class and present in all texts, we can directly use them as features. While both \u03a8 A and \u03a8 S score the plausibility of alignments, the features used in their factors are also different. \u03a8 A considers not only lexical similarities but also contexts of edits. Let us consider a simple sentence pair T: USA won the war but Japan lost the war. H: Japan won the war. In this example, T and H share the same verb won but the word won in H should be aligned to lose in T because they share the same subject (Japan). So, we introduce features that capture predicate-argument structure-level contextual information: e.g. how many arguments are shared by the two predicates (NUM_SHARED_ARGS)? On the other hand, \u03a8 S pays more attention to inferring the lexical semantic relations of edits. The features used in \u03a8 P and \u03a8 C work as rules to infer sentence-level semantic relations. Learning the Model The parameters \u03bb of the proposed model are trained from sentence-level semantic relations via marginal-likelihood maximization \u03bb = n log p(r C T = l n |x n ; \u03bb). By applying this objective function, we expect that the proposed model is trained so as to prefer alignment edits and The partial differential of the objective function is \u2202 L \u2202 \u03bb k = n \u2202 \u2202 \u03bb k log \u2329e,r e \u232a\u2208 r :r C T =l exp k \u03a8 k (e, r e , r P e , r C , x ) \u2212 \u2202 \u2202 \u03bb k log Z(x ) (2) Algorithm 1 The alignment algorithm. where edits e, their semantic relations r e , projected semantic relations r P e and joined relations excluding the sentence-level semantic relation are all hidden variables. Given r e , r P e and r C can be identified uniquely by using projection and composition rules. Since the objective function is non-convex, estimated parameters can be local-optima. In optimization, only the parameters in \u03a8 A and \u03a8 S are updated, and the parameters in \u03a8 P and \u03a8 C are left to initial values. In order to update the parameters, we need to calculate marginal probabilities of the alignments. However, unlike sequential or tree models, calculating exact values of alignments is prohibitively difficult. We use only N-bests provided by the extended MANLI algorithm to calculate an approximate partition function Z(x ) instead of Z(x ), and approximate marginal probabilities. Inference of Alignments Given two sentences, the problem of alignment inference in our model is predicting the best edits and their semantic relations \u2329e, r e \u232a = arg max \u2329e,r e \u232a\u2208 \u2329e i ,r e i \u232a\u2208\u2329e,r e \u232a \u03a8 A (e i , x ; \u03bb) + \u2329e i ,r e i \u232a\u2208\u2329e,r e \u232a \u03a8 S (e i , r e i , x ; \u03bb) where is a set of all possible edits and their semantic relations between two sentences. The original MANLI algorithm (MacCartney et al., 2008) only provides the best edits, so we extend the algorithm so as to provide not only edits, but also their semantic relations. The extended version of MANLI is shown in Algorithm 1. Given two sentences, the algorithm starts at an initial alignment e 0 which consists of deletion edits of bunsetsus in T and insertion edits of bunsetsu in H, and then searches for more good alignments by changing edits from a pair of a deletion and an insertion edit to a substitution edit, or changing semantic labels. The main differences between the original MANLI and our algorithm are: (1) alignments have their semantic relations, (2) keeps a set of alignments ordered by scores provided by \u03a8 A and \u03a8 S to provide N-bests. We omitted the annealing procedure which is included in the original MANLI because our algorithm need to keep an ordered set of alignments based on scores. If we introduce a temperature value, we have to update all of the alignments in the set when the value is changed. However this is computationally expensive. The Order of Composition The composition order of semantic relations defined in Natural Logic is non-commutative. Let us consider joining an alternation (|) and a forward-entailment (\u228f). The pair of semantic relations frequently appear in contradiction examples. \u228f joined with | yields |, on the other hand, | joined with \u228f yields {\u2261, \u2227 , |, \u222a, #}. The former way of composition derives the desired result, however, the latter way derives an ambiguous result. We defined the order of composition so as to keep joined semantic relations unambiguous as far as possible. Our proposed model at first joins \u2261 and \u228f, then |, then \u2227 , and \u2290 in the end 4 . Experiments Data We developed a dataset for semantic relation recognition which includes a diverse selection of linguistic phenomena. Although there is an textual entailment recognition data set for Japanese (RITE (Shima et al., 2011 )), we do not consider it an appropriate target for evaluation and instead construct our own dataset. Our motivation is as follows. Much of the progress made in textual entailment recognition has been on a set of phenomena that can be handled with methods of lexical and phrasal similarity, however, there are many other phenomena that have not been addressed. 2010 ) make a case for more detailed analysis of the linguistic phenomena important to textual entailment recognition so that their impact on existing approaches can be properly measured. In that spirit, we investigated textual entailment recognition phenomena and found that quantification, negation, and monotonicity require consideration of their semantic structure and are beyond the scope of similarity-based methods. Constructing systematic and robust models of handling these phenomena is the focus of this paper. It is reasonable to target these phenomena next because many of the remaining problems for textual entailment recognition require world knowledge and are thus problems of inference or AI. Existing datasets for textual entailment recognition are insufficient for our purposes because the phenomena they contain are too broad and they do not contain enough examples of the phenomena we are targeting to draw meaningful conclusions. Sammons et al. ( We selected the categories based on FraCaS (Cooper et al., 1996) , the corpus developed by Bentivogli et al. (2010) and the categories discussed in (MacCartney, 2009) : lexical semantic relation (e.g. synonym, antonym, hypernym-hyponym relation), quantifiers, modifiers, negation, coordination, relative clauses, apposition, temporal and numerical expressions, active/passive, factive verbs and functional relations. The statistics of the dataset is shown in Table 4 .1. The distribution of the categories is not balanced: the quantifier category accounts for approximately 30% of the total. One of our interests is whether the model can automatically capture behaviour of functional expressions such as quantifiers from sentence-level semantic relations. In order to conform this point, we developed many examples for quantifiers. T: Japan got a bronze medal in Team Fencing. Contradiction H: Japan hasn't gotten a bronze medal in any sports. Implicative/Factive T: Earthquake-proofing prevented the house's collapse. Forward-Ent. H: The house did not collapse. Coordination T: Tokyo has a population of 13,000,000 and Miyagi has a population of 2,300,000. Contradiction H: Tokyo has a population of 2,300,000. Table 3 : Some examples in the dataset (translated in English). For each example, we annotated one of the four types of sentence-level semantic relations (paraphrase, forward-entailment, contradiction and independence), and alignment edits and their semantic relations in Natural Logic. In the dataset, the number of paraphrase examples is 97, forward-entailment is 313, contradiction is 100, and independence is 88. Table 4 .1 shows some examples in the dataset. The dataset was developed by one annotator, who is a professionally trained linguist unaffiliated with this research project, and the set of annotated semantic relations does not always provide the correct semantic relation. 55.2% of the gold annotations derive correct sentence-level semantic relation (332 examples). The remaining examples include inconsistencies between sentence-level semantic relations and semantic relations of alignments, linguistic phenomena that the current model can not deal with (e.g. syntactic transformation, some quantifiers), etc. Whereas there are seven types of relations in Natural Logic, our annotation uses only four types of relations. So in the experiments, we mapped contradiction to {\u2227, |} and other to {\u222a, #} in the training and the testing phase. Settings In order to explore the effectiveness of the proposed model, we evaluated the following approaches in the experiments. Initial Weight Initial weights of the model are used for testing. Resource-based Alignment Alignments are determined based on a surface-based similarity measures and lexical resources. In this setting, a pair of two phrases is aligned if the character-bigram cosine similarity is greater than a pre-defined threshold (we set it to 0.8), or the pair matches an entry in the lexical resources such as Japanese WordNet, Hypernym-Hyponym relations, Verb Entailment Relations, and Verb Relation Dictionary. Semantic relations of alignment edits are determined as follows: \u2261 if the pair of the bunsetsus \u2329b 1 , b 2 \u232a is the same, similar or is synonym, | if the pair is antonym, \u228f if b 2 is the hypernym of b 1 or b 1 entails b 2 , \u2290 if b 1 is the hypernym of b 2 or b 2 entails b 1 . The bunsetsus not aligned by the similarity measure or the resources are converted to deletion or insertion edits, and their semantic relations are set to \u228f and \u2290 respectively with exceptions described later. Alignment Supervised The model is trained using gold alignments which have correct semantic relations defined in Natural Logic. In this setting, sentence-level semantic relations are not considered in training. As in the proposed model, we constructed the model using a log-linear discriminative model, and the model was trained log-likelihood maximization of gold alignments. The objective function used in training was \u03bb = n log p(e, r e |x n ; \u03bb). Weakly Supervised (proposed) The model is trained by marginal likelihood maximization over sentence-level semantic relations. The dataset we used in the experiments include the examples whose correct sentence-level semantic relations can not be derived from the pre-annotated semantic relations of alignment edits. It seems that these are hard to derive correct sentence-level semantic relations from the current possible edits. So, we conducted experiments on the examples whose correct sentence-level semantic relations can be derived from the gold alignments (hereafter, we say reachable). For the factors \u03a8 P and \u03a8 C , we initialized the weights to 0.0 if the semantic relation tuple is covered by our projection rules and composition rules, and \u2212\u221e otherwise. For the factors \u03a8 A and \u03a8 S , we set initial weights to some features 5 . In training of the model, we update the parameters in \u03a8 A and \u03a8 S , and the parameters in \u03a8 P and \u03a8 C are left to the initial values. Parameter updating was performed using stochastic gradient descent (SGD), and the number of iterations was set to 2. Also, we applied L 2 regularization. As for the alignment algorithm, the number of iterations was set to 40, and the number of N-bests was set to 10. For each edit type, we restricted the maximum size of units: only allows one-to-one for substitution, allows at most three units for insertion and deletion edits. Also, we constrained the types of semantic relations for each edit type. Substitution edits can have one of the five types of semantic relations: \u2261, \u228f, \u2290, \u2227 and | with an exception. If the lemma sequences of the two bunsetsus are the same, the edit can have only \u2261. Deletion edits and insertion edits can have \u228f and \u2290 respectively with exceptions. They can have | if the head of bunsetsu matches an entry in the list of counter-factive expressions 6 , and they can have \u2261 if the head of bunsetsu matches an entry in the list of less-informative expressions 7 . Evaluation Measures We use the following measures in evaluation: (1) Alignment (Unlabeled): A predicted alignment is correct if there is a gold alignment which has the same span, but the semantic label is not considered, (2) Alignment (Labeled): A predicted alignment is correct only if there is a gold alignment which has the same span and their semantic relations are also the same, and (3) Sem. Rel.: Accuracy of sentence-level semantic relations. 5 For instance, the weights of the combination feature \"NEGATION=0\" and \"JAPANESE_WORDNET=antonym\" are set to 1.0 if label is | and \u22121.0 otherwise 6 A hand-crafted list which contains 13 entries. 7 As with the list of counter-factive expressions, the list was hand-crafted, and contains 30 entries. Preprocessing For each sentence, we conducted various forms of linguistic analysis: morphological analysis using MeCab (Kudo et al., 2004) , syntactic parsing using the Japanese dependency parser, CaboCha (Kudo and Matsumoto, 2002) and predicate-argument structure analysis (Watanabe et al., 2010) to provide a basis for alignment and semantic relation classification. Results Table 4 shows the experimental results of 10-fold cross validation for alignment prediction and sentence level semantic relation recognition. We can see that while the proposed method is less successful at reproducing gold standard alignments, it greatly outperforms Supervised Learning for sentence-level semantic relation recognition 8 . We expected Supervised Learning to perform best on reachable examples, which should have the most straightforward connection between alignment semantic relation labels and sentence level semantic relations. Nevertheless, our proposed method achieved the best performance on this dataset as well. These results support our theory that gold standard alignment data is necessary for semantic relation recognition. Indeed, alignment labels appear to degrade performance in several cases.   Table 6 : The details of the performances of alignment prediction. alignments and semantic relation labels. However, it is interesting to note that while Resource Alignment performs competitively at alignment prediction (it rivals Alignment Supervised on Forward-Entailment and outperforms all other methods on Alternation/Negation), it performs drastically worse on sentence-level semantic relation recognition, sometimes with an f-score that is more than 20 points lower than the best performing method. These results suggest that it is important to jointly model alignment prediction and sentence-level semantic relation recognition so that globally optimal alignments are promoted. Related Work There are a number of existing works which explore the use of latent variable or structure models for recognizing textual entailment. Chang et al. (2010) proposed a discriminative linear model where alignments are treated as hidden structures, and the sentence-level semantic relation is derived based on the best latent alignment structure. They formulated the problem of predicting the best hidden structure as an Integer Linear Programming problem, where domain knowledge is encoded as constraints. Wang and Manning (2010) proposed a latent variable model where the model provides a conditional distribution of a sequence of edits, which can be seen as a transformation-based approach. In the model, edits are treated as hidden variables that populate a positive set and a negative set in the search space. Sentence-level semantic relations are predicted based on the sum of the scores of edit sequences in the positive set and the negative set. The differences between our proposed model and theirs are that the number of semantic relations and compositionality. Both Wang and Manning (2010) and Chang et al. (2010) consider only entailment and non-entailment, while our proposed model identifies a rich set of relations: paraphrase, forward entailment, backward entailment, contradiction, and independence. Furthermore, as discussed in Section 2, our model exhibits compositionality by incorporating Natural Logic at two different levels. First, it incorporates information about upward and downward monotonicity into a projection layer, allow it to handle flips in entailment direction caused by scope of negation that can influence the final sentence-level semantic relation. In addition, it considers the result of combining projected semantic relations of alignment edits, allowing it to handle complex interactions between linguistic phenomena in sentences. The alignment models of Wang and Manning (2010) and Chang et al. (2010) do not consider the interaction between alignments that we model with Natural Logic making it difficult for them to classify examples that contain complex semantic structures. Conclusion In this paper, we proposed a novel latent variable model for compositional entailment relation recognition. We gave the proposed model compositionality by incorporating a set of semantic relations and their composition rules of Natural Logic. The model has ability to predict local correspondences (alignments) between sentences, the semantic relations, and the sentence-level semantic relation simultaneously. The model can be trained from only sentence-level semantic relations by using marginal-likelihood maximization. In evaluation, our proposed method outperformed a supervised alignment method on a sentence-level semantic relation recognition task, and detailed analysis on that task and an alignment prediction task did not provide evidence that gold standard alignment labels contributed to semantic relation recognition performance and instead suggests that they can be detrimental to performance if used in a manner that prevents the learning of globally optimal alignments. A future research direction we are investigating is extending the model so as to deal with structural transformations. The current model has a big drawback: the model assumes that all of sentence-level semantic relations can be derived from only bunsetsu -level transformations. We would like to explore how to incorporate transformation rules (used in e.g. (Stern et al., 2011) ) into the proposed model. Acknowledgements This work is supported by the PRESTO program of JST and the Grants-in-Aid for Scientific Research No. 23240018, No. 23700157 and No. 23700159.",
    "abstract": "Recognizing semantic relations between sentences, such as entailment and contradiction, is a challenging task that requires detailed analysis of the interaction between diverse linguistic phenomena. In this paper, we propose a latent discriminative model that unifies a statistical framework and a theory of Natural Logic to capture complex interactions between linguistic phenomena. The proposed approach jointly models alignments, their local semantic relations, and a sentence-level semantic relation, and has hidden variables including alignment edits between sentences and their semantic relations, only requires sentences pairs annotated with sentence-level semantic relations as training data to learn appropriate alignments. In evaluation on a dataset including diverse linguistic phenomena, our proposed method achieved a competitive results on alignment prediction, and significant improvements on a sentence-level semantic relation recognition task compared to an alignment supervised model. Our analysis did not provide evidence that directly learning alignments and their labels using gold standard alignments contributed to semantic relation recognition performance and instead suggests that they can be detrimental to performance if used in a manner that prevents the learning of globally optimal alignments.",
    "countries": [
        "Japan"
    ],
    "languages": [
        "Japanese",
        "English"
    ],
    "numcitedby": "8",
    "year": "2012",
    "month": "December",
    "title": "A Latent Discriminative Model for Compositional Entailment Relation Recognition using Natural Logic"
}