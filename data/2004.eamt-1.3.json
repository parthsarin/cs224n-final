{
    "article": "We report on the results of an experiment aimed at enabling a machine translation system to select the appropriate strategy for dealing with words and phrases which have different translations depending on whether they are used as proper names or common nouns in the source text. We used the ANNIE named entity recognition system to identify named entities in the source text and pass them to MT systems in the form of \"do-not-translate\" lists. A consistent gain of about 20% in translation accuracy was achieved for all tested systems. The results suggest that successful translation strategy selection is dependent on accurate segmentation and disambiguation of the source text -aspects which could be significantly improved by named entity recognition. We further suggest an automatic method for distinguishing and lexical differences in MT output that could have applications in automated MT evaluation for morphologically rich languages. Introduction Language communities develop certain acceptable practices and norms for translating different types of concepts, expressions and texts from other languages and cultures. These practices are described as translation methods, translation strategies and translation procedures. (Vinay and Darbelnet, 1958, 1995) . Translation methods relate to whole texts, while strategies and (finer-grained) procedures relate to sentences and smaller units (Newmark, 1988:81) . The choice of a translation strategy often depends on the type of a translated unit. For example, for certain types of proper names the optimal translation strategy is transference, i.e., a \"donot-translate\" or \"transliterate\" strategy, while the majority of common nouns are translated with other strategies: literal translation, transposition, modulation, etc. (Newmark, 1988: 81-88) . This implies that recognising different types of units in the source text is a necessary condition for optimising the choice of translation strategy and, ultimately, for improving the quality of the target text. The problem of selecting translation strategies for words that may be used as proper names or common nouns in the source language is related to a more general problem of word sense disambiguation (WSD) -one of the most serious problems for Machine Translation technology. Dealing with \"proper vs common disambiguation\" (PCD) often requires combining different knowledge sources, in a similar way to WSD (Stevenson and Wilks, 2001) . But the cross-level nature of this problem also suggests that improvement in MT quality could be achieved through improving related aspects of the source-text analysis, such as Named Entity (NE) recognition (Babych and Hartley, 2003; Somers, 2003:524) . For the purposes of this discussion, we assimilate proper nouns to NEs and investigate NE recognition as a possible solution to the PCD problem insofar as it might enable the selection of the correct strategy. Accurate NE recognition is important for the general quality of MT for the following reasons: 1. The translation of the same token may be different depending on whether the token is a common noun or part of an NE, e.g. in Russian if a common name is a part of an organization name, a \"do-not-translate\" or \"transliterate\" strategy should be used instead of a default translation strategy: (1) Original: \u2026the Los Angeles office of the Hay Group, a management consulting firm. In this case, NE recognition affects mainly morpho-syntactic segmentation, but individual words normally have correct translation strategies. However, a different morpho-syntactic context often requires the selection of a different translation strategy (either within or outside NEs), which may cause PCD errors in MT output, so there is an indirect link between morpho-syntactic disambiguation and PCD e.g.: MT output (3) Original: Moody's Investors Service Inc. placed the long-term debt under review. MT output: \u0418\u043d\u0432\u0435\u0441\u0442\u043e\u0440\u044b \u041c\u0443\u0434\u0438 \u041e\u0431\u0441\u043b\u0443\u0436\u0438\u0432\u0430\u044e\u0442 \u043a\u043e\u043c\u043f\u0430\u043d\u0438\u044e, \u043f\u043e\u043c\u0435\u0441\u0442\u0438\u043b \u0434\u043e\u043b\u0433\u043e\u0441\u0440\u043e\u0447\u043d\u044b\u0439 \u0434\u043e\u043b\u0433 \u043f\u043e\u0434 \u043e\u0431\u0437\u043e\u0440\u043e\u043c. ('Investors of Moody serve the company, he placed the long-term debt under review'). Here the NE Investors Service Inc. is not treated as a single segment, which causes a combined morpho-syntactic and PCD error: the system translates the word service as a verb that means 'to serve' instead of using the correct \"do-nottranslate\" strategy. Thus NE recognition could be beneficial both for morpho-syntactic well-formedness and for correct PCD in MT output. In (Babych and Hartley, 2003) we addressed the first of these two problems. In this paper, we concentrate on the second problem and show how PCD can be improved using existing NE recognition modules. Certain types of NEs, such as organisation names, appear to be a weak point even for some leading-edge MT systems, such as Systran and Reverso. At the same time, the problem of accurate NE recognition has been specifically addressed and benchmarked by the developers of information extraction (IE) systems. For example, the NE recognition module of the ANNIE IE system achieves a combined Precision & Recall score of 80-90% on news texts (Cunningham et al., 2002) . Our suggestion is that combining this highly accurate NE recognition module with state-of-the-art MT systems would be beneficial for MT output, even if we do not change any of the other MT components. The source code for commercial MT systems is not publicly available, so for our experiment we used one of the pre-processing tools of these systems -\"do-not-translate\" (DNT) lists. These lists were created from NE annotation produced by the ANNIE NE recognition module. For each of the three available MT systems we generated two different translations: a baseline translation and the DNT-processed translation. We made an approximate distinction between PCD and morpho-syntactic differences automatically using statistical frequency weights similar to tf.idf scores. We evaluated the improvement in PCD by manually annotating the PCD differences in the baseline and NE-processed MT output. The remainder of the paper is organised as follows: in section 2 we discuss the rationale of our automated method for distinguishing lexical and morpho-syntactic differences in MT output. In section 3 we describe the linguistic resources and scoring procedure used in the experiment. In section 4 we present the PCD improvement achieved for three MT systems. Section 5 points out possible applications of the work to automatic MT evaluation. In section 6 we discuss conclusions and future work. Distinguishing lexical and morphosyntactic differences in MT output DNT-processing causes both morpho-syntactic and lexical differences in compared translations. In example (4) we annotate lexical (L) and morpho-syntactic (M) differences in the reference and DNT-processed translations. These differences are due to the fact that the company name \"Eastern (Airlines)\" received a correct morpho-syntactic category as a result of DNTprocessing (Noun, not Adjective). Moreover, not translating this company name is the correct option for Russian target text. Original Baseline DNT-proc. L Eastern \u0412\u043e\u0441\u0442\u043e\u0447\u043d\u044b\u0439 ('Eastern (ADJ) ') Eastern (not translated) L Current \u043f\u043e\u0442\u043e\u043a\u0430 (stream (NOUN) ') \u0442\u0435\u043a\u0443\u0449\u0438\u0445 ('current (ADJ) ') L Contract \u0437\u0430\u043a\u043b\u044e\u0447\u0430\u044e\u0442 ('conclude (VERB) ') \u043a\u043e\u043d\u0442\u0440\u0430\u043a\u0442\u0430 ('contract (NOUN) ') M Moved \u043f\u0435\u0440\u0435\u043c\u0435\u0449\u0435\u043d\u043d\u044b\u0439 (PARTICIPLE) \u043f\u0435\u0440\u0435\u043c\u0435\u0441\u0442\u0438\u043b (VERB) M Cost \u0441\u0442\u043e\u0438\u043c\u043e\u0441\u0442\u0438 (GEN) \u0441\u0442\u043e\u0438\u043c\u043e\u0441\u0442\u044c\u044e (INST) M Agreements \u0441\u043e\u0433\u043b\u0430\u0448\u0435\u043d\u0438\u044f (ACC) \u0441\u043e\u0433\u043b\u0430\u0448\u0435\u043d\u0438\u0439 (GEN) Table 1 . Examples of translation differences In this example, all six variants in the DNTprocessed translation are better than their counterparts in the baseline translation. Note that a correct PCD choice for lexical differences is determined by the senses of the words in the source text, and there is no way of correctly using lexical items from the baseline translation as alternative translations. In contrast, the source text does not require particular values of morpho-syntactic categories in the target text. These values are determined by the rules of the target language and by the morpho-syntactic structure of a sentence, chosen by a translator. In many cases these values can be subject to greater variation then the lexical choices. For example, there is a legitimate way of using the last two words in the Table 1 in the genitive and accusative case, as in the baseline translation shown in example (5), if these values are required by their morpho-syntactic position: (5) \u041f\u0440\u0435\u0434\u043b\u0430\u0433\u0430\u044f \u0434\u0430\u0442\u0443 \u0432\u0441\u0442\u0440\u0435\u0447\u0438, Eastern \u043f\u0435\u0440\u0435\u043c\u0435\u0441\u0442\u0438\u043b\u0441\u044f \u043d\u0430 \u043e\u0434\u0438\u043d \u0448\u0430\u0433 \u0431\u043b\u0438\u0436\u0435 \u043a \u0442\u043e\u043c\u0443, \u0447\u0442\u043e\u0431\u044b \u043f\u043e\u0432\u0442\u043e\u0440\u043d\u043e \u043e\u0442\u043a\u0440\u044b\u0442\u044c \u0442\u0435\u043a\u0443\u0449\u0438\u0435 \u043a\u043e\u043d\u0442\u0440\u0430\u043a\u0442\u043d\u044b\u0435 \u0441\u043e\u0433\u043b\u0430\u0448\u0435\u043d\u0438\u044f (ACC) \u0432\u044b\u0441\u043e\u043a\u043e\u0439 \u0441\u0442\u043e\u0438\u043c\u043e\u0441\u0442\u0438 (GEN) . ('By proposing a meeting date, Eastern moved one step closer toward that [situation], to reopen current agreements (ACC) of high cost (GEN) ) A rough distinction between morpho-syntactic and lexical differences in the compared output texts can be drawn automatically using term frequency weights proposed in (Babych, Hartley, Atwell, 2003) for evaluating MT for Information Extraction purposes. These weights (S-scores) are similar to tf.idf scores: they describe the relative salience of terms in a particular text. They were found to make an accurate distinction between content and function words. With a varying degree of accuracy (depending on how analytic the grammar of a given language is) this distinction also separates lexical and morphosyntactic differences in compared texts. For Russian (which has a not highly analytic grammar) it achieves 88.4% Precision for lexical items, while for French the Precision is 98%. The S-scores are computed for each word in each text using the following formula: ( ) ) ( ) ( )] ( ) , ( / ) ( log ) , ( i corp i i doc corp j i doc P N df N P P j i S \u2212 \u00d7 \u2212 = \u2212 where: -P doc(i,j) is the relative frequency of the word in the text; (\"Relative frequency\" is the number of tokens of this word-type divided by the total number of tokens). -P corp-doc(i) is the relative frequency of the same word in the rest of the corpus, without this text; -P corp(i) is the relative frequency of the word in the whole corpus, including this particular text. -df i is the number of documents in the corpus where the word w i occurs (the document frequency); -N is the total number of documents in the corpus; We computed S-scores for words with: (P doc(i,j) -P corp-doc(i) ) > 0; AbsFrq i > 1, where AbsFrq i is the number of occurrences of the word w i in the corpus. Table 2 illustrates the ranking of words according to their S-score for one of the English texts from MUC6 NE corpus, for which tf i,j > 1 (tf i,j is the number of occurrences of the word w i in the document d j ). We established by experiment that a reasonable threshold for distinguishing content words and functional words is: S-score = 1 This threshold gives good results for text in all analysed languages: English, French and Russian. Our assumption implies that for comparing lexical differences in two variants of translation we need to compare for each text sets of words with an S-score above the threshold. Accordingly, all words that were different in each set were automatically highlighted in their respective texts and presented for manual scoring. In the examples of MT in the following sections, words with tf i,j > 1 are bold, words with tf i,j = 1 are bold and italic. In the original English sentences, the NEs used for the DNT lists are highlighted in bold. Resources and scoring method For our experiment we used the following linguistic resources: 30 texts (news articles) which were processed with the NE recognition module of the GATE-1 IE system in the DARPA MUC6 competition. The results of manual NE annotation were also available, but GATE NE recognition is sufficiently accurate for these texts (Recall -84%, Precision -94 %, Precision and Recall -89.06% (Gaizauskas et al, 1995) ) that errors in the GATE output will not have had a major impact on our results. Table 3 summarises the statistical parameters of the corpus analysed. The corpus is rich in NEs, so the effect of NE recognition on PCD could be accurately measured for the MT systems. Number of: For the corpus Av. per doc. Av. per para. Av All differences highlighted in the whole MUC-6 NE corpus were manually annotated for each of the MT systems under consideration. Cases of morpho-syntactic differences were also annotated and excluded from the scored set of differences. The number of annotated differences is presented in Table 4 :  The larger number of differences and the lower Precision for the Russian system can be attributed to the largely synthetic morphology of Russian. ProMT 1998 E-R The overall score for improvement / decline in PCD for each MT system was calculated as a sum of all scores of lexical differences divided by the number of lexical differences for the particular system. Results of the experiment for PCD The set-up of this experiment gives a reasonable estimate of the influence of NE recognition on MT quality, and suggests that if improvement in MT can be achieved via pre-processing tools, then we can expect even greater improvement when an NE recognition module is properly integrated into MT systems (e.g., types of NEs requiring non-transference translation strategies are also distinguished). The improvement achieved for the MT systems under consideration was around 20%. The results of manual annotation are summarised in Table 5 :  All systems showed consistent improvement in PCD tasks after NE recognition. The results indicate that systematic NE recognition has great potential for improving the quality of MT, and that successful PCD depends on appropriate analysis of other aspects in the source text, such as determining correct values for morphological categories and correct syntactic segmentation. These aspects could be substantially improved via NE recognition. However, finding appropriate segmentation and morpho-syntactic disambiguation is a necessary but not a sufficient condition for achieving improvement in MT: most cases of decline in MT quality after DNT-processing are due to the lack of flexibility in determining the optimal translation strategy for NEs. In our experiment, the overall improvement in the quality of PCD is due to the fact that the transference (\"do-not-translate\") strategy is optimal, or it is an acceptable translation strategy for the majority of NE that occurred in our corpus (Newmark, 1982) . But many NEs might need to be translated by specific translation equivalents that are normally recognised by the state-of-the-art MT systems. This is especially important for names of well-known organisations, such as 'The Treasury', 'The Army', 'The Navy' 'Labour', which are often part of more complex NEs: 'The Treasury Secretary', 'The Labour Government', 'The Army Chief' -in all these cases a \"do-not-translate\" strategy could cause a serious decline in MT quality. Our analysis suggests that targeting specific needs of MT could be a way of improving MT quality with IE technology: the NE recognition stage could meet the needs of MT systems by distinguishing different classes of NEs which require different translation strategies. Appropriate annotation of these NEs in the source text could then guide the MT system at the transfer stage. Conclusions and future work We have characterised the potential improvement in PCD for MT systems achievable with accurate NE recognition. The results indicate that PCD is very sensitive to those aspects of MT quality which can be improved with NE recognition: finding appropriate morpho-syntactic categories and correct segmentation for NEs often influences the correctness of the general analysis of the source sentence. But some aspects of PCD cannot be improved with existing NE recognition and need to be addressed by the IE and MT communities jointly. NE recognition modules can be extended to distinguish between types of NEs that require different translation strategies; and MT systems can be adapted to deal more flexibly with user input, by using NE annotation designed specifically for MT purposes. The proposed method of making a rough automatic distinction between lexical and morpho-syntactic differences allowed us to annotate important features in a relatively large corpus within a reasonable amount of time. We suggest that this method could have applications in other domains of NLP, in particular -in automated MT evaluation and in automatic alignment of parallel texts. Application to automatic MT evaluation Current automatic evaluation methods, such as BLEU (Papineni et al., 2001) , do not make a distinction between lexical and morpho-syntactic differences, but distinguishing them and controlling the quality of MT on several separate levels might be useful to for the evaluation of MT systems under development (especially for target languages with a rich morphology, where these two types of differences clearly characterise different aspects of quality). Another important problem for further research is establishing whether different degrees of legitimate variation in translation are allowed for items with different tf.idf and S-scores. One of the most serious problems for the BLEU method is related to legitimate variability in the reference translation. In order not to penalise acceptable MT that is different from human translation, the metric uses several reference translations of the same text. These resources can be expensive to create. However, if terms with different significance scores show different levels of legitimate variation, then the metric could rely on potentially more stable terms, so fewer reference texts would be needed to produce consistent evaluation scores for MT systems. Yet another problem for the BLEU metric is high data scarcity of N-grams in languages with complex synthetic morphology, such as Slavonic languages. In order to achieve evaluation scores comparable with scores for English or other analytical languages, we need to use much larger reference corpora of human translations. An alternative solution to this problem could be to make automatically a rough distinction between lexical and morphological differences and to concentrate on the lexical differences that are expected to be less sparse across human translations and MT output. Application to automatic alignment of parallel texts An analysis of S-scores (Section 2) of lexical differences in the compared translations also gives interesting results. It can be noted that words which are translations of the same word in the DNT-processed and the baseline target texts have very close scores. Ranked lists of differences for Russian MT are presented in  The match between S-scores is closer for words with a unique translation, which implies that they have similar distribution in the text and in the corpus. Another interesting property of the statistical significance measure is that different word forms which are translations of the same word (e.g., an English NE) often have very close S-scores, which are also close to the score of the original word. For example, S-scores for the first word in the NE \"Pan Am\" and for three morphological variants of its wrong translation into Russian are presented in Table 7 . All are variants of the lexeme \"\u043a\u0430\u0441\u0442\u0440\u044e\u043b\u044f\" -'saucepan', and also have different frequencies in the text. This effect is also the strongest for words which have a unique translation in the corpus.  This property of the S-score may be useful in MT evaluation for highly inflected languages. Future work in this direction will involve measuring the accuracy of the suggested method of distinguishing morpho-syntactic and lexical differences in MT output for typologically different languages and evaluating the degree of legitimate variation in translation at different levels of the significance scores.",
    "funding": {
        "defense": 0.0,
        "corporate": 0.0,
        "research agency": 0.0,
        "foundation": 1.9361263126072004e-07,
        "none": 1.0
    },
    "reasoning": "Reasoning: The article does not provide any specific information regarding funding from defense, corporate entities, research agencies, foundations, or any other sources. Without explicit mention of funding sources, it is not possible to accurately determine the presence of any specific type of funding."
}