{
    "article": "We address corpus building situations, where complete annotations to the whole corpus is time consuming and unrealistic. Thus, annotation is done only on crucial part of sentences, or contains unresolved label ambiguities. We propose a parameter estimation method for Conditional Random Fields (CRFs), which enables us to use such incomplete annotations. We show promising results of our method as applied to two types of NLP tasks: a domain adaptation task of a Japanese word segmentation using partial annotations, and a partof-speech tagging task using ambiguous tags in the Penn treebank corpus. Introduction Annotated linguistic corpora are essential for building statistical NLP systems. Most of the corpora that are well-known in NLP communities are completely-annotated in general. However it is quite common that the available annotations are partial or ambiguous in practical applications. For example, in domain adaptation situations, it is time-consuming to annotate all of the elements in a sentence. Rather, it is efficient to annotate certain parts of sentences which include domain-specific expressions. In Section 2.1, as an example of such efficient annotation, we will describe the effectiveness of partial annotations in the domain adaptation task for Japanese word segmentation (JWS). In addition, if the annotators are domain experts c 2008. Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/). Some rights reserved. rather than linguists, they are unlikely to be confident about the annotation policies and may prefer to be allowed to defer some linguistically complex decisions. For many NLP tasks, it is sometimes difficult to decide which label is appropriate in a particular context. In Section 2.2, we show that such ambiguous annotations exist even in a widely used corpus, the Penn treebank (PTB) corpus. This motivated us to seek to incorporate such incomplete annotations into a state of the art machine learning technique. One of the recent advances in statistical NLP is Conditional Random Fields (CRFs) (Lafferty et al., 2001) that evaluate the global consistency of the complete structures for both parameter estimation and structure inference, instead of optimizing the local configurations independently. This feature is suited to many NLP tasks that include correlations between elements in the output structure, such as the interrelation of part-of-speech (POS) tags in a sentence. However, conventional CRF algorithms require fully annotated sentences. To incorporate incomplete annotations into CRFs, we extend the structured output problem in Section 3. We focus on partial annotations or ambiguous annotations in this paper. We also propose a parameter estimation method for CRFs using incompletely annotated corpora in Section 4. The proposed method marginalizes out the unknown labels so as to optimize the likelihood of a set of possible label structures which are consistent with given incomplete annotations. We conducted two types of experiments and observed promising results in both of them. One was a domain adaptation task for JWS to assess the proposed method for partially annotated data. The other was a POS tagging task using ambiguous annotations that are contained in the PTB corpus. We summarize related work in Section 6, and conclude Incomplete Annotations Partial Annotations In this section, we describe an example of an efficient annotation which assigns partial word boundaries for the JWS task. It is not trivial to detect word boundaries for non-segmented languages such as Japanese or Chinese. For example, the correct segmentation of the Japanese phrase \" \" (incised wound or abrasion) is shown by the lowest boxes segmented by the solid lines in Figure 1 . However, there are several overlapping segmentation candidates, which are shown by the other boxes, and possible segmentation by the dashed lines. Thus, the decisions on the word segmentation require considering the context, so simple dictionary lookup approach is not appropriate. Therefore statistical methods have been successfully used for JWS tasks. Previous work (Kudo et al., 2004) showed CRFs outperform generative Markov models and discriminative history-based methods in JWS. In practice, a statistical word segment analyzer tends to perform worse for text from different domains, so that additional annotations for each target domain are required. A major cause of errors is the occurrence of unknown words. For example, if \" \" (abrasion) is an unknown word, the system may accept the word sequence of \" \" as \" \" (incised wound), \" \" (file), and \" \" (injury) by mistake. On one hand, lists of new terms in the target domain are often available in the forms of technical term dictionaries, product name lists, or other sources. To utilize those domain word lists, Mori (2006) proposed a KWIC (KeyWord In Context) style annotation user interface (UI) with which a user can delimit a word in a context with a single user action. In Figure 2 , an annotator marks the occurrences of \" \", a word in the domain word list, if they are used as a real word in their context. The \" \" in the first row is a part of another word \" \" (scratch), and the annotator marks the last two rows as correctly segmented examples. This UI simplifies annotation operations for segmentation to yes/no decisions, and this simplification can also be effective for the reduction of the annotation effort for other NLP tasks. For example, the annotation operations for unlabeled dependency parsing can be simplified into a series of yes/no decisions as to whether or not given two words have syntactic dependency. Compared with sentence-wise annotation, the partial annotation is not only effective in terms of control operations, but also reduces annotation errors because it does not require annotating the word boundaries that an annotator is unsure of. This feature is crucial for annotations made by domain experts who are not linguists. 1 We believe partial annotation is effective in creating corpora for many other structured annotations in the context of the domain adaptations. Ambiguous Annotations Ambiguous annotations in this paper refer to a set of candidate labels annotated for a part of a structured instance. For example, the following sentence from the PTB corpus includes an ambiguous annotation for the POS tag of \"pending\": That/DT suit/NN is/VBZ pending/VBG|JJ ./. , where words are paired with their part-of-speech tag by a forward slash (\"/\"). 2 Uncertainty concerning the proper POS tag of \"pending\" is represented by the disjunctive POS tag (\"VBG and JJ\") as indicated by a vertical bar. The existence of the ambiguous annotations is due to the task definition itself, the procedure man-1 The boundary policies of some words are different even among linguists. In addition, the boundary agreement is even lower in Chinese (Luo, 2003 ual for the annotators, or the inadequate knowledge of the annotators. Ideally, the annotations should be disambiguated by a skilled annotator for the training data. However, even the PTB corpus, whose annotation procedure is relatively welldefined, includes more than 100 sentences containing POS ambiguities such as those listed in Table 1. Although the number of ambiguous annotations is not considerably large in PTB corpus, corpora could include more ambiguous annotations when we try to build wider coverage corpora. Also, ambiguous annotations are more common in the tasks that deal with semantics, such as information extraction tasks so that learning algorithms must deal with ambiguous annotations. Problem Definition In this section, we give a formal definition of the supervised structured output problem that uses partial annotations or ambiguous annotations in the training phase. Note that we assume the input and output structures are sequences for the purpose of explanation, though the following discussion is applicable to other structures, such as trees. Let x=(x 1 , x 2 , \u2022 \u2022 \u2022 , x T ) be a sequence of observed variables x t \u2208 X and y=(y 1 , y 2 , \u2022 \u2022 \u2022 , y T ) be a sequence of label variables y t \u2208 Y . Then the supervised structured output problem can be defined as learning a map X \u2192 Y . In the Japanese word segmentation task, x can represent a given sequence of character boundaries and y is a sequence of the corresponding labels, which specify whether the current position is a word boundary. 3 In the POS tagging task, x represents a word sequence and y is a corresponding POS tag sequence. An incomplete annotation, then, is defined as a sequence of subset of the label set instead of a sequence of labels. Let L=(L 1 , L 2 , \u2022 \u2022 \u2022 , L T ) be a sequence of label subsets for an observed sequence x, where L t \u2208 2 Y \u2212 {\u2205}. The partial annotation at position s is where L s is a singleton and the rest L t =s is Y . For example, if a sentence with 6 character boundaries (7 characters) is partially annotated using the KWIC UI described in Section 2.1, a word annotation where its boundary begins with t = 2 and ends with t = 5 will be represented as: L = ({ , \u00d7}, { }, {\u00d7}, {\u00d7}, { } partial annotation , { , \u00d7}), where and \u00d7 denote the word boundary label and the non-word boundary label, respectively. The ambiguous annotation is represented as a set which contains candidate labels. The example sentence including the ambiguous POS tag in Section 2.2 can be represented as: L = ({DT}, {NN}, {VBZ}, {VBG, JJ} ambiguous annotation , {.}). Note that, if all the elements of a given sequence are annotated, it is the special case such that the size of all elements is one, i.e. |L t | = 1 for all t = 1, \u2022 \u2022 \u2022 , T . The goal in this paper is training a statistical model from partially or ambiguously annotated data, D = {(x (n) , L (n) )} N n=1 . Marginalized Likelihood for CRFs In this section, we propose a parameter estimation procedure for the CRFs (Lafferty et al., 2001) incorporating partial or ambiguous annotations. Let \u03a6(x, y) : X \u00d7 Y \u2192 d denote a map from a pair of an observed sequence x and a label sequence y to an arbitrary feature vector of d dimensions, and \u03b8 \u2208 d denotes the vector of the model parameters. CRFs model the conditional probability of a label sequence y given an observed sequence x as: P \" (y|x) = e \"\u2022\u03a6(x,y) Z \",x,Y (1) where \u2022 denotes the inner product of the vectors, and the denominator is the normalization term that guarantees the model to be a probability: (x,y) . Z \",x,S = y\u2208S e \"\u2022\u03a6 Then once \u03b8 has been estimated, the label sequence can be predicted by \u0177 = argmax y\u2208Y P \" (y|x). Since the original CRF learning algorithm requires a completely labeled sequence y, the incompletely annotated data (x, L) is not directly applicable to it. Let Y L denote all of the possible label sequence consistent with L. We propose to use the conditional probability of the subset Y L given x: P \" (Y L |x) = y\u2208Y L P \" (y|x), (2) which marginalizes the unknown ys out. Then the maximum likelihood estimator for this model can be obtained by maximizing the log likelihood function: LL(\u03b8) = N n=1 ln P \" (Y L (n) |x (n) ) (3) = N n=1 ln Z \",x (n) ,Y L (n) \u2212 ln Z \",x (n) ,Y . This modeling naturally embraces label ambiguities in the incomplete annotation. 4  Unfortunately, equation ( 3 ) is not a concave function 5 so that there are local maxima in the objective function. Although this non-concavity prevents efficient global maximization of equation ( 3 ), it still allows us to incorporate incomplete annotations using gradient ascent iterations (Sha and Pereira, 2003) . Gradient ascent methods require the partial derivative of equation (3): \u2202 LL(\u03b8) \u2202\u03b8 = N n=1 \u239b \u239d y\u2208Y L (n) P \" (y|Y L (n) , x (n) )\u03a6(x (n) , y) \u2212 y\u2208Y P \" (y|x (n) )\u03a6(x (n) , y) \u239e \u23a0 , (4) where P \" (y|Y L , x) = e \"\u2022\u03a6(x,y) Z \",x,Y L (5) is a conditional probability that is normalized over Y L . Equations ( 3 ) and ( 4 ) include the summations of all of the label sequences in Y or Y L . It is not practical to enumerate and evaluate all of the label configurations explicitly, since the number of all of the possible label sequences is exponential on the number of positions t with |L t | > 1. However, under the Markov assumption, a modification of the  Forward-Backward algorithm guarantees polynomial time computation for the equations ( 3 ) and (4). We explain this algorithm in Appendix A. \u22122 c \u22121 , c \u22121 c +1 , c +1 c +2 , Term in dic. c \u22122 c \u22121 c +1 , c \u22121 c +1 c +2 Term in dic. starts at c \u22121 , c +1 Term in dic. ends at Experiments We conducted two types of experiments, assessing the proposed method in 1) a Japanese word segmentation task using partial annotations and 2) a POS tagging task using ambiguous annotations. Japanese Word Segmentation Task In this section, we show the results of domain adaptation experiments for the JWS task to assess the proposed method. We assume that only partial annotations are available for the target domain. In this experiment, the corpus for the source domain is composed of example sentences in a dictionary of daily conversation (Keene et al., 1992) . The text data for the target domain is composed of sentences in a medical reference manual (Beers, 2004) . The sentences of all of the source domain corpora (A), (B) and a part of the target domain text (C) were manually segmented into words (see Table 2 ). The performance measure in the experiments is the standard F measure score, F = 2RP/(R + P ) where R = # of correct words # of words in test data \u00d7 100 P = # of correct words # of words in system output \u00d7 100. In this experiment, the performance was evaluated using 2-fold cross-validation that averages the results over two partitions of the data (C) into the  We implemented first order Markov CRFs. As the features for the observed variables, we use the characters and character type n-gram (n=1, 2, 3) around the current character boundary. The character types are categorized into Hiragana, Katakana, Kanji, English alphabet, Arabic numerals, and symbols. We also used lexical features consulting a dictionary: one is to check if any of the above defined character n-grams appear in a dictionary (Peng et al., 2004) , and the other is to check if there are any words in the dictionary that start or end at the current character boundary. We used the unidic 6 (281K distinct words) as the general purpose dictionary, and the Japanese Standard Disease Code Master (JSDCM) 7 (23K distinct words) as the medical domain dictionary. The templates for the features we used are summarized in Table 3 . To reduce the number of parameters, we selected only frequent features in the source domain data (A) or in about 50K of the unsegmented sentences of the target domain. 8 The total number of distinct features was about 300K. A CRF that was trained using only the source domain corpus (A), CRF S , achieved F =96.84 in the source domain validation data (B). However, it showed the need for the domain adaptation that this CRF S suffered severe performance degradation (F =92.3) on the target domain data. This experiment was designed for the case in which a user selects the occurrences of words in the word list using the KWIC interface described in Section 2.1. We employed JSDCM as a word list in which 224 distinct terms appeared on average over 2 test sets (C1). The number of word an-notations varied from 100 to 1000 in this experiment. We prioritized the occurrences of each word in the list using a selective sampling technique. We used label entropy (Anderson et al., 2006) , H(y s t ) = y s t \u2208Y s t P \"(y s t |x) ln P \"(y s t |x) , as importance metric of each word occurrence, where \u03b8 is the model parameter of CRF S , and y s t = (y t , y t+1 , \u2022 \u2022 \u2022 , y s ) \u2208 Y s t is a subsequence starting at t and ending at s in y. Intuitively, this metric represents the prediction confidence of CRF S . 9 As training data, we mixed the complete annotations (A) and these partial annotations on data (C1) because that performance was better than using only the partial annotations. We used conjugate gradient method to find the local maximum value with the initial value being set to be the parameter vector of CRF S . Since the amount of annotated data for the target domain was limited, the hyper-parameter \u03c3 was selected using the corpus (B). For the comparison with the proposed method, the CRFs were trained using the most probable label sequences consistent with L (denoted as argmax). The most probable label sequences were predicted by the CRF S . Also, we used a point-wise classifier, which independently learns/classifies each character boundary and just ignores the unannotated positions in the learning phase. As the point-wise classifier, we implemented a maximum entropy classifier which uses the same features and optimizer as CRFs. Figure 3 shows the performance comparisons varying the number of word annotations. The combination of both the proposed method and the selective sampling method showed that a small number of word annotations effectively improved the word segmentation performance. In addition, the proposed method significantly outperformed argmax and point-wise classifier based on the Wilcoxon signed rank test at the significance level of 5%. This result suggests that the proposed method maintains CRFs' advantage over the point-wise classifier and properly incorporates partial annotations. Part-of-speech Tagging Task In this section, we show the results of the POS tagging experiments to assess the proposed method using ambiguous annotations. As mentioned in Section 2.2, there are words which have two or more candidate POS tags in the PTB corpus (Marcus et al., 1993) . In this experiment, we used 118 sentences in which some words (82 distinct words) are annotated with ambiguous POS tags, and these sentences are called the POS ambiguous sentences. On the other hand, we call sentences in which the POS tags of these terms are uniquely annotated as the POS unique sentences. The goal of this experiment is to effectively improve the tagging performance using both these POS ambiguous sentences and the POS unique sentences as the training data. We assume that the amount of training data is not sufficient to ignore the POS ambiguous sentences, or that the POS ambiguous sentences make up a substantial portion of the total training data. Therefore we used a small part (1/10 or 1/5) of the POS unique sentences for training the CRFs and evaluated their performance using other (4/5) POS unique sentences. We conducted two experiments in which different numbers of unique sentences were used in the training phases, and these settings are summarized in Table 4. The feature sets for each word are the caseinsensitive spelling, the orthographic features of the current word, and the sentence's last word. The orthographic features are whether a spelling begins with a number or an upper case letter; whether it begins with an upper case letter and contains a period (\".\"); whether it is all upper case letters or all lower case letters; whether it contains a punctuation mark or a hyphen; and the last one, two, and three letters of the word. Also, the sentence's last word corresponds to a punctuation mark (e.g. \".\", \"?\", \"!\"). We employed only features that appeared more than once. The total number of resulting distinct features was about 14K. Although some symbols are treated as distinct tags in the PTB tag definitions, we aggregated these symbols into a symbol tag (SYM) since it is easy to restore original symbol tags from the SYM tag. Then, the number of the resulting tags was 36. For the comparison with the proposed method (mrg), we used three heuristic rules that disambiguated the annotated candidate POS tags in the POS ambiguous sentences. These rules selected a POS tag 1) at random, 2) as the first one in the description order 10 , 3) as the most frequent tag in the corpus. In addition, we evaluated the case when the POS ambiguous sentences are 4) discarded from the training data. For evaluation, we employed the Precision (P) and Average Precision for Ambiguous words (APA): P = # of correctly tagged word # of all word occurrences \u00d7100 APA = 1 |A| w\u2208A # of the correctly tagged w # of all occurrences of w \u00d7100 where A is a word set and is composed of the word for which at least one of its occurrences is ambiguously annotated. Here, we employed APA to evaluate each ambiguous words equally, and |A| was 82 in this experiment. Again, we used the conjugate gradient method to find the local maximum value with the initial value being set to be the parameters obtained in the CRF learning for the discarded setting. Table 5 shows the average performance of POS tagging over 5 different POS unique data. Since the POS ambiguous sentences are only a fraction of all of the training data, the overall performance (P) was slightly improved by the proposed method. However, according to the performance for ambiguously annotated words (APA), the proposed method outperformed other heuristics for POS disambiguation. The P and APA scores between the proposed method and the comparable methods are significantly different based on the Wilcoxon signed rank test at the 5% significance level. Although the performance improvement in this POS tagging task was moderate, we believe the proposed method will be more effective to the NLP tasks whose corpus has a considerable number of ambiguous annotations. 6 Related Work Pereira and Schabes (1992) proposed a grammar acquisition method for partially bracketed corpus. Their work can be considered a generative model for the tree structure output problem using partial annotations. Our discriminative model can be extended to such parsing tasks. Our model is interpreted as one of the CRFs with hidden variables (Quattoni et al., 2004) . There are previous work which handles hidden variables in discriminative parsers (Clark and Curran, 2006; Petrov and Klein, 2008) . In their methods, the objective functions are also formulated as same as equation (3). For interactive annotation, Culotta et al. (2006) proposed corrective feedback that effectively reduces user operations utilizing partial annotations. Although they assume that the users correct entire label structures so that the CRFs are trained as usual, our proposed method extends their system when the users cannot annotate all of the labels in a sentence. Conclusions and Future Work We are proposing a parameter estimation method for CRFs incorporating partial or ambiguous annotations of structured data. The empirical results suggest that the proposed method reduces the domain adaptation costs, and improves the prediction performance for the linguistic phenomena that are sometimes difficult for people to label. The proposed method is applicable to other structured output tasks in NLP, such as syntactic parsing, information extraction, and so on. However, there are some NLP tasks, such as the word alignment task (Taskar et al., 2005) , in which it is not possible to efficiently calculate the sum score of all of the possible label configurations. Recently, Verbeek and Triggs (2008) independently proposed a parameter estimation method for CRFs using partially labeled images. Although the objective function in their formulation is equivalent to equation (3), they used Loopy Belief Propagation to approximate the sum score for their application (scene segmentation). Their results imply these approximation methods can be used for such applications that cannot use dynamic programming techniques. Acknowledgments We would like to thank the anonymous reviewers for their comments. We also thank Noah Smith, Ryu Iida, Masayuki Asahara, and the members of the T-PRIMAL group for many helpful discussions. Appendix A Computation of Objective and Derivative functions Here we explain the effective computation procedure for equation ( 3 ) and (4) using dynamic programming techniques. Under the first-order Markov assumption 11 , two types of features are usually used: one is pairs of an observed variable and a label variable (denoted as f (x t , y t ) : X \u00d7 Y ), the other is pairs of two label variables (denoted as g(y t\u22121 , y t ) : Y \u00d7 Y ) at time t. Then the feature vector can be decomposed as \u03a6(x, y) = T +1 t=1 \u03c6(x t , y t\u22121 , y t ) where \u03c6(x t , y t\u22121 , y t ) = f (x t , y t ) + g(y t\u22121 , y t ). In addition, let S and E be special label variables to encode the beginning and ending of a sequence, respectively. We define \u03c6(x t , y t\u22121 , y t ) to be \u03c6(x t , S, y t ) at the head t = 1 and g(y t\u22121 , E) at the tail where t = T + 1. The technique of the effective calculation of the normalization value is the 11 Note that, although the rest of the explanation based on the first-order Markov models for purposes of illustration, the following arguments are easily extended to the higher order Markov CRFs and semi-Markov CRFs. precomputation of the \u03b1 \",x,L [t, j], and\u03b2 \",x,L [t, j] matrices with given \u03b8, x, and L. The matrices \u03b1 and \u03b2 are defined as follows, and should be calculated in the order of t = 1, \u2022 \u2022 \u2022 , T , and (xt,j,k)+\u03b2[t+1,k] else Note that L = (Y, \u2022 \u2022 \u2022 , Y ) is used to calculate all the entries in Y . In the rest of this section, we omit the subscripts \u03b8, x, and L of \u03b1, \u03b2, Z unless misunderstandings could occur. The time complexity of the \u03b1 Finally, equations ( 3 ) and ( 4 ) are efficiently calculated using \u03b1, \u03b2. The logarithm of Z in equation ( 3 ) is calculated as: ln Z \",Y L = ln j\u2208L T e \u03b1 \",L [T,j]+\"\u2022g(j,E) . Similarly, the first and second terms of equation ( 4 ) can be computed as: where \u03b8, x are omitted in this equation, and \u03b3 \",x,L and \u03b5 \",x,L are the marginal probabilities: \u03b3 \",x,L (t, j) = P \",L (y t = j|x) = e \u03b1[t,j]+\u03b2[t,j]\u2212ln Z Y L , and \u03b5 \",x,L (t, i, j) = P \",L (y t\u22121 = i, y t = j|x) = e \u03b1[t\u22121,i]+\"\u2022ffi(xt,i,j)+\u03b2[t,j]\u2212ln Z Y L . Note that Y L is replaced with Y and L = (Y, \u2022 \u2022 \u2022 , Y ) to compute the second term.",
    "abstract": "We address corpus building situations, where complete annotations to the whole corpus is time consuming and unrealistic. Thus, annotation is done only on crucial part of sentences, or contains unresolved label ambiguities. We propose a parameter estimation method for Conditional Random Fields (CRFs), which enables us to use such incomplete annotations. We show promising results of our method as applied to two types of NLP tasks: a domain adaptation task of a Japanese word segmentation using partial annotations, and a partof-speech tagging task using ambiguous tags in the Penn treebank corpus.",
    "countries": [
        "Japan"
    ],
    "languages": [
        "Chinese",
        "Japanese"
    ],
    "numcitedby": "85",
    "year": "2008",
    "month": "August",
    "title": "Training Conditional Random Fields Using Incomplete Annotations"
}