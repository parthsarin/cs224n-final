{
    "article": "In this paper, we investigate how topic dynamics during the course of an interaction correlate with the power differences between its participants. We perform this study on the US presidential debates and show that a candidate's power, modeled after their poll scores, affects how often he/she attempts to shift topics and whether he/she succeeds. We ensure the validity of topic shifts by confirming, through a simple but effective method, that the turns that shift topics provide substantive topical content to the interaction. Introduction Analyzing political speech has gathered great interest within the NLP community. Researchers have analyzed political text to identify markers of persuasion (Guerini et al., 2008) , predict voting patterns (Thomas et al., 2006; Gerrish and Blei, 2011) , and detect ideological positions (Sim et al., 2013) . Studies have also looked into how personal attributes of political personalities such as charisma, confidence and power affect how they interact (Rosenberg and Hirschberg, 2009; Prabhakaran et al., 2013b) . Our work belongs to this genre of studies. We analyze how a presidential candidate's power, modeled after his/her relative poll standings, affect the dynamics of topic shifts during the course of a presidential debate. Motivation In early work on correlating personal attributes to political speech, Rosenberg and Hirschberg (2009) analyzed speech transcripts in the context of 2004 Democratic presidential primary elections, to identify prosodic and lexico-syntactic cues that signal charisma of political personalities. More recently, Prabhakaran et al. (2013a) introduced the notion of power an election candidate has at a certain point in the election campaign, modeled after the confidence that stems from their recent poll standings. They analyzed the 2012 Republican presidential primary debates and found that the candidate's power at the time of a debate impacts the structure of interactions (e.g., frequency of turns and interruption patterns). They followed up their study with an automatic ranker to identify leading candidates based on the interaction within a debate (Prabhakaran et al., 2013b) . One of the interesting findings by Prabhakaran et al. (2013a) was that candidates' power correlates with the distribution of topics they speak about in the debates. They found that when candidates have more power, they speak significantly more about certain topics (e.g., economy) and less about certain other topics (e.g., energy). However, these findings relate to the specific election cycle they analyzed and will not carry over to all political debates in general. A topical dimension with broader relevance is how topics change during the course of an interaction (e.g., who introduces more topics, who attempts to shift topics etc.). For instance, Nguyen et al. (2013) found that topic shifts within an interaction are correlated with the role a participant plays in it (e.g., being a moderator). They also analyzed US presidential debates, but with the objective of validating a topic segmentation method they proposed earlier (Nguyen et al., 2012) . They do not study the topic shifting tendencies among the candidates in relation to their power differences. In this paper, we bring these two ideas together. We analyze the 2012 Republican presidential debates, modeling the power of a candidate based on poll scores as proposed by Prabhakaran et al. (2013a) and investigate various features that capture the topical dynamics in the debates. We show that the power affects how often candidates at- tempt to shift topics and whether they succeed in it or not. In order to correctly model topic shifts, we ensure that the shifts happen in turns that contribute substantial topical content to the interaction. We introduce the notion of a \"non-substantial turn\", and use a simple, but effective method to automatically identify non-substantial turns. This allows us to identify different topic segments within the interaction, while permitting (and capturing) interruptions within those segments. We will compare the segments that we obtain with those by Nguyen et al. ( 2012 ) in future work. Domain and Data We use the same corpus as Prabhakaran et al. (2013b) . The corpus contains manual transcripts of 20 debates held between May 2011 and February 2012 as part of the 2012 Republican presidential primaries. The transcripts are obtained from The American Presidency Project. 1 Each turn is clearly demarcated in the transcripts and their speakers are identified. The turns in the corpus are preprocessed using the Stanford CoreNLP package to perform basic NLP steps such as tokenization, sentence segmentation, parts-of-speech tagging and lemmatization. We show an excerpt 1 http://www.presidency.ucsb.edu/debates.php from one of the debates in Table 1 . This segment of the debate discusses marriage equality followed by the overturning of the \"Don't Ask/Don't Tell\" policy prohibiting openly gay, lesbian, or bisexual persons from US military service. Prabhakaran et al. (2013b) added each candidate's power at the time of each debate to the corpus, computed based on their relative standing in recent public polls. We refer the reader to (Prabhakaran et al., 2013b) for the detailed description of how the relative standings in national and statelevel polls from various sources are aggregated to obtain candidates' power. The poll numbers capture how successful candidates are in convincing the electorate of their candidature, which in turn affects their confidence within the debates. These debates serve as a rich domain to explore manifestations of power since they are a medium through which candidates pursue and maintain power over other candidates. 4 Modeling Topics Prabhakaran et al. (2013a) model topics in the debates using Latent Dirichlet Allocation (LDA), assigning topic probabilities to each turn. The number of topics was set to be 15 and the topic that was assigned the highest probability for a turn was cho-sen as its topic. Assigning topics to each turn in this manner, however, is problematic. Not all turns by themselves contribute to the conversational topics in an interaction. A large number of turns, especially by the moderator, manage the conversation rather than contribute content to it. These include turns redirecting questions to specific candidates (e.g., turns 224, 226 and 228 in Table 1 ) as well as moderator interruptions (e.g., \"Quickly.\", \"We have to save time\"). Furthermore, some other turns address a topic only when considered together with preceding turns, but not when read in isolation. These include turns that are short oneword answers (e.g., turn 227) and turns that are uninterpretable without resolving anaphora (e.g., \"That's right\"). While these turns are substantive to human readers, topic modeling approaches such as LDA cannot assign them topics correctly because of their terseness. We define the turns that do not, in isolation, contribute substantially to the conversational topics as non-substantive turns. In order to obtain a gold standard for non-substantivity, two of the authors manually annotated each turn in one entire debate (dated 06/13/11) as either substantive (S) or nonsubstantive (NS). The annotators were instructed not to consider the identity of the speaker or the context of the turn (preceding/following turns) in making their assessment. We obtained a high inter-annotator agreement (observed agreement = 89.3%; Kappa = .76). We took the assessments by one of the annotators as the gold standard, in which 108 (31.5%) of the 343 turns were identified as non-substantive. We show the S vs. NS assessments for each turn in column 4 of Table 1 . Figure 1a shows the line graph of topic probabilities assigned by LDA to the sequence of turns in Table 1 . As the graph shows, non-substantive turns are assigned spurious topic probabilities by LDA. For example, turn 224 by KING (\"OK. Lets just go through this.\") was assigned small probabilities for all topics; the highest of which was economy (probability of 0.12). This error is problematic when modeling topic shifts, since this turn and the next one by PAUL would have been incorrectly identified as shifts in topic from their corresponding previous turns. Instead, if we assume that the non-substantive turns follow the same topic probabilities as the most recent substantive turn, we obtain the line graph shown in Figure 1b . This topic assignment captures the topic dynam-  ics in the segment more accurately. It identifies Gay Rights as the predominant topic until turn 234 followed by a mix of Gay Rights and Military as topics while discussing the \"Don't Ask/Don't Tell' policy. It also captures the attempt by ROMNEY in turn 242 to shift the topic to Economy. Identifying Non-substantive Turns In order to automatically detect non-substantive turns, we investigate a few alternatives. A simple observation is that many of the NS turns such as redirections of questions or short responses have only a few words. We tried a word count threshold based method (WC Thresh) where we assign a turn to be NS if the number of tokens (words) in the turn is less than a threshold. Another intuition is that for a non-substantive turn, it would be hard for the LDA to assign topics and hence all topics will get almost equal probabilities assigned. In order to capture this, we used a method based on a standard deviation threshold (SD Thresh), where we assign a turn to be NS if the standard deviation of that turn's topic probabilities is below a threshold. We also used a combination system where we tag a turn to be NS if either system tags it to be. We tuned for the value of the thresholds and the best performances obtained for each case are shown in Table 2 . We obtained the best results for the WC Thresh method with a threshold of 28 words, while for SD Thresh the optimal threshold is .13 (almost twice the mean). Topic Assignments We first ran the LDA at a turn-level for all debates, keeping the number of topics to be 15, and selected the best model after 2000 iterations. Then, we ran the WC Thresh method described above to detect NS turns. For all NS turns, we replace the topic probabilities assigned by LDA with the last substantive turn's topic probabilities. Note that an S turn coming after one or more NS turns could still be of the same topic as the last S turn, i.e., non-substantivity of a turn is agnostic to whether the topic changes after that or not. A topic shift (or attempt) happens only when LDA assigns a different topic to a substantive turn. Topical Dimensions We now describe various features we use to capture the topical dynamics within each debate, with respect to each candidate. When we compute a feature value, we use the topic probabilities assigned to each turn as described in the previous section. For some features we only use the topic with the highest probability, while for some others, we use the probabilities assigned to all topics. We consider features along four dimensions which we describe in detail below. Topic Shift Patterns We build various features to capture how often a candidate stays on the topic being discussed. We say a candidate attempted to shift the topic in a turn if the topic assigned to that turn differs from the topic of the previous (substantive) turn. We use a feature to count the number of times a candidate attempts to shift topics within a debate (TS Attempt#) and a version of that feature normalized over the total number of turns (TS Attempt# N ). We also use a variation of these features which considers only the instances of topic shift attempts by the candidates when responding to a question from the moderator (TS AttemptAfterMod# and TS AttemptAfterMod# N ). We also compute a softer notion of topic shift where we measure the average Euclidean distance between topic probabilities of each of the candidate turns and turns prior to them (EuclideanDist). This feature in essence captures whether the candidate stayed on topic, even if he/she did not completely switch topics in a turn. Topic Shift Sustenance Patterns We use a feature to capture the average number of turns for which topic shifts by a candidate was sustained (TS SustTurns). However, as discussed in Section 4, the turns vary greatly in terms of length. A more sensible measure is the time period for which a topic shift was sustained. We approximate the time by the number of word tokens and compute the average number of tokens in the turns that topic shifts by a candidate were sustained (TS SustTime). Topic Shift Success Patterns We define a topic shift to be successful if it was sustained for at least three turns. We compute three features -total number of successful topic shifts by a candidate (TS Success#), that number normalized over the total number of turns by the candidate (TS Success# N ), and the success rate of candidate's topic shifts (TS SuccessRate) Topic Introduction Patterns We also looked at cases where a candidate introduces a new topic, i.e., shifts to a topic which is entirely new for the debate. We use the number of topics introduced by a candidate as a feature (TS Intro#). We also use features to capture how important those topics were, measured in terms of the number of turns about those topics in the en tire debate (TS IntroImpTurns) and the time spent on those topics in the entire debate (TS IntroImpTime). Analysis and Results We performed a correlation analysis on the features described in the previous section with respect to each candidate against the power he/she had at the time of the debate (based on recent poll scores). Figure 2 shows the Pearson's product correlation between each topical feature and candidate's power. Dark bars denote statistically significant (p < 0.05) features. We obtained significant strong positive correlation for TS Attempt# and TS AttemptAfterMod#. However, the normalized measure TS Attempt# N did not have any significant correlation, suggesting that the correlation obtained for TS Attempt# is mostly due to the fact that candidates with more power have more turns, a finding that is already established by Prabhakaran et al. (2013b) . However, interestingly, we obtained a weak, but statistically significant, negative correlation for TS AttemptAfterMod# N which suggests that more powerful candidates tend to stay on topic when responding to moderators. We did not obtain any correlation for EuclideanDist. We did not obtain any significant correlations between candidate's power and their topic shift sustenance features. We obtained significant correlation for topic shift success (TS Success#), modeled based on the sustenance of topic shifts, suggesting that powerful candidates have a higher number of successful topic shifts. However, TS SuccessRate or TS Success# N did not obtain any significant correlation. We also found that powerful candidates are more likely to introduce new topics (TS Intro#) and that the topics they introduce tend to be important (TS IntroImpTurns and TS IntroImpTime). Related Work Studies in sociolinguistics (e.g., (Ng et al., 1993; Ng et al., 1995) ) have explored how dialog structure in interactions relates to power and influence. Reid and Ng (2000) identified that factors such as frequency of contribution, proportion of turns, and number of successful interruptions are important indicators of influence. Within the dialog commu-nity, researchers have studied notions of control and initiative in dialogs (Walker and Whittaker, 1990; Jordan and Di Eugenio, 1997) . Walker and Whittaker (1990) define \"control of communication\" in terms of whether the discourse participants are providing new, unsolicited information in their utterances. Their notion of control differs from our notion of power; however, the way we model topic shifts is closely related to their utterance level control assignment. Within the NLP community, researchers have studied power and influence in various genres of interactions, such as organizational email threads (Bramsen et al., 2011; Gilbert, 2012; Prabhakaran and Rambow, 2013) , online discussion forums (Danescu-Niculescu-Mizil et al., 2012; Biran et al., 2012) and online chat dialogs (Strzalkowski et al., 2012) . The correlates analyzed in these studies range from word/phrase patterns, to derivatives of such patterns such as linguistic coordination, to deeper dialogic features such as argumentation and dialog acts. Our work differs from these studies in that we study the correlates of power in topic dynamics. Furthermore, we analyze spoken interactions. Conclusion We studied the topical dynamics in the 2012 US presidential debates and investigated their correlation with the power differences between candidates. We showed that a candidate's power, modeled after their poll scores, has significant correlation with how often he/she introduces new topics, attempts to shift topics, and whether they succeed in doing so. In order to ensure the validity of our topic shifts we devised a simple yet effective way to eliminate turns which do not provide substantial topical content to the interaction. Furthermore, this allowed us to identify different topic segments within the interaction. In future work, we will explore how our way of identifying segments compares to other approaches on topic segmentation in interactions (e.g., (Nguyen et al., 2012) ). Acknowledgments This paper is based upon work supported by the DARPA DEFT Program. The views expressed are those of the authors and do not reflect the official policy or position of the Department of Defense or the U.S. Government. We also thank Debanjan Ghosh and several anonymous reviewers for their constructive feedback.",
    "abstract": "In this paper, we investigate how topic dynamics during the course of an interaction correlate with the power differences between its participants. We perform this study on the US presidential debates and show that a candidate's power, modeled after their poll scores, affects how often he/she attempts to shift topics and whether he/she succeeds. We ensure the validity of topic shifts by confirming, through a simple but effective method, that the turns that shift topics provide substantive topical content to the interaction.",
    "countries": [
        "United States"
    ],
    "languages": [
        ""
    ],
    "numcitedby": "0",
    "year": "2014",
    "month": "June",
    "title": "Power of Confidence: How Poll Scores Impact Topic Dynamics in Political Debates"
}