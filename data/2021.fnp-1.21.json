{
    "article": "This paper presents the FinTOC-2021 Shared Task on structure extraction from financial documents, its participants results and their findings. This shared task was organized as part of The 2nd Joint Workshop on Financial Narrative Processing (FNP 2021), held at the University of Lancaster. This shared task aimed to stimulate research in systems for extracting table-of-contents (TOC) from investment documents (such as financial prospectuses) by detecting the document titles and organizing them hierarchically into a TOC. For the third edition of this shared task, two subtasks were presented to the participants: one with English documents and the other one with French documents but with a different and revised dataset compared to FinTOC'2 edition. Introduction The use of PDF electronic documents is recurrent in the financial domain. They are used to share and broadcast information concerning investment strategies, policy and regulation. Even with a great layout, long documents can be hard to navigate, hence, the presence of a table-of-contents (TOC) can provide a valuable assistance for potential investors or regulators by increasing readability and facilitating navigation. In this shared task, we focus on extracting the TOC of financial prospectuses. In these official documents, investment funds accurately depict their characteristics and investment modalities. Depending on their country of origin, they might be edited with or without a TOC, and they might follow a template as well. But even though their format is regulated, the choice of the text format, the layout, the graphics and tabular presentation of the data is in the hand of the editor. Thus, the TOC is of fundamental importance to tackle sophisticated NLP tasks such as information extraction or question answering on long documents. In this paper, we report the results and findings of the FinTOC-2020 shared task. 1 The Shared Task was organized as part of The 1st Joint Workshop on Financial Narrative Processing and MultiLing Financial Summarisation (FNP-FNS 2020) , to be held at The 28th International Conference on Computational Linguistics (COLING'2020) . A total of 5 teams submitted runs and contributed 5 system description papers. All system description papers are included in the FNP-FNS 2020 workshop proceedings and cited in this report. Previous Work on TOC extraction There are mainly two concepts in the literature to approach TOC extraction. The first one parses the hierarchical structure of sections and subsections from the TOC pages embedded in the document. This area of research was mostly motivated by the INEX (Dresevic et al., 2009) and ICDAR competitions (Doucet et al., 2013; Beckers et al., 2010; Nguyen et al., 2018) which aim at extracting the TOC of old and lenghtly OCR-ised books. The documents we target in this shared task are very different: they contain graphical elements, and the text is not displayed to respect a linear reading direction but is optimized to condense information and catch the eye of the reader. Apart from these competitions, we find the methods proposed by El-Haj et al (El Haj et al., 2014 , 2019; El-Haj et al., 2019) , also based on the parsing of the TOC page. In the second category of approaches, we find algorithms that detect the titles of the document using learning methods based on layout and text features. The set of titles is then hierarchically ordered according to a predefined rule-based function (Doucet et al., 2013; Liu et al., 2011; Gopinath et al., 2018) . Lately, we find systems that address the hierarchical ordering of the titles as a sequence labelling task, using neural networks models such as Recurrent Neural Networks and LSTM networks (Bentabet et al., 2019) . Task Description As part of the FNP-FNS Workshop, we present a shared task on Financial Document Structure Extraction. Participants to this shared task were given two sets of financial prospectuses with a wide variety of document structure and length. Their systems had to automatically process the documents to extract their document structure, or TOC. In fact, the two sets were specific to two different subtasks: \u2022 TOC extraction from French documents: The set of French documents is rather homogeneous in terms of structure, due to the existence of a common template. However, the words and phrasing can differ from one prospectus to another. Also, French prospectuses never include a TOC page that could be parsed. \u2022 TOC extraction from English documents: English prospectuses are characterized by a wide variety of structures as there is no template to constrain their format. Contrary to the French documents, there is always a TOC page but the latter is usually highly incomplete as only the higher level section titles are displayed. For both sets, we observe that: \u2022 some documents contain specific titles that do not appear in any other document \u2022 the same title in two different documents can have a different position in the hierarchy \u2022 two titles that follow each other can have the same layout but a different position in the TOC \u2022 the font size of a higher-level title can be smaller than the font size of a lower-level one \u2022 and a title can have the exact same layout as its associated paragraph. For each subtask, all participating teams were provided with a training dataset which included the original PDFs alongside their corresponding JSON file representing the TOC of the document. This JSON represented the TOC by giving the titles, their pages, their depths and their IDs, as shown in Fig. 2 . A private test set was used to evaluate the TOCs generated by the participants systems. As stated in Section 2, most of the previous research on TOC generation has focused on short papers such as research publications (Arxiv database), or weakly graphical material such as digitalized books. However, the task of extracting the TOC of commercial documents with a complex layout structure in the domain of finance is not much explored in the literature. Shared Task Data In this section, we discuss the corpus of documents used for the TOC extraction subtasks. Corpus annotation Investment documents can be accessed online in PDF format, and are also made available from asset managers. We compiled a list of 81 French documents, and 82 English documents from Luxembourg, to create the datasets of each subtask. We chose documents with a wide variety of layouts and styles. We provided annotators with the original PDFs and a software that was developed internally to manually annotate the TOC of any PDF document. Once the annotator finishes their annotation task, the software produces a file containing the  TOC-entries (title, page number, depth, and id) in a hierarchically structured format. Each annotator was asked to: 1. Identify the title: Locate a title inside the PDF document. 2. Associate the entry level in the TOC: Every title is tagged with an integer representing the depth of the title in the TOC tree. The depth ranges from 1 to 10. 3. Tag the next title. Each document was annotated independently by two people and a third person would review the annotations to resolve possible conflicts. For each dataset, the agreement scores between annotators are depicted in Table 1 and Table 2 . We can observe high agreement scores, allowing us to be confident enough about the quality of our datasets. Annotation Challenge: Title identification Investment prospectuses are commercial documents whose complex layout is optimized to highlight  specific information such that a potential investor can identify it quickly. Hence, annotating a title and its level in the TOC hierarchy is a difficult task as one cannot rely on the visual appearance of the title to do so. Some examples can be observed in Fig. 3 and Fig. 4 . Annotation Challenge: Tagging PDF documents. The annotation of PDF documents is not an easy task since they are meant to be displayed. The tool we used for the annotations allows the annotators to directly tag on the PDF, however, the text selection relies on the HTML encoding of the  is actually displayed. For instance, it is possible that a piece of text is impossible to select if it is from an image. It is also possible that the tagged text has additional or missing characters. Corpus Description In the following, we provide an analysis of the data used for the shared task. We simplified greatly the format of the annotation files compared to the first edition of the shared task (Juge et al., 2019) . Instead of the XML format inherited from the Structure Extraction Competition (SEC) (Doucet et al., 2013) that implicitly encodes the title level, we used a simple JSON file containing a list of entries, where each entry has the following information: textual content, id, level, page number. An example of a JSON extract is provided in Fig. 2 . In particular, the title level is explicitly stated. Statistics about levels on the French and English datasets are presented in Table 3 . In addition to the annotation files, the public dataset provided to the participants contained documents in PDF format. The private dataset on which participants were ranked contained documents in PDF format only. Participants and Systems A total of 30 teams registered in the shared task all from different institutions. Eventually, 6 teams participated and 5 teams submitted a paper with the description of their method, see Table 5 for more information about their affiliation. In Table 4 , we show the details on the submissions per task. All the participants that submitted a standard run, sent a paper describing their approach as well. Participating teams explored and implemented a wide variety of techniques and features. In this section, we give a brief description of each system. More details could be found in the description papers published in the proceedings of the FNP 2021 Workshop. Christopher Bourez (Bourez, 2021) : This team participated in both subtasks in both languages. They used ABBYY Finereader to extract text blocks and exclude tables from pages. The system leverages style properties such as font name, color, font type such as weight or italics, font size and computes a hash for the paragraph and the first line. Statistics are then computed on these style properties to feed a XGBoost classifier; these include font size ratio compared to common size of the document; indentation of the first line; local frequency of the style in a window of paragraphs; local and global frequency of each style feature; etc. ISPRAS (Ilya et al., 2021) : This team participated in both tasks in both languages. Their system uses PdfMiner to extract text, font and colors. They also attempt to extract the TOC page using regular expression and keyword matching techniques. Based on this preprocessing they build feature vectors including visual features (font, color, spacing), letter statistics, regex matches for line beginning and ending or content, presence in TOC, and the same features for a window of 3 lines around the candidate line to categorize. These features are fed to train an XGBoost classifier in various setups. YSEOP (Gupta et al., 2021) : This team participated in both tasks in both languages. Their system uses pdfminer to extract text lines and only extract features when they match the annotation or when the text line is a subset of the annotation. The features extracted include normalized coordinates, font statistics (%of bold and italic chars), page and line statistics, line beginning and line ending patterns and TFIDF of char ngrams. This was then used to identify bounding boxes in imageconverted and fed into a Faster-RCNN classifier to fine tune the PubLayNet model. This was extract the IoU and probability of being a title of each text line which was in a 3rd step fed into a Gradient  Boosting Classifier trained on the dataset. To obtain the TOC, the titles were ordered by size where the largest titles were attributed the highest level. CILAB (Kim et al., 2021) : This team participated in both subtasks in English. They used PDFminer to extract the text and its coordinates, as well as font style properties such as font size and font weight. They used a Random Forest model for title detection after experimenting with a total of 5 ML algorithms such as SVM. They also gathered additional data (400 prospectuses) which was pseudo-labeled and experimented on different splits of the data. For TOC extraction, a number of heuristics were designed based on a careful analysis of the data, using regular expressions font size and font style. The team observed that data augmentation was reflected by better performance. Daniel (Giguet and Lejeune, 2021) : This team participated in both tasks on both languages. They design a preprocessing pipeline which structures the document and extracts features from text (token, line and text block), vector shapes (rectangles and borders) and images (figures, but also small character shapes like arrows and checkboxes) from pdf2xml. The system performs generic Page Layout Analysis (PLA) of which title detection and TOC extraction is a step. It recognizes and labels content areas such as text, paragraphs, tables, figures, lists, headers and footers, and use a deterministic algorithm to detect the TOC page which is parsed and then linked to matching text lines and pages in the document which are then labelled as titles. Results and Discussion Evaluation Metric Since both subtasks tackle the same problem but on different corpora, we used the same evaluation metric as in FinTOC2020. For the TOC generation part, we adapted the metrics proposed by the Structure Extraction Competition (SEC) held at ICDAR 2013 (Doucet et al., 2013) : we adapted the script, replaced the customized Levenshtein distance specifically designed for SEC by a standard Levenshtein distance whose edit cost is 1 in all cases, and removed the constraint on first and last 5 characters. The final ranking is based on the harmonic mean between Inex F1 score and Inex level accuracy. In the calculation of the Inex F1 score, correct entries in the predicted TOC are those which match the title of an entry in the groundtruth TOC and have the same page number as this entry. The Inex level accuracy evaluates the hierarchy of the predicted TOC. If we denote by E ok an entry in the predicted TOC with a correct page number, and by E ok an entry in the predicted TOC with a correct page number and a correct hierarchical level, then the Inex level accuracy is: E ok E ok Team Affiliation Tasks Yseop Lab (Gupta et al., 2021) Yseop, Paris, France F and E Daniel (Giguet and Lejeune, 2021) Normandie Univ, UNICAEN, GREYC, Caen, France F and E ISPRAS (Ilya et al., 2021) ISP RAS, Moscow, Russia F and E CILAB (Kim et al., 2021) KIT, Gumi, Korea E Christopher Bourez (Bourez, 2021) iValua, Paris, France F and E Table 5 : List of the 5 teams that participated in Subtasks of the FinTOC2021 Shared Task. \"F\" refers to the French substask and \"E\" refers to the English subtask We also provided scores for the title detection part separately: we used the F1 score, and considered as correct entries the predicted entries which match the titles of groudtruth entries according to the standard Levenshtein distance. For both parts, the threshold on the Levenshtein score was set to 0.85 2 . Moreover, the Inex scores and title F1 score are calculated for each document and then averaged over the documents of the private set to produce two performance figures per team submission: one for TOC extraction, and another for title detection (TD). Baseline For comparison purposes, we used the same baseline Title and TOC extractor used in Fin-TOC2020: \u2022 extracting textual content from the PDF documents using pdftohtml utility from Poppler library 3 \u2022 assigning groundtruth labels (title or non-title) to text segments by fuzzy string matching with the annotations \u2022 vectorizing text segments into onedimensional vectors of length 3 encoding the following features: is_bold, is_italic, is_all_capitalized \u2022 training a SVM on the obtained dataset \u2022 assigning to a predicted title the most frequent hierarchy level found in the training set Table 6 (respectively Table 7 ) reports the results obtained by the participants and the baseline on TOC extraction from French documents (respectively English documents). Discussion. Fior all tasks in all languages, we observe the same ranking: Christopher Bourez2, Christopher Bourez1 and ISP RAS; the scores between these 3 best systems are quite tight, partic-ularly on Enligh TD (83, 82.2, 81.3 respectively) and the gap is much bigger on TOC tasks between the second and third (53.6, 52.5, 37.9 respectively). The other teams obtained much lower scores on TOC and online largely beat the baseline on English TD task, which probably means that French TD is an easier task than English TD. So the winning recipe seems to involve a lot of feature engineering, visual features, windowing techniques and Gradient Boosted trees (see (Bourez, 2021) and (Ilya et al., 2021) for more details). Since TOC extraction task depends on TD task, participants have focused on improving their TD models, to the expense of TOC. We believe this partly explains why the scores are lower on TOC extraction compared to TD. Overall it seems that most systems have a much simpler approach to TOC compared to TD and they mostly fine-tuned their systems on TD. Conclusions In this paper we presented the setup and results for the Financial Document Structure Extraction task (FinToc) 2021, organized as part of The 2nd Joint Workshop on Financial Narrative Processing (FNP 2021). A total of 30 teams registered and 6 teams participated in the shared task with a wide variety of techniques. Five teams contributed with a paper describing their system. This edition improved the datasets, composed of French investment documents, and annotated for the TOC extraction problem. A test set also supplements previously released datasets for both English and French (Bentabet et al., 2020) (Juge et al., 2019) . TOC extraction on PDF documents is a realistic problem in everyday applications which explain the interest from and participation of both public universities and profit organizations. Acknowledgements We would like to thank our dedicated annotators who contributed to the building of the corpora used in this Shared Task over the years: Anais Koptient, Aouataf Djillani, and Lidia Duarte, Bianca Chong, Marion Cargill, as well as Sandra Bellato and Mei Gan, authors of this paper.",
    "abstract": "This paper presents the FinTOC-2021 Shared Task on structure extraction from financial documents, its participants results and their findings. This shared task was organized as part of The 2nd Joint Workshop on Financial Narrative Processing (FNP 2021), held at the University of Lancaster. This shared task aimed to stimulate research in systems for extracting table-of-contents (TOC) from investment documents (such as financial prospectuses) by detecting the document titles and organizing them hierarchically into a TOC. For the third edition of this shared task, two subtasks were presented to the participants: one with English documents and the other one with French documents but with a different and revised dataset compared to FinTOC'2 edition.",
    "countries": [
        "France",
        "United Kingdom"
    ],
    "languages": [
        "English",
        "French"
    ],
    "numcitedby": "0",
    "year": "2021",
    "month": "15-16 September",
    "title": "The Financial Document Structure Extraction Shared Task ({F}in{TOC}2021)"
}