{
    "article": "Due to the phenomenal growth of online product reviews, sentiment analysis (SA) has gained huge attention, for example, by online service providers. A number of benchmark datasets for a wide range of domains have been made available for sentiment analysis, especially in resource-rich languages. In this paper we assess the challenges of SA in Hindi by providing a benchmark setup, where we create an annotated dataset of high quality, build machine learning models for sentiment analysis in order to show the effective usage of the dataset, and finally make the resource available to the community for further advancement of research. The dataset comprises of Hindi product reviews crawled from various online sources. Each sentence of the review is annotated with aspect term and its associated sentiment. As classification algorithms we use Conditional Random Filed (CRF) and Support Vector Machine (SVM) for aspect term extraction and sentiment analysis, respectively. Evaluation results show the average F-measure of 41.07% for aspect term extraction and accuracy of 54.05% for sentiment classification. Introduction With the globalization of Internet, web generated contents are increasing at a tremendous pace. This huge amount of data has introduced several new challenges and opportunities in the research communities. These days customers or users are relying heavily on other user's opinion about a product or service before experiencing themselves. In order to get an unbiased opinion one has to extract and read all the reviews which is not an easy task to perform. Sentiment Analysis (Pang and Lee, 2008) refers to the problem of automatically determining the polarity of sentiment/opinion expressed by user in a chunk of text or review. In general, polarity of a review belongs to one of the four possible classes: positive, negative, neutral and conflict. Aspect based sentiment analysis (ABSA) is a fine-grained analysis of sentiments at the aspect or feature or attribute level. The term 'aspect' refers to an attribute or a component of the product/service that has been commented on in a review. Overall problem of aspect based sentiment analysis can be thought as a two-step process. The first step, i.e., aspect term extraction focuses on identifying various terms that denote aspects, and the second step, i.e. sentiment classification deals with classifying the sentiments with respect to the aspect. A review sentence, therefore, may contain more than one aspect term and the sentiment associated with each. Such a fine-grained analysis provides greater insight to the sentiments expressed in the written reviews. In recent times, there have been a growing trend for sentiment analysis at the more fine-grained level, i.e. for aspect based sentiment analysis (ABSA). Some of the recent systems that have emerged are (Toh and Wang, 2014; Chernyshevich, 2014; Wagner et al., 2014; Castellucci et al., 2014; Gupta et al., 2015) . However, almost all these research are related to some specific languages, especially the English. Sentiment analysis in Indian languages are still largely unexplored due to the non-availability of various resources and tools such as annotated corpora, lexicons, Part-of-Speech (PoS) tagger etc. Existing works (Joshi et al., 2010; Balamurali et al., 2012; Balamurali et al., 2011; Bakliwal et al., 2012; Mittal et al., 2013; Sharma et al., 2014; Das and Bandyopadhyay, 2010b; Das and Bandyopadhyay, 2010a; Das et al., 2012) involving Indian languages mainly discuss the problems of sentiment analysis at the coarse-grained level with the aims of classifying sentiments either at the sentence or document level. In this work we describe our research on aspect based sentiment analysis in Hindi. Hindi is the national language in India, and ranks 5th in the world in terms of speaker population. As we already mentioned, the bottleneck for performing sentiment analysis involving Hindi is again due to the non-availability of benchmark datasets and the scarcity of various other resources and tools. Annotated dataset is certainly the foremost requirement for NLP task, irrespective of application and domain, and sentiment analysis is no exception. Therefore, a good dataset both in terms of quality and quantity has great impact on the overall system performance. Several benchmark datasets for sentiment analysis for resource-rich languages like English exist and these have been made freely available for research, e.g., SemEval 2014 datasets (Pontiki et al., 2014) . However, Indian languages are still far behind in terms of such resources. Datasets, specific to Indian languages, which were created for the in-house developments by few of the research groups are very few in number, and there are three basic limitations: (i). smaller size (mostly in few 100s) (Joshi et al., 2010) (Balamurali et al., 2012) (Balamurali et al., 2011), (ii) . low quality, as the data were generated by translating English reviews using Google translator (Bak-liwal et al., 2012), and (iii) . none of these was meant for aspect based sentiment analysis. The focus of our work is to provide a benchmark setup for creating a dataset for aspect based sentiment analysis in Hindi, and then developing models for aspect term extraction and sentiment analysis for the effective usage of this dataset. This will surely open avenues for research in sentiment analysis involving Indian languages. To the best of our knowledge ours is the very first initiative, where we make an attempt to provide a benchmark setup for ABSA in Indian languages. Few of the examples are shown in Table 1 that gives an idea of what kind of datasets we have created. Three review text are listed in Devanagri script along with their Roman transliteration 1 and English translation form. The first review has one mulit-word aspect term while the other two has one single-word aspect term. Sentiment towards respective aspect terms are listed in the last column of the table. For the effective usage of the dataset we develop models for aspect term extraction and sentiment classification. We use Conditional Random Field (CRF) (Lafferty et al., 2001) as our learning algorithm for the aspect term extraction task and Support Vector Machine (SVM) (Cortes and Vapnik, 1995) for sentiment classification task. Evaluation shows the overall precision, recall and F-measure values of 61.96%, 30.72% and 41.07%, respectively for aspect term extraction and an accuracy of 54.05% for sentiment classification. The rest of the paper is organized as follows: Various aspects of resource creation and its challenges are discussed in Section 2.1.. In Section 3., we describe a brief overview of aspect based sentiment analysis task. Experiments and evaluation results are furnished in Section 4.. Finally, we conclude in Section 5. Benchmark Setup for ABSA in Hindi To address the challenges as we pointed out earlier, we design web crawler, collect raw data, clean and annotate user generated reviews. In subsequent subsections we discuss these processes. Data Crawling We design a web crawler that downloads product reviews from various online sources. We have crawled more than 100 newspapers, blogs, e-commence websites etc. 2 Following this process we have collected a total of 8,000 re-view sentences covering 12 domains. The set of domains comprises Laptops, Mobiles, Tablets, Cameras, Homeappliances, Mobile apps, Smart watches, Headphones, Speakers, Television, Travel and Movies. Some statistics of this dataset are presented in Section 2.4.. Pre-processing We pre-process the crawled data to convert it into the desired forms. We perform the following steps to prepare the datasets for our use: \u2022 At first, we identified and removed many irrelevant reviews from the dataset. This was done semiautomatically to ensure that the data we use finally was suitable for sentiment analysis. \u2022 From the remaining reviews we dropped off many unprintable characters and various emoticons like ':)'(smiley), '(Y)'(thumps up) etc. \u2022 We scanned the reviews and corrected few of the obvious spelling mistakes by adding and/or deleting few characters or words. \u2022 Many mismatched pairs (braces, quotes etc.) were corrected. \u2022 Some sentences had missing sentence end marker (|), and hence we appended it. A few examples of pre-processing are listed in Table 2 . Data Annotation For annotation of dataset, we follow the guidelines, which are in line with SemEval 2014 (Pontiki et al., 2014) shared task. We convert datasets in xml form. Each aspect term that appears in a review sentence is annotated along with its associated sentiment. The sentiment is classified into four categories, viz., positive, negative, neutral and conflict. Two instances of the dataset along with their xml structure are presented in Table 3 . At the top of the table, two example sentences are given in its original form, i.e., in Davanagri script along with its Roman transliteration and English translation. The first review contains only one aspect term and its polarity is positive. However, the second review does not have any aspect term. The other half of  the 'term' which is 'positive'. Position of the aspect term in the review text is determined by attributes 'from' and 'to' which store the index of first and last character, respectively in the review text. All the review documents collected are presented to three different annotators, who were native speakers of Hindi language. To check the goodness of annotations by different annotators we calculate inter-rater agreement. Cohen's Kappa coefficient (Cohen, 1960) is a statistical measure to analyze the inter-rater agreement and defined as K = P r(a) \u2212 P r(e) 1 \u2212 P r(e) ( 1 ) where P r(a) & P r(e) are the observed and by chance agreement among raters. We perform Cohen's Kappa coefficient on the datasets and an average agreement of 95.18% was obtained. This shows that the annotated dataset we generated is of acceptable quality. Finally, majority voting based technique was employed to merge three annotated versions of datasets. Agreement/disagreement matrices among annotators for aspect term extraction task are listed in Figure 1 . Dataset Statistics After pre-processing, our dataset contains 5,417 review sentences across 12 domains. There are a total of 2,290 positive, 712 negative, 2,226 neutral and 189 conflict reviews (sentence-level). Overall it contains 100,279 and 4,509 tokens and aspect terms, respectively. Polarity classification of these aspect terms count to 1,986 positive, 569 negative, 1,914 neutral and 40 conflict sentiments. Overall and domain-wise details of this dataset are reported in Table 4 . Method for Aspect Term Extraction and Sentiment Analysis In this section we describe the models that we develop for aspect term extraction and sentiment classification. For both the tasks we identify and implement a set of language independent features which are implemented without using any domain-specific external resources and/or tools. Aspect Term Extraction Aspect term extraction task is cast as a sequence learning problem. Each token of the review is marked with the BIO encoding scheme, where B, I and O denote the beginning, 4. Prefixes and suffixes: Prefix and suffix strings of surface word are used as the features. They are extracted by stripping off a fixed length character sequences from the beginning or end positions of words. We have used LTRC shallow parser 3 for tokenization, POS and chunk information. Sentiment Classification Once the aspect terms are identified, sentiment analysis is performed to predict the polarity of sentiment expressed towards this aspect term in the given review. We choose Support Vector Machine (SVM) (Cortes and Vapnik, 1995) 1. Target aspect term and local context: Sentiment bearing words usually occur closer to the target aspect term. We extract target term along with its preceding and following few tokens, and use as features for training. For the proposed method we fix context window size to 5. 2. Word Bigrams: Pair of two consecutive tokens in the local context are used as features to capture the cooccurrence behavior of the tokens. 3. Semantic Orientation (SO): Semantic Orientation (SO) (Hatzivassiloglou and McKeown, 1997 ) is a measure of association of a token towards positive or negative sentiments and can be defined as: SO(t) = P M I(t, posRev) \u2212 P M I(t, negRev) (2) where P M I(t, posRev) stands for point-wise mutual information of a token t towards positive sentiment reviews. Experiments and Evaluation As a base learning algorithm we make use of Conditional Random Field (CRF) and Support Vector Machine (SVM) for the aspect term extraction and sentiment classification tasks respectively. We use CRF++ 4 and TinySVM 5 based packages for our experiments. To evaluate the performance of the system, we use the evaluation scripts made available by the SemEval 2014 shared task organizers. We perform 3-fold cross-validation to report the final evaluation results. We obtain average Fmeasure of 41.07% for aspect term extraction and accuracy of 54.05% for sentiment analysis. We also train, test and evaluate the models of aspect term extraction and sentiment analysis for each domain separately. Evaluation results are reported in Table 5 . It is evident that the performance is greatly influenced by the amount of reviews available for a particular domain. The only exception is the Travel domain which reports merely 15.03% for aspect term extraction despite having relatively good amount of reviews. This could be because Travel contains reviews from a diverse set of places e.g. 'religious', 'hill stations', 'beaches', 'monuments' etc. and most of the aspect terms belong to its specific category.  class may be addressed with more training instances as well as by implementing class-specific features. We also perform qualitative analysis of errors that the system incurs. Error Analysis Aspect term extraction: \u2022 We observe that the presence of prepositions and conjunctions inside an aspect entity confuses the \u2022 When a noun phrase precedes or succeeds an aspect term, the system marks each token of the neighboring phrase as a part of the aspect term. Sentiment Classification: \u2022 When the sentiment bearing words occur far away from the aspect term, its sentiment is not correctly captured by the system. In the following sentence\" \u0930 \u092f\u0942 \u092e \u0928\u094b \u091f \u092b\u0915\u0947 \u0936\u0928\" (rijyoom noTiphikeshan) is an aspect term and its polarity is positive. The sentiment bearing word \"\u0916\u093e\u0938\" (khaas) is located 7 words away from the aspect term. Because of this long distance, classifier was not able to capture the sentiment properly. Review: \"\u092a\u0947 \u0930\u0903\u0915\u094b\u092a \u090f\u092a \u092e \u0930 \u092f\u0942 \u092e \u0928\u094b \u091f \u092b\u0915\u0947 \u0936\u0928 \u092b \u091a\u0930 \u0926\u092f\u093e \u0917\u092f\u093e \u0939\u0948 \u091c\u094b \u092c\u0939\u0941 \u0924 \u0939 \u0916\u093e\u0938 \u0939\u0948 \u0964\" Transliteration: \"periskop Ep meN rijyoom noTiphikeshan pheechara diyaa gayaa hai jo bahut hee khaas hai.\" It should be noted that, for the tasks, we make use of a very basic language and domain independent features. Performance of both these models can be improved by defining more domain-specific features. Systematic feature engineering might be useful to pickup the best set of features. Conclusion In this paper we propose a benchmark setup for aspect based sentiment analysis in Hindi. We have crawled various online sources, performed pre-processing to clean the data, and annotated the dataset with aspect terms and polarity classes. The dataset comprises of Hindi product reviews crawled from various online sources across 12 domains. Based on this dataset we build supervised classifiers for aspect term extraction and sentiment classification. Evaluation results on 3-fold cross-validation show the overall precision, recall and F-measure values of 61.96%, 30.72% and 41.07%, respectively for aspect term extraction and an accuracy of 54.05% for sentiment classification. We also make the dataset available to the community for the advancement of further research involving Indian languages. In future, we would like to investigate domain-specific features for both the tasks. We would also like to explore deep learning methods for aspect based sentiment analysis. Acknowledgements We acknowledge undergraduate students Siddharth Kumar (IIEST, Shibpur), Kumari Geeta (BIT Patna) and Pooja Sharma (Manipal University) for contributing in collection and annotation of datasets.",
    "funding": {
        "defense": 0.0,
        "corporate": 0.0,
        "research agency": 1.9361263126072004e-07,
        "foundation": 0.0,
        "none": 1.0
    },
    "reasoning": "Reasoning: The article does not mention any specific funding sources, including defense, corporate, research agencies, or foundations. Without explicit mention of funding, it is assumed that the article does not report funding from any of the specified sources."
}