{
    "article": "Most of statistical machine translation systems are combinations of various models, and tuning of the scaling factors is an important step. However, this optimisation problem is hard because the objective function has many local minima and the available algorithms cannot achieve a global optimum. Consequently, optimisations starting from different initial settings can converge to fairly different solutions. We present tuning experiments with the Simultaneous Perturbation Stochastic Approximation (SPSA) algorithm, and compare them to tuning with the widely used downhill simplex method. With IWSLT 2006 Chinese-English data, both methods showed similar performance, but SPSA was more robust to the choice of initial settings. Introduction Statistical machine translation (SMT) was originally based on the noisy channel approach [1] . In present SMT systems, the noisy channel approach has been expanded to a more general maximum entropy approach in which a log-linear combination of multiple feature functions is implemented [2] . Translation quality can be improved by adjusting the weight of each feature function in the log-linear combination. This can be effectively performed by minimising translation error over a development corpus for which manually translated references are available [3] . This minimisation problem in multiple dimensions is difficult because of three main characteristics of the objective function. Firstly, it has no analytic representation, so the gradient cannot be calculated. Secondly, it has many local minima. Finally, its evaluation has a significant computational cost (depending on the scheme, it implies translating the development corpus or re-ranking an n-best list for this corpus, and calculating some translation error measure). Gradient may be approximated, but this is costly since it requires typically as many function evaluations as the number of scaling factors. Thus, algorithms based on derivatives are discarded. Algorithms which require many objective functions evaluations, such as simulated annealing or genetic algorithms, are also discarded. Two popular alternatives are Powell's method [4, 5, 3] and the downhill simplex method [6, 5, 7] . In recent experiments at the 2006 John Hopkins University Summer Workshop on SMT, both meth-ods achieved similar performance [8] . The simplex method is self-contained and straightforward and thus widely used for SMT tuning [7, 9, 10, 11] , although it is not very efficient in terms of number of objective function evaluations for a high number of dimensions [12] . However, from the authors experience, a slight modification of initial parameters in the simplex optimisation can result in an appreciable difference in both the value of the local minimum found and the value of the optimal parameters. This difference is transmitted when these parameters are used to translate a test corpus. When a translation system is compared to a baseline, the difference arising only from the tuning process can be even greater than the difference arising from the two systems differences, leading to insignificant results. In some data sets, some inconsistencies of the tuning method have also been reported [13] . In this paper we compare tuning with the Downhill Simplex method and with the Simultaneous Perturbation Stochastic Approximation [14] (SPSA) method. SPSA has been successfully applied in areas including statistical parameter estimation, simulation-based optimisation, signal and image processing [15] . This paper is structured as follows. First the essential features of the SPSA method are presented. Then in section 3, objectives and details of the experimental work are given. In section 4, results are shown and discussed. Finally, some concluding remarks and perspectives are given. Presentation of SPSA algorithm The SPSA method is based on a gradient approximation which requires only two evaluations of the objective function, regardless of the dimension of the optimisation problem. This feature makes it especially powerful when the number of dimensions is increased. The SPSA procedure is in the general recursive stochastic approximation form: \u03bbk+1 = \u03bbk \u2212 a k \u011dk ( \u03bbk ) (1) where \u011dk ( \u03bbk ) is the estimate of the gradient g(\u03bb) \u2261 \u2202E/\u2202\u03bb at the iterate \u03bbk based on the previous mentioned evaluations of the objective function. a k denotes a positive number that usually gets smaller as k gets larger. Two-sided gradient approximations involve evaluations of E( \u03bbk + perturbation) and E( \u03bbk \u2212 perturbation). In the simultaneous perturbation approximation, all elements of \u03bbk are randomly perturbed together and the approximated gradient vector is: E( \u03bbk + c k \u2206 k ) \u2212 E( \u03bbk \u2212 c k \u2206 k ) 2c k \uf8ee \uf8ef \uf8ef \uf8ef \uf8f0 1/\u2206 k1 1/\u2206 k2 . . . 1/\u2206 kN \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fb (2) In equation 2, \u2206 k is a perturbation vector of same dimension N as \u03bb, whose values \u2206 i are computed randomly. c k denotes a small positive number that usually gets smaller as k gets larger. Compared to a finite-difference gradient approximation, involving N times more function evaluations, the simultaneous approximation causes deviations of the search path. These deviations are averaged out in reaching a solution and according to [15] , under reasonably general conditions, both gradient approximations achieve the same level of statistical accuracy for a given number of iterations. Notice that in general, SPSA converges to a local minimum. The general form of the algorithm consists of the following steps (see section 3.4 for further implementation details): Step 1 Calculate gain sequences a k and c k . Step 2 Generate the simultaneous perturbation vector \u2206 k . Step 3 Evaluate E( \u03bbk + c k \u2206 k ) and E( \u03bbk \u2212 c k \u2206 k ). Step 4 Approximate the gradient as in equation 2 Step 5 Update \u03bb estimate as in equation 1 Step 6 Iteration or termination. Return to Step 2 with k + 1 replacing k. Terminate if the maximum number of iterations have been reached or if there is little change in several successive iterates. Experimental Settings Translation system used Although the following discussion would be valid in many contexts, and in particular for any Empirical MT system, it is convenient here to present briefly the models implemented by our system, and whose respective weights are tuned. For a more complete description see [16] . The SMT approach used here considers a translation model which is based on a 4-grams language model of bilingual units which are referred to as tuples. Tuples are extracted from Viterbi alignments and can be formally defined as the set of shortest phrases that provides a monotonic segmentation of the bilingual corpus. In addition to the bilingual 4-gram translation model, the translation system implements a log linear combination of five additional feature functions: a 4-gram language model of the target language (denoted TM); a 4-gram language model of target POS-tags (TTM) which helps, along with the target language model, to provide a better concatenation of tuples; a word bonus feature (WB), which compensates the system preference for short translations over large ones; and finally, two lexicon models (L1 and L2) that implement, for a given tuple, the IBM-1 translation probability estimate between the source and target (or target and source, respectively) sides of it. Objectives Thus we have a translation system whose outcome depends on a set of parameters \u03bb (in this experiment, parameters were restricted to the scaling factors of the various models). We want to minimise a function E(\u03bb), which measures the translation errors over a given development set, made by the system with the parameter vector \u03bb. In this experiment, each evaluation of E(\u03bb) implies computing full translation of the development corpus, which is computationally intensive (the number of evaluations of E(\u03bb) to achieve convergence is in the order of 100). Note that in other setups [3, 8] , tuning is performed in two stages. In the first stage, full translation of the development corpus is computed, with n-best output. In the second stage, the n-best list is re-ranked. In this second stage, a parameter optimisation is performed with the downhill simplex method or with Powell's method 1 . In this case, an evaluation of the objective function only implies reranking the n-best list. The number of re-rankings necessary to achieve convergence is also in the order of 100. After this optimisation, the optimum parameters are used to translate again the development corpus and generate an updated n-best list. In this setup, convergence (on the first stage level) usually occurs after less than 10 full translations. The objective of the experiment was to perform the optimisation of E(\u03bb) with the downhill simplex method and the SPSA method, and to compare the consistency of the results over changes in initial settings. For this, we ran the algorithms from 7 different initial points and for each point, for 10 slightly different realisations. For both algorithms, an evaluation of E(\u03bb) implied a translation of the development corpus by exactly the same system (except the model weights). Thus, an objective function evaluation had the same computational cost for both algorithms. We aimed at choosing initial points well distributed in parameter space, but nevertheless realistic. Notice that in the log-linear combination, weights can be rescaled to set one of the parameters to some value, so the translation model was set to 1 and kept fixed during optimisation. In the first initial point, all parameters are also 1, so that all models start with equal weights. In the second initial point, all parameters are equal to 0.5. The other points were chosen in the following way. We collected sets of optimal parameters obtained previously on another development corpus, and noted down in which range the scaling factor of each model behaved. We selected the initial value of each parameter randomly within its corresponding range. The error function we choose is the BLEU score [17] . Actually it does not measure an error but a translation accuracy, so its opposite is to be minimised. Downhill simplex implementation details We implemented the simplex method according to [5] . The method uses a geometrical figure called a simplex consisting, in N dimensions, of N + 1 points and all their interconnecting line segments, polygonal faces, etc. The starting point is a set of N + 1 points in parameter space, defining an initial simplex. At each step, the simplex performs geometrical operations (reflexions, contractions and expansions) until a local minimum is reached. Given a starting point P 0 (see section 3.2), the other N points of the initial simplex were taken to be P i = P 0 + \u03b1 i e i , where the e i are unit vectors. The N constants \u03b1 i were chosen randomly such that the perturbed parameter P 0i + \u03b1 i be in the range corresponding to this scaling factor (as defined in section 3.2). For each of the seven starting points P 0 , we ran the algorithm from 10 different initial simplexes. Different initial simplexes were obtained by varying the seed of the random generator used to compute the \u03b1 i constants. SPSA implementation details After some experiments, we adopted slight changes to the form of the algorithm presented in section 2. The algorithm presented in section 2 does not restrict the updated set of parameters \u03bb at a new iteration. This means that if we are unlucky with the \u2206 k vector, we can go back from an good \u03bb vector to a bad \u03bb vector. This process will eventually converge, but it can take many iterations. Thus we introduced a function evaluation after step 5, to be able to determine whether the new parameters led to an improvement or not. A new set of parameters \u03bb k+1 which was worse than the current one (\u03bb k ) was accepted according to the following probability distribution: exp \u2212 |E( \u03bbk+1 ) \u2212 E( \u03bbk )| T (k + 1) , (3) were T was empirically set to 0.005. According to this probability distribution, the worse the new set of lambdas, the less probability to accept it. Since we introduced an evaluation of E( \u03bbk ), we replaced the two-sided gradient approximation by a one-sided one, which involves evaluations of E( \u03bbk ) and E( \u03bbk + perturbation). If the noise caused by the one-sided approximation (as opposed to the two-sided approximation) is small compared to the noise arising from the simultaneous approximation, one-sided approximation can be more efficient since it saves one function evaluation at each iteration. Finally, after a certain number of iterations without improving the optimum, we also changed the distribution in Step 2 to a 0, \u00b11 distribution with probability 1/3 for each outcome. Although this distribution seems to slow down the algorithm, it allows for a finer approximation of the gradient in a subpart of the parameter space. At the end the SPSA algorithm was implemented as follows: Step 1 Calculate gain sequences a k and c k . Notice that the choice of the gain sequence a k and c k are critical to the performance of SPSA. We choose the basic parameters according to [18] , and tuning the algorithm over various development sets (distinct from the one used in this experiment) from different machine translation tasks. Thus these parameters are expected to be valid for experiments with the same objective function on other language pairs and corpora. We used a k = 8/(2 + k + 1) 0.602 and c k = 0.25/(k + 1) 0.101 . Step 2 Generate the simultaneous perturbation vector \u2206 k . Each component of \u2206 k was a Bernoulli \u00b11 distribution with probability of 1/2 for each \u00b11 outcome (or a 0, \u00b11 distribution with probability 1/3 for each outcome, as mentioned above). Step 3 Evaluate E( \u03bbk + c k \u2206 k ) Step 4 Approximate the gradient as in equation 2, but replacing E( \u03bbk \u2212 c k \u2206 k ) by E( \u03bbk ) and dividing by c k instead of 2c k . Step 5 Update \u03bb estimate as in equation 1, and evaluate the objective function with this new set of parameters. Accept the new parameters according to the probability distribution in equation 3. Step 6 Iteration or termination (as in section 2). In our comparative experiment, for each starting point P 0 , we ran the algorithm with 10 different seeds for the random generator which computes the simultaneous perturbation vector in step 2. These seeds were the same as those used to generate the 10 initial simplexes (see subsection 3.3). Data set The translation system was trained with the Chinese-English data provided for IWSLT'06 evaluation campaign, and the parameters were tuned over the development set provided for the same evaluation (dev4). These parameters were then used to translate the test set, which was a selection of 500 sentences among the development sets of previous evaluations (dev1, dev2 and dev3). Results We report in table 3 the average BLEU score and standard deviation obtained after running 20, 40, 60 and 90 function evaluations of the simplex algorithms and SPSA algorithm. When an optimisation converged before the given number of function evaluations, the optimum value was taken. In each cell of table 3 , the upper number refers to the simplex, and the lower refers to SPSA. For each initial set of parameters, average and standard deviation are calculated over the 10 slightly different realisations controlled with the random seeds. First, from table 3 it seems that both algorithms have similar performance in terms of the optimum value achieved after a given number of function evaluations. Nevertheless, it is remarkable that from 60 function evaluations on, the standard deviation is always smaller for the SPSA algorithm, which suggests that this is a more stable method. Since the implementation of the different realisations cannot be the same for both algorithms, we cannot be totally certain that it was fair. A change of seed to generate the simultaneous perturbation for the SPSA may be less significant than a change of initial simplex. To verify this, we need to fix the seed and see how the algorithm behaves across several initial points. A first indication is given by the last row of table 3. In this row, the average and standard deviation of the averages < BLEU > N i taken after N function evaluations, for each point i, are calculated. The standard deviation of the averages, after 60 function evaluations, is much lower with SPSA method, which confirms that on this data set, the simplex optimal value is more dependent on the starting parameters than SPSA. 3 : Average BLEU score and standard deviation obtained with the simplex method (above) and SPSA method (below) in the development set, after 20, 40, 60, and 90 function evaluations, for each initial point in parameter space (referred to as pt). In the last row, separated from the rest of the table, the average and standard deviation of the averages are displayed. seed used, determining a given realisation, the only varying factor is the starting point. For each seed, the average BLEU score and standard deviation over all 7 starting points, after 20, 40, 60, and 90 function evaluations, are shown. For all seeds, after at least 60 function evaluations, the optimum value obtained with SPSA is less sensitive to the choice of initial parameters, which should lead to more consistent results. For SPSA, the highest standard deviation after 90 function evaluations is 0.18. For the simplex, it reaches 0.67. Thus doing two successive optimisations, one can expect in average up to 0.4 percent BLEU difference with SPSA and up to more than 1.3 percent BLEU different with the simplex. The conjugated effect of two SPSA properties not shared by the simplex method may contribute to explain this difference in stability. Firstly, SPSA search path follows in average the direction of the gradient, whereas the simplex orientation is blind. Secondly, SPSA has always a probability to go away from a zone close to a minimum, which allows it to find a lower minimum elsewhere in the search space. On the contrary, when the simplex shrinks in a zone close to a minimum, it is stuck in that zone. While optimal objective function values lie in a pretty close range, as seen in Table 3 , Figure 1 show that final values in parameter space are very dispersed. Thus different parameter sets lead to similar scores. Surprisingly, the value of the lexical (L1) model weight does not seem to be determi- nant, although this model has got a big impact in translation quality [19] . This is an indication of the interdependence of the various models. Figure 1 also suggests that there would be no point in averaging parameter values in order to gain generalisation power. As ultimate goal, we need to see if the stability of SPSA optimisations is conserved when translating new text (i.e. the test corpus). For each initial point and seed, and after a given number of function evaluations, we collected the optimum parameter set over the development corpus, and translated the test corpus with these parameters. Results are brought together in Table 5 . Table 5 instructs, as expected, that dispersion of scores is higher in test than in development. It also reveals that the standard deviation in test is similar for both algorithms. Thus the stability gain observed in the development corpus for SPSA was not conserved with new data. Finally, the last row of Table 5 indicates that the average BLEU score in test is similar for both algorithms. Since we have got 10 realisations of the algorithms for each initial set of parameters, it is interesting to select the parameters corresponding to the best score out of the 10 realisations, and translate the test corpus with these parameters. The results are plotted in Figure 2 . Firstly, we can notice that the selected parameters do not lead to substantially better results than the average of all results (reported in the last row of Table 5 ). The largest gain is 0.2 point BLEU for SPSA after 60 function evaluations. Secondly, while no over-fitting seems to occur, continuing the optimisation over development data after 30 function evaluations does not lead to significant translation quality improvement in test. Even 10 function evaluations were sufficient to obtain nearly optimal parameters with both algorithms. Conclusions and further work We have presented experiments in which the SPSA algorithm has been used to tune SMT parameters. These experiments have been repeated with the downhill simplex method for comparison. According to the results obtained in this task, both methods seem to have similar performance. However, SPSA was more robust than the simplex with respect to the choice of initial parameters and with respect to slightly different realisations of the algorithm. This conclusion is not restricted to a particular tuning setup. However, this SPSA advantage was not conserved when using the optimal parameters to translate new data. We also observed a high dispersion in parameter space, showing that various sets of param- 5 : Average BLEU score and standard deviation obtained with the simplex method (above) and SPSA method (below) in the TEST set, after 20, 40, 60, and 90 function evaluations, for the parameters obtained in development for each initial point (referred to as pt). In the last row, separated from the rest of the table, the average and standard deviation of the averages are displayed. eters led to similar scores. While no over-fitting was noticed, nearly optimum results in test could be obtained after only 10 function evaluations over the development corpus. The dispersion of results in test may be overvalued because of the task, which allows particularly poor generalisation since training, development and test corpora are small. Thus, it would be interesting to repeat these experiment with more data, such as those of European Parliament corpus. Furthermore, SPSA being expected to perform better for a problem of higher dimensionality, we should carry out experiments with a system including more feature functions. Finally, we are planing to perform a sensitiveness analysis with neural networks, in order to study the impact in translation score (of the development corpus) resulting from perturbations of each parameter. Acknowledgements",
    "abstract": "Most of statistical machine translation systems are combinations of various models, and tuning of the scaling factors is an important step. However, this optimisation problem is hard because the objective function has many local minima and the available algorithms cannot achieve a global optimum. Consequently, optimisations starting from different initial settings can converge to fairly different solutions. We present tuning experiments with the Simultaneous Perturbation Stochastic Approximation (SPSA) algorithm, and compare them to tuning with the widely used downhill simplex method. With IWSLT 2006 Chinese-English data, both methods showed similar performance, but SPSA was more robust to the choice of initial settings.",
    "countries": [
        "Spain"
    ],
    "languages": [
        "Chinese",
        "English"
    ],
    "numcitedby": "17",
    "year": "2006",
    "month": "November 27-28",
    "title": "Tuning machine translation parameters with {SPSA}"
}