{
    "article": "International library standards require cataloguers to tediously input Romanization of their catalogue records for the benefit of library users without specific language expertise. In this paper, we present the first reported results on the task of automatic Romanization of undiacritized Arabic bibliographic entries. This complex task requires the modeling of Arabic phonology, morphology, and even semantics. We collected a 2.5M word corpus of parallel Arabic and Romanized bibliographic entries, and benchmarked a number of models that vary in terms of complexity and resource dependence. Our best system reaches 89.3% exact word Romanization on a blind test set. We make our data and code publicly available. Introduction Library catalogues comprise a large number of bibliographic records consisting of entries that provide specific descriptions of library holdings. Records for Arabic and other non-Roman-script language materials ideally include Romanized entries to help researchers without language expertise, e.g., Figure 1. There are many Romanization standards such as the ISO standards used by French and other European libraries, and the ALA-LC (American Library Association and Library of Congress) system (Library of Congress, 2017) widely adopted by North American and UK affiliated libraries. These Romanizations are applied manually by librarians across the world -a tedious error-prone task. In this paper, we present, to our knowledge, the first reported results on automatic Romanization of undiacritized Arabic bibliographic entries. This is a non-trivial task as it requires modeling of Arabic phonology, morphology and even semantics. We collect and clean a 2.5M word corpus of parallel Arabic and Romanized bibliographic entries, and evaluate a number of models that vary in terms Knight, 2002) and so-called Arabizi transliteration (Darwish, 2014) tend to be lossy and inconsistent while strict orthographic transliterations such as Buckwalter's (Buckwalter, 2004) tend to be exact but not easily readable. The ALA-LC transliteration is a relatively easy to read standard that requires a lot of details on phonology, morphology and semantics. There has been a sizable amount of work on mapping Arabizi to Arabic script using a range of techniques from rules to neural models Chalabi and Gerges (2012) ; Darwish (2014) ; Al-Badrashiny et al. (2014); Guellil et al. (2017) ; Younes et al. (2018) ; Shazal et al. (2020) . In this paper we make use of a number of insights and techniques from work on Arabizi-to-Arabic script transliteration, but apply them in the opposite direction to map from Arabic script to a complex, detailed and strict Romanization. We compare rule-based and corpus-based techniques including a Seq2Seq model based on the publicly available code base of Shazal et al. (2020) . 3 Data Collection Sources We collected bibliographic records from three publicly available xml dumps stored in the machine-readable cataloguing (MARC) standard, an international standard for storing and describing bibliographic information. The three data sources are the Library of Congress (LC) (10.5M), the University of Michigan (UMICH) (680K), and New York University Abu Dhabi's Arabic Collections Online (ACO) (12K), amounting to 11.2 million records in total. Extraction From these collections, we extracted 107,493 records that are specifically tagged with the Arabic language code (MARC 008 \"ara\"). Filtering Within the extracted records we filter out some of the entries using two strategies. First, we used a list of 33 safe tags (determined using their definitions and with empirical sampling check) to eliminate all entries that include a mix of translations, control information, and dates. The star-marked tags in Figure 1 are all included, while the rest are filtered out. Second, we eliminated all entries with mismatched numbers of tokens. This check was done after a cleaning step that corrected for common errors and inconsistencies in many entries such as punctuation misalignment and incorrect separation of the conjunction wa+ 2 'and' clitic. As a result of this filtering, a small number of additional records are eliminated since all their entries were eliminated. The total number of retained records is 107,439. The full details on extraction and filtering are provided as part of the project's public github repo (see footnote 1). Data Splits Finally, we split the remaining collection of records into Train, Dev, and Test sets. Details on the number of records, entries, and words they contain is presented in Table 1 . We make our data and data splits available (see footnote 1). Task Definition and Challenges As discussed above, there are numerous ways to \"transliterate\" from one script to another. In this section we focus on the Romanization of undiacritized Arabic bibliographic entries into the ALA-LC standard. Our intention is to highlight the important challenges of this task in order to justify the design choices we make in our approaches. For a detailed reference of the ALA-LC Arabic Romanization standard, see (Library of Congress, 2012). Phonological Challenges While Romanizing Arabic consonants is simple, the main challenge is in identifying unwritten phonological phenomena, e.g., short vowels, under-specified long vowels, consonantal gemination, and nunnation, all of which require modeling Arabic diacritization. Morphosyntactic Challenges Beyond basic diacritization modeling, the task requires some morphosyntactic modeling: examples include (a) proclitics such as the definite article, prepositions and conjunctions are marked with a hyphen, (b) case endings are dropped, except before pronominal enclitics, (c) the silent Alif, appearing in some masculine plural verbal endings, is ignored, and (d) the Ta-Marbuta ending can be written as h or t depending on the morphosyntactic state of the noun. For more information on Arabic morphology, see (Habash, 2010) . Semantic Challenges Proper nouns need to be marked with capitalization on their first non-clitic alphabetic letter. Since Arabic script does not have \"capitalizations\", this effectively requires namedentity recognition. The Romanization of the word AlqAhrh 'Cairo' as al-Q\u0101hirah in Figure 1 illustrates elements from all challenge types. Special Cases The Arabic ALA-LC guidelines include a number of special cases, e.g., the word bn 'son of' is Romanized as ibn, and proper noun \u03c2mrw is Romanized as 'Amr. Romanization Models We compare multiple Romanization models built using four basic techniques with different expectation about training data availability, contextual modeling, and system complexity. The models are listed in Table 2 . The encoder consists of two gated recurrent unit (GRU) layers (Cho et al., 2014) with only the first layer being bidirectional, and the decoder has two GRUs with attention (Luong et al., 2015) . For the input, we used character embeddings concatenated with embeddings of the words in which the characters appear. For all other setting details, see Shazal et al. (2020) 's Line2Line model. We also show how Seq2Seq performs with different corpus sizes in Table 2 . CharTrans Technique The Seq2Seq technique is known for occasionally dropping tokens, which in our case leads to misalignment with the Arabic input. To handle this issue in model Seq2Seq, we align its output and fill such gaps using the outputs produced by three other techniques, thus creating models Seq2Seq+Rules Morph, Seq2Seq+MLE Simple, and Seq2Seq+MLE Morph. The alignment technique we use relies on minimizing character-edit distance between present words to identify missing ones. Corpus Experimental Results Table 2 presents the Dev and Test results for the models discussed in the previous section. All results are in terms of three word accuracy metrics: exact match (Exact), case-insensitive match (CI), and case and punctuation-insensitive match (CPI). The Rules Simple baseline manages to correctly produce an exact answer in close to 1/6th of all the cases. Rules Morph, which uses no training data, misses about 1/3rd of all exact transliteration matches; however, about half of the errors are from capitalization issues. The  The CPI metric values are consistently higher than CI by \u223c1.3% absolute for all models. Blind test results presented in the right hand side of Table 2 are consistent with Dev results. Error Analysis We classified a sample of 100 word errors (ignoring capitalization and punctuation) from the Dev set of our best performing model (Seq2Seq+MLE Morph). Our classification results are presented in Table 3 along with representative examples. Gold Errors We found 52 gold errors, where the human-provided target reference is incorrect. Romanization errors such as typos, incorrect vowelization, and dropped definite articles, constitute roughly 65% of gold errors. The rest of the errors include issues such as first and last name flipping which we classify as an alignment issue, Arabic input source typos, and errors in which the target is a translation instead of a Romanization. Notably, we observe that our Seq2Seq+MLE Morph model generates correct predictions for 85% of all gold error cases. System Errors Romanization errors make up 75% of system errors. The vast majority of these mistakes are due to wrong prediction of vowels or gemination. An additional 21% of the errors is due to Seq2Seq model hallucinations of characters unsupported by the source input. We also encountered 2 predictions that did not match the target reference but are correct variants. In \u223c44% of system error cases, outputs generated by the MLE Morph or Rules Morph models are in fact correct, but were not chosen during alignment and combination because of existing Seq2Seq answers. Conclusions and Future Work We presented a new task for Arabic NLP, namely the Romanization of Arabic bibliographic records. Our extracted corpus and benchmark data splits, as well as our code base will be publicly available. In the future, we plan to create an online Romanization interface to assist librarians. As more data is created efficiently, better models can be created. We also plan to exploit the latent annotations in bibliographic records for improving Arabic NLP tools, e.g. using vowelization for automatic diacritization and possible morphological disambiguation (Habash et al., 2016) , marked clitics for tokenization, and Roman-script capitalization for Arabic named entity recognition. Acknowledgments This work was carried out on the High Performance Computing resources at New York University Abu Dhabi (NYUAD). We thank Salam Khalifa, Ossama Obeid, Justin Parrott, and Alexandra Provo for helpful conversations. And we especially thank Elie Kahale for introducing us to this interesting challenge during the Winter Institute in Digital Humanities at NYUAD.",
    "abstract": "International library standards require cataloguers to tediously input Romanization of their catalogue records for the benefit of library users without specific language expertise. In this paper, we present the first reported results on the task of automatic Romanization of undiacritized Arabic bibliographic entries. This complex task requires the modeling of Arabic phonology, morphology, and even semantics. We collected a 2.5M word corpus of parallel Arabic and Romanized bibliographic entries, and benchmarked a number of models that vary in terms of complexity and resource dependence. Our best system reaches 89.3% exact word Romanization on a blind test set. We make our data and code publicly available.",
    "countries": [
        "United Arab Emirates"
    ],
    "languages": [
        "Arabic"
    ],
    "numcitedby": "0",
    "year": "2021",
    "month": "April",
    "title": "Automatic {R}omanization of {A}rabic Bibliographic Records"
}