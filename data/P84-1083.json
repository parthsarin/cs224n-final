{
    "article": "In this paper prototype versions of two word experts for text analysis are dealt with which demonstrate that word experts are a feasible tool for parsing texts on the level of text cohesion as well as text coherence. The analysis is based on two major knowledge sources: context information is modelled in terms of a frame knowledge base, while the co-text keeps record of the linear sequencing of text analysis. The result of text parsing consists of a text graph reflecting the thematic organization of topics in a text. i. Word Experts as a Text Parsing Device This paper outlines an operational representation of the notion of text cohesion and text coherence based on a collection of word experts as central procedural components of a distributed lexical grammar. By text cohesion, we refer to the micro level of textuallty as provided, e.g. by reference, substitution, ellipsis, conjunction and lexical cohesion (cf. HALLIDAY/HASAN 1976), whereas text coherence relates to the macro level of textuality as induced, e.g. by patterns of semantic recurrence of topics (thematic progression) of a text (cf. DANES 1974) . On a deeper level of propositional analysis of texts further types of semantic development of a text can be examined, e.g. coherence relations, such as contrast, generalization, explanation (cf. HOBBS 1979 , HOBBS 1982 , DIJK 1980a) , basic modes of topic development, such as expansion, shift, or splitting (cf. GRIMES 1978) , and operations on different levels of textual macro-structures (DIJK 1980a) or schematlzed superstructures (DIJK 1980b) . The identification of cohesive parts of a text is needed to determine the continuous development and increment of information with regard to single thematic focl, i.e. topics of the text. As we have topic elaborations, shifts, breaks, etc. in texts the extension of topics has to be delimited exactly and different topics have to be related properly. The identification of coherent parts of a text serves this purpose, in that the determination of the coherence relations mentioned above * Work reported in this paper is supported by BMFT/GID under grant no. PT 200.08. contributes to the delimitation of topics and their organization in terms of text grammatical well-formedness considerations. Text graphs are used as the resulting structure of text parsing and serve to represent corresponding relatlons holding between different topics. The word experts outlined below are part of a genuine text-based parsing formalism incorporating a llnguistical level in terms of a distributed text grammar and a computational level in terms of a corresponding text parser (HAHN/REIMER 1983; for an account of the original conception of word expert parsing, cf. SMALL/RIgGER 1982). This paper is intended to provide an empirical assessment of word experts for the purpose of text parsing. We thus arrive at a predominantly functional description of this parsing device neglecting to a large extent its procedural aspects. The word expert parser is currently being implemented as a major system component of TOPIC, a knowledge-based text analysis system which is intended to provide text summarization (abstracting) facilities on varlable layers of informational speclfity for German language texts (each approx. 2000-4000 words) dealing with information technology. Word expert construction and modification is supported by a word expert editor using a special word expert representation language fragments of which are introduced in this paper (for a more detailed account, cf. HAHN/REIMER 1983 , HAHN 1984) . Word experts are executed by interpretation of their representation language description. TOPIC's word expert system and its editor are written in the C programming language and are running under UNIX. 2. Some General Remarks about Word Expert Strutture and the Knowledge Sources Available for Text Parsin~ A word expert is a procedural agent incorporating linguistic and world knowledge about a particular word. This knowledge is represented declaratlvely in terms of a decision net whose nodes are constructed of various conditions. Word experts communicate among each other as well as with other system components in order to elaborate a word's meaning (reading). The conditions at least are tested for two kinds of knowledge sources, the context and the co-text of the corresponding word. Context is a frame knowledge base which contains the conceptual world knowledge relevant for the texts being processed. Simple conditions to be tested in that knowledge base are: : <---> strl occurs in the same sentence as str2 EQUAL ( strl , str2 ) : <---> strl equals str2 FACT ( f ) ACTIVE ( f ) : <---=> f is an active frame EISA ( f , f\" ) : <---> frame f : <==-> frame f was affected by an activation operation in the knowledge base SACT ( f , s ) : <-=-> slot s of frame f was affected by an activation operation in the knowledge base SVAL ( f , s , v ) : <--=> slot s of frame f was affected by the assignment of a slot value v in the knowledge base SAME TRANSACTION ( f , f\" ) : <---> --frame f and frame f\" are part of the same transaction with respect to a single text token, i.e. the set of all operations on the frame knowledge base which are carried out due to the readings generated by the word experts which have been put into operation with respect to this token From the above atomic predicates more complex conditions can be generated using common logical operators (AND, OR, NOT). These expressions underlie an implicit existential quantification, unless specified otherwise. During the operation of a word expert the variables of each condition have to be bound in order to work out a truth value. In App The word expert given in App.A starts running whenever a frame name occurs in the text. Starting at the occurrence of frame \"Mikrocnmputer\" indicated by {06} no reading is worked out. At {09} the expert's input variable \"frame\" is bound to \"Z-80\" as it starts again. A test in the knowledge base indicates that \"Z-80\" is an active frame (by default operation). Proceeding backwards from the current entry in co-text the evaluation of nodes #i0 and #Ii yields TRUE, since pronoun llst contains an element \"ein\" a morphological variant of which occurs immediately before frame (Z-80) within the same sentence. In addition, we set frame\" to \"Mikrocomputer\" (micro computer) as it is next before frame (with proximity left unconstrained due to \"any') in correspondence with {06}, and it is an active frame, too. The evaluation of node #12, finally, produces FALSE, since frame\" (Mikrocompurer) is not a subordinate or instance of frame (Z-80) -actually, \"Z-80\" is an instance of \"Hikroprozessor\" (micro processor). Following the FALSE arc of #12 leads to expression #2 which evaluates to FALSE, as frame\" (Mikrocomputer) is a frame which roughly consists of the following set of slots (given by indentation) Mikrocomputer Mikroprozessor Peripherie Hauptspelcher Programmiersprache Systemsoftware micro computer mirco processor peripheral devices main memory programming language system software Following the FALSE arc of #2, #3 also evaluates to FALSE as according to the current state of analysis context contains no information indicating that frame\" (Mikrocomputer) has a slot\" to which has been assigned any slot value (in addition, \"Z-80\" is not used as a default slot value of any of the slots supplied above). Turning now to the evaluation of #4 slot\" has to be identified which must be a slot of frame\" (Mikrocomputer) and frame (Z-80) must be within the value range of permitted slot values for slot\" of frame'. Trying \"Mikroprozessor\" for slot\" succeeds, as \"Z-80\" is an instance of \"Mikroprozessor\" and thus (due to model-dependent semantic integrity constraints inherent to the underlying frame data model {REIMER/HAHN 1983]) it is a permitted slot value with respect to slot\" (Mikroprozessor) which in turn is a slot of frame\" (Mikrocomputer). Thus, the interpretation slot\" as \"~tlkroprozessor\" holds. The execution of word experts terminates if a reading has been generated. Readings are labels of leaf nodes of word experts, so followlng the TRUE arc of #4 the reading SVAL ASSIGN ( Mikrocomputer , Mikroprozessor , Z-80 ) i~ reached. SVAL ASSIGN* is a command issued to the frame knowledge base (as is done with every reading referring to cohesion properties of texts) which leads to the assignment of the slot value \"Z-80\" to the slot \"Mikroprozessor\" of the frame \"Mikrocomputer\", This operation also gets recorded in co-text (SVAL). Therefore, entry {09} get augmented: When more than a slngle frame within the same transaction may be referred to by word experts the following reference convention is applied: \u2022 ~K~ TYPE ANNOT {eg] z-8~ z- [2i] [2ii] if ANNOT -FRAME and an annotation of type FACT exists examine the frame corresponding to FACT if ANNOT -FRAME or ANNOT -WEXP and annotations of type SACT or SVAL exist examine f as frame, s as slot, and v as slot value, resp. according to the order of parameters f . s . v In these cases reference of word experts to the frame correponding to the annotation FRAME would cause the provision of insufficient or even false structural information about the context of the current lexlcal item, although more significant information actually is available in the knowledge sources. In the word expert considered, frame\" is set to \"Mikrocomputer\" according to [211] . Following the TRUE arc of #ii expression #12 states that frame\" (Mikroeomputer) must be a subordinate or instance of frame (System) which also holds TRUE. Thus, one gets the reading SHIFT ( System , M/krocomputer ) which says that the activation weight of frame (System) has to be decremented (thus neutralizing the default activation), while the activation weight of frame\" (Mikrocomputer) gets incremented instead. Based on this re-asslgnment of activation weights the system is protected against invalid activation states, since \"Mikrocompurer\" is referred to by \"System\" due to styllstlcal reasons only and no indication is available that a real topical change in the the text is implied, e.g. some generalization with respect to the whole class of micro computers. We thus have an augmented entry for {34} in co-text together with the result of processing the remainder of [1]: No. SPLITTING RHEMES ( f , f\" ) fram~ f is alpha ancestor to f\" DESCENDING RHEMES ( f , f\" , f'\" ) frame-'f is alpha ancestor to f\" & frame f\" is alpha ancestor to f'\" ~KEN CONSTANT THEME ( f , str ) frame f is beta ancestor=~strlng str SPLITTING THEMES ( f , f', str) fram~ f is alpha ancestor to f\" & frame f\" is beta ancestor to string str CASCADING THEMES ( f , f', f'' , f' '\" , sir ) fram-e f is alpha ancestor f\" & frame f\" is beta ancestor to f'\" & frame f'\" is alpha ancestor to f''\" & frame f''\" is beta ancestor to string str SEPARATOR ( f ) frame f is alpha ancestor to a separator symbol We now illustrate the operation of the word expert designed to handle special cases of text coherence (App.B) as indicated by text segment [i] . It gets started whenever a frame name has been identified in the text. Suppose, we have frame set to \"Mikrocomputer\" with respect to {06}. Since #i fails (there is no other frame\" available within transaction {06}), evaluating #2 leads to the assignment of \"Mikroeomputer\" to frame\" (with respect to {09}), since according to convention [21i] and to the entries of co-text frame\" (Mikrocomputer/{09}) occurs after frame and is immediately adjacent to frame (Mikrocomputer/06}); in addition, both, frame as well as frame', belong to different transactions. Thus, #2 is evaluated TRUE. Obviously, #3 also holds TRUE, whereas #4 evaluates to FALSE, since frame\" is annotated by SVAL according to the co-text Instead of SACT, as is required by #4. Note that only the same transaction (if #I holds TRUE) or the next transaction (if #2 holds TRUE) is examined for appropriate occurrences of SACTs or SVALs. With respect to #5 the SVAL annotation covers the following parameters in {09}: frame\" (Mikrocomputer), slot\" (Mikroprozessot) and sval\" (Z-80). Proceeeding to the next state of the word expert (#6) we have frame (Mikrocomputer) but no SVAL or SACT annotation with respect to {06}. Thus, @6 necessarily gets FALSE, so that, flnally, the reading SPLITTING THEMES (Mikrocomputer , Mikroprozessor , z-g0 ) --is generated. A second example of the generation of a coherence reading starts setting frame to \"RAM-l\" at position {13} in the co-text. Evaluating #1 leads to the asslgment of \"Mikrocomputer\" to frame', since two frames are available within the same transaction. Both frames being different from each other one has to follow the FALSE arc of #3. Similar to the case above, both transaction elements in {13} are annotated by SVAL, such that #7 as well as #9 are evaluated FALSE, thus reaching #11. Since frame (RAM-I) has got no slot to which has been assigned frame\" (Mikrocomputer), #ii evaluates to FALSE. With respect to #13 we have frame\" (Mikrocomputer) whose slot\" (Hauptspelcher) has been assigned a slot value which equals frame (RAM-l). At #14, finally, slot (Groesse) and sval (48 KByte) are determined with respect to frame (RAM-l). The coherence reading worked out is stated as CASCADING THEMES ( Mikrocomputer , Hauptspelcher , RAM-I , Groesse , 48 KByte ). Completing the coherence analysis of text segment [I] at last yields the final expansion of co-text (note that both word experts described operate in parallel, as they are activated by the same starting criterion): coherent graph. Accordingly, the ~raph generation procedure also operates as a kind ot topic/comment monitoring device. Obviously, one also has to take into account defective topic/c~ent patterns in the text under analysis. The SEPARATOR reading is a basic indicator of interruptions of toplc/comment sequencing. Its evaluation leads to the notion of toplc/comment islands for texts which only partially fulfill the requirements of toplc/comment sequencing. Further coherence readings are generated by computations based solely on world knowledge indicators generating condensed lists of dominant concepts (lists of topics instead of topic graphs) (HAHN/REIMER 1984). Conclusion In this paper we have argued in favor of a word expert approach to text parsing based on the notions of text cohesion and text coherence. Readings word experts work out are represented in text graphs which illustrate the topic/comment structure of the underlying texts. Since these graphs represent the texts\" thematic structure they lend themselves easily for abstracting purposes. Coherency factors of the text graphs generated, the depth of each text graph, the amount of actual branching as compared to possible branching, etc. provide overt assessment parameters which are intended to control abstracting procedures based on the toplc/comment structure of texts. In addition, as much effort will be devoted to graphical modes of system intercation, graph structures are a quite natural and direct medium of access to TOPIC as a text information system. _.. ~. ACKNOWLEDGEMENTS I would like to express my deep gratitude to U. Reimer for many valuable discussions we had on the word expert system of TOPIC. R. Hammwoehner and U. Thiel also made helpful remarks on an earlier version of this paper. Herstel let. FascWate Mikroc~ter. p~ogr an~iersprsche. Pascal. Hersteller. PascWare The word expert Just discussed accounts for a single frame (here: M_Ikrocomputer) with nested slot values of arbitrary depth. This basic description only slightly has to be changed to account for knowledge structures which are implicitly connected inthe text. Basically divergent types of coherence patterns are worked out by word experts operating on, e.g. aspectual or contrastlve coherence relations (cf. HAHN 1984) . The Generation of Text Graphs Based on Topic/Comment Monitoring The procedure of text graph generation for this basic type of thematic progression can be described as follows. After initialization by drawing upon the first frame entry occurring in co-text the text graph gets incrementally constructed whenever a new coherence reading is available in the corresponding data repository. Then, it has to be determined, whether its first parameter equals the current node of text graph which iselther the leaf node of the initialized text graph (when the procedure starts) or the leaf node of the toplc/comment subgraph which has previously been attached to the text graph. If equality holds, the coherence reading is attached to this node of the graph (including some merging operation to exclude redundant information from the text graph). If equality does not hold, remaining siblings or ancestors (in this order) are tried, until a node equal to the first parameter of the current coherence reading is found to which the reading will be attached dlrectly. If no matching node in the text graph can be found, a new text graph is constructed which gets inltlallzed by the current coherence reading. The text graph as the result of parsing of the text segment [i] with respect to the coherence readings generated in set.3.2 is provided in App.C. Note that the text graph generation procedure allows for an interpretation of basic coherence readings supplied by various word experts in terms of compound patterns of thematic progression, e.g. as given by the exposition of splitting rhemes (DANES 1974) . Nevertheless, the whole procedure essentially depends upon the continuous availability of reference topics to construct a",
    "abstract": "In this paper prototype versions of two word experts for text analysis are dealt with which demonstrate that word experts are a feasible tool for parsing texts on the level of text cohesion as well as text coherence. The analysis is based on two major knowledge sources: context information is modelled in terms of a frame knowledge base, while the co-text keeps record of the linear sequencing of text analysis. The result of text parsing consists of a text graph reflecting the thematic organization of topics in a text.",
    "countries": [
        "Germany"
    ],
    "languages": [
        "German"
    ],
    "numcitedby": "2",
    "year": "1984",
    "month": "July",
    "title": "Textual Expertise in Word Experts: An Approach to Text Parsing Based on Topic/Comment Monitoring"
}