{
    "article": "This paper proposes a generation method for feature-structured)ased unification grammars. As comlx~red with fixed ~rity term notation, feature structure notation is more tlexible for representing knowledge needed to generate idiom~ttic structures as well as genem~l constructions. The method enables feature strncture retrieval via nmltiple indices. The indexing mechanism, when used with a semantic head driven generation algorithm, attains efficient generation even when a large amount of generation knowledge must be considered. Our method can produce all possi ble structures in parNlet, using structure sharing among ambiguous substructures. Introduction PracticM generation systems must lnwe linguistic knowledge of both specilic expressions like idioms and generM grammatical constructions, ;rod ttmy should efgtciently produce sm'face strings applying that knowledge [[] [2] . In order to satisfy the first requirement, our system employs a set of trees annotated with fe,~ture structures to represent generation knowledge. l:;ach tree represents a t?agment of a syntactic strncture, and is paired with a semantic feature structure. We can describe idiomatic eonstructions, by making a tree which cont~tins lexical specifications and is paired with a specilie rather than general semautic structure. Because feature structures allow partial speeiiicatiom we can encode generation knowledge r;mgiug over multiple levels of generality in a. uniform way. llowever, notice that this property will be restricted if we use DCG or (tixed arity) term notation 1 Suppose there is a generation knowledge structure whose syntactic part is \"go on foot\". 'rim feat, tu'e structure notation of its semantic part will be sonmthing like: ~The flexibility of structure notation colnpated Lo tetln notation is also discussed il~ [4] . [ [Rein GO] [Agent ?agent [] ] [Instrument FOOT]]. while the term notation is : (1) instrument(go(Agent), foot) (2) These two notations seem to be equivalent, but there is a cruciN diflerence. A generation knowledge structure containing the fe~tture-based selnantics will still be unifiable even if the semantic input to be unified contains additional material. Thus the knowledge structure will be discovered and its syntactic information can he used for generation. By contrast, a term-based input with additiona.1 elements would not unify with the term-based semantic structure shown above. It would thus be necessary to create additional generation structures containing distinct (though partly overlN)ping) term-based semantic structures. Such additional structures are redundant ~tn(l cause superfluous output. For example, consider the a,ugmented feature structure (3) . [ [Rein ~o] [Agent Ken] [Instrument FOOT] [Time I0 : OOmn] ] (3) it will indeed nnify with (1) above. But termbased input semantic structure (4) will not unify with term-based semantic structure (2) . instrument(time(go(ken), 10:00am), foot). To unifv (2), semantic ,structure (5) would a.lso be required. time(instzument(go(ken), foot), 10:00ma). ( ) 5 For this reason, our generation knowledge consists of trees represented as feature structures. A tree can be substituted for a leaf node of asother tree to form a larger structure. Thus, tile tree can be regarded as a rule in a context-free feature-structure-based unification grammar. The second requirement for a generation system is efficient creation of syntactic structures. This is the main topic of this paper. Our system is based upon Semantic }lead Driven Generation [6] , which is an efficient algorithm for unilication based formalisms. However, this algorithm requires some additional mechanisms to efficiently retrieve relevant generation knowledge, because feature structures can not be easily indexed. The algorithm presented here uses a nmltiple index network of feature structures to efficiently choose relevant generation knowledge from the knowledge base. The algorithm \"also uses an hypothetical node so as to efficiently maintain ambiguous structures during generation. Phrase Description(PD) Generation knowledge is represented as a set of trees aunotated with feature structures, l,',ach tree is called a Phrase Description (PD). ALl example of a l)D is shown in Figure . 1. Structure: (S AUX (NP PRON) VP) Annotation: (S [[syn [[cat S] [inv +]]1 [sem [[reln REQUEST] [agon *SP*] [recp *HR*] [obje ?ACTION]]]]) (AUX [[syn [[cat AUX] [lex \"would\"] [v-morph PAST]]]]) (NP [[syn [[cat NP] [case NOM]]]]) (PRON [[syn [[cat PRON] [case NOM] [lex \"you\"]]]]) (VP [[syn [[cat VP][v-morph BSE]]] [sem ?ACTION]J) The structure definition defines tile structure of a tree by using a list in which the first element corresl)onds to the mother node and tile rest of the elements correspond to daughters. l';ach daughter may t)e a tree rather than a sin> pie node. The annotation part specifies the feature structure of each symhol appearing in the structure definition. A feature structure description can contain tags or variables (symbols with \"?\" as a prefix in the figure), The scope of a tag in a PD is the entire PD. Each node should have a semmltic and syntactic feature structure. The semantic feature on the root node of a PD represents the semaattics of the PD; thus we call it the semantic structure of the PD. Although the description represents a tree, it is the same ms for a (partial) derivation structure of a unification-l)ased CFG, because tile current system does not allow adjoining operations. If the structure definition of every PD is restricted to mother-daughter relations only, the PD set is strictly equivalent to a unification-based CFG. Generation Algorithm Our algorithm is aal efficient extension of Semaattic Head Driven Generation. 3?he major extensions are: 1) it handles feature structures directly, and 2) it creates all possible phrase structures in parallel. These extensions are embodied mainly in the t'l) activation and ambiguity handling mechanisms discussed in this section. Overview of the algorithm The main part of the generation process is expansion process, which iterates through expanding node selection, activation, prccombination, and application, using an e~Tmnding node agenda. Input to the process is a feature structure conraining syntactic, semantic and pragmatic features as an initial constraint on the root node. q'he Cxl)auding node agenda contains tim unlexicalized leaf nodes of the tree under creation. At the beginning of the process, it conta.ins only one node, which has the feature structure giveu as an initial constraint. The expanding node selection step picks up one node, say expanding node, from the agenda. If no node is picked ill) , the expaa~sinn process stops. The PD activation step activates all PD's whose senlantic strlLetures s~tlJs~tme the semantic structure of the expanding node. The precombination step makes PD sequences from activated PD's to satisfy some constraints. The application step instantiates the PD sequence(s) and applies it to tile expanding node. The expanding node selection step is for fetching one node from the expanding node agenda. From among the nodes whose semantic feature has been instamtiated, one is chosen. In this step, if tile fetched node satisfies some termination conditions (if~ for instance, it satisfies tile conditions for slash terminatim0, the node is discarded (i.e., not expanded any more). If the agenda is empty or contains no node with an instantiated semantic feature, the expansion process stops. PD1 PD2 v3 v4 v2 Activation This step is responsible for selecting all PD's whose semantic structures subsume the semantic structure of an expanding node. The selection is done by traversing a multiple index network of PD's called the PD net. Compiling PD's A set of PD's are pl'e-compiled into a PI) net. Suppose there are two PD's whose sema~ntic structures 2 are defined as the dags (i.e. directed acyelic graphs) in Figure 2 . in the figure, fa,fl),fc,.., and vl,v2,., represent arc babels (feature names) and atomic values respectively. These PD's are coinpiled to the PD net shown in Figure 3 . The uet has two kinds of nodes: path nodes@i), and PI) nodes (PDj). These nodes are linked by three kinds of labeled directed arcs: 2The semantic feature of a PD. is a semantic feature on the root node of the PD Figure 3 : an example of PD net feature arcs(bold lines), vMue arcs(dashed), and tag arcs(with arrows). A path node is used to represent a particular feature path in one or more feature structure. As shown in Figure 3 , path nodes are linked by bold feature arcs to form a tree. The sequence of arc labels from the root path node to a path node Pl is the path of Pi. [It Figure 3 , p3 and p5 show paths (Po N) and (re fd) respectively. Each PD node (rectangle) corresponds to a particular PD, which may have value ares and tag arcs. \u2022 Value Arcs: Which PD's contain which atomic vNues along certain paths ? A PD node may be linked to path nodes with value ares. If a (rectangular) PD node is linked to a. (round) path node pn with a dashed value are labeled v, then following the path leading to pn yields atomic value v in that PD. Consider the dashed value are vl in Figure 3 . It indicates that following path fa in PDI yiehls an atomic value vl. This is just tim situation depicted in Figure 2 . \u2022 Tag Arcs: In a given PD, which paths share a. cel't~in feature structure as a vaJue ? A PD node may also be linked to path nodes with tag arcs. If lowo tag arcs have the same label and they cdnnect ;~ PD node to two path nodes, say pnl and pn2, then tim feature structure of that PI) has a substrm;ture which is the value of both paths, that of phi and pn2. t, br example, the two tag arcs from rectangular PDI node labeled \"tl\" in Figure 3 show that the semantic structure of PD1 has a substructure serving as the vMue of (~) and (fc). Traversing the PD net The data structure of nodes and arcs are shown ill. Figure 4 A path node has three slots: values, features, oatd dagstore. The values slot and the arcs slot contain value arcs and feature arcs respectively. The dagstore stot is initially empty; later it holds a pointer to a dag which passed the path node. Each PD node has a PD slot, a tagares slot, a valueNum slot, and a status slot. The PD slot contains a pointer to the represented PD itself. The tagarcs slot contains the data structure of the tagarcs (see below). The valueNum slot has the number of value arcs to the PD node. For example, the value of the number slot of PD1 node in Figure3 is 3, because the node has one value a.rc labeled vl and two value arcs labeled vl. The status slot holds integer and is initially set to 0. Every type of arc has two slots, 'label' and 'destination'. 'Label' is an atomic symbol which labels the arc, and 'destination' is a pointer to the node which is the destination of the arc. We use the PD net as a dataltow net. The entry point of the net is the root path node amd the token which flows is a dag of a semantic feature structure. The action of a path node is shown in Figure 5 . \"faihn'e\" means there is no PD whose semantic structure subsumes the given dag. Thus the entire retrieval process fails. The action of a 1)D node is shown in Figure 6 . The status is incremented each time the node receives a tokeu. As a result, if all atomic values in tl,e semantic structure of the PI) are satisfied, the status becomes equM to the valueNum (that is the nulnber of atomic values). Once this is detected, then uuifiability of shared structure is checked by cMling the tagtcst procedure. Tagtest tests unifiability of the dags in the dagstores of p(ath) nodes connected by tag arcs with the same label. Iu Figure 3 , if the status of PD1 becomes 3 and if the dag in p2 and the dag in 114 are identical, then the PD becomes active. That is, the PD has been found to subsume the generation input. It may or may not actually be applied, depending on later events. Precombination The precombiuation step is responsible for making sequences of PD's from activated PD's under certain constraints. A PD sequence is a rough plan for a potential structure which can realize a semantic specification of the node being expanded a. If no sequence is obtained, the ambiguity resolution process, discussed later, is invoked. We divide PD's into two groups: propagation type and non-propagation type. A propagation type PD has has one propagation node. A propagation node of a PD is a leaf node whose semantic structure is identical with the semantic structure of the root node of the PD 4. The rest of the PD's, which have no propagation nodes, are classified as non-propagation type PD's. This distinction is an extension of Shieber's chain rule and non-chain rule distinction. A PD sequence PD1 ..... PD,~ must satisfy the following constraints. 1. semantic structure sharing constraints (a) PDi(1 <_ i < n) is a propagation PD, (b) PD~ is a non-propagation PD, Under these constraints, the system can make a partial phrase structure by unifying the propagation node of PDI with the root uode of PDi+l. Tile root node of the created structure contains the unified semantic structure of all semantic structures of PD's in the sequence. The covering constraint ensures complete generation [6] . If the constraint is not sarisfled, a given semantic structure may not be completely realized in the generation result. For example, if all input semantic strucure is (3) (in Section 1) and the unified semantic structure of a PD sequence is (1), then the resulting PD sequence lacks the locative phrase for the \"time\" feature, which will not appear in the generation result. local unifiability constraints disjointness constraints For each PD (PDi), there is no other PD (PDj(i # j)), such that PDI has a top arc whose label is included in the set of top arcs of PDj. The definition of top arc is given above. If this constraint is not satisfied, the generation result may contain duplicated or invalid expressions. For example, if a PD sequence contains two distinct PD's each of which is for a locative adjunct and has a \"time\" feature on the top level, the generation result will have two locative adjuncts for one semantic feature (i.e. tile \"time\" feature). The disjointness constraint also ensures compaetgeneration. Suppose a coherent and complete generator produces a string w, and the grammar assigns a semantic structure fso to w using a set of rules R. String w is minimal if every sub-structure of fso is supplied from one rule in R. The generator is compact if any string w is minimal. Ill general, completeness, &lid conlpactness cannot actually be judged until the entire generation fiulshes. Thus the last two constraints (3 and 4) do not reaiiy guarantee completeness and compactness; rather, they help to limit search space in a practical way. PD Application The PD application step is responsible for creating phrase structure(s) fl'om PD sequence(s) and attaching them to the expanding node. In this section, we restrict ourselves to the simple case such that there is only one PD sequence obtained during the previous step. The case of multiple PI) sequences, (i.e., generation ambiguity), will be discussed in the next section. First, the module connects all PD's in the PD sequence PDI...PD,, by unifying the propagation node of PDi with the root node of PDI+1. All unification operations are quasi-destructive, or temporal [7] . The result of the unification is valid until the module copies it (see below). If this entire unification process succeeds (i.e., if every PI) in the sequence can indeed be unified, and the sequence thus proves to be globally unifiable; see 3.7), then the module makes a copy of the unified PD sequence. Otherwise expansion failure (see next section) is signified. The copy, which is a phrase structure tree, is called an instance of the PD sequence. Then the module attaches (unifies) the instantiatted PD sequence to the expanding node. Finally, the system stores in the exl)andiug node agenda leaf nodes of expanded structures which have no lexieal feature values.. 3.6 Ambiguity Handling 3.6.1 Ambiguity packing If multiple PD sequences are applicable to an expanding node, the substructure of the expanding node can not be uniquely determined, because each PD sequence indicates only an hypothesis for' the potential substructure. The system maintain these hyl)otheses in a special hypotheses slot on the undetermined expanding node. For each PD sequence, a copy of the expanding node (:ailed an hypothesis node is created. These copies are stored into the hypotheses slot of the original expanding node. Then the system ap plies each PD sequence to the corresponding hypothesis node, as described in the previous section, and continues expansion. In Figure 7 , three suhtrees in the \"hypo\" slol. on the undetermined node have been created for' the hypothetical Pl) sequences. The hyl)othetical PI) sequences are not unb lied with the original expanding node, but unb tied with copies of the expanding node. This pre vents tire original feature structure of the undetermined node from being modilied by further expansion of the hypothetical structures (T I-T3 in Figure 7 ). q'he further expansion sometimes makes an hypothesis node inconsistent with the original node. This is detected in the ambiguity resohltion process described in the next section. Expansion Failure and Ambiguity ILesolution Expansion failure occurs when: 1. ]to PD is activated in the PD activation, or 2. no PD sequences are obtained in the pre combination, or 3. no PI) sequences satisfy global connectability in the application. The failure signifies that the feature strncture of the current exl)anding node is inconsistent with a set of Pl)'s given as generation knowledge. The module searches tbr the ne;~rest (i.e., lowest) hypothesis node (Nh) dominating the failed expanding node and deletes Nh fi'om the hypotheses slot containing it. If the number of hyl)othetical structures in the hyl>otheses slot of a.n undetermined re>de (N,,) hecomes one, then N,~ and the root node. of the remaining structnre in the hypotheses slot are unified. If the unilication f~tils, amlriguity resoh> tion continues recursively upw~rd. An examt)le of ambiguity resolution is illus trated in Figure 8 . The values of tire hyt)otheses slot of node VI' are the hypothetical nodes VPl, VP2, and vt'3, corresponding to hypothet ical trees TI, T2, 'I'3 respectively. If expansion failure occur in T I and '1'2, VP1 ;~nd V I'2 are removed from the hypothesis slot. Then, Vl'3 is unitied with VP, because there is only one hy pothesis node left in the slot VP node. If there is no hypothesis node dominating the failed expansion node, the entire generation l)r~)cess fails. AcrEs VP1 VP2 VP3 perform adjunct operation [9] . The algorithm is implemented in SL-Trans, a spoken language translation system [8] . Acknowledgments The author would like to thank M0zk Seligma~t for helpful comments on this paper and also would like to thank Akira Kurematsu, Tsuyoshi Morimoto and other members of ATR for their constant help and fruitful discussions. Expansion halts when no node is selected in the expanding node selection step. This does not necessarily mean the agenda is empty, because there m~y be some nodes without instantiated smnantic structure. ltow do such semantically empty nodes arise? The problem is that feature structnres within hy-potheticM nodes are not allowed to unify with the feature structure on the \"real\" dominating node. The solution is: for each hypothetical node, we create a complete tree using copies of the \"real\" dominating structure, Feature structures can then be permitted to unify with dominating structures. Then, the system collects all unlexicalized leaf re)des as initial values of the expanding node agenda and starts the normal expansion loop again. 4 Concluding Remarks A semantic head driven generation method based on feature structures is proposed in this paper. This method efliciently generates all possi ble phrase structures fl'om a given semantic feature structure. The method involves multiple indexing of feature structures and a precombination nlechanisn]. These lnechanisnls constrain applicable gralnmatical knowledge beR)re instantiation; thus the method eliminates the copying of fegture structures, which consunles conlputillg resources. The proposed grammar notation is appropriate for describing idiomatic phrase structures easily. To make the best use of the notation, we are extending the Mgorithm so that it can",
    "abstract": "This paper proposes a generation method for feature-structured)ased unification grammars. As comlx~red with fixed ~rity term notation, feature structure notation is more tlexible for representing knowledge needed to generate idiom~ttic structures as well as genem~l constructions. The method enables feature strncture retrieval via nmltiple indices. The indexing mechanism, when used with a semantic head driven generation algorithm, attains efficient generation even when a large amount of generation knowledge must be considered. Our method can produce all possi ble structures in parNlet, using structure sharing among ambiguous substructures.",
    "countries": [
        "Japan"
    ],
    "languages": [
        "Sema"
    ],
    "numcitedby": "6",
    "year": "1992",
    "month": "",
    "title": "Feature Structure Based Semantic Head Driven Generation"
}