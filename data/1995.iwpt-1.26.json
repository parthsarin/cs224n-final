{
    "article": "The availability of large, syntactically-bracketed corpora such as the Penn Tree Bank affords us the opportunity to automatically build or train broad-coverage grammars, and in particular t.o train probabilistic grammars. A number of recent parsing experiments have also indicated that. grammars whose production probabilities are dependent on the ,context can be more effective than context-free grammars in selecting a correct parse. To make maximal use of context, we have automatically constructed, from the Penn Tree Bank version 2, a grammar in which the symbols S and NP are the only real non terminals, and the other non-terminals or grammatical nodes are in effect embedded into the right-hand-sides of the S and NP rules. For example, one of the rnles extraded from the tree bank would be S -> NP VBX JJ CC VBX NP [1] ( where NP is a non-terminal and the other symbols are terminals -part-of-speech tags of the Tr-ee Bank). Tbe most common structure in t.he Tree Bank a5 sociat.ed with this expansion is (S \u2022 NP (VP (VP VB.I (ADJ JJ) CC (VP VBX NP ) ))) [2] . So if our parser uses rule [l] jn parsing a sentence, it. will generate structure [2] for the corresponding part of the sentence. l. sing 94% of the Penn Tree Bank for training, we extracted 32,296 distinct rules (2:3,386 for S, and \ufffd.910 for NP ). We also built a smaller version of the grammar based ,on higher f r equency patterns for use a5 a back-up when the larger grammar is unable to produce a parse due to memory limitation. We applied this parser to 1,989 Wall St1\u2022eet Journal sentences (separate from the training set and with no lirrnt on sentence length). Of the parsed sentences (1,899), the percentage of no-crossing sentences is 33:9%, and Parseval recall and precision are 73.43% and 72.61 %. An \"Ultimate Parser\" and a Compromise An \"Ultimate parser\" : parsing by look-up Because of the existence of large syntactically-bracketed corpora and the ad vantage of context sensitive parsing, we can contemplate an ultimate parsing strategy -parsing by table look-up. This approach is based on the assumption that the corpus covers most of the possible sentence structures in a domain. In other words, most of the time, you can find the structure of any given sentence in the corpus. If this assumption were correct, we could parse a sentence just by look up. The system first assigns parts-of-speech to an input sentence using a tagger, and then just searches for the same sequence of parts-of-speech in the corpus. The structure of the matched sequence is the output of the system. Now we will see if the assumption is correct. We investi gated the Penn Tree Bank corpus version 2, which is one of the largest syntactically-bracketed corpora, but it turned out that this strategy does not look practical. Out of 4,7219 sentences in the corpus 1 , only 2,2:32 sentences (4.7%) have exactly the same structure as another sentence in the corpus. This suggests that, if we apply the above strategy, we would find a match , and hence be able to produce a parse for only 4.7% of the sentences in a new text. C0111pr0111ise We therefore have to make a compromise. Instead of seeking a complete match for the part of-speech sequence of an entire sentence, we introduce partial sequence matchings based on the two important non-terminals in the Penn Tree Bank, S (sentence) and NP (noun phrase) . We try to find a nested . set of S and NP fragments in the given sentence so that the whole sentence is derived from a single S and then apply the look-up strategy for each fragment. In other words, at first the system collects, for each instance of S and NP in the training corpus, its expansion into S ' s, NP ' s, and lexical categories; this is, in effect, a production in a grammar with non-terminals S and NP . It also records the full constituent structure for each instance. In analyzing a new sentence, it tries to find the best segmentation of the input into S's and NP's; it then outputs the combination of thr structures of the chosen segments. To assure that this strategy is applicable, we collected statistics from the Penn Tree Bank (Table 1). From the table, we can see that there are a considerable number of multiple occurrences of structures, and that a very small number of structures covers a large number of instances in the corpus. The most frequent structures for S and NP are shown just below. The numbers on the left indicate their frequency. Most of Introduction The availability of large, sy ntactically-bracketed corpora such a5 the University of Pennsylvania Tree Bank affords us the opportunity to automatically build or train broad-coverage grammars. Although it is inevitable that a structured corpus will contains errors , statistical methods and the size of the corpus may be able to ameliorate the effect of individual errors. Aiso, because a large corpus will include examples of many rare constructs, we have the potenitial of obtaining broader coverage than we might with a hand-constructed grammar. Furthermore, experiments over the past few years have shown the benefits of using probabilistic information in parsing, and the large corpus allows us to train the probabilities of a grammar (8) {7] [l l] :(2) [4] , (12] . A number of recent parsing experiments have also indicated that grammars whose production prob,:i bilities are dependent on the context can be more effective than context-free grammars in selecting a correct parse. This context sensitivity can be acquired ea5ily using a large corpus, whereas human ability to compute such information is obviously limited. . There have been several attempts to build context-dependent grammars based on large corpora. (14] (1 1] (13] (2] (4] (12]. As is evident from the two lists of citations, there has been considerable research involving both probabilistic grammar based on syntactically-bracketed corpora and context-sensitivity. For example, Black proposed 'History based parsing', a context-dependent grammar trained using a large corpus (2] . History-based parsing uses decision-tree methods to identify the most useful information in the prior context for selecting the next production to try. This approach, however, requires a hand-constructed grammar as a starting point. Bod (4) has described how to parse directly from a tree bank. A new parse tree can be assembled from arbitrary subtrees drawn from the tree bank; the parser searches for the com bination with highest probability. This can, in principle, take advantage of arbitrary context information. However, the search space is extremely large, so a full search is not practical , even for a small tree bank (Bod proposes using Monte Carlo methods instead) . Results have been reported only for a small tree bank of 7.50 ATIS sentences. In this paper we will present a parsing method which involves both probabilistic techniques based on a syntactically-bracketed corpus and context sensitivity. We will describe a very simple approach which allows us to create an efficient parser and to make use of a very large tree bank. Alt.hough we see that many structures are covered by the data in the corpus, there could be ambiguities where two or more structures can be created from an identical part-of-speech sequence. For example, the prepositional attachment problem leads to such ambiguities. The survey on Penn Tree Bank shows us the percentage of the sequences which could be derived from S and NP \\V ith diffe rent structures are 7% and 12%, respectively. The maximum number of diffe rent structures for the same part-of-speech sequence are 7 for S and 12 for NP. However, by taking the most frequent structure for each ambiguous sequence , we can keep such mistakes to a minimum. We find that the errors caused by this are 8% and :3 % for S and NP, respectively. vVe believe these errors can be reduced by introducing lexical or semantic information in the parsing. This will be discussed later. Category II s NP Frorn these statistics, we can conclude that many structures of S and NP can be covered by the data in the Penn Tree Bank. This result supports the idea of the parsing with two non terrninals, S and NP which segment the input, and the structure inside the segment is basically decided by table look-up. However, because we introduce non-terminals and hence introduce ambiguities of segment boundary, the overall process becomes more like parsing rather than just table look-up. Grammar Minor modification We made four kinds of minor modification to the grammar, in order to improve its coverage and accuracy. First, the punctuation mark at the end of each sentence is deleted. Tagging As the first step in parsing a sentence, one or more part-of-speech tags are assigned to each input. token, based on the tags assigned to the same token in the training corpus. ( Note that this introduces ambiguity. ) Each tag has a probability which will be used in the score calculation in parsing. The probability is based on the relative frequency of the tag assigned to the token in the corpus. We set the threshold for. the probability to 5% in order to make the parser efficient. Tags with smaller probability than the threshold are discarded. Score Calculation Frequency of word w with tag t Pta g ( tl w ) = ----------F1\u2022equency of word w ( 1) The fo rmulae for the probability of an individual rule P ru t e. and the score of a parsed tree Stre.e. (2) (3) Although we built a parser which can handle a large grammar, as described in the next section, it is unable to parse some long sentences, because of computer memory limitations. So we prepared a smaller grammar, for use in case the larger grammar can't parse a sentence. The small grammar consists of the rules having frequency more than 2 in the corpus . Because the number of rules is small, parsing is rarely blocked by space limitations . The parsed result of this grammar is used only when the larger grammar does not produce a parse tree. Table 2 shows the numbers of rules in the larger grammar(G-0) and the smaller grammar {G-2) . The number of rules in G-0 is smaller than the number of 'distinct structures' shown in  rulPs, \"G-2\" is the grammar with rules of frequency more than 2. \"No parse\" means the parser can 't get S for the whole structure, \"space exhausted\" means that the node space of the parser is exhausted in the middle of the parsing. \"Sentence length\" is the average length of parsed sentences, and the run time is the parse time per sentence in seconds using a SPARC 5. Although the average run time is quite high, more than half of the sentences can be parsed in less than :3 seconds while a small number of sentences take more than 60 seconds. We can see that the number of \"no parse\" sentences with G-2 is larger than that with G-0. This is because there are fewer grammar rules in G-2, so some of the sequences have no matching pattern in the grammar. It is not easy to compare these numbers between systems, because some conditions of the test sentences, length , complexity, etc. , affect the result. However, roughly speaking, these numbers are rnmparable to or better than the score of so-called traditional grammar, or hand made grammars. For example, Black [:3] <;:ited the best non-crossing score using a traditional grammars as 41 % and the average of several systems as 22%. Experiment For our experiments, the WSJ corpus of the Penn Tree Bank is divided into two portions. One is used for training (96%) and the other part is used for testing. The training corpus is used to extract grammar rules and the test corpus contains 1,989 sentences. The parsing results are shown in It. is natural that the _number of sentences which exhaust memory is larger for G-0 than for G-2, because of the larger number of rules. Next, the evaluation using parseval method on parsed sentences is shown in Table 4. \"Parse val\" is the measurement of parsed result proposed by Black et.al. [l] . The result in the table is the result achieved by the G-0 grammar, supplemented by the result using the G-2 grammar, if the larger grammar can't generate a parse tree. These numbers are based only on the sentences which parsed (1,899 out of 1,989 sentences; in other words 90 sentences are left as unable-to be-parsed sentences even using the back-up method). Here, \"complete match\" means that the result is exactly the same as the corresponding tree in the Penn Tree Bank. \"No-crossing\" is the Future work Analyzing the errors made by the parser, we found that a considerable number of unparsed sentences (including no-parse and memory-exhausted sentences) and wrongly parsed sentences contain special symbols, like ':', '-', To r ')'. Our strategy to enumerate structures, is not good at. parsing sentences which have rare tokens like these symbols. Furthermore, there are some odd sentences involving these symbols. For example, there are sentences which have an unbalanced parenthesis, because of incorrect division of the text into sentences or multiple sentences within a single pair of parentheses. In order to parse these sentences, we believe, special pre-treatments are needed. As was mentioned earlier, there are several part-of-speech sequences which could generate several diffe rent structures. One source of ambiguity is annotator's inconsistencies, which we can \u2022t deal with . Another major source is attachment problems, such as prepositional attachment or conj unctive (and, or) attachment. Although it is well known that some of these ambiguities are unsolvable using only the context within the sentence, many of them are heavily related to the lexical or semantic information within the sentence. We have been conducting research on automatically acquiring these selectional constraints, and we are planning to incorporate this semantic knowledge into the parser [9j , (15] . Introducing lexical information in the parser is also useful for other kinds of the structural disambiguation. We showed this in minor modification 4, by introducing new categories based on lexicon . However. the method we used to choose the candidates depended on human intuition. We a.re considering creating an automatic method to identify those words for which it is beneficial to make a new category. Conclusion We developed a corpus-ba5ed probabilistic grammar whose rules are extracted from syntactically bracketed corpora. The grammar has only two non-terminals, S and NP . The rules of the grammar contain grammatical non-terminal within \u2022 the tree. This feature introduces context sensitivity for the terminals. Corpus-ba5ed grammar generation has a significant advantage over building a grammar by hand , particu larly if we aspire to a high degree of coverage. Once we have a syntactically bracketed corpus for a new domain, a grammar can be automatically created for that domain. While building syntactically-bracketed corpora is not so easy, large-scale corpora have been successfully constructed by teams of coders; building a very-broad-coverage grammar by hand has proven much more challenging. We conducted an experiment using two grammars derived from a tagged corpus. The accu racy is about the same or better than with a conventional grammar. As this grammar uses only part-of-speech information, we may be able to improve it by incorporating lexical or semantic information. Acknowledgments The work reported here was supported by the Advanced Research Projects Agency under con tract DABT63-93-C-0058 from the Department of the Army. Also, we would like to thank our colleagues at NYU and the member of Penn Tree Bank Project. (15] S.Sekine, S.Ananiadou, .J ..J.Carroll, .J.Tsujii: \"Linguistic Knowledge Generatol'.\" COLING-92 (1992) References (l] E.Black, et.al. \"A procedure for",
    "abstract": "The availability of large, syntactically-bracketed corpora such as the Penn Tree Bank affords us the opportunity to automatically build or train broad-coverage grammars, and in particular t.o train probabilistic grammars. A number of recent parsing experiments have also indicated that. grammars whose production probabilities are dependent on the ,context can be more effective than context-free grammars in selecting a correct parse. To make maximal use of context, we have automatically constructed, from the Penn Tree Bank version 2, a grammar in which the symbols S and NP are the only real non terminals, and the other non-terminals or grammatical nodes are in effect embedded into the right-hand-sides of the S and NP rules. For example, one of the rnles extraded from the tree bank would be S -> NP VBX JJ CC VBX NP [1] ( where NP is a non-terminal and the other symbols are terminals -part-of-speech tags of the Tr-ee Bank). Tbe most common structure in t.he Tree Bank a5 sociat.ed with this expansion is (S \u2022 NP (VP (VP VB.I (ADJ JJ) CC (VP VBX NP ) ))) [2] . So if our parser uses rule [l] jn parsing a sentence, it. will generate structure [2] for the corresponding part of the sentence. l. sing 94% of the Penn Tree Bank for training, we extracted 32,296 distinct rules (2:3,386 for S, and \ufffd.910 for NP ). We also built a smaller version of the grammar based ,on higher f r equency patterns for use a5 a back-up when the larger grammar is unable to produce a parse due to memory limitation. We applied this parser to 1,989 Wall St1\u2022eet Journal sentences (separate from the training set and with no lirrnt on sentence length). Of the parsed sentences (1,899), the percentage of no-crossing sentences is 33:9%, and Parseval recall and precision are 73.43% and 72.61 %. An \"Ultimate Parser\" and a Compromise An \"Ultimate parser\" : parsing by look-up Because of the existence of large syntactically-bracketed corpora and the ad vantage of context sensitive parsing, we can contemplate an ultimate parsing strategy -parsing by table look-up. This approach is based on the assumption that the corpus covers most of the possible sentence structures in a domain. In other words, most of the time, you can find the structure of any given sentence in the corpus. If this assumption were correct, we could parse a sentence just by look up. The system first assigns parts-of-speech to an input sentence using a tagger, and then just searches for the same sequence of parts-of-speech in the corpus. The structure of the matched sequence is the output of the system. Now we will see if the assumption is correct. We investi gated the Penn Tree Bank corpus version 2, which is one of the largest syntactically-bracketed corpora, but it turned out that this strategy does not look practical. Out of 4,7219 sentences in the corpus 1 , only 2,2:32 sentences (4.7%) have exactly the same structure as another sentence in the corpus. This suggests that, if we apply the above strategy, we would find a match , and hence be able to produce a parse for only 4.7% of the sentences in a new text. C0111pr0111ise We therefore have to make a compromise. Instead of seeking a complete match for the part of-speech sequence of an entire sentence, we introduce partial sequence matchings based on the two important non-terminals in the Penn Tree Bank, S (sentence) and NP (noun phrase) . We try to find a nested . set of S and NP fragments in the given sentence so that the whole sentence is derived from a single S and then apply the look-up strategy for each fragment. In other words, at first the system collects, for each instance of S and NP in the training corpus, its expansion into S ' s, NP ' s, and lexical categories; this is, in effect, a production in a grammar with non-terminals S and NP . It also records the full constituent structure for each instance. In analyzing a new sentence, it tries to find the best segmentation of the input into S's and NP's; it then outputs the combination of thr structures of the chosen segments. To assure that this strategy is applicable, we collected statistics from the Penn Tree Bank (Table 1). From the table, we can see that there are a considerable number of multiple occurrences of structures, and that a very small number of structures covers a large number of instances in the corpus. The most frequent structures for S and NP are shown just below. The numbers on the left indicate their frequency. Most of",
    "countries": [
        "United States"
    ],
    "languages": [
        ""
    ],
    "numcitedby": "140",
    "year": "1995",
    "month": "September 20-24",
    "title": "A Corpus-based Probabilistic Grammar with Only Two Non-terminals"
}