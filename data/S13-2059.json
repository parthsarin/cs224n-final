{
    "article": "In this paper, we describe our system that participated in SemEval-2013, Task 2.B (sentiment analysis in Twitter). Our approach consists of adapting Naive Bayes probabilities in order to take into account prior knowledge (represented in the form of a sentiment lexicon). We propose two different methods to efficiently incorporate prior knowledge. We show that our approach outperforms the classical Naive Bayes method and shows competitive results with SVM while having less computational complexity. Introduction With the advent of Internet microblogging, social networks, like Twitter 1 and Facebook 2 , have brought about a real revolution in our way of communicating. People share their opinions of everyday life without taboos or restrictions thanks to the anonymity offered by these tools, which makes them a valuable source of information rather rich of subjective data. These data can be mined using sentiment analysis as a means to understand people's feelings towards a political cause or what people are thinking about a product or a service. Recent works showed that Twitter sentiments can be correlated to box-office revenues (Asur and Huberman, 2010) or political polls (O'Connor et al., 2010) . Machine learning methods, like Naive Bayes (NB) and Support Vector Machines (SVM), have been widely used in sentiment analysis (Pang et al., 1 http://www.twitter.com/ 2 http://www.facebook.com/ 2002; Pak and Paroubek, 2010) . One major problem with these methods, and in particular NB, is that the model is built only on the learning data which can lead to overfitting. In this paper, we describe our approach that participated in SemEval-2013, Task 2.B (sentiment analysis in Twitter) (Wilson et al., 2013) . Our approach consists of learning with both NB and prior knowledge. We show that our approach outperforms the classical NB method and gives competitive results compared to SVM while having less computational complexity. The remainder of this paper is organized as follows: prior works on sentiment analysis are discussed in Section 2. The proposed approach is detailed in Section 3. Then, experiments and results are given in Section 4 and 5. Background Sentiment analysis is a text mining task which deals with the feelings expressed explicitly or implicitly in a textual content. It concerns subjectivity analysis (subjective/objective), opinion mining (positive/negative/neutral), strength analysis, etc. Although the term \"sentiment analysis\" includes all these tasks, it often refers to opinion mining. Sentiment analysis methods can be categorized into machine learning, linguistic and hybrid methods. Machine learning methods are usually supervised. A model is built based on a learning dataset composed of annotated texts and represented by a bag of words. The model is then deployed to classify new texts. Pang et al. (2002) use machine learning methods (NB, SVM and MaxEnt) to detect sentiments on movie reviews. Pak and Paroubek (2010) use NB to perform sentiment analysis on Twitter data. Linguistic methods use lexicons and manuallycrafted rules to detect sentiments. Kennedy and Inkpen (2006) use syntactic analysis to capture language aspects like negation and contextual valence shifters. Other works (Turney and Littman, 2003; Kamps et al., 2004) propose to use a term similarity measure which can be statistical (e.g., Mutual Information, LSA) or semantic (e.g., WordNet-based) . Hybrid methods use both statistical and linguistic approaches. Esuli and Sebastiani (2011) , which is the closest work to ours, propose to use annotated lexical resources to improve opinion extraction. The bag-of-word text representation is enriched by new tags (e.g. subjectivity, polarity). Then, an SVMbased system is used for opinion classification. Our approach NB is a machine learning method that builds a classification model based only on the learning data which makes it highly dependent on this data. For example, in a sentiment analysis task, if the term actor appears more frequently within a negative context than in a positive one, it will be classified as negative while actually it is not. Moreover, NB tends sometimes to predict the class of majority (observed on learning data) which increases classification errors on unbalanced data. Our approach consists of incorporating prior knowledge into the NB model to make it less dependent on learning data. To be efficiently used, prior knowledge must be represented in a structured form. We choose, here, to represent it by a sentiment lexicon (a set of positive and negative terms). Several lexicons have already been developed to address sentiment analysis issues. Some of them are publicly available like the MPQA subjectivity lexicon (Wilson et al., 2005 ), Liu's opinion lexicon (Ding et al., 2008) , Senti-WordNet (Esuli and Sebastiani, 2006) . We believe that such knowledge can be quite useful if used correctly and efficiently by machine learning methods. In the following, we settle for a 2-way classification task (positive vs. negative). Texts are represented by a vector space model (Salton et al., 1975) and terms are weighted according to their presence/absence in the text because previous works (Pang et al., 2002; Pak and Paroubek, 2010) showed that Boolean model performs better than other weighting schemes in sentiment analysis. We denote by w and w the presence, respectively absence, modality of a word w. A \"term\" stands, here, for any type of text features (smileys, n-grams). Sentiment lexicon We represent the prior knowledge by a 2-class sentiment lexicon: a list of subjective terms (words, n-grams and smileys) manually annotated with two scores: positive (score c + ) and negative (score c \u2212 ). Each term has a score of 1 on a class polarity (we call it right class) and 0 on the other one (wrong class). For example, the word good has score c + = 1 and score c \u2212 = 0. Then, c + is the right class of the word good and c \u2212 is the wrong class. NB method NB is based on calculating class-wise term probabilities on a learning dataset D where each text d \u2208 D is annotated with a class c \u2208 {c + , c \u2212 }. In the learning step, probability values p(w|c) are estimated from D as follows: p(w|c) = 1 nb(c) \u2022 nb(w, c) (1) Where nb(c) denotes the number of texts of class c and nb(w, c) is the number of texts of class c that contain the term w. Once these probabilities are calculated for each couple (w, c), the model can be used to classify new texts. We choose to assign a new text d to the class that maximizes the probability p(c|d). Using Bayes' theorem and independence assumption between term distributions, this probability is calculated as follows (the denominator can be dropped because it is not dependent on the class c): p(c|d) = p(c) \u2022 w\u2208d p(w|c) p(d) (2) Incorporating prior knowledge Prior knowledge is incorporated by adapting NB formulas. We propose two different methods to do this: Add & Remove and Transfer. These methods differ in the way to calculate the class-wise term probabilities p(w|c) but use the same classification rule: class(d) = arg max c\u2208{c + ,c \u2212 } p(c|d). Add & Remove. This method consists of artificially adding some occurrences of term w to the right class and removing some occurrences from the wrong class. The lexicon is used to determine for each term its right and wrong classes. To ensure that probability values do not exceed 1, we introduce nb( w, c), the number of texts of class c that do not contain the term w, which is also equal to the maximum number of occurrences of w that can be added to the class c. Thus, the number of added occurrences is a ratio \u03b1 c of this maximum (0 \u2264 \u03b1 c \u2264 1). Likewise, if c was the wrong class of w, the number of removed occurrences from the class c is a ratio \u03b2 c of the maximum number that can be removed from the class c, nb(w, c), with 0 \u2264 \u03b2 c \u2264 1. Formally, term probabilities are calculated as follows: p(w|c) = 1 nb(c) \u2022[nb(w, c)+\u03b1 c \u2022score c (w)\u2022nb( w, c) \u2212\u03b2 c \u2022 score c(w) \u2022 nb(w, c)] (3) Transfer. This method consists of transferring some occurrences of a term w from the wrong class to the right class. The number of transferred occurrences is such that the final probability is not greater than 1 and the number of transferred occurrences is not greater than the actual number of occurrences in the wrong class. To meet these constraints, we introduce max(w, c): the maximum number of occurrences of w that can be transferred to the class c from the other class c. This number must not be greater than both the number of texts from c containing w and the number of texts from c not containing w. max(w, c) = min{nb(w, c), nb( w, c)} (4) Finally, the number of occurrences actually transferred is a ratio \u03b1 c of max(w, c) with 0 \u2264 \u03b1 c \u2264 1. Term probabilities are estimated as follows: p(w|c)= 1 nb(c) \u2022[nb(w, c)+\u03b1 c \u2022score c (w)\u2022max(w, c) \u2212\u03b1 c \u2022 score c(w) \u2022 max(w, c)] (5) Both methods, Add & Remove and Transfer, consist of removing occurrences from the wrong class and adding occurrences to the right class with the difference that in Transfer, the number of added occurrences is exactly the number of removed ones. Experiment Sentiment lexicon For SemEval-2013 contest (Wilson et al., 2013) , we have developed our own lexicon based on Liu's opinion lexicon (Ding et al., 2008) and enriched with some \"microblogging style\" terms (e.g., luv, xox, gd) manually collected on the Urban Dictionary 3 . The whole lexicon contains 7720 English terms (words, 2-grams, 3-grams and smileys) where 2475 are positive and 5245 negative. Dataset and preprocessing To evaluate the proposed approach, we use SemEval-2013 datasets: TW (tweets obtained by merging learn and development data) and SMS, in addition to MR (English movie reviews of Pang and Lee (2004) ). Concerning SMS, the classification is performed using the model learned on tweets (TW) in order to assess how it generalizes on SMS data. Note that our approach is adapted to binary classification but can be used for 3-way classification (which is the case of TW and SMS). We do this by adapting only positive and negative probabilities, neutral ones remain unchanged. Texts are preprocessed by removing stopwords, numerics, punctuation and terms that occur only once (to reduce vocabulary size and data sparseness). Texts are then stemmed using Porter stemmer (Porter, 1997) . We also remove URLs and Twitter keywords (via, RT) from tweets. Tools As we compare our approach to SVM method, we have used SVM multiclass (Crammer and Singer, 2002) . For a compromise between processing time and performance, we set the trade-off parameter c to 4 on MR dataset and 20 on TW and SMS (based on empirical results). Results and discussion In addition to the two proposed methods: Add & Remove (A&R) and Transfer (TRA), texts are classified using NB and SVM with two kernels: linear (SVM-L) and polynomial of degree 2 (SVM-P). All the scores given below correspond to the average F-score of positive and negative classes, even for 3-way classification. This measure is also used in SemEval-2013 result evaluation and ranking (Wilson et al., 2013) . General results General results are obtained only with unigrams and smileys. Figure 1 presents the results obtained on the different datasets on both 2-way (left) and 3way (right) classifications. For 2-way classification, neutral texts are ignored and the model is evaluated using a 5-fold cross validation. For 3-way classification, the model is evaluated on the provided test data. Compared with NB, our approach performs better on all datasets. It also outperforms SVM, that achieves poor results, except on MR.  Parameter effect. To examine the effect of parameters, we perform a 2-way classification on TW and MR datasets using 5-fold cross validation (Figure 2 ). We take, for A&R method, \u03b2 c + = \u03b2 c \u2212 = 0 and for both methods, \u03b1 c + = \u03b1 c \u2212 (denoted \u03b1). This configuration does not necessarily give the best scores. However, empirical tests showed that scores are not significantly lower than the best ones. We choose this configuration for simplicity (only one parameter to tune). Figure 2 shows that best scores are achieved with different values of \u03b1 depending on the used method (A&R, TRA) and the data. Therefore, parameters must be fine-tuned for each dataset separately. SemEval-2013 results For SemEval-2013 contest, we have enriched text representation by 2-grams and 3-grams and used A&R method with: \u03b1 c + = \u03b1 c \u2212 = 0.003, \u03b2 c + = 0.04 and \u03b2 c \u2212 = 0.02. All of these parameters have been fine-tuned using the development data. We have also made an Information Gain-based feature selection (Mitchell, 1997) . Only the best 2000 terms are kept to which we added terms of the lexicon. Under these conditions, our approach achieved the scores 62.55% on tweets (ranked 6 th /35) and 53.63% on SMS (ranked 9 th /28). Dataset Class Pecision  Regarding F-score of each class (Figure 3 ), our approach gave better results on the negative class (under-represented in the learning data) than NB (49.09% on TW and 47.63% on SMS). Conclusion In this paper, we have presented a novel approach to sentiment analysis by incorporating prior knowledge into NB model. We showed that our approach outperforms NB and gives competitive results with SVM while better handling unbalanced data. As a future work, further processing may be required on Twitter data. Tweets, in contrast to traditional text genres, show many specificities (short size, high misspelling rate, informal text, etc.). Moreover, tweets rely on an underlying structure (re-tweets, hashtags) that may be quite useful to build more accurate analysis tools.",
    "abstract": "In this paper, we describe our system that participated in SemEval-2013, Task 2.B (sentiment analysis in Twitter). Our approach consists of adapting Naive Bayes probabilities in order to take into account prior knowledge (represented in the form of a sentiment lexicon). We propose two different methods to efficiently incorporate prior knowledge. We show that our approach outperforms the classical Naive Bayes method and shows competitive results with SVM while having less computational complexity.",
    "countries": [
        "France"
    ],
    "languages": [
        "English"
    ],
    "numcitedby": "5",
    "year": "2013",
    "month": "June",
    "title": "{AMI}{\\&}{ERIC}: How to Learn with Naive {B}ayes and Prior Knowledge: an Application to Sentiment Analysis"
}