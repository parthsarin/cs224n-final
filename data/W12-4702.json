{
    "article": "Over the years, the usage of discourse relations has been proven to enhance many applications such as text summarization, question answering and natural language generation. This paper proposes an approach that expands the benefit of discourse relations for natural language processing from a different aspect. We exploit the discourse relations existing between sentences to generate clusters of similar sentences from document sets. We first examined and defined the type of discourse relations that useful to retrieve sentences with identical content. We then assigned these relations to each sentence pair using a machine learning method. Finally we performed discourse relation-based clustering algorithm to generate clusters of similar sentences. We evaluated our method by measuring the cohesion and separation of the clusters and compared to a well recognized clustering method. The experimental result shows that our method performed significantly well, which demonstrated that discourse relation between sentences can be exploited for text clustering. Introduction The massive amount of data growth each day has become motivation for many researchers to develop text processing system with the ability to comprehend and process data effectively. The interpretation of how the phrases, clauses, and texts relate to each other is crucial to retrieve relevant information from texts. Therefore, the knowledge of discourse relation is prominent for natural language processing. Many discourse coherent structures have been proposed over the years, such as Rhetorical Structure Theory (RST) (Mann and Thompson, 1987) , RST Treebank (Carlson et al., 2002) , Lexicalized Tree-Adjoining Grammar based discourse (Webber et al., 2003) , Cross-document Structure Theory (CST) (Radev et al., 2004) , and Discourse GraphBank (Wolf and Gibson, 2005, 2006) . Discourse GraphBank represents discourse relation as graph structure, while other works represent them as hierarchical structure between textual units. Each work proposed different kind of methods to distinguish how events in text are related by identifying the transition point of a relation from one text span to another. Here, similar to the TDT project, an event refers to something that occurs at a specific place and time associated with some specific actions. This gives system abilities to detect important information or content within the text spans. For instance, the following example describes \"Evidence\" relation between texts proposed by RST. Example 1: S 1 : Smokes billows from the Pirelli building. S 2 : The Pirelli Building in Milan, Italy, was hit by a small plane. S1 describes an event (claim), while S2 describes the information to increase the reader's belief, which is the evidence of why the event occurred. This relation indicates that information in S2 is necessary for S1 to take place. Consider another example of discourse relation from different structure. The following sentences describe \"Subsumption\" relation defined by CST. Example 2: S 3 : Police were trying to keep people away, and many ambulances were at the scene. S 4 : Police and ambulance were at the scene. CST defined sentences with Subsumption relation as having the same content along with additional facts in one sentence compared to another. From this example, Subsumption indicates that the content conveyed by S4 is alternatively can be expressed in S3 with more information. We found that discourse relation between sentences not only indicates how two sentences are connected to each other, but also shows the amount of similar contents in both sentences. Relations such as Identical (defined in many discourse structures), Subsumption (CST), and Generalization (RST), links two text span in different way, however, provides identical information regarding the corresponding event. For instance, we observed that the same information can be extracted from Subsumption in Example 2, where both sentences indicate that police and ambulance were at the scene. Therefore, we are motivated to explore the potential of discourse relation further more. By exploiting discourse relation between text spans, we believe that clusters of similar sentences can be constructed. We propose a method that establishes the benefit of discourse relation in generating cluster of similar sentences. Our main objective is to expand the usage of discourse relation to data mining in natural language processing. In addition, we also hope to explore the construction of text clustering based on user preference, where users can determine how much similarity of information allowed in a text cluster according to the type of discourse relations used during clustering, which is difficult to achieve only with lexical and syntactic features of the sentences. For instance, clustering of sentences with Identity relation would only allow sentences with the exact same information within a cluster, while sentences with Overlap would include sentences with partial overlapping information within a cluster. Our method consists of three main steps. We first define discourse relations which are useful for text clustering. Then, we identify these relations using Support Vector Machine (SVMs) (Vapnik, 1995) . Finally, we performed a discourse relation based clustering algorithm to create clusters of similar sentences. Next section provides an overview of the existing works regarding discourse relation. Section 3 describes the framework of our system. In Section 4, we report experimental results and conclude our discussion with some direction for further works. Previous Work Since large scale machine readable textual corpus has become available, many techniques have been proposed to harvest vital information from documents using discourse relations analysis. Up until now, discourse relations have benefit various NLP applications such as text summarization ( (Marcu, 1997) , (Zhang et al., 2002) , (Radev et al., 2004) , (Uz\u00eada et al., 2009) , (Louis et al., 2012) ), question answering ( (Litkowski, 2002) , (Verbe and Oostdijk, 2007) ) and natural language generation ( (Theune, 2002) , (Piwek et al., 2010) ). In text summarization, discourse relations are used to produce optimum ordering of sentences in a document, and remove redundancy from generated summaries. One of the well known works is CST based text summarization (Zhang et al., 2002) . In this work, sentences with most relations in the documents are considered to be important. They proposed an enhancement of text summarization by replacing low-salience sentences with sentences having maximum numbers of CST relations. Another work, (Uz\u00eada et al., 2009) presents comparative evaluation of RST-based text summarization methods. Besides informativeness, they also examined the effect of summary characteristics such as coherence and cohesion against each RST methods. One of the most recent work is a deep knowledge summarizer system (Jorge, 2010) , which ranks input sentences according to the number of CST relations existing between sentences in accordance with user preference. They also demonstrated the effectiveness of redundancy elimination in summary using discourse relations. Most of the CST-based work observed the effects of individual CST relationships to the summary generation, and focused on the user preference based summarization, which requires manually annotated corpus. The relevance of discourse analysis in QA application is pointed out by (Litkowski, 2002) . This approach makes use of structural information of sentences, e.g., discourse entities, semantic relation to generate database for question answering system. Another work, (Verbene et al., 2007) suggested that the propositions of a question topic and answer are both represented by a text span in document, where the connection between text spans are described by RST relation. The topic of text span that matches RST tree will be the answer to the why-question. Many of the previous works mentioned in the above show that the information obtained by discourse relation can improve single or multi-document summarization and QA application. In contrast, our work has different objective and approach. We investigated the potential of discourse relation in retrieving similar sentences, i.e. text clustering for data mining. Framework Redefinition of Discourse Relations Different work proposed different types and definitions of discourse relations. Since our objective is to retrieve sentences with similar content using discourse relation, discourse structure that defines discourse relation between two text spans is mostly appropriate. Therefore, in this paper, we adopted the definition of rhetorical relation by CST (Radev et al., 2004) Example 4: S 7 : The crash put a hole in the 25th floor of the Pirelli building, and smoke was seen pouring from the opening. S 8 : A small plane crashed into the 25th floor of a skyscraper in downtown Milan today. Both sentences can be categorized as Elaboration and Follow-up. We can see from Example 5 that Subsumption and Elaboration also shares some similar characteristics. Example 5: S 9 : The building houses government offices and is next to the city's central train station. S 10 : The building houses the regional government offices, authorities said. Thus, sentence pair connected as Subsumption can also be defined as Elaboration. However, sentence pair belongs to Elaboration in Example 2 cannot be defined as Subsumption. Here, Subsumption denotes S 2 as the subset of S 1 , but as for Elaboration, S 2 is not necessary a subset of S 1 . Therefore, we keep Subsumption and Elaboration as two different relations so that we can precisely perform the automated identification of discourse relation by using SVMs. We redefined the definition of relations from CST by combining the relations types that resemble each other as described in Example 3, 4 and 5. Fulfillment by CST refers to sentence pair which asserts the occurrence of predicted event, where overlapped information present in both sentences. Therefore, we combined Fulfillment and Overlap as one type of relation. As for Change of Perspective, Contradiction and Reader Profile, these relations generally refer to sentence pairs presenting different information regarding the same subject. Thus, we simply merged these relations as one group. We also combined Description and Historical Background, as both type of relations provide description (historical or present) of an event. The combination of rhetorical relations in this paper is concluded in Table 1 . We modified the definition of each relation in accordance with the combination of relations shown in Table 1 . The taxonomy for rhetorical relations we used in the system is described in Determining Discourse Relations Using SVMs To identify discourse relations, we used a machine learning approach, Support Vector Machine (SVMs) (Vapnik, 1995) . We used CST-annotated sentences pair obtained from CST Bank (Radev et al., 2004) as training data for the SVMs. Each data is classified into one of two classes, where we defined the value of the features to be 0 or 1. Features with more than 2 value will be normalized into [0,1] range. This value will be represented by 10 dimensional space of a 2 value vector, where the value will be divided into 10 value range of [0.0,0.1], [0.1,0.2], \u2026, [0.9,1.0]. For example, if the feature of text span S j is 0.45, the surface features vector will be set into 0001000000. We extracted 2 types of surface characteristic from both sentences, which are lexical similarity between sentences and the sentence properties. Although the similarity of information between sentences can be determined only with lexical similarity, we also included sentences properties as features to emphasis which sentences provide specific information, e.g. location and time of the event. We provided the surface characteristics to SVMs for learning and classification of the text span S 1 according to the given text span S 2 . Lexical Similarity between Sentences The amount of overlapping information among sentences is important to determine the type of discourse relations exist between them. Here, we used a few similarity measurements to compute the similarity between word content in both sentences from different aspects. We defined nouns, verbs and adjectives as word content in the experiment. Cosine Similarity We compute the similarity of both sentences using cosine similarity measurement, defined as follows: \uf0e5 \uf0e5 \uf0e5 \uf02a \uf02a \uf03d 2 , 2 2 , 1 , 2 , 1 2 1 ) ( ) ( ) , cos( i i i i s s s s S S (1) where S 1 and S 2 represents the frequency vector of the sentence pair, S 1 and S 2 , respectively. The cosine similarity metric measures the correlation between the two sentences. We observed the following 5 types of similarity in this experiment: i) Similarity between word contents ii) Similarity of nouns tokens iii) Similarity of verbs tokens iv) Similarity of adjectives tokens v) Similarity of bigram words We not only measure the similarity value of words, but also consider the similarity value of word sequence in (v). We found that different word sequence sometimes provides different meaning. For example, the word \"test driving\" and \"driving test\". The word \"test driving\" refers to the action of driving a vehicle in order to evaluate its performance, meanwhile \"driving test\" refers to procedure designed to test a person's ability to drive a motor vehicle. The words ordering indirectly determine the semantic meaning in sentences. Therefore, we included the similarity of bigram words in the measurement. 2. Overlap ratio of words from S 1 in S 2 , and vice versa The overlap ratio is measured to identify whether all the words in S 2 are also appear in S 1 , and vice versa. This measurement will determine how much the sentences match with each other. For instance, given the sentences pair with relations of Subsumption, the ratio of words from S 2 appear in S 1 will be higher than the ratio of words from S 1 appear in S s . We add this measurement because cosine similarity does not extract this characteristic from sentences. The overlap ratio is measured as follows: 2 ) ( # ) , ( # ) ( 1 2 1 1 \uf0b4 \uf03d S words S S s commonword S wol 2 ) ( # ) , ( # ) ( 2 2 1 2 \uf0b4 \uf03d S words S S s commonword S wol (2) (3) where \"#commonword\" and \"#words\" represent the number of matching words and the number of words in a sentence, respectively. The feature with higher overlap ratio is set to 1, and 0 for lower value. Longest Common Substring Longest Common Substring metric extracts the maximum length of matching word sequence against S 1 , given two text span, S 1 and S 2, . ) ( )) , ( ( ) ( 1 2 1 1 S Length S S tring MaxComSubs Length S lcs \uf03d (4) The metric value shows if both sentences are using the same phrase or term, which will benefit the identification of Overlap or Subsumption. Ratio overlap of grammatical relationship for S 1 We used a broad-coverage parser of English language, MINIPAR (Lin, 1994) to parse S 1 and S 2 , and extract the grammatical relationship between words in the text span. Here we extracted the number of surface subject and the subject of verb (subject) and object of verbs (object). We then compared the grammatical relationship in S 1 which occur in S 2 , compute as follows: ) ( # ) , ( # ) ( _ 1 2 1 1 S Subj S S comSubj S ove Subj \uf03d ) ( # ) , ( # ) ( _ 1 2 1 1 S Obj S S comObj S ove Obj \uf03d (5) (6) The ratio value describes whether S 2 provides information regarding the same entity of S 1 , i.e. Change of Topics. We also compared the subject in S 1 with noun of S 2 to examine if S 1 is discussing topics about S 2 . ) ( # ) ( ) ( # ) ( _ 1 2 1 1 S Subj S Noun S Subj com S ove SubjNoun \uf03d (7) The ratio value will show if S 1 is describing information regarding subject mention in S 2, , i.e. Description. Sentences Properties The type of information described in two text spans is also crucial to classify the type of discourse relation. Thus, we extracted the following information as additional features for each relation. Number of entities Sentences describing an event often offer information such as the place where the event occurs (location), the party involves (person, organization or subject), or when the event takes place (time and date). The occurrences of such entities can indicate how informative the sentence can be, thus can enhance the classification of relation between sentences. Therefore, we derived these entities from sentences, and compared the number of entities between them. We As Stanford NER only recognizes proper nouns, the common noun such as \"boy\" in the context is not labeled as PERSON. Thus, in order to harvest maximum information from a text span, we make use of the lexical units obtained from lexical database, FrameNet (Fillmore et al. 2003) . We extracted lexical unit from FrameNet which matches the 7 class defined by Stanford NER class. The manual lexical unit extraction is carried out by 2 human judges. Table 3 shows the example of frames used in the experiment. We used data from FrameNet to retrieve the unidentified type of information from common noun in sentences. We hereafter refer to the information retrieved here and by Stanford NER as sentences entity. We computed the number of sentences entities appearing in both S 1 and S 2. Based on the study of training data from CSTBank, there are no significant examples of annotated sentences indicates which entity points to any particular discourse relation. Therefore, in the experiment, we only observed the number of sentences entities in both text spans. The features with higher number of entities are set to 1, and 0 for lower value. Number of conjunctions We observed the occurrence of 40 types of conjunctions. We measured the number of conjunctions appear in both S 1 and S 2. The feature with higher number of entities is set to 1, and 0 for lower value. Lengths of sentences We defined the length of S j as follows: \uf0e5 \uf0ce \uf03d j i S w j w S Len ) ( ( 8 ) where w is the word appearing in the corresponding text span. Type of Speech We determined the type of speech, whether the text span, S 1 cites another sentence by detecting the occurrence of quotation marks to identify Citation or Indirect Speech which are the sub-category of Identity. Discourse Relations based Clustering Algorithm Connections between two sentences can be represented by multiple discourse relations. For instance, in some cases, sentences defined as Subsumption can also be define as Identity. As we proposed a method of cluster generation of similar sentences, applying the same process against the same sentence pairs will be redundant. Therefore to reduce redundancy, we assigned the strongest relation to represent each connection according to the following order: (i) whether both sentences are identical or not (ii) whether one sentence includes another (iii) whether both sentences share partial information (iv) whether both sentences share the same subject of topic (v) whether one sentence discusses any entity mentioned in another The priority of the discourse relations assignment can be concluded as follows: Identity > Subsumption > Elaboration > Overlap > Change of Topics > Description We then performed clustering algorithm to construct groups of similar sentences. The algorithm is summarized as follows: i) Assign the strongest relations determined by SVMs to each connection (refer to Figure 1 (a)). ii) Suppose each sentence is a centroid of its own cluster. Identify sentences connected to the centroid as Identity (ID), Subsumption (SUB), Elaboration (ELA) and Overlap (OVE) relations 1 . Sentences with these connections are evaluated as having similar content, and aggregated as one cluster (refer Figure 1(b) ). iii) Remove similar clusters by retrieving centroids connected as Identity, Subsumption or Elaboration. iv) Merge the clusters from (iii) to minimize the occurrence of the same sentences in multiple clusters (refer Figure 1 (c)). v) Iterate step (iii) and (iv) until the number of clusters is convergence. provided 30 and 59 document sets consisting 10,412 and 14,790 sentences, respectively. We used Brill's Tagger (Brill, 1992) to POS-tag the sentences, and extracted content words and lemmas of the words. Result and Discussion Discourse Relation Identification The discourse relations assigned between sentences by SVMs is manually evaluated by 2 human judges. Since no human annotation is available for DUC data sets, 5 times of random sampling consisting 100 sentence pairs is performed against each document set (DUC '2001 and DUC'2002) . The human judges performed manual annotation against sentence pairs, and assessed if SVMs assigned the correct discourse relation to each pair. The correct discourse relation refers to either one of the discourse relations assigned by human judges in case of multiple relations exist between the two sentences. We also assigned the most frequent relations  to all sentence pairs as a baseline method. We used the precision, recall and F-measure score as an evaluation measure. The examples show that the subject of the verb in both sentences is different and both sentences semantically represent no relation with each other. Consider another example: S 13 : The eight day trip will leave from Chicago and will include sightseeing, guided runs and fun run from Malahide Castle to Swords. S 14 : I had to have patience and run from the back. Both sentences were identified as Overlap by SVMs while there is no relation present between the sentences. As a result, the low recall value affected the F-measure of No Relations. Overall, classification by SVMs shows that our method outperformed over the baseline method, where our system achieved more than 60% accuracy for most relations even though we only consider surface characteristics from sentence pairs during classification. Discourse Relation-based Clustering We evaluated our method by measuring the cohesion and separation of the constructed clusters (Raskutti and Leckie, 1999) (IBM SPSS Statistics, 2011) . The cluster cohesion refers to how closely the sentences are related within a cluster, measured using Sum of Squared Errors (SSE); \uf0e5 \uf0e5 \uf0ce \uf03d i C x i i m x sim N AverageSSE 2 ) , ( 1 (9) where sim (x,m i ) refers to the similarity of sentence x with other members in the same cluster, m i and N denotes the number of clusters. The smaller value of SSE indicates that the sentences in clusters are closer to each other. Meanwhile, cluster separation refers to how distinct or wellseparated a cluster from others, measured using Sum of Squares Between (SSB); \uf0e5 \uf03d i i i m m sim C N AverageSSB 2 ) , ( 1 (10) where sim(m,m i ) refers the similarity between sentences from the corresponding cluster with sentences outside the cluster, |C i | is the size of cluster and N is the number of clusters. The high value of SSB indicates that the sentences are well separated with each other. Cosine similarity measurement is used to measure the similarity between sentences in both SSE and SSB evaluation. We also obtained the average of Silhouette Coefficient (SC) to measure the harmonic mean of both cohesion and separation of the clusters (Kaufman and Rousseeuw, 1990 ) (IBM SPSS Statistics, 2011) by using Equation ( 11 ); ) 1 ( 1 b a N AverageSC \uf02d \uf03d if a < b or, ) 1 ( 1 \uf02d \uf03d a b N if a\u2265 b ( 11 ) where a is the average similarity of sentence i with other members in the cluster, and b is the minimum average distance of sentence i with sentences outside the cluster and N is the number of clusters. The value range of the Silhouette Coefficient is between 0 and 1, where the value closer to 1 is the better. In addition, we examined the clustered sentences by using a pair-wise evaluation measure, where we sampled 5 sets of data consisting 100 sentences pairs and evaluated if both sentences are actually belong to the same clusters. We can see from Table 5 and Table 6 that the connection between sentences can allow text clustering according to the user preference. For instance, sentences with Identity, Subsumption and Elaboration were classified into a small group without overlapping with other clusters. In contrast, sentences with Identity, Subsumption, Elaboration and Overlap allow minimum information overlapping between clusters. Thus, the experimental results demonstrate that the utilization of discourse relation can be another alternative of cluster construction other than observing word distribution in corpus. Conclusion and perspectives This paper explored the benefits of discourse relation in data mining. The evaluation results showed that the discourse relation-based method has promising potential as a novel approach for text clustering. Our method is capable to offer various kind of text clustering, such as clustering of only identical or overlapping sentences. In future, addition of other types of relations, e.g., Attribution (from CST) can be used to perform clustering of attributed information from corpus. Previously, discourse relation has been used to remove redundancy from generated summaries, thus, sentence clustering based on discourse relations will definitely benefits text summarization for multiple documents. Our future works will include (i) the investigation of more discourse relations for text clustering, (ii) to improve the classification of discourse relations, and (iii) the application of discourse relation-based clustering to text summarization.",
    "abstract": "Over the years, the usage of discourse relations has been proven to enhance many applications such as text summarization, question answering and natural language generation. This paper proposes an approach that expands the benefit of discourse relations for natural language processing from a different aspect. We exploit the discourse relations existing between sentences to generate clusters of similar sentences from document sets. We first examined and defined the type of discourse relations that useful to retrieve sentences with identical content. We then assigned these relations to each sentence pair using a machine learning method. Finally we performed discourse relation-based clustering algorithm to generate clusters of similar sentences. We evaluated our method by measuring the cohesion and separation of the clusters and compared to a well recognized clustering method. The experimental result shows that our method performed significantly well, which demonstrated that discourse relation between sentences can be exploited for text clustering.",
    "countries": [
        "Japan"
    ],
    "languages": [
        "English"
    ],
    "numcitedby": "8",
    "year": "2012",
    "month": "December",
    "title": "Exploiting Discourse Relations between Sentences for Text Clustering"
}