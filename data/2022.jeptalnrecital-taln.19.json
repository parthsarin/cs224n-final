{
    "article": "La reconnaissance d'entit\u00e9s nomm\u00e9es est une t\u00e2che de traitement automatique du langage naturel bien \u00e9tudi\u00e9e et utile dans de nombreuses applications. Derni\u00e8rement, les mod\u00e8les neuronaux permettent de la r\u00e9soudre avec de tr\u00e8s bonnes performances. Cependant, les jeux de donn\u00e9es permettant l'entra\u00eenement et l'\u00e9valuation de ces mod\u00e8les se concentrent sur un nombre restreint de domaines et types de documents (articles journalistiques, internet). Or, les performances d'un mod\u00e8le entra\u00een\u00e9 sur un domaine cibl\u00e9 sont en g\u00e9n\u00e9ral moindres dans un autre : ceux moins couverts sont donc p\u00e9nalis\u00e9s. Pour tenter de rem\u00e9dier \u00e0 ce probl\u00e8me, cet article propose d'utiliser une technique d'augmentation de donn\u00e9es permettant d'adapter un corpus annot\u00e9 en entit\u00e9s nomm\u00e9es d'un domaine source \u00e0 un domaine cible o\u00f9 les types de noms rencontr\u00e9s peuvent \u00eatre diff\u00e9rents. Nous l'appliquons dans le cadre de la litt\u00e9rature de fantasy, o\u00f9 nous montrons qu'elle peut apporter des gains de performance. Introduction La reconnaissance d'entit\u00e9s nomm\u00e9es (REN) a b\u00e9n\u00e9fici\u00e9 r\u00e9cemment des avanc\u00e9es en apprentissage profond (Li et al., 2020) , et notamment de l'arriv\u00e9e des mod\u00e8les de langue neuronaux contextuels pr\u00e9-entrain\u00e9s, tels que BERT (Devlin et al., 2019) . Ceux-ci ont en effet permis d'am\u00e9liorer les performances de nombreuses t\u00e2ches de traitement automatique du langage naturel (TALN). Malgr\u00e9 les performances \u00e9lev\u00e9es dont font preuve ces mod\u00e8les pour la REN, celle-ci est encore loin d'\u00eatre consid\u00e9r\u00e9e comme r\u00e9solue (Stanislawek et al., 2019) . L'un des d\u00e9fauts de ces mod\u00e8les provient de leurs donn\u00e9es d'entra\u00eenement et d'\u00e9valuation. En effet, s'il existe de nombreux corpus annot\u00e9s en entit\u00e9s nomm\u00e9es pour certains domaines (on peut citer le corpus journalistique CoNLL-2003 (Tjong Kim Sang & De Meulder, 2003) , le corpus multi-domaines OntoNotes (Weischedel et al., 2011) ou encore WikiGold (Balasuriya et al., 2009) , tir\u00e9 de Wikip\u00e9dia), d'autres sont plus d\u00e9laiss\u00e9s et n'ont que peu ou pas de corpus d\u00e9di\u00e9s : c'est le cas, par exemple, du domaine litt\u00e9raire. Un mod\u00e8le entra\u00een\u00e9 sur les donn\u00e9es d'un domaine sp\u00e9cifique \u00e9tant g\u00e9n\u00e9ralement moins performant lorsqu'il est appliqu\u00e9 sur celles d'un autre, ce d\u00e9laissement se traduit par des performances moindres dans les domaines n'ayant pas de donn\u00e9es annot\u00e9es. Dans ce contexte, il est donc int\u00e9ressant de disposer de techniques permettant d'adapter un corpus ou un mod\u00e8le d'un domaine source, o\u00f9 l'on poss\u00e8de beaucoup de donn\u00e9es, \u00e0 un domaine cible plus pauvre en ressources. Plusieurs possibilit\u00e9s existent pour r\u00e9aliser cette adaptation. Gururangan et al. (2020) montrent par exemple que continuer de pr\u00e9-entra\u00eener un mod\u00e8le neuronal contextuel sur le domaine cible permet d'augmenter les performances dans celui-ci. Malheureusement, ce pr\u00e9-entra\u00eenement est plus co\u00fbteux que l'affinage (fine-tuning) d'un mod\u00e8le pr\u00e9-entra\u00een\u00e9. Une autre voie possible est l'adaptation du corpus original par augmentation. L'augmentation de donn\u00e9es est une technique devenue standard en apprentissage profond pour le traitement de l'image (Shorten & Khoshgoftaar, 2019) . Des op\u00e9rations comme le recadrement (cropping), le retournement (flipping) ou l'ajout de bruit permettent de cr\u00e9er des exemples synth\u00e9tiques suppl\u00e9mentaires, ce qui accro\u00eet le nombre de donn\u00e9es d'entra\u00eenement. Comparativement, elle est moins explor\u00e9e en TALN, bien que des recherches r\u00e9centes commencent \u00e0 s'y int\u00e9resser (Feng et al., 2021) . En effet, il ne para\u00eet pas aussi facile de g\u00e9n\u00e9rer de nouveaux exemples \u00e0 partir du texte, car cela requiert de garder la coh\u00e9rence de la phrase tout en la modifiant. L'augmentation de donn\u00e9es est encore moins explor\u00e9e dans le cadre de la REN, car celle-ci se heurte \u00e0 des probl\u00e8mes sp\u00e9cifiques : certaines techniques classiques d'augmentation (comme le remplacement par un synonyme, l'\u00e9change de mots ou encore l'insertion al\u00e9atoire (Wei & Zou, 2019)) peuvent notamment engendrer des exemples synth\u00e9tiques avec des labels incorrects (Dai & Adel, 2020) . Il existe tout de m\u00eame quelques travaux utilisant cette technique pour adapter des corpus \u00e0 un autre domaine. Ding et al. (2020) proposent d'entra\u00eener un mod\u00e8le de langage pour g\u00e9n\u00e9rer des exemples synth\u00e9tiques dans le cas o\u00f9 peu d'exemples sont disponibles, mais supposent cependant l'existence d'un minimum d'exemples d\u00e9j\u00e0 annot\u00e9s. Chen et al. (2021) d\u00e9crivent une architecture neuronale capable d'apprendre \u00e0 transformer une phrase d'un domaine source vers un domaine cible, et s'en servent pour g\u00e9n\u00e9rer des exemples synth\u00e9tiques proches du domaine cible. N\u00e9anmoins, leur m\u00e9thode n\u00e9cessite d'entra\u00eener cette architecture, ce qui demande aussi de disposer de quelques exemples annot\u00e9s dans le domaine cible. Nous pr\u00e9sentons dans cet article une m\u00e9thode d'augmentation des donn\u00e9es, le remplacement de mentions (Dai & Adel, 2020) , pour permettre d'adapter un corpus annot\u00e9 en entit\u00e9s nomm\u00e9es d'un domaine \u00e0 un autre. Cette m\u00e9thode a l'avantage de la simplicit\u00e9, et de ne pas demander l'annotation de donn\u00e9es du domaine cible. Elle consiste \u00e0 g\u00e9n\u00e9rer de nouveaux exemples en rempla\u00e7ant, dans une phrase du corpus original, une entit\u00e9 nomm\u00e9e par une autre du m\u00eame type. Nous d\u00e9crivons notre m\u00e9thode dans la Section 2. Pour montrer l'int\u00e9r\u00eat de cette technique, nous exp\u00e9rimentons en adaptant le corpus CoNLL-2003 (Tjong Kim Sang & De Meulder, 2003) , qui couvre originellement le domaine journalistique, \u00e0 celui de la litt\u00e9rature de fantasy. Nous discutons les r\u00e9sultats obtenus en Section 3. Protocole Exp\u00e9rimental Jeux de donn\u00e9es Nous utilisons deux jeux de donn\u00e9es diff\u00e9rents, provenant de deux sources distinctes, tous deux compos\u00e9s de textes en anglais. Nous nous concentrons sur les entit\u00e9s nomm\u00e9es d\u00e9signant des personnes. Dekker et al. (2019) ont proc\u00e9d\u00e9 \u00e0 une \u00e9valuation de plusieurs mod\u00e8les de REN, en annotant un corpus litt\u00e9raire pour les entit\u00e9s de type PERSONNE. Il se compose du premier chapitre de 40 romans. Cependant, d'apr\u00e8s nos observations, ce jeu de donn\u00e9es souffre de probl\u00e8mes d'annotations (erreurs et incoh\u00e9rences), d'encodage et de tokenisation, que nous avons donc cherch\u00e9 \u00e0 corriger. Nous avons rectifi\u00e9 les probl\u00e8mes d'encodage et de tokenisation manuellement. Afin de pallier les erreurs et les incoh\u00e9rences, nous avons d\u00e9fini un ensemble de r\u00e8gles d'annotation que nous avons appliqu\u00e9es \u00e0 tout le corpus gr\u00e2ce \u00e0 un processus semi-automatique. Celui-ci s'articule en 3 \u00e9tapes : 1) l'application d'heuristiques de correction supervis\u00e9es par un humain, puis 2) une correction assist\u00e9e \u00e0 l'aide d'un mod\u00e8le BERT (Devlin et al., 2019) , et finalement 3) une correction manuelle en dernier ressort. Nos r\u00e9sultats sont \u00e9valu\u00e9s sur le sous-ensemble de ce corpus form\u00e9 par les 17 romans de fantasy qu'il contient. Jeu d'\u00e9valuation Mod\u00e8le et Entra\u00eenement Nous utilisons un mod\u00e8le BERT-base (Devlin et al., 2019) pr\u00e9-entra\u00een\u00e9, obtenu via la librairie huggingface (Wolf et al., 2020), auquel nous apposons une couche neuronale de classification. Ce mod\u00e8le est affin\u00e9 (fine-tuning) sur notre corpus d'entra\u00eenement pendant 2 cycles d'apprentissage avec un taux d'apprentissage de 2 \u2022 10 \u22125 (Devlin et al., 2019) . Augmentation des donn\u00e9es Nous proposons l'utilisation d'une technique simple, le remplacement de mentions (Dai & Adel, 2020), pour adapter un corpus annot\u00e9 en entit\u00e9s nomm\u00e9es d'un domaine source vers un domaine cible. Afin de g\u00e9n\u00e9rer un nouvel exemple, nous partons d'un exemple de d\u00e9part et rempla\u00e7ons une mention (un passage continu du texte annot\u00e9 comme une entit\u00e9) et ses mentions \u00e9quivalentes (les autres passages identiques de l'exemple) par une autre entit\u00e9 de m\u00eame type r\u00e9cup\u00e9r\u00e9e dans une liste pr\u00e9d\u00e9finie. La longueur des passages remplac\u00e9s pouvant \u00eatre modifi\u00e9e, les labels sont ajust\u00e9s en fonction. La Figure 1 p < 0.05). La Table 1 indique les r\u00e9sultats de nos exp\u00e9rimentations. Nous calculons la pr\u00e9cision, le rappel et la F-mesure selon la m\u00e9thode du CoNLL-2003 (Tjong Kim Sang & De Meulder, 2003) en utilisant la librairie python seqeval (Nakayama, 2018) . L'augmentation externe intra-domaine (fantasy) avec un taux d'augmentation de 5 % donne une am\u00e9lioration significative de la F-mesure, ce qui met en valeur l'utilit\u00e9 d'injecter des noms proches du corpus cible lors de l'entra\u00eenement. De mani\u00e8re g\u00e9n\u00e9rale, on observe une augmentation du rappel et une baisse de la pr\u00e9cision pour toutes les configurations, effet qui semble augmenter avec l'accentuation du taux d'augmentation, jusqu'\u00e0 un certain point. L'augmentation parfaite (dekker) d\u00e9montre bien cet effet, avec un rappel tr\u00e8s \u00e9lev\u00e9 mais une pr\u00e9cision tout de m\u00eame amoindrie. Elle d\u00e9montre aussi une marge de progression de la performance importante, avec une augmentation du rappel de plus de 11 points par rapport \u00e0 la configuration sans augmentation (none). Hors augmentation parfaite, l'augmentation externe intra-domaine semble avoir le plus d'effets, avec l'accroissement du rappel le plus important mais \u00e9galement la baisse de pr\u00e9cision la plus importante. L'augmentation du rappel nous permet de remarquer que certaines classes de noms sont mieux reconnues par le mod\u00e8le dans la configuration fantasy : -Les noms qui sont aussi des noms communs (\"Bug\", \"Silent\", \"Weasel\"). -Les noms de fantasy \u00e0 apostrophes, tels que \"Rand al'Thor\" ou \"Bran al'Vere\".",
    "abstract": "La reconnaissance d'entit\u00e9s nomm\u00e9es est une t\u00e2che de traitement automatique du langage naturel bien \u00e9tudi\u00e9e et utile dans de nombreuses applications. Derni\u00e8rement, les mod\u00e8les neuronaux permettent de la r\u00e9soudre avec de tr\u00e8s bonnes performances. Cependant, les jeux de donn\u00e9es permettant l'entra\u00eenement et l'\u00e9valuation de ces mod\u00e8les se concentrent sur un nombre restreint de domaines et types de documents (articles journalistiques, internet). Or, les performances d'un mod\u00e8le entra\u00een\u00e9 sur un domaine cibl\u00e9 sont en g\u00e9n\u00e9ral moindres dans un autre : ceux moins couverts sont donc p\u00e9nalis\u00e9s. Pour tenter de rem\u00e9dier \u00e0 ce probl\u00e8me, cet article propose d'utiliser une technique d'augmentation de donn\u00e9es permettant d'adapter un corpus annot\u00e9 en entit\u00e9s nomm\u00e9es d'un domaine source \u00e0 un domaine cible o\u00f9 les types de noms rencontr\u00e9s peuvent \u00eatre diff\u00e9rents. Nous l'appliquons dans le cadre de la litt\u00e9rature de fantasy, o\u00f9 nous montrons qu'elle peut apporter des gains de performance.",
    "countries": [
        "France"
    ],
    "languages": [],
    "numcitedby": "0",
    "year": "2022",
    "month": "6",
    "title": "Remplacement de mentions pour l{'}adaptation d{'}un corpus de reconnaissance d{'}entit{\\'e}s nomm{\\'e}es {\\`a} un domaine cible (Mention replacement for adapting a named entity recognition dataset to a target domain)"
}