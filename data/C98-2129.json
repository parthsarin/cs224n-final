{
    "article": "Rich mark-up can considerably benefit the process of establishing bitext correspondences, that is, the task of providing correct identification and alignment methods for text segments that are translation equivalences of each other in a parallel corpus. We present a sentence alignment algorithm that, by taking advantage of previously annotated texts, obtains accuracy rates close to 100%. The algorithm evaluates the similarity of the linguistic and extralinguistic mark-up in both sides of a bitext. Given that annotations are neutral with respect to typological, grammatical and orthographical differences between languages, rich mark-up becomes an optimal foundation to support bitext correspondences. The main originality of this approach is that it makes maximal use of annotations, which is a very sensible and efficient method for the exploitation of parallel corpora when annotations exist. Introduction Adequate encoding schemes applied to large bodies of text in electronic form have been a main achievement in the field of humanities computing. Research in computational linguistics, which since the late 1980s has resorted to methodologies involving statistics and probabilities in large corpora, has however largely neglected the existence and provision of extra information from such encoding schemes. In this paper we present an approach to sentence alignment that crucially relies on previously introduced annotations in a parallel corpus. Following (Harris 88) , corpora containing bilingual texts have been called \"bitexts\" (Melamed 97) , (Martfnez et al. 97) . The utility of annotated bitexts will be demonstrated by the proposition of a methodology that crucially takes advantage of rich markup to resolve bitext correspondences, that is, the task of providing correct identification and alignment methods for text segments that are translation equivalencies of each other (Chang &:Chen 97) . Bitext correspondences provide a great source of information for applications such as example and memory based approaches to machine translation (Sumita &= Iida 91) , (Brown et al. 93) , (Collins et al. 96) ; bilingual terminology extraction (Kupiec 93) , (Eijk 93) , (Dagan et al. 94) , (Smajda et al. 96) ; bilingual lexicography (Catizione et al. 93) , (Daille et al. 94) , (Gale &: Church, 91b) ; multilingual information retrieval (SIGIR 96) , and word-sense disambiguation (Gale et al. 92) , (Chan & Chen 97) . Moreover, the increasing availability of running parallel text in annotated form (e.g. WWW pages), together with evidence that poor mark-up (as HTML) will progressively be replaced by richer mark-up (e.g. SGML/XML), are good enough reasons to investigate methods that benefit from such encoding schemes. We first provide details of how a bitext sample has been marked-up, with particular emphasis on the recognition and annotation of proper nouns. Then we show how sentence aligmnent relies on mark-up by the application of a methodology that resorts to annotations to determine the similarity between sentence pairs. This is the 'tags as cognates' algorithm, TasC. Bitext tagging and segmentation A large bitext has been compiled consisting of a collection of administrative and legal bilingual documents written both in Spanish and Basque, with close to 7 million words in each language. t)br the experiments, we have worked on a representative subset of around 500,000 words in each language. Several stages of automatic tagging, based on pattern matching and heuristics, were undertaken, rendering different descriptive lewds: General encoding (paragraph, sentence, quoted text, dates, numbers, abbreviations, etc.). \u2022 Document specific tags that identify document types and define document internal organisation (sections, divisions, identification code, number and date of issue, issuer, lists, itemised sections, etc.). \u2022 Proper noun tagging (identification and categorisation of proper nouns into several classes, including: person, place, organisation, law, title, publication and uncategorised). This collection of tags (shown in Table 1 ) reflects basic structural and referential features, which appear consistently at both sides of the bitext. Although the aligmnent of smaller segments (multi-word lexical units and collocations) will require more expressive tagging, such as part-of-speech tagging (POS), ibr the task of sentence alignment, this is not only unnecessary, but also inappropriate, since it would introduce undesired language dependent information. TILe encoding scheme has been based on TEI's guidelines for SGML based mark-up (Ide & Veronis 95). Proper noun tagging As for many other text processing applications, proper noun tagging plays a key role in our approach to sentence alignment. It has been reported that proper nouns reach up to 10% of tokens in text (newswire text (Wakao et al. 96 ) and (Coates-Stephens 92)) and one third of noun groups (in the Agencc France Pressc flow (Wolinski el; al. 95) ). We have calculated that proper nouns constitute a 15% of the tokens in our corpus. The module for the recognition of proper nouns relies on patterns of typography (capitalisation and punctuation) and on contexrum intbrmation (Church 88). It also makes use of lists with most cmnmon person, organisation, law, publication and place names. The tagger annotates a multi-word chain as a proper noun when each word in the chain is uppercase initial. A closed list of flmctional words (prepositions, conjunctions, determiners, etc.) is allowed to appear inside the proper noun chain, see examples in Table 2 . A collection of heuristics discard uppercase initial words in sentence initial position or in other exceptional cases. In contrast with other known classifications (e.g. MUC-6 95), we exclude fi'om our list of proper nouns time expressions, percentage expression, and monetary amount expressions (which for us fall raider a different descriptive level). However, on top of organisation, person and location names, we include other entities such as legal nomenclature, the name of publications as well as a number of professional titles whose occurrence in the bitext becomes of great value for alignment. Bitext asymmetries Because our approach to alignment relies on consistent tagging, bitext asymmetries of any type need to be carefully dealt with. For example, capitalisation conventions across languages may show great divergences. Although, in theory, this should not be the case between Spanish and Basque, since otficially they follow identical conventions for capitalisation (which are by tile way the same as in French), in practise these conventions have been interpreted very differently by the writers of the two versions (lawyers in Spanish and translators in Basque). In the Basque version, nouns referring to organisations saila 'Department', professional titles diputatua 'Deputy', a~s well as many orographic or geographical sites arana 'Valley', are often written in lowercase, while in the Spanish original documents these are normally written in uppercase (see Table 2 ). These nouns belong to the type described as 'trigger' words by (Wakao et al. 96) , in the sense that they permit the identification of the tokens surrounding them as proper nouns. Then, it has been required to resort to contextual information. The results of the resolution of these singularities are shown in Table I1 (Kay & Roscheisen 93) , to the more recent ones of (Chang & Chen 97), or (Tillmann et al. 97) . The techniques employed include statistical machine translation, cognates identification, pattern recognition, and digital signal and image processing. Our algorithm, as (Simard et al. 92) , and (Melamed 97) employs cognates to align sentences; and sinfilar to (Brown et al. 91) , it also uses mark-up for that purpose. Its singularity does not lie on the use of mark-up as delimiter of text regions (Brown et al. 91) in combination with other techniques, but on the fact that it is the sole foundation for sentence alignment. We call it the 'tags as cognates' algorithm, TasC. This algorithm is not disrupted by word order differences or small asymmetries in non-literal translation, and, unlike other reported algorithms (Melamed 97) , it possesses the additional advantage of being portable to any pair of languages without the need to resort to any language-specific heuristics. Provided an adequate and consistent bitext mark-up, sentence alignment becomes a simple and accurate process also in the case of typologically disparate or orthographically distinct language pairs for which techniques based on lexical cognates may be problematic. One of the best consequences of this approach is that the burden of language dependent processing is dispatched to the monolingual tagging and segmentation phase. Similarity calculus between bitexts The alignment algorithm establishes similarity metrics between candidate sentences which are delimited by corresponding mark-up. Dice's coefficient is used to calculate these similarity metrics (Dice 45) . The coefficient returns a real numeric value in the range 0 to 1. Two sentences which are totally dissimilar in the content of their internal mark-up will return a Dice score of 0, while two identical contents will return a Dice score of 1. For two text segments, P and Q, one in each language, the formula for Dice's similarity coefficient will be: Dice(P, Q) - 2FpQ Fp+ FQ where FpQ is the number of identical tags that P and Q have in common, and Fp and FQ are the number of tags contained by each text segment P and Q. Since the alignment algorithm determines the best matching on the basis of tag similarity, not only tag names used to catcgorise different cognate classes (number, date, abbreviation, proper noun, etc.), but also attributes contained by these tags may help identify the cognate itself: <num num=57>57</num>. Furthermore, attributes The difference mean between Dice's coefficients corresponding to correct alignments and next higher vahms is: ?L (DCc -DCw ) M ----i=1 = 0.45 Where for a given source sentence i, DCci represents Dice's coefficient corresponding to its correct alignment and DCwi represents the next higher valise of Dice's coetficients for the saint source sentence i. In all the cases, this difference is greater than 0.2. For consistently marked-up bitexts, these results show that sentence aligmnent founded on the similarity between annotations can be robust criterion. Figurc 2 illustrates how the Dice's coefficient is calculated between candidate sentences to aligmnent. Applying the general definition of tile problem to the particular ease of sentence alignment: V and U represent two disjoint sets of vertices correst)onding to the Spanish and Basque sentences that we wish t;o align. In this case, each edge has not a cost but a similarity metric quantified by Dice's coefficient. The fact that vertices are materiMised by sentences detracts gen-Spanish Sentence: <s id=sESdocg-4>Habi~ndose deteetado en el anuncio publicado en el nfimero<num num=79> 79 </num> de feeha <date date=27/04>27 de abril</date> de este <rs type=publication>Boletfn</rs>, la omisidn del primer pgrrafo de la <rs type=law>Orden Foral</rs> de referencia, se procede a su fntegra publieacidn. < / s > Basque Sentence: <s id=sEUdocS-S>Agerkaria honetako <date date=27/O4>apirilaren 27ko</date> <num nura=79>79k.an </num> argitaratutako iragarkian aipameneko <rs type=law>Foru Aginduaren</rs> lehen lerroaldea ez dela geri detektatu ondoren beraren argitarapen osoa egitera jo da.</s> The strategy of the The common tags are: <date date=27/04>, <num num=79>, <rs type=law> The Dice's similarity coefficient will be: Dice(P,Q)= 2x3 / 4+3 = 0.857 Figure 2 : Similarity calculus between candidate sentences erality to the assignment problem and makes it possible to add constraints to the solutions reported in the literature. These constraints take into account the order in which sentences in both the source and target texts have been written, and capture the prevailing fact that translators maintain the order of the original text in their translations, which is even a stronger property of specialised texts. By default, a whole document delimits the space in which sentence alignment will take place, although this space can be customised in the algorithm. The average number of sentences per document is approximately 18. Two types of alignment can take place: \u2022 1 to 1 alignment: when one sentence in the source document corresponds to one sentence in the target document (94.39% of the cases). \u2022 N to M alignment: when N sentences in the source document correspond to M sentences in the target document (only 5.61% of the cases). It includes cases of 1-2, 1-3 and 0-1 alignments. Both alignment types are handled by the algorithm. The algorithm The TasC algorithm works in two steps: . It obtains the similarity matrix S from Dice's coefficients corresponding to candidate alignment options. Each row in S represents the alignment options of a source sentence classified in decreasing order of similarity. In this manner, each column represents a preference position (1 the best alignment option, 2 the second best and so oil). Therefore, each S/,j is the identification of one or more target sentences which match the source sentence i in tile preference position j. In order to obtain tile similarity matrix, it is not necessary to consider all possible alignment options. Constraints regarding sentence ordering and grouping greatly reduce the number of cases to be evaluated by the algorithm. In the algorithm each source sentence xi is compared with candidate target sentences yj as follows: (xi, Yi); (xi, YjYj+t ..., where YjYj+I represents the concatenation of yj with Yj+I. The algorithm module that deals with candidate alignment options can be easily customised to cope with different bitext configurations (since bitexts may range from a very simple one-paragraph text to more complex structures). In the current version of the algorithm seven alignment options are taken into account. 2. The TasC algorithm solves an assignment problem with several constraints. It aligns sentences by assigning to each ith source sentence the Si,j target option with minimum j value, that is, the option with more similarity. Furthermore, the algorithm solves the possible conflicts when a sentence matches with other sentences already aligned. The average cost of the algorithm, experimentally contrasted , is linear in the size of the input, although in the worst case the cost is bigger. The result of sentence alignment is reflected in the bitext by the incorporation of the attribute 'corresp to sentence tags, as can be seen Cases %Corpus % Accuracy 1-1 94.39% 100% N -M 5.61% 99.68% 3 . This attribute points to the corresponding sentence identification code in the other language. Evaluation The current version of the algorithm has been tested against a subcorpus of 500,000 words in each language consisting of 5,988 sentences and has rendered the results shown in Table 4 . The accuracy of the 1 to 1 alignment is 100%. In the N to M case only 1 error occurred out of 314 sentences, which reaches 99.68% accuracy. The algorithm to sentence alignment has been designed in suct~ a modular way that it can easily change the tagset used for alignment and the weight of each tag to adapt it to different bitext annotations. The current version of the algorithm uses the tagset shown in Table 1 without weights. 5 Future work Once sentences have been aligned, the next step is the alignment of sentence-internal segmeats. The sentence will delimit the search space for this alignment, and hence, by reducing the search space, the alignment complexity is also reduced. Proper noun alignment Proper nouns are a key factor for the efficient management of the corpus, since they are the basis for the indexation and retrieval of documents in the two versions. For this reason, at present we arc concerned with proper noun alignment, something which is not usually done in the mapping of bitexts. The Mignment is achieved by resorting to: \u2022 The identification of cognate nouns, aided by a set of phonological rules that apply when Spanish terms are taken to produce loan words in Basque. \u2022 The restriction of cognate search space to previously aligned sentences, and \u2022 The application of the TasC algorithm adapted to proper noun alignment. Alignment of collocation The next step is the recognition and alignment of other multi-word lexical units and collocations. Due to the still unstable translation choices of much administrative terminology in Basque, on top of the considerable typological aud structural differences between Basque and Spanish, many of the techniques reported in the literature (Smadja et al. 96) , (Kupiec 93) and (Eijk 93 ) cannot be effectively applied. POS tagging combined with recurrent bilingual glossaw lookup is the approach we are currently experimenting with. Conclusions We have presented a sentence Mignment approach that, by taking advantage of previously introduced mark-up, obtains accuracy rates close to 100%. This approach is not disrupted by word order differences and is portable to any pair of languages without tile need to resort to any language specific heuristics. Provided and adequate and consistent bitext mark-up, sentence alignment becomes an accurate and rotmst process also in the case of typologically distinct language pairs tbr which other known techniques may be problematic. The TasC algorithm has been designed in such a modular way that it can be easily adapted to different bitext configurations as well as other specific tagsets. 7 Acknowledgements This research is being partially supported by the Spanish Research Agency, project ITEM, TIC-96-1243-C03-01. Spanish Sentence: <s id=sESdoc5-4 corresp=sEUdoc5-5:>Habidndose detectado en el anuncio publicado en el nfimero<num num=79> 79 </num> de fecha <date date=27~04>27 de abril</date> de este <rs type=publication>Boletin</rs>, la omisi6n del primer pArrafo de la <rs type=law>Orden Foral</rs> de referencia se procede a su integra publicaci6n.</s> Basque Sentence: <s id=sEUdoc5-5 corresp=sESdoc5-4>Agerkaria honetako <date date=2Y/04> apirilaren 27ko</date> <num num=79>79k.an </num> argitaratutako iragarkian aipameneko <rs type=lau>Foru Aginduaren</rs> lehen lerroaldea ez dela geri detektatu ondoren beraren argitarapen osoa egitera jo da.</s> [136] [137] [138] [139] [140] [141] [142] [143] 1988 . Association for Computational Linguistics.",
    "abstract": "Rich mark-up can considerably benefit the process of establishing bitext correspondences, that is, the task of providing correct identification and alignment methods for text segments that are translation equivalences of each other in a parallel corpus. We present a sentence alignment algorithm that, by taking advantage of previously annotated texts, obtains accuracy rates close to 100%. The algorithm evaluates the similarity of the linguistic and extralinguistic mark-up in both sides of a bitext. Given that annotations are neutral with respect to typological, grammatical and orthographical differences between languages, rich mark-up becomes an optimal foundation to support bitext correspondences. The main originality of this approach is that it makes maximal use of annotations, which is a very sensible and efficient method for the exploitation of parallel corpora when annotations exist.",
    "countries": [
        "Spain"
    ],
    "languages": [
        "Basque",
        "Spanish"
    ],
    "numcitedby": "0",
    "year": "1998",
    "month": "",
    "title": "Bitext Correspondences through Rich Mark-up"
}