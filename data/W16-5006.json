{
    "article": "This paper presents the main sources of disagreement found during the annotation of the Spanish SFU Review Corpus with negation (SFU Review SP -NEG). Negation detection is a challenge in most of the task related to NLP, so the availability of corpora annotated with this phenomenon is essential in order to advance in tasks related to this area. A thorough analysis of the problems found during the annotation could help in the study of this phenomenon. Introduction Negation is a key element in tasks related to Natural Language Processing (NLP) that has generated special interest in the research community during the last years, such as Sentiment Analysis, Information Extraction and Question Answering. It is a complex linguistic phenomenon that requires a deep analysis. The availability of corpora annotated with negation is essential for carrying out a study of this phenomenon. Actually, most of the available corpora are for English language (Pyysalo et al., 2007; Kim et al., 2008; Vincze et al., 2008; Councill et al., 2010; Konstantinova et al., 2012; Morante and Daelemans, 2012; Bokharaeian et al., 2014; Blanco and Moldovan, 2014; Banjade and Rus, 2016) . However, the presence of languages other than English on the Internet is greater every day and, consequently, the development of systems able to deal with negation in these other languages is a necessity. Due to this fact, we decided to annotate a Spanish corpus with negation. Moreover, taking into account the importance of negation in texts that express opinions since it directly affects their polarity, we also annotated how negation affects the polarity of the words that are within its scope. The Spanish SFU Review Corpus (Taboada et al., 2006) was selected for the annotation because of its multi-domain nature and the fact that it is widely known in the domain of Sentiment Analysis and Opinion Mining. The English version of the SFU Review Corpus was annotated at the token level with negative and speculative keywords and at the sentence level with their linguistic scope (Konstantinova et al., 2012) . The authors used the guidelines defined by Vincze (2010) , but they adapted the annotation scheme to the review domain (Konstantinova and De Sousa, 2011) . Although we considered these guidelines, after a thorough analysis of negation in Spanish, we defined criteria more suitable to the typology of negation patterns in this language (Mart\u00ed et al., 2016) . In this work, we show the main problems found during the annotation of negation for the Spanish SFU Review Corpus (SFU Review SP -NEG). The annotation scheme defined is briefly described in Section 2. Following, the main sources of disagreement are presented in Section 3. Finally, conclusion and future works are outlined in Section 4. Annotation scheme The SFU Review SP -NEG corpus 1 consists of 400 reviews of cars, hotels, washing machines, books, cell phones, music, computers and movies extracted from the Ciao.es website. Each domain contains 25 positive and 25 negative reviews. We annotated each review at token level with the lemma and the PoS and at sentence level with negation markers or negation cues, their linguistic scope and the event. We also annotated how negation affects the words that are within its scope (if there is a change in the polarity or an increment or reduction of its value), which is very useful for Sentiment Analysis. The general annotation scheme followed can be seen in Figure 1 . The labels used for the annotation of negation in the corpus are described briefly below: \u2022 <review polarity=\"positive/negative\">. The attribute polarity describes the polarity of the review, which can be \"positive\" or \"negative\", according to the value assigned to it in the Spanish SFU Review Corpus. \u2022 <sentence complex=\"yes/no\">. The label sentence corresponds to a complete sentence, a phrase or a fragment/chunk of a sentence in which a negative structure can occur. In SFU Review SP -NEG, we only annotate the structures that contain at least one negation marker or negation cue. Therefore, sentences without negation markers are not labeled. This label has the attribute complex assigned to it and it can take one of the following values: -\"yes\", if the sentence contains more than one negative structure <neg structure> (1a). 1a. <sentence complex=\"yes\"> Sin embargo, <neg structure> las habitaciones no est\u00e1n cuidadas </neg structure>,hay manchas de humedad, techos desconchados, <neg structure> las TV no tienen mando a distancia </neg structure>, los suelos de los pasillos est\u00e1n levantados, necesita una remodelaci\u00f3n urgente! </sentence> 'However, the rooms are not well maintained, there are humidity stains, peeling ceilings, there is no TV remote control, the floors of the halls are raised, it needs urgent renovation!' -\"no\", if the sentence contains only one negative structure (2a). 2a. <sentence complex=\"no\"> <neg structure> No hay en la habitaci\u00f3n ni una triste hoja para ver qu\u00e9 hay para comer </neg structure> </sentence> 'The room does not have nor a sad sheet to see what's for lunch.' \u2022 <neg structure>. This label corresponds to a syntactic structure in which a negation marker or a negation cue occurs. It has 4 attributes assigned to it, and two of which (change and polarity modifier) are mutually exclusive (1b, 2b): -polarity: indicates the semantic orientation of the negative structure, i.e., whether it is \"positive\", \"negative\" or \"neutral\". -change: states whether the polarity or the meaning of the negative structure has been totally modified (change=\"yes\") or not (change=\"no\") because of the negation. -polarity modifier: indicates whether the negative structure contains an element that nuances its polarity. If there is an increment in the intensity of the polarity value it takes the value \"increment\" and, in contrast, if there is a diminishing of the polarity value it takes the value \"reduction\". -value: shows the meaning of the negative structure, that is to say, if it expresses negation (\"neg\"); if it indicates contrast or opposition between terms (\"contrast\"); if it expresses a comparison or inequality between terms (\"comp\") or if it does not negate (\"noneg\") despite containing a negation marker o cue. 1b. <sentencecomplex=\"yes\"> Sin embargo, <neg structure polarity=\"negative\" change=\"yes\" value=\"neg\"> las habitaciones no est\u00e1n cuidadas </neg structure>, hay manchas de humedad, techos desconchados, <neg structure polarity=\"negative\" change=\"yes\" value=\"neg\"> las TV no tienen mando a distancia </neg structure>, los suelos de los pasillos est\u00e1n levantados, necesita una remodelaci\u00f3n urgente! </sentence> 'However, the rooms are not well maintained, there are humidity stains, peeling ceilings, there is no TV remote control, the floors of the halls are raised, it needs urgent renovation!' 2b. <sentence complex=\"no\"> <neg structure polarity=\"negative\" polarity modifier=\"increment\" value=\"neg\"> No hay en la habitaci\u00f3n ni una triste hoja para ver qu\u00e9 hay para comer </neg structure> </sentence> 'The room does not have nor a sad sheet to see what's for lunch.' \u2022 <scope>. The label scope delimits the part of the negative structure that is within the scope of negation (1c, 2c). It includes both the negation marker or cue (<negexp>) and the event (<event>). \u2022 <negexp>. This label corresponds to the word(s) that express(es) negation (1c, 2c). It can have the attribute discid associated to it if negation is expressed by more than one negative element and they are discontinuous (2c). \u2022 <event>. The label event denotes the words that are directly affected by negation (usually verbs or adjectives) (1c, 2c). It is usually part of the scope, though it can also match the scope. 1c. <sentencecomplex=\"yes\"> Sin embargo, <neg structure polarity=\"negative\" change=\"yes\" value=\"neg\"> <scope> las habitaciones <negexp> no </negexp> <event> est\u00e1n cuidadas </event> </scope> </neg structure>, hay manchas de humedad, techos desconchados, <neg structure polarity=\"negative\" change=\"yes\" value=\"neg\"> <scope> las TV <negexp> no </negexp> <event> tienen </event> mando a distancia </scope> </neg structure>, los suelos de los pasillos est\u00e1n levantados, necesita una remodelaci\u00f3n urgente! </sentence> 'However, the rooms are not well maintained, there are humidity stains, peeling ceilings, there is no TV remote control, the floors of the halls are raised, it needs urgent renovation!' 2c. <sentence complex=\"no\"> <neg structure polarity=\"negative\" polarity modifier=\"increment\" value=\"neg\"> <scope> <negexp discid=\"1n\"> No </negexp> <event> hay </event> en la habitaci\u00f3n <negexp discid=\"1c\"> ni </negexp> una triste hoja </scope> para ver qu\u00e9 hay para comer </neg structure> </sentence> 'The room does not have nor a sad sheet to see what's for lunch.' Problematic cases Two types of annotations problems should be distinguished concerning negation: a) those that are related to the lack of agreement between the annotators, since what it is being annotated is complex: especially the scope, but also the event, and the discontinuities; and b) the problems arising from how the negation pattern is interpreted. These cases occur in constructions that are at the limit of what can be considered negation. They are semantic problems, i.e., problems involved in interpreting these constructions. In our typology, these cases mainly correspond to negation patterns in comparative and contrastive constructions. Disagreement cases The corpus was annotated by 4 annotators: two trained annotators who carried out the annotation task and two senior researchers with experience in corpus annotation who supervised the whole process. Firstly, a training phase was carried out in which 50 files were annotated in parallel by the trained annotators in order to refine the annotation guidelines. After that, a further 50 files were annotated individually by the same annotators to measure inter-annotator agreement with the aim of detecting and resolving problematic cases. A total of 528 negative structures were annotated and 49 cases of disagreement were found. An observed agreement of 90.72% corresponding to a kappa-score of 0.74 was observed in the inter-annotator agreement test. We then proceeded to annotate the whole corpus. We will now discuss the main sources of disagreement (Table 1 ). Most of the problematic cases (63.26%) were related to the scope of the negation and the event, though disagreements related to the value of the attributes of the <neg structure> label and to discontinuities were also observed. Below, we describe these cases with a representative example 2 : \u2022 Disagreements related to the scope of negation: 16 disagreements were due to the non-inclusion of the relative pronoun within the scope (3) . We decided to include the relative pronoun (the subject of the relative clause) in the scope, therefore in the SFU Review SP -NEG corpus the subject is always included within the scope when the word directly affected by negation is the verb of the sentence (3b): 3. (a) Una c\u00e1mara de fotos que <scope> no es una maravilla </scope> (b) Una c\u00e1mara de fotos <scope> que no es una maravilla </scope> 'A photo camera that is not so fantastic.' \u2022 Disagreements related to the event were mainly due to the treatment of verbal forms: pronominal verbs and light verbs. We observed a total of 15 cases. The problem with the pronominal verbs was the non-inclusion of the pronoun inside the event (4). In this case, we opted to include the pronoun inside the event (4b), since it is part of the verb: 4. (a) <negexp> No </negexp> <event> he podido resistir </event> me (b) <negexp> No </negexp> <event> he podido resistir me </event> 'I could not resist myself.' On the other hand, the problem with the light verbs arose from the incorrect identification of the lexicalized arguments. In (5) the argument una rallada ('a scratch') was incorrectly treated as a lexicalized form, whereas in (6) the opposite is the case: tan mal is part of the verbal form (the complete verbal form should be: dejar (tan) mal). 5. (a) <negexp discid=\"1n\"> No </negexp> <event> ten\u00eda <negexp discid=\"1c\"> ni </negexp> una rallada </event> (b) <negexp discid=\"1n\"> No </negexp> <event> ten\u00eda </event> <negexp discid=\"1c\"> ni </negexp> una rallada 'It did not have a single scratch.' 6. (a) <negexp> No </negexp> lo <event> dejar\u00e9 </event> tan mal (b) <negexp discid=\"1n\"> No </negexp> lo <event> dejar\u00e9 <negexp discid=\"1c\"> tan </negexp> mal </event> 'I will not leave him so badly.' \u2022 10 disagreements were found in the value of the attributes of the <neg structure> label. Most of them were related to the value of the attributes polarity and value. For instance, in (7) the negation structure was annotated as if it expressed negation (value=\"neg\"), whereas the correct value should be \"contrast\". In (8), the annotator forgot to assign the value of the attribute value to the negative structure. 7. (a) Los motorolas a m\u00ed <neg structure value= \"neg\" polarity=\"negative\"> no hacen m\u00e1s que darme problemas <neg structure> (b) Los motorolas a m\u00ed <neg structure value= \"contrast\" polarity=\"negative\"> no hacen m\u00e1s que darme problemas <neg structure> 'Motorolas (devices) have not given me anything but trouble.' 8. (a) <neg structure value=> no me puedo mover <neg structure> (b) <neg structure value=\"neg\"> no me puedo mover <neg structure> 'I can not move (about).' \u2022 Disagreements related to discontinuities were due to the non-identification of intensifiers ( 9 ) and diminishers (10). In both of the following examples, the annotator failed to identify the discontinuous negative expression, the intensifier para nada ('at all') and the diminisher del todo ('completely') were not annotated. 9. (a) <negexp> no </negexp> me <event> extra\u00f1a< /event> para nada los problemas que tiene (b) <negexp discid=\"1n\"> no </negexp> me <event> extra\u00f1a< /event> <negexp discid=\"1c\"> para nada </negexp> los problemas que tiene 'I am not surprised at all by the problems he is having.' think that the availability of corpora annotated at this level is essential for developing systems that take into account negation; consequently, a thorough analysis of this phenomenon is needed. Our future lines of research are related to using the corpus to develop a system to generate a model that uses the information annotated in it in order to automatically detect negation and its scope. Furthermore, we aim to create a lexicon of simple and complex negation markers. On the other hand, we also intend to demonstrate the importance of a corpus annotated with negation for Sentiment Analysis. Acknowledgements This work has been partially supported by a Grant from the Ministerio de Educaci\u00f3n, Cultura y Deporte (MECD -scholarship FPU014/00983), Fondo Europeo de Desarrollo Regional (FEDER) and REDES project (TIN2015-65136-C2-1-R) from the Ministerio de Econom\u00eda y Competitividad. We would like to thank Maite Taboada and her team for sharing the useful SFU resource with the research community. Conclusions and further work In this work we have presented the main sources of disagreement detected during the annotation with negation of the Spanish SFU Review Corpus. We hope this will help in future annotations of this phenomenon. We have also briefly presented the annotation scheme that we defined for the annotation. We"
}