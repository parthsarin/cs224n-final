{
    "article": "This paper presents a supervised method for resolving metonymies. We enhance a commonly used feature set with features extracted based on collocation information from corpora, generalized using lexical and encyclopedic knowledge to determine the preferred sense of the potentially metonymic word using methods from unsupervised word sense disambiguation. The methodology developed addresses one issue related to metonymy resolution -the influence of local context. The method developed is applied to the metonymy resolution task from SemEval 2007. The results obtained, higher for the countries subtask, on a par for the companies subtask -compared to participating systems -confirm that lexical, encyclopedic and collocation information can be successfully combined for metonymy resolution. Introduction Metonymies are a pervasive phenomenon in language. They occur because in communicating, we use words as pointers to a larger body of knowledge, that encompasses various facets of the concept evoked by a given word. A listener need not understand the cello to be moved by its playing, just as it is unnecessary for a rider to understand technical jargon; all that matters is sensation, and here the Kawasaki excels. The cockpit is sensibly designed, with a narrow front seat portion ... Kawasaki is a company, it has an organization, facilities, employees, it makes specific products. In the context above, the company name stands in for its products -motorcycles. Motorcycles have parts, the cockpit and front seat are some of them, and this provides the discourse links between the two sentences. Constraints on the interpretation of a word w in context comes both from the local and global context, and are applied to the information/knowledge evoked by w. The local constraints come from the words with which w is (grammatically) related to. The global constraints come from the domain/topic of the text, discourse relations that span across sentences. Metonymic words have a rather small number of possible interpretations (also called readings) which occur frequently (Markert and Nissim, 2002) . Idiosyncratic interpretations are also possible, but very rare. One can view the possible interpretations of a potentially metonymic word (PMW) as corresponding to the word's possible senses (Nissim and Markert, 2003) , bringing the task close to word sense disambiguation. The approach to metonymy resolution presented here is supervised, with unsupervised feature enrichment. We apply techniques inspired by unsupervised word sense disambiguation, which allow us to go beyond the annotated data provided in training, and quantify the restrictions imposed on the interpretation of a PMW by its grammatically related neighbours through collocation information extracted from corpora. The only annotation required for the corpora are automatically induced part-of-speech tags from which we obtain grammatical relations through regular expression matching over sequences of parts-of-speech. Collocation information is combined with lexical resources -WordNet -and encyclopedic knowledge extracted from Wikipedia to help us generalize the collocations found to determine higher level constraints on a word's grammatical collocates. In the example above, Kawasaki is grammatically related to the verb excel -it is its subject. To determine the most likely interpretation of Kawasaki given that it is in the subject relation with excel we look at all the nouns in the corpora that appear as this verb's subjects, and estimate from this the preferences excel has for its subjects. Let us say the corpus contains the following collocations in subject position (with frequency information in parentheses): player (4), musician (50), car (30), computer (12), camera (40), driver (55), bike (20) .... The knowledge resources -WordNet, isa relations extracted from Wikipedia -will help generalize these collocations: player, musician, driver to person and car, computer, camera, bike to artifact. This together with frequency of occurrence are used to estimate the probability that the verb excel takes a person or artifact-type subject. These are excel's selectional preferences towards certain collocates, and will help determine which possible interpretation for the PMW Kawasaki is appropriate in this contextorganization-for-people or organization-for-product. The paper continues with related work in Section 2 and the description of the data in Section 3. The representation used is introduced in Section 4. The results and the discussion are presented in Section 5. The paper wraps up with conclusions and future work. Related Work Analysis of metonymies as a linguistic phenomenon dates back at least to the 1930s (Stern, 1931) , and are increasingly recognized as an important phenomenon to tackle in the interest of higher level language processing tasks, such as anaphora resolution (Harabagiu, 1998; Markert and Hahn, 2002) , question answering (Stallard, 1993) or machine translation (Kamei and Wakao, 1992) . Until the early 90s, the main view about metonymies was that they violate semantic constraints in their immediate context. To resolve metonymies then amounts to detecting violated constraints, usually from those imposed by the verbs on their arguments (Pustejovsky, 1991; Hobbs et al., 1993; Fass, 1991) . Markert and Hahn (2002) showed that this approach misses metonymies which do not violate selectional restrictions. In this case referential cohesion relations may indicate that the literal reading is not appropriate and give clues about the intended metonymic interpretation. Markert and Nissim (2003) have combined observations from the linguistic analysis of metonymies with results of corpus studies. Linguistic research has postulated that (i) conven-tional metonymic readings are very systematic; (ii) unconventional metonymies can be created on the fly and their interpretation is context dependent; (iii) metonymies are frequent. The fact that most metonymic interpretations are systematic and correspond to a small set of possible readings allow the metonymy resolution to be modelled as a classifier learning task. Markert and Nissim (2002) and Nissim and Markert (2003) have shown that conventional metonymies can be effectively resolved using a supervised machine learning approach. Moreover, grammatically related words are crucial in determining the interpretation of a PMW. The shortcoming is that manually annotated data is in short supply, and the approach suffers from data sparseness. To address this problem, Nissim and Markert (2003) proposed a word similarity-based method. They use Lin's thesaurus (Lin, 1998) to determine how close two lexical heads are, and use this instead of the more restrictive identity constraint when comparing two instances. This technique is complex, requiring smoothing, multiple iterations over the thesaurus and hybrid methods to allow a back-off to grammatical roles. The supervised approach to resolving metonymies was encouraged by the metonymy resolution task at the semantic evaluation exercise SemEval 2007 (Markert and Nissim, 2007) . The participating systems in this task were varied. Most of them (four out of five) have used supervised machine learning techniques. The systems that beat the baseline used either the grammatical annotations provided by the organizers (Farkas et al., 2007; Nicolae et al., 2007) , or a robust and deep (not freely available) parser (Brun et al., 2007) . These systems represented instances in a manner similar to (Nissim and Markert, 2005) . They used additional manually built resources -WordNet, FrameNet, Levin's verb classes, manually built lists of \"trigger\" words -to generalize the existing features. Brun et al. (2007) also used the British National Corpus (BNC) for computing the distance between words based on their syntactic distribution. While lexical resources and corpora are used to estimate word similarity, all these systems rely exclusively on the data provided by the organizers -instance representation captures only information that can be derived from or between the data points provided. The approach presented here goes beyond the given data, and induces from corpora measures that allow the system to determine what are the preferences of the words surrounding a PMW towards each of PMW's possible readings. The technique employed is adapted from unsupervised word sense disambiguation (WSD). In short, we use the local grammatical context as it is commonly used in WSD approaches, to guide the system in choosing the reading that fits best. The benefits of using grammatical information for automatic WSD were first explored by Yarowsky (1995) and Resnik (1996) in unsupervised approaches to disambiguating single words in context. The method described here uses automatically induced selectional preferences, computed from sense-untagged data, similar to Nastase (2008) . Data We work with the data from the metonymy resolution task at SemEval 2007 (Markert and Nissim, 2007) , generated based on a scheme developed by Markert and Nissim (2003) . The metonymy resolution task at SemEval 2007 consisted of two subtasks -one for resolving country names, the other for companies. For each subtask there is a training and a test portion. Figure 1 shows the text fragment for one sample, and Table 1 the data statistics. The reading column shows the possible interpretations of a PMW for countries and companies respectively. For example, org-for-product would be the interpretation of the PMW Kawasaki in the example shown in the introduction. Occurrences of country and company names were annotated with a small number of possible readings, as shown in Table 1 . This reflects previous analyses of the metonymy phenomenon, which showed that there is a rather small number of possible interpretations that appear more frequently (Markert and Nissim, 2002) . Special interpretations are very rarely encountered. Within the framework of the SemEval task, metonymy resolution is evaluated on the given test data, on three levels of granularity: coarse -distinguish between literal and non-literal readings; medium -distinguish between literal, mixed and non-literal readings; fine -identify the specific reading of the target word/words (potentially metonymic word -PMW). Representation The method presented in this paper is a supervised learning method, along the same general lines as As such, it represents each PMW in the data through features that describe its context and some semantic characteristics. The minimum set of necessary features is taken to be that presented by Nissim and Markert (2005) , and proved to be effective in solving metonymies. These are the M&N features (Markert and Nissim features). We expand on these features and estimate preferences from words in a PMW's context towards specific PMW interpretations. These constitute the selectional preference features. Finally, Wikipedia is a source of facts which can be used to derive information that can bias the decision towards certain interpretations for a PMW. Each of these features are described in more detail in the following subsections. M&N features The features used by Nissim and Markert (2005) are: \u2022 grammatical role of PMW (subj, obj, ...); \u2022 lemmatized head/modifier of PMW (announce, say, ...); POS tags <bnc:s id=\"samp114-bncCNJ-s341\"> ... <bnc:w id=\"samp114-bncCNJ-s343-w29\" bnc:type=\"NN0\"> team </bnc:w> <bnc:w id=\"samp114-bncCNJ-s343-w30\" bnc:type=\"PRF\"> of </bnc:w> <annot> <org reading=\"literal\"> <bnc:w possmeto=\"yes\" id=\"samp114-bncCNJ-s343-w31\" bnc:type=\"NP0\"> IBM </bnc:w> </org> </annot> <bnc:w id=\"samp114-bncCNJ-s343-w32\" bnc:type=\"NN2\"> researchers </bnc:w> ... \u2022 number of grammatical roles in which the PMW appears in its current context; \u2022 number of words in PMW; All these features can be extracted from the grammatically annotated and POS tagged data provided by the organizers. Selectional preference features The grammatical relations and the connected words are important to describe the local context of the target PMW. Because of the limited amount of annotated data (a few thousand instances), lemmas of PMW's grammatically related words will make for very sparse data that a machine learning system would not be able to generalize over. Nissim and Markert (2003) and the teams participating in the metonymy resolution task have then supplemented their systems with Lin's thesaurus, WordNet, Beth Levin's verb groups, FrameNet information, or manually designed lists of words to generalize the grammatically related words and thus find shared characteristics across instances of metonymies in text. The notion of selectional restrictions used in metonymy resolution -meaning the restrictions imposed on the interpretation of a PMW by its context -is similar to the notion of selectional preferences from word sense disambiguationmeaning the preferences of a word for the senses of the words in its context. We import this notion, and compute selectional preferences for the words in a PMW's (grammatical) neighbourhood, and allow them to influence the chosen reading for the PMW. Applying methods from unsupervised WSD allow us to estimate such preferences from (sense/metonymy) untagged corpora. A potentially metonymic word (or phrase) has a small number of possible readings. These can be viewed as possible senses, and the task is to choose the one that fits best in the given context. The preference for each possible sense can be determined based on the PMW's grammatically related words. To estimate these sense preferences we use grammatical collocations extracted from the British National Corpus (BNC), detected using regular expression matching over sequences of POS using the Word Sketch Engine (Kilgarriff et al., 2004) . The scores are computed following a technique similar to Nastase (2008) , which is illustrated using the following example: The Kawasaki drives well, steers brilliantly both under power and in tight corners ... The target whose interpretation must be determined is Kawasaki. If for a potentially metonymic word representing a company name, there are the following possible interpretations: company, member/person, product/artifact, facility, name, we compute the preference for each of these interpretations based on the extracted collocations. For the verb drive for example, the collocations engine, car, taxi, truck are all artifacts (according to WordNet), and thus vote for the product/artifact reading, while chauffeur, motorist, man are all person, and vote for the member/person reading. Preferences from different grammatical relation for the same PMW are summed. The Formally, we choose the PMWs' \"senses\"a set of words which are close to the possible readings of metonymic words in the data. In this work, these senses are the WordNet 3.0 supersenses: S = { act, animal, artifact, attribute, body, cognition, communication, event, feeling, food, group, location, motive, object, person, phenomenon, plant, possession, process, quantity, relation, shape, state, substance, time }. Because none of these can be seen as a sense for \"company\", the list is supplemented with company and organization. Granted, there is no 1:1 mapping from these supersenses to PMW readings, but find such a strict correspondence is not necessary because the context preferences for each of these senses are used as features, and the mapping to PMW readings is found through a supervised learned model. To compute the preference of a word w in the grammatical context of a PMW t (the target) towards each of t's possible senses, we consider each relation (w, R, t), where R is the grammatical relation. The set C of word collocations are extracted from the BNC C = {(w, R, w j : f j )|(w, R, w j ) \u2208 BN C, f j is the frequency of occurrence} and used to compute a preference score P s i for each sense s i \u2208 S: P s i = (w,R,w i,j :f i,j )\u2208Cs i f i,j (w,R,w j :f j )\u2208C f j where C s i = {(w, R, w j : f j )|(w, R, w j : f j ) \u2208 C; supersense(w j , s i ) isa(w j , s i )}. supersense(w j , s i ) is true if s i is a supersense of one of w j 's senses; isa(w j , s i ) is true if s i is a hypernym of one of w j 's senses in WordNet, or is a fact extracted from Wikipedia. To determine the supersense and isa relation we use WordNet 3.0, and a set of 7,578,112 isa relations extracted by processing the page and category network of Wikipedia 1 (Nastase and Strube, 2008) . The collocations extracted from BNC contain numerous named entities, most of which are not part of WordNet. If an isa relation between a collocate from the corpus w j and a possible sense of a PMW s i cannot be established using supersense information (for the supersenses) or through transitive closure in the hypernymhyponym hierarchy in WordNet (for company and organization) for any sense of w j , it is tried against the Wikipedia-based links. This process transforms the grammatical annotation file and enhances it with the collocation estimates, as shown in Table 2 (compare this with a sample of the original file presented in Figure 1 ). Farkas et al. (2007) observed that using the PMWs themselves as features leads to improvement on determining the reading for organization names, and postulate that this is because some company names are more likely to be used in a metonymic way. This is often the case with companies that make products which are commonly used (cars, for example). Brun et al. (2007) note that certain locations, such as Vietnam, are more likely to be used with an event reading than others locations. Generally, locations strongly associated with events tend to be used to refer to the event, and more often have a place-for-event interpretation rather than a literal one. Product and event features These two observations have lead us to mine for these pieces of information in the Wikipedia relations, and to add two more features for a target PMW: has-product will take a value of 1 if any of the PMW's hypernyms (according to the isa relations extracted from Wikipedia) contains the string manufacturer, will have the value 0 otherwise; has-event will have the value 1 if any of the PMW's hypernyms refers to an event (movements/operations/riots), and value 0 otherwise. Data representation As mentioned before, the representation built can be seen as consisting of roughly three subsets of features: \u2022 the M&N features proposed by Nissim and Markert (2005) . To combine the grammatical information from all relations, we transform the grammatical relations into features (as opposed to values). For a relation subject for example, we generate a binary subject feature that indicates whether for a given target this grammatical relation is filled or not, and a subject lemma feature , whose value is the lemma of the grammatically related word. \u2022 the selectional preference scores. Each of these features corresponds to one of the elements of S, presented above. These features combine the selectional preferences of all the grammatical relations for one target PMW. \u2022 product and event information from Wikipedia -has-product and has-event. The grammatical annotation file consists of one entry for each grammatical relation in which a PMW appears. For the final representation, information about all relations of a given PMW is compressed into one instance. Because the basic features were binarized, and instead of having one grammatical role feature now each possible grammatical relation has its own feature, combining several entries for one PMW is easy, as it only implies setting the correct value for the grammatical relations that are valid in the PMWs context. The final representation consists of 63 features + class feature for the subset for company PMWs, 59 features + class feature for the subset containing countries PMWs. The sample ID and the PMW itself were not part of this representation. Results The models for determining a PMW's correct interpretation are learned on the training data provided, and evaluated on the test portion, using the answer keys and evaluation script provided with the data. For learning the models we use Weka (Witten and Frank, 2005) , and select the final learning algorithms based on 10-fold crossvalidation on the training data. We have settled on support vector machines (SMO in Weka), and we use the learner's default settings. Tables 3 and Table 4 show the results obtained, and the baseline and the best results from the Sem-Eval task for comparison (Markert and Nissim, 2007) . The baseline in Table 3 corresponds to classifying everything as the most frequent class -literal interpretation. The M&N feat. and M&N feat.bin. correspond to datasets that contain only the M&N features and the binarized versions of these features, respectively. SemEval best gives the best results obtained on each task in the SemEval 2007 task (Markert and Nissim, 2007) . SM O wiki are the results obtained with the complete feature set described in Section 4, and SM O SP are the results obtained when only the new features are used -only selectional preference, has-product and has-event features ( (Markert and Nissim, 2007) . The SM O column shows the results of learning when Wikipedia information is not used to compute the values of the collocation, has-product and has-event features. Nissim and Markert (2003) have shown that grammatical roles are very strong features. Experiments on the data represented exclusively through grammatical role features confirm this observation, as the results obtained using only the syntactic features (no lexical head information) give the same results as the M&N feat.bin. which does include lexical information. On the location metonymies, the current approach performs better on all evaluation types (coarse, medium, fine) by 0.9, 1.1 and 0.9% points respectively. The improvement comes from recognizing better the metonymic readings, as it is apparent from the detailed F-score results in Table 4. For the coarse readings, the F-score for the non-literal reading is 1.5% points higher than the best performance at SemEval, and 2.5% and 7.7% points respectively for the metonymic and mixed readings for the medium and fine coarseness. It is interesting that the learning is quite successful even when only selectional preference and Wikipedia-based has-product and hasevent features are used -the SM O SP column in Table 3 . The grammatical role and the related lemma were used to derive these collocation features, but they do not appear as such in the representation used for this batch of experiments. For company metonymies the current approach does not perform better than the state-of-the-art. For these metonymies the syntactic information is not as useful. This is evidenced by the lower performance of the classifier that uses only syntactic information (column M&N feat.bin. in Table 3 ), despite the fact that the training dataset for com-panies is larger than the one for countries. This observation is further supported by the low results when using only selectional preference features. It indicates that for company metonymies the local context does not provide as strong clues as it does for locations. For such PMWs we should explore the larger context. We have made a start with the Wikipedia-based features built following the observation about companies and their products made by Farkas et al. (2007) and Brun et al. (2007) . In future work we plan to analyse this matter further, and find a method to derive more such features, and without manually provided clues (such as manufacturer or riots). Wikipedia derived information does not contribute very much, but as expected it is helpful to identify other classes than the literal one. It is helpful to detect the mixed class -16% F-score when using Wikipedia information compared to 8.7% for the countries data when we estimate preferences using only WordNet. It also increases the performance on the non-literal, metonymic and org-for-members classes in coarse, medium and fine classification respectively for both countries and companies. There is a small improvement for recognizing the org-for-product reading for organizations when using Wikipedia-based features. It is an indication that the has-product feature is useful. We cannot draw conclusions about the has-event feature, as there are only 3 training instances for the place-for-event reading. The results are encouraging, as we have just scraped the surface of the information that Wikipedia can provide. The corpus derived selectional preferences perform very well, especially for determining the reading of locations. Analysis of the data and the features gives some indication as to why this happens: in the grammatical annotations provided, when the PMW is a prepositional complement or has a prepositional complement, the grammatically related word is a preposition. We extract only grammatical collocations for open-class words, restricted by the grammatical relation of interest, so we do not extract collocations for prepositions. Location prepositions (in, at, from) are less ambiguous than others (e.g. for), which are more common for the organization data. We have attempted to bypass this problem by generating parses using the dependency output of the Stanford Parser (de Marneffe et al., 2006) , and bypassing the preposition -incorporate it in the grammatical role (pp in, for example), and using as lemma the head of the prepositional complement or the constituent which dominates the prepositional phrase, depending on the position of the PMW. Now we can use the grammatical relation and the associated open-class word to look for collocations. This approach did not lead to good results, because the quality of the automatic parses is far from the manually provided information. Conclusions We have explored the use of selectional preference scores derived from a sense untagged corpus as local constrains for determining the interpretation of potentially metonymic words. Such methods were previously successfully used for word sense disambiguation, and transfer nicely to the metonymy resolution task. Adding encyclopedic knowledge to the mix improved the results further, by filling in gaps for WordNet, and extracting information particular to PMW. We plan to expand on this, and find methods to extract more such features automatically, without manually provided clues. For a more comprehensive treatment of metonymies one must take into consideration not only local context but also discourse relations. A possible avenue of research is to build upon coreference resolution systems, and use the mentions they detect and link to each other in a manner similar to using grammatical information and grammatically related words to determine constraints from a larger context. Determining the link between two mentions in a text can take advantage of encyclopedic knowledge, and the system's ability to infer the connection between the mentions. There is much work on unsupervised word sense disambiguation. Working with untagged data gives a system access to a much larger information base. Since selectional preferences acquired from sense-untagged corpora have worked well for the metonymy resolution task, we plan to push further towards unsupervised metonymy resolution, putting to use the lessons learned from unsupervised WSD. Acknowledgements We thank the Klaus Tschira Foundation, Heidelberg, for financial support, and the organizers of the SemEval-2007 Task #8 Metonymy Resolution -Katja Markert and Malvina Nissim -for making the annotated data freely available."
}